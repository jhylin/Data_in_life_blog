[
  {
    "objectID": "posts/Blog-Portfolio_projects/Portfolio_projects.html",
    "href": "posts/Blog-Portfolio_projects/Portfolio_projects.html",
    "title": "Portfolio projects",
    "section": "",
    "text": "To keep myself somewhat occupied, I’m still working on the Tableau project at the moment (while I’m working towards the end of a Tableau course) and have then added two further projects – one a Python one about rare disease drugs and the other one using SQL. I’ve just completed and published the Python one (please see Portfolio section for details) and within this week I’m aiming to start the SQL project. This time I’ll not be using IBM Db2 or SQLite, which was what I’ve used for the course but rather I’ve managed to install MySQL server and also DBeaver GUI to work on the SQL project. The dataset is still to be decided as I sort of want to integrate the SQL one with Tableau and the latest Python project. I’ll have another look again…\n\n\n\nPhoto by Joanna Kosinska on Unsplash"
  },
  {
    "objectID": "posts/03_Long_COVID_data_in_SQL/Long_COVID_SQL.html",
    "href": "posts/03_Long_COVID_data_in_SQL/Long_COVID_SQL.html",
    "title": "Long COVID data in SQL",
    "section": "",
    "text": "Introduction\nFor this SQL project1, I’ve used the same set of data as the Tableau project in order to see if there will be any other new insights when using SQL for data analysis. Dataset is from this paper – Michelen M, Manoharan L, Elkheir N, et al. Characterising long COVID: a living systematic review. BMJ Global Health 2021;6:e005427, which was discovered through PubMed. One other thing of note was that the paper only collected long COVID-related data up until 17th March 2021. All other more recent developments of long COVID will likely require more time before further data are more readily available, for example, the long COVID impact from Omicron variants.\n Image: Rawpixel.com\n\n\nThe process\nMySQL server was installed with DBeaver used as the GUI. Four tables (Continents, Countries, Risk factors and Hospitalisation) in .csv file formats were imported into the newly created database named LongCovid. A series of SQL queries were written and performed. Two views were created so that selected data were stored for future use, such as for data visualisations in Tableau.\n\n\nProject link\nSQL file can be found in my GitHub repository of Portfolio-projects at this URL: https://github.com/jhylin/Portfolio-projects or directly here to view.\n\n\n\n\n\nFootnotes\n\n\nThe published date reflected the most recent date I worked on associated file with the project, prior to the blog move. This work is under CC BY-SA 4.0 International License for anyone interested in exploring the area further.↩︎"
  },
  {
    "objectID": "posts/PhD_projects/PhD_projects.html",
    "href": "posts/PhD_projects/PhD_projects.html",
    "title": "PhD project",
    "section": "",
    "text": "The projects\nMy PhD12 started about 6 months after I’ve finished my MPhil so it was around the beginning of 2015 that I’ve officially begun my PhD and it took a solid 4 years to finish (while working part-time as a hospital pharmacist). In simple words, there were two main research projects going on concurrently in my PhD:\n\nSERCA project (details in a separate post as named)\nFilamenting temperature-sensitive Z protein project (also known as FtsZ project)\n\nFtsZ project was not a new project at the time, but rather a continuation from my previous predecessors in the lab group. Its primary focus was to look for other novel anti-bacterial hit compounds that were different from the ones that were already synthesised and tested in the group. This project was better than the SERCA project in a way that the collaborators were much easier to communicate with even though they were based in India. One down side was that because they’re based overseas, it did take a long time for the compound testing to happen and to have the results returned on time. However, overall, there were much more progress in this project which involved 3 main iterative stages:\nComputational work – involved molecular/homology modelling, virtual compound screening (compound size roughly in several 100,000s, please see below links for details) and compound selection for synthesis (using Schrödinger software mainly for this first stage of work)\nCompound synthesis – this was certainly the part that has painstakingly taken a lot of time in a chemistry lab out of my four years with many failures in between but with some successes in the end obviously…\nCompound testing – it was mainly done by our research collaborators After the completion of these two projects, I was less of a research newbie but I would still humbly call myself a junior researcher, considering how the field of drug discovery can have such an unfathomable depth and breadth…\n\n\n\nImage taken by author\n\n\nThe image above was taken literally when I packed up everything after I’ve completed my PhD, which was physically summed into this little box, but what I’ve gained from the journey was far bigger than this. The two hardcover books on the left hand side were my MPhil and PhD theses (potentially useful as treatment for insomnia due to their lengths and time required to read).\n\n\nPhD thesis link\nPlease visit http://hdl.handle.net/2123/20236 if anyone is even remotely wanting to read the full thesis, for completeness, here it is (beware: very long).\n\n\nAbstract of the projects\nDrug discovery is one of the most challenging research fields that contributes to the birth of novel drugs for therapeutic use. Due to the complexity and intricate nature of the research, lengthy processes are involved in identifying potential hit molecules for a therapeutic target. To shorten the time required to reach the hit-to-lead stage, computer-aided drug design (CADD) has been used to expedite the process and reduce laboratory expenses. Common strategies used within CADD involve structure-based drug design (SBDD) and ligand-based drug design (LBDD). Both strategies were used extensively in two projects showing the complementarity of each strategy throughout the process. In this work, two separate drug discovery projects are detailed: Design, synthesis and molecular docking study of novel tetrahydrocurcumin analogues as potential sarcoplasmic-endoplasmic reticulum calcium ATPases (SERCA) inhibitors – details the identification, synthesis and testing of potential hit candidate(s) targeting SERCA by using SBDD Filamenting temperature-sensitive mutant Z (FtsZ) as therapeutic target in ligand-based drug design – details the identification, synthesis and testing of potential hit molecule(s) targeting FtsZ In the first project, homology modelling and virtual compound library screening were utilised as the SBDD methods to identify potential hit molecules for testing in P-type calcium ATPases such as SERCA. Preliminary results have found compound 20, an analogue of tetrahydrocurcumin, to show some SERCA inhibitory effect at 300µM based on a SERCA-specific calcium signalling assay performed via fluorometric imaging plate reader. Molecular docking study has also reflected this outcome with desirable ligand-protein binding energies found for 20 when compared with other tested ligands. Pharmacophore screening was used as the main LBDD method in the second project to identify probable hit candidates targeting FtsZ. Potential ligands were synthesised, and tested for antibacterial effect in Bacillus Subtilis strain 168 (Bs168) and Streptococcus pneumoniae strain R6 (SpnR6) cells. One of the tetrahydrocurcumin analogues, compound 4, was found to have minimum inhibitory concentration (MIC) ≤ 10 µM in Bs168 cells and ≤ 2 µM in spnR6 cells. The IC50 values for 4 were 9.1 ± 0.01 µM and 1 ± 0.01 µM in Bs168 and SpnR6 cells respectively. The MIC of 4 was found to be very similar to the MIC of compound 1, a known hit compound targeting against Bs168 cells. On the other hand, the MIC of 4 was lower than the MIC (> 64 µg/mL) of a well-known FtsZ inhibitor, PC190723, against S. pneumoniae. Subsequent molecular docking analyses were completed to evaluate the ligand-protein binding energies to correlate against the testing results. Both compounds 20 and 4 possess some structural similarities and differences that may confer their different effects in these protein targets, which render both with potentials to become the next lead molecules for future development.\n\n\nFinal update on FtsZ project\nAs time was ticking along towards the end of 2022, my last attempt to try to get this work published occurred around end of August, where I contacted one of my previous PhD advisers. After that I actually thought there was no way I could carry on in this line of research work, or even think about expanding into cheminformatics for drug discovery and design etc. So in September, I thought about leaving all of this behind and that I need to change direction completely (again), e.g. into health data science or similar. Perhaps it was the universe’s answering or for other unknown reasons, around end of September, an email was sent to me from my previous PhD adviser asking for my help to organise the draft manuscript into the journal template that we were intending to submit. Then in early October, I got another email saying our manuscript was submitted. Then it seemed things started to roll again, after 2019. So this was, indeed, a perfect example showing how a piece of research work was stalled, not only by the commonly known reasons such as delays from collaborating groups, but also by the global-scale pandemic and finally somehow, miraculously, made it to the publication stage.\nIf anyone asked me if I wanted to go through this again, I would firmly say no as it was mentally painful, but on the other hand, I’ve also gained invaluable things like grit and resilience throughout the process. This has, without doubts, influenced on how I want to approach similar research again, which will be in a different way, in a more data-informed way.\n\n\nPublished paper link\nThis will complete the story for the FtsZ project (finally): Discovery of 2′,6-Bis(4-hydroxybenzyl)-2-acetylcyclohexanone, a Novel FtsZ Inhibitor\n\n\n\n\n\nFootnotes\n\n\nI’ve attempted to communicate with both of my PhD advisers and our research collaborators to publish this work, but to no avail due to the severe restrictions imposed by the COVID-19 situation from the beginning of 2020 and basically also in 2021 (our collaborators were unable to perform any experiments during lockdowns…), a direct publication in a scientific journal is not going to happen any time soon so I thought to provide at least my part to showcase what I’ve done at least…↩︎\nUpdates on 31/1/2022 – it appeared that my supervisors are in communications with our overseas research collaborators recently about the manuscript so there is a higher chance now that we may be able to publish this work towards the end of 2022 (fingers-crossed…).↩︎"
  },
  {
    "objectID": "posts/15_Molviz/Molviz.html",
    "href": "posts/15_Molviz/Molviz.html",
    "title": "Molecular visualisation (Molviz) web application",
    "section": "",
    "text": "The final deployed app is on Shinyapps.io:\n\nLink: here or please visit https://jhylin.shinyapps.io/molviz_app/\nCode: here or please visit https://github.com/jhylin/Molviz_app\n\n\n\nBackground - how the app started\nOriginally I had an idea of incorporating mols2grid library within Shiny for Python web app framework (after seeing an example of a similar app in Streamlit previously). So I worked on a few ideas, but obviously mols2grid was designed to work inside Jupyter Notebook/Lab and Shiny for Python was only out of alpha at that stage so things were still being developed. After a few trials, unfortunately mols2grid wasn’t directly compatible with the Shiny for Python framework at that time (I even wrote a small story about it as a comment to an issue).\nI then went away to work on another project on molecular scaffolds and left this mini project aside. However, recently I had another idea of trying to build a Shiny for Python app from the scratch (with a focus on cheminformatics or chemical information), so that users in relevant fields can view and save 2D images of small molecules in a web browser environment instead of only inside a Jupyter Notebook/Lab. I also thought to place the Shiny for Python framework to test if it was being used in a more intensive area such as chemistry and drug discovery.\nAnother reason that have triggered this side project was that I came across a comment from an old RDKit blog post from someone asking about how to save compound image as a PNG1 file, since SVG2 version was hard to convert etc. (or something along that line). I thought it should be possible, and this should not be only limited to Jupyter environments only (thinking of people not doing coding at all…), so here we are.\n\n\n\nAbout each version of the app\nI’ll try to explain what each version of the app_x.py script entails, as there are currently several different versions of them inside the repository. The final version is the one called “app.py”, named this way so that it’ll be recognised by rsconnect/Shinyapps.io when deploying the app. By providing some explanations below should also show that it was quite a process to arrive at the final “app.py”, it wasn’t built within a day for sure (at least for me).\n\n\napp_molviz_v1.py\nThis was the first version that purely provided the ability to show 2D images of the molecules via selecting their corresponding index numbers. The libraries used appeared less aligned and a few tests were run below (some of them commented out during trials). This was the one that I’ve figured out how to make the image appeared in the app.\n\n\n\napp_molviz_v2.py\nFor the second version, I started thinking about how I would present the app in a simple layout for the end users. The backbone code to support image generations was by using rdkit.Chem.Draw package’s MolToImage() module, which normally returns a PIL3 image object, and also supports atom and bond highlighting. Another useful module that I’ve tried was MolToFile() within the same package, which would generate and save a PNG file for a specified molecule from the dataframe.\nI then took a bit more time to familiarise myself with some basic PIL image manipulations, and used online resources to formulate code to merge separate PNG images into one table grid-like image - potentially may be useful for substructural or R-group comparisons.\nI have also added the interactive data table at the end to see how it would fit in with the rest of the app.\n\n\n\napp_molviz_v3.py\nThe third version mainly dealt with how to segregate and differentiate between highlighting or non-highlighting and also with or without index numbers showing for the compounds in the images. I’ve tried to use a different code for atom labelling this time with thanks to this link. However, there was always an issue of not being able to flip back from with index to without index, since the atom labelling code itself somehow overflows its effect to the rest after labelling the atom indices (presumably this atom labelling code would work great in a Jupyter notebook scenario).\n\n\n\napp_molviz_v4.py & app_molviz_v5.py\nBoth version 4 and 5 were where I’ve tested using “atomNote” (numbers appear beside atoms) instead of “atomLabel” (numbers replaces atoms directly in structures) to label atoms in molecular structures.\nAn example of the atom labelling code would look like this (replace ‘atomNote’ with ‘atomLabel’ to get different labelling effect):\n```{python}\nfor atom in mols[input.mol()].GetAtoms():\n  atom.SetProp('atomNote', str(atom.GetIdx()))\n```\nI’ve also started adding introductory texts for the app and edited the layout a bit more.\n\n\n\napp_molviz_v6_hf.py\nThis was basically the final version of the app, but with code edited to attempt to deploy the app on HuggingFace. The main difference I was testing was on how to store the saved images as Docker was new to me at the time, and then while I was thinking about changing the Dockerfile, there was actually another problem in relation to the cairosvg code. Because of this, I then placed this deployment on hold in order to buy more time to figure out code, and also to try Shinyapps.io to see if this could be deployed.\n\n\n\napp_molviz_v6.py or app.py\nThis was the last version and was the version used to deploy the app on Shinyapps.io. I had to rename the file as mentioned previously to “app.py” so that the Shinyapps.io servers would recognise this Python script as the script to run the app (otherwise it wouldn’t be deployed successfully, this took me a few tries and to read the log file to figure this out). So it was saved as a separate file, and for any latest text changes in the app I would refer to app.py as the most current app file.\nThe biggest code change was that I ended up not using the MolToImage() or MolToFile() modules, but rather I used rdMolDraw2D module from rdkit.Chem.Draw package. The reason being I’ve noticed the image resolutions weren’t great for the previously used modules (Jupyter notebook environments should not have this problem, as you could simply switch on this line of code by setting it to true like this, IPythonConsole.ipython_useSVG = True). So I resorted to other means and came across this useful link to generate images with better resolutions, and introduced the cairosvg library.\nSo the code was changed and would now use rdMolDraw2D.MolDraw2DSVG() first and add on addAtomIndices from drawOptions() and also DrawMolecule() to highlight substructures. The SVG generated would then be converted to PNG via cairosvg library. The end result produced slightly better image resolutions. Although I’ve found for more structurally complexed molecules, the image size would really need to be quite large to be in the high resolution zone. For compounds with simpler structures, this seemed to be much less of a problem. This was also why I had to have these PNG images blown up this large in the app, to cater for the image resolution aspect.\n\n\n\n\nOther files\n\ncode_test.py\nI’m not exactly sure how other data scientists/developers work, but for me since I came from a completely different background and training, I’m used to plan, set up and do experiments to test things I’d like to try, and see where the results will lead me to. So for this in a virtual computer setting, I used the “code_tests.py” to test a lot of different code.\nIf you go into this file, you’ll likely see a lot of RDKit code trials, and I have had a lot of fun doing this since I got to see results straight away when running the code, and learn new code and functions that way. If the end result was not the one I’ve intended, I would go on short journeys to look for answers (surprisingly I didn’t use any generative AI chatbots actually), it would be chosen intuitively as I searched online, but for this particular project, a lot of it was from past RDKit blogs, StackOverflow and random snippets I came across that have given me ideas about solving issues I came across.\n\n\n\napp_table.py & app_itables.py\nThese two files were trials for incorporating dataframe inside a web app. The difference was that app_table.py was just a data table sitting inside the app, without any other particular features, while app_itables.py utilised a different package called itables, which provided an interactive feature to search for data in the table. The previous post on data source used for this app was presented as an interactive data table embedded inside a Quarto document, the same principle would also apply for a table inside a Jupyter notebook environment.\n\n\n\napp_sample.py\nThis file was provided by Posit (formerly known as RStudio) from their Python for Shiny app template in HuggingFace as an example script for an app.\n\n\n\n\nFeatures of the app\nThere are three main features for this app which allows viewing, saving4 and highlighting substructures of target molecules as PNG image files. I’m contemplating about adding a download feature for image file saving on the deployed app version but because I’m currently using the free version of Shinyapps.io with limited amount of data available, this may be unlikely (also because the app is more of a demonstration really as the focus is not to provide particular data/image downloads).\n\n\n\nApp deployment\nThere were two places I’ve tried so far, which were HuggingFace and Shinyapps.io. As mentioned briefly earlier under the subsection of “app_molviz_v6_hf.py”, it turned out cairosvg code didn’t quite play out as expected. I have so far not returned to fix this yet on HuggingFace, since I’ve managed to deploy the app on Shinyapps.io. I had a feeling I might need to revert back to the older code version with poorer image resolutions, so that was also another reason why I haven’t fixed it yet as I’d prefer to keep the better resolution one (unless someone has better ideas out there).\nHowever, deploying the app to Shinyapps.io also wasn’t a smooth ride as well, there were some problems initially. The very first problem I got was being told by the error message that rsconnect-python was only compatible with Python version 3.7, 3.8, 3.9 and 3.10 only. I did some information digging in the Posit community forum, and I think several people mentioned using 3.9 without any problems to deploy their apps. Python version 3.11 definitely did not work at all so please avoid for now if anyone would like to try using Shiny for Python app (unless updated by rsconnect-Python in the future).\nSo I think the ideal app building workflow might be like this:\nNote: all code examples below are to be run in the command line interface\n\nRefer to this link provided by Shiny for Python, which details about how to set up the working directory, download the Shiny package and create a virtual environment\nWhen creating the virtual environment, use venv which was already built-in within Python (and also as suggested by the Shiny for Python link) and set it to a compatible Python version.\n\n```{python}\n# To create a venv with a specific Python version e.g. Python 3.9\npython3.9 -m venv my_venv_name\n\n# Activate the created venv\nsource my_venv_name/bin/activate\n```\n\nIf you’ve accidentally set it to Python 3.11 (like what I did), just deactivate the old venv and re-create another one by using the code above. The code below can be used to deactivate the venv set up in the first place.\n\n```{python}\n# Deactivate the old venv\ndeactivate\n```\n\nIf you had to set up a new venv with a new Python version, and did not want to re-add/install all the packages or libraries used in the older version, save all the pip packages like this code below as a requirements.txt file.\n\n```{python}\npip freeze > requirements.txt\n```\n\nOnce the requirements.txt was saved and after the new venv was set up and activated, install all the saved packages used to run the app by using this code.\n\n```{python}\npip freeze -r requirements.txt\n```\n\nStart coding for your app and have fun - don’t forget to save and push the files to your repository.\nTo deploy to Shinyapps.io, follow this link, which explains all the steps. One thing I would like to remind again here is to make sure the app script (i.e. the one with data source, user interface and server code) was saved as “app.py”, so that the rsconnect-python server will recognise it and be able to deploy it to the cloud environment.\n\n\n\n\nFurther improvements of the app\nThere are of course a few things I think could be done to make the app better.\n\nIt may be useful to add a download option as mentioned previously, but for demonstration purpose, I’m leaving it as a “View” only for now, unless I get comments from readers that they’d like to try this. For localhost version, the saving image function should work with files saved to the working directory.\nIt may be even better to use SMARTS5 or SMILES for highlighting compound substructures actually (atom and bond numbering can be a bit tricky, I’ve tried the app myself, and it might not be as straight forward). I’m using atom indices here since I’m using a specific code in RDKit, but perhaps more experienced users for RDKit will know how to make code alterations etc.\nThe app layout could be further optimised for aesthetics e.g. interactive data table could be placed at a different location, and potentially the data table could contain other data such as compound bioassay results to really fit in the structure-activity relationship exploring task.\n\n\n\n\nFinal words\nThe whole idea behind this side project was to show that interested users could use this web app framework to build an interactive app by using their own data. Other useful web app frameworks are also available out there and could potentially be more or equally useful as this one (I’m simply testing out Python for Shiny here since it’s relatively new). In a drug discovery and development setting, this could be useful to make non-coding members understand where the computer side was trying to do, and to possibly assist them during their lab workflows, hoping to add some convenience at least.\n\n\n\nAcknowledgements\nAs always, I’d like to thank all of the authors of RDKit, Datamol, Shiny for Python, itables, Pandas and Polars, without them, I don’t think I can build this app out of the blue.\n\n\n\n\n\nFootnotes\n\n\nPortable network graphic (image file)↩︎\nScalable vector graphic (image file)↩︎\nPython image library↩︎\nThis is currently limited to localhost version if running the app.py in IDE such as VS Code, where the saved files can be located in the working directory. The deployed version on Shinyapps.io currently only allow image viewing and structure highlighting only.↩︎\nSMILES arbitrary target specification↩︎"
  },
  {
    "objectID": "posts/15_Molviz/itables.html",
    "href": "posts/15_Molviz/itables.html",
    "title": "Molecular visualisation (Molviz) web application",
    "section": "",
    "text": "Introduction\nThis time I’m trying to build a web application in the hope to contribute my two cents towards minimising the gap between computational and laboratory sides in a drug discovery (or chemistry-related work) setting. There are definitely many other useful web applications available out there for similar uses, but I guess each one has its own uniqueness and special features.\nFor this app, it is mostly aimed at lab chemists who do not use any computer programming code at all in their work, and would like to quickly view compounds in the lab while working, and also to be able to highlight compound substructures during discussions or brainstorming for ideas during compound synthesis. Importantly, this app can exist outside a Jupyter notebook environment with internet required to access the app.\nThis is also the first part prior to the next post which will showcase the actual app. This part mainly involves some data cleaning but not as a major focus for this post. This is not to say that data cleaning is not important, but instead they are fundamental to any work involving data in order to ensure reasonable data quality, which can then potentially influence decisions or results. I have also collapsed the code sections below to make the post easier to read (to access code used for each section, click on the “Code” links).\n\n\n\nCode and explanations\nIt was actually surprisingly simple for this first part when I did it - building the interactive table. I came across this on LinkedIn on a random day for a post about itables being integrated with Shiny for Python plus Quarto. It came at the right time because I was actually trying to build this app. I quickly thought about incorporating it with the rest of the app so that users could refer back to the data quickly while visualising compound images. The code and explanations on building an interactive table for dataframes in Pandas and Polars were provided below.\nTo install itables, visit here for instructions and also for other information about supported notebook editors.\n\n\nCode\n# Import dataframe libraries\nimport pandas as pd\nimport polars as pl\n\n# Import Datamol\nimport datamol as dm\n\n# Import itables\nfrom itables import init_notebook_mode, show\ninit_notebook_mode(all_interactive=True)\n\n\n# Option 1: Reading df_ai.csv as a pandas dataframe\n#df = pd.read_csv(\"df_ai.csv\")\n#df.head\n\n# Option 2: Reading df_ai.csv as a polars dataframe\ndf = pl.read_csv(\"df_ai.csv\")\n#df.head()\n\n\n# Below was the code I used in my last post to fix the missing SMILES for neomycin \n# - the version below was edited due to recent updates in Polars\n# Canonical SMILES for neomycin was extracted from PubChem \n# (https://pubchem.ncbi.nlm.nih.gov/compound/Neomycin)\n\ndf = df.with_columns([\n    pl.when(pl.col(\"Smiles\").str.lengths() == 0)\n    .then(pl.lit(\"C1C(C(C(C(C1N)OC2C(C(C(C(O2)CN)O)O)N)OC3C(C(C(O3)CO)OC4C(C(C(C(O4)CN)O)O)N)O)O)N\"))\n    .otherwise(pl.col(\"Smiles\"))\n    .keep_name()\n])\n\n#df.head()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPolars dataframe library was designed without the index in mind (which is different to Pandas), therefore the itables library did not work on my specific polars dataframe which required an index column to show (note: all other Polars dataframes should work fine with itables without the index column!).\nHowever to show row counts in Polars dataframes, we could use with_row_count() that starts the index from 0, and this would show up in a Jupyter environment as usual. A small code example would be like this below.\n\n\nCode\n# Uncomment below to run\n#df = df.with_row_count()\n\n\nThen I converted the Polars dataframe into a Pandas one (this could be completely avoided if you started with Pandas actually).\n\n\nCode\ndf = df.to_pandas()\n\n\nThen I added Datamol’s “_preprocess” function to convert SMILES1 into other molecular representations such as standardised SMILES (pre-processed and cleaned SMILES), SELFIES2, InChI3, InChI keys - just to provide extra information for further uses if needed. The standardised SMILES generated here would then be used for generating the molecule images later (in part 2).\n\n\nCode\n# Pre-process molecules using _preprocess function - adapted from datamol.io\n\nsmiles_column = \"Smiles\"\n\ndm.disable_rdkit_log()\n\ndef _preprocess(row):\n    mol = dm.to_mol(row[smiles_column], ordered=True)\n    mol = dm.fix_mol(mol)\n    mol = dm.sanitize_mol(mol, sanifix=True, charge_neutral=False)\n    mol = dm.standardize_mol(\n        mol,\n        disconnect_metals=False,\n        normalize=True,\n        reionize=True,\n        uncharge=False,\n        stereo=True,\n    )\n\n    row[\"standard_smiles\"] = dm.standardize_smiles(dm.to_smiles(mol))\n    row[\"selfies\"] = dm.to_selfies(mol)\n    row[\"inchi\"] = dm.to_inchi(mol)\n    row[\"inchikey\"] = dm.to_inchikey(mol)\n    return row\n\n#Apply the _preprocess function to the prepared dataframe.\ndf = df.apply(_preprocess, axis = 1)\n#df.head()\n\n\nThe next step was to keep the index column of the Pandas dataframe as an actual column (there was a reason for this, mainly for the app).\n\n\nCode\n# Convert index of Pandas df into a column\ndf = df.reset_index()\n#df.head()\n\n\n\n\n\nInteractive data table\n\nAn interactive table of all the prescription-only antibiotics from ChEMBL is shown below\nScroll the table from left to right to see the SMILES, standardised SMILES, SELFIES, InChI, InChI keys for each compound\nUse the search box to enter compound names to search for antibiotics and move between different pages when needed\n\n\n\nCode\ndf\n\n\n\n\n\n\n    \n      \n      index\n      Name\n      Smiles\n      standard_smiles\n      selfies\n      inchi\n      inchikey\n    \n  Loading... (need help?)\n\n\n\n\n\n\n# Saving cleaned df_ai.csv as a new .csv file (for app_image_x.py - script to build the web app)\n# df = pl.from_pandas(df)\n# df.write_csv(\"df_ai_cleaned.csv\", sep = \",\")\n\n\n\n\nOptions for app deployment\nSince I had a lot of fun deploying my previous app in Shinylive last time, I thought I might try the same this time - deploying the Molviz app as a Shinylive app in Quarto. However, it didn’t work as expected, with reason being that RDKit wasn’t written in pure Python (it was written in Python and C++), so there wasn’t a pure Python wheel file available in PyPi - this link may provide some answers relating to this. Essentially, packages or libraries used in the app will need to be compatible with Pyodide in order for the Shinylive app to work. So, the most likely option to deploy this app now would be in Shinyapps.io or HuggingFace as I read about it recently.\n\n\n\nNext post\nCode and explanations for the actual Molviz app will be detailed in the next post. To access full code and files used for now, please visit this repository link.\n\n\n\n\n\nFootnotes\n\n\nSimplified Molecular Input Line Entry Systems↩︎\nSELF-referencIng Embedded Strings↩︎\nInternational Chemical Identifier↩︎"
  },
  {
    "objectID": "posts/22_Simple_dnn_adrs/2_ADR_regressor.html",
    "href": "posts/22_Simple_dnn_adrs/2_ADR_regressor.html",
    "title": "Building a simple deep learning model about adverse drug reactions",
    "section": "",
    "text": "The notebook from this repository uses a venv created by using uv with a kernel set up this way.\nSome of the code blocks have been folded to keep the post length a bit more manageable - click on the code links to see full code (only applies to the HTML version, not the Jupyter notebook version).\n\n\nImport libraries\n\n\nCode\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn.functional import one_hot\nfrom torch.utils.data import TensorDataset, DataLoader\nimport numpy as np\nimport datamol as dm\nimport rdkit\nfrom rdkit import Chem\nfrom rdkit.Chem import rdFingerprintGenerator\nimport useful_rdkit_utils as uru\nimport sys\nfrom matplotlib import pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\nprint(f\"Pandas version used: {pd.__version__}\")\nprint(f\"PyTorch version used: {torch.__version__}\")\nprint(f\"NumPy version used: {np.__version__}\")\nprint(f\"RDKit version used: {rdkit.__version__}\")\nprint(f\"Python version used: {sys.version}\")\n\n\nPandas version used: 2.2.3\nPyTorch version used: 2.2.2\nNumPy version used: 1.26.4\nRDKit version used: 2024.09.4\nPython version used: 3.12.7 (main, Oct 16 2024, 09:10:10) [Clang 18.1.8 ]\n\n\n\n\n\nImport adverse drug reactions (ADRs) data\nThis is an extremely small set of data compiled manually (by me) via references stated in the dataframe. For details about what and how the data are collected, I’ve prepared a separate post as a data note to explain key things about the data. It may not lead to a very significant result but it is done as an example of what an early or basic deep neural network (DNN) model may look like. Ideally there should be more training data and also more features added or used. I’ve hypothetically set the goal of this introductory piece to predict therapeutic drug classes from ADRs, molecular fingerprints and cytochrome P450 substrate strengths, but this won’t be achieved in this initial post (yet).\n\ndata = pd.read_csv(\"cyp3a4_substrates.csv\")\nprint(data.shape)\ndata.head(3)\n\n(27, 8)\n\n\n\n\n\n\n  \n    \n      \n      generic_drug_name\n      notes\n      cyp_strength_of_evidence\n      drug_class\n      adverse_drug_reactions\n      first_ref\n      second_ref\n      date_checked\n    \n  \n  \n    \n      0\n      carbamazepine\n      NaN\n      strong\n      antiepileptics\n      constipation^^, leucopenia^^, dizziness^^, som...\n      drugs.com\n      nzf\n      211024\n    \n    \n      1\n      eliglustat\n      NaN\n      strong\n      metabolic_agents\n      diarrhea^^, oropharyngeal_pain^^, arthralgia^^...\n      drugs.com\n      emc\n      151124\n    \n    \n      2\n      flibanserin\n      NaN\n      strong\n      CNS_agents\n      dizziness^^, somnolence^^, sedation^, fatigue^...\n      drugs.com\n      Drugs@FDA\n      161124\n    \n  \n\n\n\n\nFor drug with astericks marked in “notes” column, see data notes under “Exceptions or notes for ADRs” section in separate post.\nI’m dropping some of the columns that are not going to be used later.\n\n\nCode\ndf = data.drop([\n    \"notes\",\n    \"first_ref\", \n    \"second_ref\", \n    \"date_checked\"\n    ], axis=1)\ndf.head(3)\n\n\n\n\n\n\n  \n    \n      \n      generic_drug_name\n      cyp_strength_of_evidence\n      drug_class\n      adverse_drug_reactions\n    \n  \n  \n    \n      0\n      carbamazepine\n      strong\n      antiepileptics\n      constipation^^, leucopenia^^, dizziness^^, som...\n    \n    \n      1\n      eliglustat\n      strong\n      metabolic_agents\n      diarrhea^^, oropharyngeal_pain^^, arthralgia^^...\n    \n    \n      2\n      flibanserin\n      strong\n      CNS_agents\n      dizziness^^, somnolence^^, sedation^, fatigue^...\n    \n  \n\n\n\n\n\n\n\nImport SMILES data from ChEMBL\nBefore extracting data from ChEMBL, I’m getting a list of drug names in capital letters ready first which can be fed into chembl_downloader with my old cyp_drugs.py to retrieve the SMILES of these drugs.\n\n\nCode\nstring = df[\"generic_drug_name\"].tolist()\n# Convert list of drugs into multiple strings of drug names\ndrugs = f\"'{\"','\".join(string)}'\"\n# Convert from lower case to upper case\nfor letter in drugs:\n    if letter.islower():\n        drugs = drugs.replace(letter, letter.upper())\nprint(drugs)\n\n\n'CARBAMAZEPINE','ELIGLUSTAT','FLIBANSERIN','IMATINIB','IBRUTINIB','NERATINIB','ESOMEPRAZOLE','OMEPRAZOLE','IVACAFTOR','NALOXEGOL','OXYCODONE','SIROLIMUS','TERFENADINE','DIAZEPAM','HYDROCORTISONE','LANSOPRAZOLE','PANTOPRAZOLE','LERCANIDIPINE','NALDEMEDINE','NELFINAVIR','TELAPREVIR','ONDANSETRON','QUININE','RIBOCICLIB','SUVOREXANT','TELITHROMYCIN','TEMSIROLIMUS'\n\n\n\n\nCode\n# Get SMILES for each drug (via copying-and-pasting the previous cell output - attempted various ways to feed the string\n# directly into cyp_drugs.py, current way seems to be the most straightforward one...)\nfrom cyp_drugs import chembl_drugs\n# Using ChEMBL version 34\ndf_3a4 = chembl_drugs(\n    'CARBAMAZEPINE','ELIGLUSTAT','FLIBANSERIN','IMATINIB','IBRUTINIB','NERATINIB','ESOMEPRAZOLE','OMEPRAZOLE','IVACAFTOR','NALOXEGOL','OXYCODONE','SIROLIMUS','TERFENADINE','DIAZEPAM','HYDROCORTISONE','LANSOPRAZOLE','PANTOPRAZOLE','LERCANIDIPINE','NALDEMEDINE','NELFINAVIR','TELAPREVIR','ONDANSETRON','QUININE','RIBOCICLIB','SUVOREXANT','TELITHROMYCIN','TEMSIROLIMUS', \n    #file_name=\"All_cyp3a4_smiles\"\n    )\nprint(df_3a4.shape)\ndf_3a4.head(3)\n\n## Note: latest ChEMBL version 35 (as from 1st Dec 2024) seems to be taking a long time to load (no output after ~7min), \n## both versions 33 & 34 are ok with outputs loading within a few secs\n\n\n(27, 4)\n\n\n\n\n\n\n  \n    \n      \n      chembl_id\n      pref_name\n      max_phase\n      canonical_smiles\n    \n  \n  \n    \n      0\n      CHEMBL108\n      CARBAMAZEPINE\n      4\n      NC(=O)N1c2ccccc2C=Cc2ccccc21\n    \n    \n      1\n      CHEMBL12\n      DIAZEPAM\n      4\n      CN1C(=O)CN=C(c2ccccc2)c2cc(Cl)ccc21\n    \n    \n      2\n      CHEMBL2110588\n      ELIGLUSTAT\n      4\n      CCCCCCCC(=O)N[C@H](CN1CCCC1)[C@H](O)c1ccc2c(c1...\n    \n  \n\n\n\n\n\n\n\nMerge dataframes\nNext, I’m renaming the drug name column and merging the two dataframes together where one contains the ADRs and the other one contains the SMILES. I’m also making sure all drug names are in upper case for both dataframes so they can merge properly.\n\n\nCode\n# Rename column & change lower to uppercase\ndf = df.rename(columns={\"generic_drug_name\": \"pref_name\"})\ndf[\"pref_name\"] = df[\"pref_name\"].str.upper()\n# Merge df & df_3a4 \ndf = df.merge(df_3a4, how=\"left\", on=\"pref_name\")\ndf.head(3)\n\n\n\n\n\n\n  \n    \n      \n      pref_name\n      cyp_strength_of_evidence\n      drug_class\n      adverse_drug_reactions\n      chembl_id\n      max_phase\n      canonical_smiles\n    \n  \n  \n    \n      0\n      CARBAMAZEPINE\n      strong\n      antiepileptics\n      constipation^^, leucopenia^^, dizziness^^, som...\n      CHEMBL108\n      4\n      NC(=O)N1c2ccccc2C=Cc2ccccc21\n    \n    \n      1\n      ELIGLUSTAT\n      strong\n      metabolic_agents\n      diarrhea^^, oropharyngeal_pain^^, arthralgia^^...\n      CHEMBL2110588\n      4\n      CCCCCCCC(=O)N[C@H](CN1CCCC1)[C@H](O)c1ccc2c(c1...\n    \n    \n      2\n      FLIBANSERIN\n      strong\n      CNS_agents\n      dizziness^^, somnolence^^, sedation^, fatigue^...\n      CHEMBL231068\n      4\n      O=c1[nH]c2ccccc2n1CCN1CCN(c2cccc(C(F)(F)F)c2)CC1\n    \n  \n\n\n\n\n\n\n\nParse SMILES\nThen I’m parsing the canonical SMILES through my old script to generate these small molecules as RDKit molecules and standardised SMILES, making sure these SMILES are parsable.\n\n\nCode\n# Using my previous code to preprocess small mols\n# disable rdkit messages\ndm.disable_rdkit_log()\n\n#  The following function code were adapted from datamol.io\ndef preprocess(row):\n\n    \"\"\"\n    Function to preprocess, fix, standardise, sanitise compounds \n    and then generate various molecular representations based on these molecules.\n    Can be utilised as df.apply(preprocess, axis=1).\n\n    :param smiles_column: SMILES column name (needs to be names as \"canonical_smiles\") \n    derived from ChEMBL database (or any other sources) via an input dataframe\n    :param mol: RDKit molecules\n    :return: preprocessed RDKit molecules, standardised SMILES, SELFIES, \n    InChI and InChI keys added as separate columns in the dataframe\n    \"\"\"\n\n    # smiles_column = strings object\n    smiles_column = \"canonical_smiles\"\n    # Convert each compound into a RDKit molecule in the smiles column\n    mol = dm.to_mol(row[smiles_column], ordered=True)\n    # Fix common errors in the molecules\n    mol = dm.fix_mol(mol)\n    # Sanitise the molecules \n    mol = dm.sanitize_mol(mol, sanifix=True, charge_neutral=False)\n    # Standardise the molecules\n    mol = dm.standardize_mol(\n        mol,\n        # Switch on to disconnect metal ions\n        disconnect_metals=True,\n        normalize=True,\n        reionize=True,\n        # Switch on \"uncharge\" to neutralise charges\n        uncharge=True,\n        # Taking care of stereochemistries of compounds\n        # Note: this uses the older approach of \"AssignStereochemistry()\" from RDKit\n        # https://github.com/datamol-io/datamol/blob/main/datamol/mol.py#L488\n        stereo=True,\n    )\n\n    # Adding following rows of different molecular representations \n    row[\"rdkit_mol\"] = dm.to_mol(mol)\n    row[\"standard_smiles\"] = dm.standardize_smiles(str(dm.to_smiles(mol)))\n    #row[\"selfies\"] = dm.to_selfies(mol)\n    #row[\"inchi\"] = dm.to_inchi(mol)\n    #row[\"inchikey\"] = dm.to_inchikey(mol)\n    return row\n\ndf_p3a4 = df.apply(preprocess, axis = 1)\nprint(df_p3a4.shape)\ndf_p3a4.head(3)\n\n\n(27, 9)\n\n\n\n\n\n\n  \n    \n      \n      pref_name\n      cyp_strength_of_evidence\n      drug_class\n      adverse_drug_reactions\n      chembl_id\n      max_phase\n      canonical_smiles\n      rdkit_mol\n      standard_smiles\n    \n  \n  \n    \n      0\n      CARBAMAZEPINE\n      strong\n      antiepileptics\n      constipation^^, leucopenia^^, dizziness^^, som...\n      CHEMBL108\n      4\n      NC(=O)N1c2ccccc2C=Cc2ccccc21\n      <rdkit.Chem.rdchem.Mol object at 0x147947d10>\n      NC(=O)N1c2ccccc2C=Cc2ccccc21\n    \n    \n      1\n      ELIGLUSTAT\n      strong\n      metabolic_agents\n      diarrhea^^, oropharyngeal_pain^^, arthralgia^^...\n      CHEMBL2110588\n      4\n      CCCCCCCC(=O)N[C@H](CN1CCCC1)[C@H](O)c1ccc2c(c1...\n      <rdkit.Chem.rdchem.Mol object at 0x1479474c0>\n      CCCCCCCC(=O)N[C@H](CN1CCCC1)[C@H](O)c1ccc2c(c1...\n    \n    \n      2\n      FLIBANSERIN\n      strong\n      CNS_agents\n      dizziness^^, somnolence^^, sedation^, fatigue^...\n      CHEMBL231068\n      4\n      O=c1[nH]c2ccccc2n1CCN1CCN(c2cccc(C(F)(F)F)c2)CC1\n      <rdkit.Chem.rdchem.Mol object at 0x147947ed0>\n      O=c1[nH]c2ccccc2n1CCN1CCN(c2cccc(C(F)(F)F)c2)CC1\n    \n  \n\n\n\n\n\n\n\nSplit data\nRandom splits usually lead to overly optimistic models, where testing molecules are too similar to traininig molecules leading to many problems. This is further discussed in two other blog posts that I’ve found useful - post by Greg Landrum and post by Pat Walters.\nHere I’m trying out Pat’s useful_rdkit_utils’ GroupKFoldShuffle code (code originated from this thread) to split data (Butina clustering/splits). To do this, it requires SMILES to generate molecular fingerprints which will be used in the training and testing sets (potentially for future posts and in real-life cases, more things can be done with the SMILES or other molecular representations for machine learning, but to keep this post easy-to-read, I’ll stick with only generating the Morgan fingerprints for now).\n\n\nCode\n# Generate numpy arrays containing the fingerprints \ndf_p3a4['fp'] = df_p3a4.rdkit_mol.apply(rdFingerprintGenerator.GetMorganGenerator().GetCountFingerprintAsNumPy)\n\n# Get Butina cluster labels\ndf_p3a4[\"butina_cluster\"] = uru.get_butina_clusters(df_p3a4.standard_smiles)\n\n# Set up a GroupKFoldShuffle object\ngroup_kfold_shuffle = uru.GroupKFoldShuffle(n_splits=5, shuffle=True)\n\n# Using cross-validation/doing data split\n## X = np.stack(df_s3a4.fp), y = df.adverse_drug_reactions, group labels = df_s3a4.butina_cluster\nfor train, test in group_kfold_shuffle.split(np.stack(df_p3a4.fp), df.adverse_drug_reactions, df_p3a4.butina_cluster):\n    print(len(train),len(test))\n\n\n20 7\n22 5\n20 7\n23 4\n23 4\n\n\n\n\n\nLocate training and testing sets after data split\nWhile trying to figure out how to locate training and testing sets after the data split, I’ve gone into a mini rabbit hole myself (a self-confusing session but gladly it clears up when my thought process goes further…). For example, some of the ways I’ve planned to try: create a dictionary as {index: butina label} first - butina cluster labels vs. index e.g. df_s3a4[“butina_cluster”], or maybe can directly convert from NumPy array to tensor - will need to locate drugs via indices first to specify training and testing sets, e.g. torch_train = torch.from_numpy(train) or torch_test = torch.from_numpy(test). It is actually simpler than this, which is to use pd.DataFrame.iloc() as shown below.\n\n# Training set indices\ntrain\n\narray([ 0,  1,  2,  3,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 21, 22, 25, 26])\n\n\n\n# What df_p3a4 now looks like after data split - with \"fp\" and \"butina_cluster\" columns added\ndf_p3a4.head(1)\n\n\n\n\n\n  \n    \n      \n      pref_name\n      cyp_strength_of_evidence\n      drug_class\n      adverse_drug_reactions\n      chembl_id\n      max_phase\n      canonical_smiles\n      rdkit_mol\n      standard_smiles\n      fp\n      butina_cluster\n    \n  \n  \n    \n      0\n      CARBAMAZEPINE\n      strong\n      antiepileptics\n      constipation^^, leucopenia^^, dizziness^^, som...\n      CHEMBL108\n      4\n      NC(=O)N1c2ccccc2C=Cc2ccccc21\n      <rdkit.Chem.rdchem.Mol object at 0x147947d10>\n      NC(=O)N1c2ccccc2C=Cc2ccccc21\n      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n      20\n    \n  \n\n\n\n\n\n# Convert indices into list\ntrain_set = train.tolist()\n# Locate drugs and drug info via pd.DataFrame.iloc\ndf_train = df_p3a4.iloc[train_set]\nprint(df_train.shape)\ndf_train.head(2)\n\n(23, 11)\n\n\n\n\n\n\n  \n    \n      \n      pref_name\n      cyp_strength_of_evidence\n      drug_class\n      adverse_drug_reactions\n      chembl_id\n      max_phase\n      canonical_smiles\n      rdkit_mol\n      standard_smiles\n      fp\n      butina_cluster\n    \n  \n  \n    \n      0\n      CARBAMAZEPINE\n      strong\n      antiepileptics\n      constipation^^, leucopenia^^, dizziness^^, som...\n      CHEMBL108\n      4\n      NC(=O)N1c2ccccc2C=Cc2ccccc21\n      <rdkit.Chem.rdchem.Mol object at 0x147947d10>\n      NC(=O)N1c2ccccc2C=Cc2ccccc21\n      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n      20\n    \n    \n      1\n      ELIGLUSTAT\n      strong\n      metabolic_agents\n      diarrhea^^, oropharyngeal_pain^^, arthralgia^^...\n      CHEMBL2110588\n      4\n      CCCCCCCC(=O)N[C@H](CN1CCCC1)[C@H](O)c1ccc2c(c1...\n      <rdkit.Chem.rdchem.Mol object at 0x1479474c0>\n      CCCCCCCC(=O)N[C@H](CN1CCCC1)[C@H](O)c1ccc2c(c1...\n      [0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n      19\n    \n  \n\n\n\n\n\n# Testing set indices\ntest\n\narray([ 4, 20, 23, 24])\n\n\n\ntest_set = test.tolist()\ndf_test = df_p3a4.iloc[test_set]\nprint(df_test.shape)\ndf_test.head(2)\n\n(4, 11)\n\n\n\n\n\n\n  \n    \n      \n      pref_name\n      cyp_strength_of_evidence\n      drug_class\n      adverse_drug_reactions\n      chembl_id\n      max_phase\n      canonical_smiles\n      rdkit_mol\n      standard_smiles\n      fp\n      butina_cluster\n    \n  \n  \n    \n      4\n      IBRUTINIB\n      strong\n      tyrosine_kinase_inhibitor\n      hypertension^^, atrial_fibrillation^^, sinus_t...\n      CHEMBL1873475\n      4\n      C=CC(=O)N1CCC[C@@H](n2nc(-c3ccc(Oc4ccccc4)cc3)...\n      <rdkit.Chem.rdchem.Mol object at 0x1479475a0>\n      C=CC(=O)N1CCC[C@@H](n2nc(-c3ccc(Oc4ccccc4)cc3)...\n      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n      16\n    \n    \n      20\n      TELAPREVIR\n      mod\n      antivirals\n      rash^^, pruritus^^, anemia^^, decreased_mean_p...\n      CHEMBL231813\n      4\n      CCC[C@H](NC(=O)[C@@H]1[C@H]2CCC[C@H]2CN1C(=O)[...\n      <rdkit.Chem.rdchem.Mol object at 0x1472ca030>\n      CCC[C@H](NC(=O)[C@@H]1[C@H]2CCC[C@H]2CN1C(=O)[...\n      [0, 3, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...\n      8\n    \n  \n\n\n\n\n\n\n\nSet up training and testing sets for X and y variables\nThis part involves converting X (features) and y (target) variables into either one-hot encodings or vector embeddings, since I’ll be dealing with categories/words/ADRs and not numbers, and also to split each X and y variables into training and testing sets. At the very beginning, I’ve thought about using scikit_learn’s train_test_split(), but then realised that I should not need to do this as it’s already been done in the previous step (obviously I’m confusing myself again…). Essentially, this step can be integrated with the one-hot encoding and vector embeddings part as shown below.\nThere are three coding issues that have triggered warning messages when I’m trying to figure out how to convert CYP strengths into one-hot encodings:\n\nA useful thread has helped me to solve the downcasting issue in pd.DataFrame.replace() when trying to do one-hot encoding to replace the CYP strengths for each drug\nA Pandas setting-with-copy warning shows if using df[“column_name”]:\n\n\nA value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead\n\nThe solution is to enable the copy-on-write globally (as commented in the code below; from Pandas reference).\n\nPyTorch user warning appers if using df_train[“cyp_strength_of_evidence”].values, as this leads to non-writable tensors with a warning like this:\n\n\nUserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:212.)\n\nOne of the solutions is to add copy() e.g. col_encoded = one_hot(torch.from_numpy(df[“column_name”].values.copy()) % total_numbers_in_column) or alternatively, convert column into numpy array first, then make the numpy array writeable (which is what I’ve used in the code below).\n\n\nCode\n## X_train\n# 1. Convert \"cyp_strength_of_evidence\" column into one-hot encoding\n# Enable copy-on-write globally to remove the warning\npd.options.mode.copy_on_write = True\n\n# Replace CYP strength as numbers\nwith pd.option_context('future.no_silent_downcasting', True):\n   df_train[\"cyp_strength_of_evidence\"] = df_train[\"cyp_strength_of_evidence\"].replace({\"strong\": 1, \"mod\": 2}).infer_objects()\n   df_test[\"cyp_strength_of_evidence\"] = df_test[\"cyp_strength_of_evidence\"].replace({\"strong\": 1, \"mod\": 2}).infer_objects()\n\n# Get total number of CYP strengths in df\ntotal_cyp_str_train = len(set(df_train[\"cyp_strength_of_evidence\"]))\n\n# Convert column into numpy array first, then make the numpy array writeable\ncyp_array_train = df_train[\"cyp_strength_of_evidence\"].to_numpy()\ncyp_array_train.flags.writeable = True\ncyp_str_train_t = one_hot(torch.from_numpy(cyp_array_train) % total_cyp_str_train)\ncyp_str_train_t\n\n\ntensor([[0, 1],\n        [0, 1],\n        [0, 1],\n        [0, 1],\n        [0, 1],\n        [0, 1],\n        [0, 1],\n        [0, 1],\n        [0, 1],\n        [0, 1],\n        [0, 1],\n        [0, 1],\n        [1, 0],\n        [1, 0],\n        [1, 0],\n        [1, 0],\n        [1, 0],\n        [1, 0],\n        [1, 0],\n        [1, 0],\n        [1, 0],\n        [1, 0],\n        [1, 0]])\n\n\nWithout going into too much details about vector embeddings (as there are a lot of useful learning materials about it online and in texts), here’s roughly how I understand embeddings while working on this post. Embeddings are real-valued dense vectors that are normally in multi-dimensional arrays and they can represent and catch the context of a word or sentence, the semantic similarity and especially the relation of each word with other words in a corpus of texts. They roughly form the basis of natural language processing and also contribute to how large language models are built… in a very simplified sense, but obviously this can get complex if we want the models to do more. Here, I’m trying something experimental so I’m going to convert each ADR for each drug into embeddings.\n\n\nCode\n# 2. Convert \"adverse_drug_reactions\" column into embeddings\n## see separate scripts used previously e.g. words_tensors.py \n## or Tensors_for_adrs_interactive.py to show step-by-step conversions from words to tensors\n\n# Save all ADRs from common ADRs column as a list (joining every row of ADRs in place only)\nadr_str_train = df_train[\"adverse_drug_reactions\"].tolist()\n# Join separate rows of strings into one complete string\nadr_string_train = \",\".join(adr_str_train)\n# Converting all ADRs into Torch tensors using words_tensors.py\nfrom words_tensors import words_tensors\nadr_train_t = words_tensors(adr_string_train)\nadr_train_t\n\n\ntensor([[ 0.2880, -1.1804],\n        [ 0.6725,  0.9416],\n        [-1.7143,  0.3996],\n        ...,\n        [ 0.2165,  0.7955],\n        [-1.3582,  0.2286],\n        [ 1.4517, -1.9432]], grad_fn=<EmbeddingBackward0>)\n\n\nWhen trying to convert the “fp” column into tensors, there is one coding issue I’ve found relating to the data split step earlier. Each time the notebook is re-run with the kernel refreshed, the data split will lead to different proportions of training and testing sets due to the “shuffle = True”, which subsequently leads to different training and testing set arrays. One of the ways to circumvent this is to turn off the shuffle but this is not ideal for model training. So an alternative way that I’ve tried is to use ndarray.size (which is the product of elements in ndarray.shape, equivalent to multiplying the numbers of rows and columns), and divide the row of the intended tensor shape by 2 as I’m trying to reshape training arrays so they’re all in 2 columns in order for torch.cat() to work later.\n\n\nCode\n# 3. Convert \"fp\" column into tensors\n# Stack numpy arrays in fingerprint column\nfp_train_array = np.stack(df_train[\"fp\"])\n# Convert numpy array data type from uint32 to int32\nfp_train_array = fp_train_array.astype(\"int32\")\n# Create tensors from array\nfp_train_t = torch.from_numpy(fp_train_array)\n# Reshape tensors\nfp_train_t = torch.reshape(fp_train_t, (int(fp_train_array.size/2), 2))\nfp_train_t.shape # tensor.ndim to check tensor dimensions\n\n\ntorch.Size([23552, 2])\n\n\n\nadr_train_t.shape\n\ntorch.Size([697, 2])\n\n\n\ncyp_str_train_t.shape\n\ntorch.Size([23, 2])\n\n\n\n# Concatenate adr tensors, fingerprint tensors and cyp strength tensors as X_train\nX_train = torch.cat([adr_train_t, fp_train_t, cyp_str_train_t], 0).float()\nX_train\n\ntensor([[ 0.2880, -1.1804],\n        [ 0.6725,  0.9416],\n        [-1.7143,  0.3996],\n        ...,\n        [ 1.0000,  0.0000],\n        [ 1.0000,  0.0000],\n        [ 1.0000,  0.0000]], grad_fn=<CatBackward0>)\n\n\nX_test is being set up similarly as shown below.\n\n\nCode\n## X_test\n# 1. Convert \"cyp_strength_of_evidence\" into one-hot encodings\ntotal_cyp_str_test = len(set(df_test[\"cyp_strength_of_evidence\"]))\narray_test = df_test[\"cyp_strength_of_evidence\"].to_numpy()\narray_test.flags.writeable = True\ncyp_str_test_t = one_hot(torch.from_numpy(array_test) % total_cyp_str_test)\n\n# 2. Convert \"adverse_drug_reactions\" column into embeddings\nadr_str_test = df_test[\"adverse_drug_reactions\"].tolist()\nadr_string_test = \",\".join(adr_str_test)\nadr_test_t = words_tensors(adr_string_test)\n\n# 3. Convert \"fp\" column into tensors\nfp_test_array = np.stack(df_test[\"fp\"])\nfp_test_array = fp_test_array.astype(\"int32\")\nfp_test_t = torch.from_numpy(fp_test_array)\nfp_test_t = torch.reshape(fp_test_t, (int(fp_test_array.size/2),2))\n\n# Concatenate adr tensors, drug class tensors and cyp strength tensors as X_test\nX_test = torch.cat([cyp_str_test_t, adr_test_t, fp_test_t], 0).float()\nX_test\n\n\ntensor([[0., 1.],\n        [1., 0.],\n        [1., 0.],\n        ...,\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]], grad_fn=<CatBackward0>)\n\n\nThis is followed by setting up y_train.\n\n\nCode\n## y_train\n# Use drug_class column as target\n# Convert \"drug_class\" column into embeddings \n# total number of drug classes in df = 20 - len(set(df[\"drug_class\"])) - using embeddings instead of one-hot\ndc_str_train = df_train[\"drug_class\"].tolist()\ndc_string_train = \",\".join(dc_str_train)\ny_train = words_tensors(dc_string_train)\ny_train\n\n\ntensor([[-0.1376,  0.3913]], grad_fn=<EmbeddingBackward0>)\n\n\nLastly, y_test is being specified.\n\n\nCode\n## y_test\n# Convert \"drug_class\" column into embeddings \ndc_str_test = df_test[\"drug_class\"].tolist()\ndc_string_test = \",\".join(dc_str_test)\ny_test = words_tensors(dc_string_test)\ny_test\n\n\ntensor([[-0.2515, -0.3926]], grad_fn=<EmbeddingBackward0>)\n\n\n\n\n\nInput preprocessing pipeline using PyTorch Dataset and DataLoader\nThere is a size-mismatch-between-tensors warning when I’m trying to use PyTorch’s TensorDataset(). I’ve found out that to use the data loader and tensor dataset, the first dimension of all tensors needs to be the same. Initially, they’re not, where X_train.shape = [24313, 2], y_train.shape = [1, 2]. Eventually I’ve settled on two ways that can help with this:\n\nuse tensor.unsqueeze(dim = 1) or\nuse tensor[None] which’ll insert a new dimension at the beginning, then it becomes: X_train.shape = [1, 24313, 2], y_train.shape = [1, 1, 2]\n\n\nX_train[None].shape\n\ntorch.Size([1, 24272, 2])\n\n\n\nX_train.shape\n\ntorch.Size([24272, 2])\n\n\n\ny_train[None].shape\n\ntorch.Size([1, 1, 2])\n\n\n\ny_train.shape\n\ntorch.Size([1, 2])\n\n\n\n# Create a PyTorch dataset on training data set\ntrain_data = TensorDataset(X_train[None], y_train[None])\n# Sets a seed number to generate random numbers\ntorch.manual_seed(1)\nbatch_size = 1\n\n# Create a dataset loader\ntrain_dl = DataLoader(train_data, batch_size, shuffle = True)\n\n\n# Create another PyTorch dataset on testing data set\ntest_data = TensorDataset(X_test[None], y_test[None])\ntorch.manual_seed(1)\nbatch_size = 1\ntest_dl = DataLoader(test_data, batch_size, shuffle=True)\n\n\n\n\nSet up a simple DNN regression model\nI’m only going to use a very simple two-layer DNN model to match the tiny dataset used here. There are many other types of neural network layers or bits and pieces that can be used to suit the goals and purposes of the dataset used. This reference link shows different types of neural network layers that can be used in PyTorch.\nBelow are some short notes regarding a neural network (NN) model:\n\ngoal of the model is to minimise loss function L(W) (where W = weight) to get the optimal model weights\nmatrix with W (for hidden layer) connects input to hidden layer; matrix with W (for outer layer) connects hidden to output layer\nInput layer -> activation function of hidden layer -> hidden layer -> activation function of output layer -> output layer (a very-simplified flow diagram to show how the layers get connected to each other)\n\nAbout backpropagation for loss function:\n\nbackpropagation is a computationally efficient way to calculate partial derivatives of loss function to update weights in multi-layer NNs\nit’s based on calculus chain rule to compute derivatives of mathematical functions (automatic differentiation)\nmatrix-vector multiplications in backpropagation are computationally more efficient to calculate than matrix-matrix multiplications e.g. forward propagation\n\nNote: there are also other types of activation functions available to use in PyTorch.\n\n\nCode\n# note: this is a very simple two-layer NN model only\n\n# Set up hidden units between two connected layers - one layer with 6 hidden units and the other with 3 hidden units\nhidden_units = [6, 3]\n# Input size same as number of columns in X_train\ninput_size = X_train.shape[1]\n# Initiate NN layers as a list\nall_layers = []\n\n## Specify how the input, hidden and output layers are going to be connected\n# For each hidden unit within the hidden units specified above:\nfor h_unit in hidden_units:\n    # specify sizes of input sample (input size = X_train col size) & output sample (hidden units) in each layer\n    # https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear\n    layer = nn.Linear(input_size, h_unit)\n    # add each layer\n    all_layers.append(layer)\n    # add activation function (trying rectified linear unit) for next layer\n    all_layers.append(nn.ReLU())\n    # for the next layer to be added, the input size will be the same size as the hidden unit\n    input_size = h_unit\n\n# Specify the last layer (where input_feature = hidden_units[-1] = 3)\nall_layers.append(nn.Linear(hidden_units[-1], 1))\n\n# Set up a container that'll connect all layers in the specified sequence in the model\nmodel = nn.Sequential(*all_layers)\nmodel\n\n\nSequential(\n  (0): Linear(in_features=2, out_features=6, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=6, out_features=3, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=3, out_features=1, bias=True)\n)\n\n\n\n\n\nTrain model\nThis part is mainly about defining the loss function when training the model with the training data, and optimising model by using a stochastic gradient descent. One key thing I’ve gathered from trying to learn about deep learning is that we’re aiming for global minima and not local minima (e.g. if learning rate is too small, this may end up with local minima; if learning rate is too large, it may end up over-estimating the global minima). I’ve also encountered the PyTorch padding method to make sure the input and target tensors are of the same size, otherwise the model will run into matrix broadcasting issue (which will likely influence the results). The training loss appears to have converged when the epoch runs reach 100 and/or after (note this may vary due to shuffle data sampling)… (I also think my data size is way too small to show a clear contrast in training loss convergence).\nReferences for: nn.MSELoss() - measures mean squared error between X and y, and nn.functional.pad() - pads tensor (increase tensor size)\nObtaining training loss via model training:\n\n\nCode\n# Set up loss function\nloss_f = nn.MSELoss()\n# Set up stochastic gradient descent optimiser to optimise model (minimise loss) during training \n# lr = learning rate - default: 0.049787 (1*e^-3)\noptim = torch.optim.SGD(model.parameters(), lr=0.005)\n# Set training epochs (epoch: each cycle of training or passing through the training set)\nnum_epochs = 200\n# Set the log output to show training loss - for every 20 epochs\nlog_epochs = 20\ntorch.manual_seed(1)\n# Create empty lists to save training loss (for training and testing/validation sets)\ntrain_epoch_loss = []\ntest_epoch_loss = []\n\n#  Predict via training X_batch & obtain train loss via loss function from X_batch & y_batch\nfor epoch in range(num_epochs):\n    train_loss = 0\n    for X_batch, y_batch in train_dl:\n        # Make predictions\n        predict = model(X_batch)[:, 0]\n        # Make input tensors the same size as y_batch tensors\n        predict_pad = F.pad(predict[None], pad=(1, 0, 0, 0))\n        # Calculate training loss\n        loss = loss_f(predict_pad, y_batch)\n        # Calculate gradients (backpropagations)\n        loss.backward(retain_graph=True)\n        # Update parameters using gradients\n        optim.step()\n        # Reset gradients back to zero\n        optim.zero_grad()\n        train_loss += loss.item()\n    \n    if epoch % log_epochs == 0:\n        print(f\"Epoch {epoch} Loss {train_loss/len(train_dl):.4f}\")\n\n    train_epoch_loss.append(train_loss)\n\n\nEpoch 0 Loss 0.0223\n\n\nEpoch 20 Loss 0.0186\nEpoch 40 Loss 0.0160\nEpoch 60 Loss 0.0142\n\n\nEpoch 80 Loss 0.0129\nEpoch 100 Loss 0.0119\n\n\nEpoch 120 Loss 0.0113\nEpoch 140 Loss 0.0108\nEpoch 160 Loss 0.0104\n\n\nEpoch 180 Loss 0.0102\n\n\nObtaining test or validation loss:\n\n\nCode\n# Predict via testing X_batch & obtain test loss \nfor epoch in range(num_epochs):\n    test_loss = 0\n    for X_batch, y_batch in test_dl:\n        # Make predictions\n        predict_test = model(X_batch)[:, 0]\n        # Make input tensors the same size as y_batch tensors\n        predict_pad_test = F.pad(predict_test[None], pad=(1, 0, 0, 0))\n        # Calculate training loss\n        loss = loss_f(predict_pad_test, y_batch)\n        # Calculate gradients (backpropagations)\n        loss.backward(retain_graph=True)\n        # Update parameters using gradients\n        optim.step()\n        # Reset gradients back to zero\n        optim.zero_grad()\n        test_loss += loss.item()\n    \n    if epoch % log_epochs == 0:\n        print(f\"Epoch {epoch} Loss {test_loss/len(test_dl):.4f}\")\n\n    test_epoch_loss.append(test_loss)\n\n\nEpoch 0 Loss 0.4129\nEpoch 20 Loss 0.2914\nEpoch 40 Loss 0.2259\nEpoch 60 Loss 0.1770\nEpoch 80 Loss 0.1391\nEpoch 100 Loss 0.1104\n\n\nEpoch 120 Loss 0.0887\nEpoch 140 Loss 0.0725\n\n\nEpoch 160 Loss 0.0606\nEpoch 180 Loss 0.0519\n\n\n\n\n\nEvaluate model\nShowing train and test losses over training epochs in a plot:\n\n\nCode\nplt.plot(train_epoch_loss, label=\"train_loss\")\nplt.plot(test_epoch_loss, label=\"test_loss\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show\n\n\n<function matplotlib.pyplot.show(close=None, block=None)>\n\n\n\n\n\nAt the moment, when this notebook is re-run on a refreshed kernel, this leads to a different train and test split each time, and also leading to a different train and test (validation) loss each time. There may be two types of scenarios shown in the plot above where:\n\ntest loss is higher than train loss (overfitting) - showing the model may be way too simplified and is likely under-trained\ntrain loss is higher than test loss (underfitting) - showing that the model may not have been trained well, and is unable to learn the features in the training data and apply them to the test data\n\nWhen there are actually more training data available with also other hyperparameters fine tuned, it may be possible to see another scenario where both test loss and train loss are very similar in trend, meaning the model is being trained well and able to generalise the training to the unseen data.\nTo mitigate overfitting:\n\nfirstly there should be more training data than what I’ve had here\nuse L1 or L2 regularisation to minimise model complexity by adding penalities to large weights\nuse early stopping during model training to stop training the model when test loss is becoming higher than the train loss\nuse torch.nn.Dropout() to randomly drop out some of the neurons to ensure the exisiting neurons will learn features without being too reliant on other neighbouring neurons in the network\nI’ll try the early stopping or drop out method in future posts since current post is relatively long already… (note on preventing model overfitting in DNN added in February 2025)\n\nTo overcome underfitting:\n\nincrease training epochs\nminimise regularisation\nconsider building a more complex or deeper neural network model\n\nI’m trying to keep this post simple so have only used mean squared error (MSE) and mean absolute error (MAE) to evaluate the model which has made a prediction on the test set. The smaller the MSE, the less error the model has when making predictions. However this is not the only metric that will determine if a model is optimal for predictions, as I’ve also noticed that every time there’s a different train and test split, the MAE and MSE values will vary too, so it appears that some splits will generate smaller MSE and other splits will lead to larger MSE.\n\n\nCode\n# torch.no_grad() - disable gradient calculations to reduce memory usage for inference (also like a decorator)\nwith torch.no_grad():\n    predict_test = model(X_test.float())[:, 0]\n    # Padding target tensor with set size of [(1, 2)] as input tensor size will vary \n    # when notebook is re-run each time due to butina split with sample shuffling\n    # so need to pad the target tensor accordingly\n    y_test_pad = F.pad(y_test, pad=(predict_test[None].shape[1] - y_test.shape[1], 0, 0, 0))\n    loss_new = loss_f(predict_test[None], y_test_pad)\n    print(f\"MSE for test set: {loss_new.item():.4f}\")\n    print(f\"MAE for test set: {nn.L1Loss()(predict_test[None], y_test_pad).item():.4f}\")\n\n\nMSE for test set: 0.0443\nMAE for test set: 0.2100\n\n\n\n\n\nSave model\nOne way to save the model is like below.\n\npath = \"adr_regressor.pt\"\ntorch.save(model, path)\nmodel_reload = torch.load(path)\nmodel_reload.eval()\n\nSequential(\n  (0): Linear(in_features=2, out_features=6, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=6, out_features=3, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=3, out_features=1, bias=True)\n)\n\n\n\n\n\nReload model\nThe saved model is reloaded below with a check to make sure the reloaded version is the same as the saved version.\nReferences for: torch.max and torch.argmax\n\npred_reload = model_reload(X_test)\ny_test_rel_pad = F.pad(y_test, pad=(pred_reload[None].shape[1] - y_test.shape[1], 0, 0, 0))\ncorrect = (torch.argmax(pred_reload, dim=1) == y_test_rel_pad).float()\naccuracy = correct.mean()\nprint(f\"Test accuracy: {accuracy:.4f}\")\n\nTest accuracy: 0.9995\n\n\n\nA few things to consider in the end:\n\nI haven’t done feature standardisation for X_train which is to centre X_train mean and divide by its standard deviation, code may be like this, X_train_normalised = (X_train - np.mean(X_train))/np.std(X_train) (if used on training data, need to apply this to testing data too)\nTraining features are certainly too small, however, the main goal of this very first post is to get an overall idea of how to construct a baseline DNN regression model. There are lots of other things that can be done to the ADRs data e.g. adding more drug molecular features and properties. I have essentially only used the initial molecular fingerprints generated when doing the data split to add a bit of molecular aspect in the training dataset.\nI haven’t taken into account the frequencies of words (e.g. same drug classes and same ADR terms across different drugs) in the training and testing data, however, the aim of this first piece of work is also not a semantic analysis in natural language processing so this might not be needed…\nThere may be other PyTorch functions that I do not yet know about that will deal with small datasets e.g. perhaps torch.sparse may be useful?… so this piece is certainly not the only way to do it, but one of the many ways to work with small data\n\n\n\n\nAcknowledgements\nI’m very thankful for the existence of these references, websites and reviewer below which have helped me understand (or scratch a small surface of) deep learning and also solve the coding issues mentioned in this post:\n\nPyTorch forums\nStack Overflow\nRaschka, Sebastian, Yuxi (Hayden) Liu, and Vahid Mirjalili. 2022. Machine Learning with PyTorch and Scikit-Learn. Birmingham, UK: Packt Publishing.\nNoel O’Boyle for feedback on this post"
  },
  {
    "objectID": "posts/22_Simple_dnn_adrs/4_Prevent_overfit_note.html",
    "href": "posts/22_Simple_dnn_adrs/4_Prevent_overfit_note.html",
    "title": "Prevent model overfitting in deep neural networks",
    "section": "",
    "text": "note: there could be more ways to handle model overfitting, so this note is more like a slow-evolving document over time, and it mainly describes approaches applicable to neural networks (NN) built by using PyTorch but I suspect similar concepts may also apply (to a certain degree) towards other deep learning libraries/frameworks such as TensorFlow or Keras (and likely may apply to other machine learning algorithms too)\n\n\nHow to prevent overfitting in neural networks?\nIt appears there are three main approaches used to prevent model overfitting:\n\nDrop out layer\n\n\nbased on this (preprint) paper\nadding a drop out layer is likely better and more useful for a larger NN, and is probably not great for the tiny two-layer NN that has been used in this post\nthere are 2 types: nn.Dropout() with a code example and F.dropout() (note: F = functional)\ndrop out is most effective if used during model training phase\nan explanation about differences between these 2 types of drop out, but essentially they’re the same but useful to use F.dropout() (a functional interface) when there are no parameters (e.g. weights and biases) required and will need to specify if in training or evaluation mode, and use nn.Dropout() (a PyTorch module) when parameters are needed with no need to specify the training or evaluation mode since nn.Dropout() will take care of this automatically\n\n\n\nCheckpoints with early stopping\n\n\nbased on the concept that PyTorch can retrieve and restore weights or parameters of NN\nfirst to save weights or parameters of the model\n\n```{python}\ntorch.save(model.state_dict(), model_filename_or_path)\n```\n\nthen reload the model\n\n```{python}\nmodel.load_state_dict(torch.load(model_filename_or_path)) \n```\n\nneed to set up an early stop threshold and use accuracy (e.g. accuracy as y_predict = model (X_test))\none feature is that you can set n_epochs with a very large number as the training loop can be terminated with a code break when there’s a threshold set up\na code example which may be useful\n\n\n\nEarly stopping in model training loop\n\nVersion 1:\nThe code being used here is inspired and adapted (with thanks) from this thread.\n```{python}\nclass EarlyStopping:\n    def __init__(self, epochs_to_wait = 1, delta = 0):\n        self.epochs_to_wait = epochs_to_wait\n        self.delta = delta\n        self.early_stop = False\n        self.counter = 0\n\n    def __call__(self, test_loss, train_loss):\n        if (test_loss - train_loss) > self.delta:\n            self.counter += 1\n            if self.counter > self.epochs_to_wait:\n                self.early_stop = True\n\nearly_stopper = EarlyStopping(epochs_to_wait = 2, delta = 0)\n\nfor i in range(len(train_epoch_loss)):\n    early_stopper(train_epoch_loss[i], test_epoch_loss[i])\n    print(f\"train loss: {train_epoch_loss[i]} test loss: {test_epoch_loss[i]}\")\n    if early_stopper.early_stop:\n        print(\"Early stop at epoch:\", i)\n        break\n```\nThe code output for one of the runs from the notebook:\ntrain loss: 1.2966824769973755 test loss: 1.9737834930419922 train loss: 1.293437123298645 test loss: 1.93597412109375 train loss: 1.2902556657791138 test loss: 1.8992326259613037 train loss: 1.2871367931365967 test loss: 1.8635075092315674 train loss: 1.2840790748596191 test loss: 1.828752040863037 train loss: 1.2810810804367065 test loss: 1.7949209213256836 train loss: 1.2781414985656738 test loss: 1.7619731426239014 train loss: 1.275259256362915 test loss: 1.7298691272735596 train loss: 1.2724330425262451 test loss: 1.6985728740692139 train loss: 1.269661545753479 test loss: 1.6680500507354736 train loss: 1.2669436931610107 test loss: 1.6382684707641602 train loss: 1.2642782926559448 test loss: 1.6091980934143066 train loss: 1.2616642713546753 test loss: 1.580810308456421 train loss: 1.2591005563735962 test loss: 1.5532073974609375 train loss: 1.2565860748291016 test loss: 1.5262627601623535 train loss: 1.2541197538375854 test loss: 1.499927043914795 train loss: 1.251700758934021 test loss: 1.474177360534668 train loss: 1.2493280172348022 test loss: 1.4489929676055908 train loss: 1.2470005750656128 test loss: 1.424353837966919 train loss: 1.2447175979614258 test loss: 1.4002411365509033 train loss: 1.2424780130386353 test loss: 1.3766369819641113 train loss: 1.240281105041504 test loss: 1.3535246849060059 train loss: 1.2381259202957153 test loss: 1.3308889865875244 train loss: 1.2360116243362427 test loss: 1.3090163469314575 train loss: 1.2339375019073486 test loss: 1.2876880168914795 train loss: 1.2319027185440063 test loss: 1.2667698860168457 train loss: 1.229906439781189 test loss: 1.246250867843628 train loss: 1.2279479503631592 test loss: 1.226119875907898 train loss: 1.2260264158248901 test loss: 1.2063673734664917 train loss: 1.2241413593292236 test loss: 1.1869832277297974 Early stop at epoch: 29\nSome comments:\n\ncan alter delta to specify how big the difference is between train and test losses (the gap between them)\nepochs_to_wait can be altered too to specify at least how many epochs need to pass before using early stopping\ndue to the small-sized dataset being used here, the delta needs to be at 0 (since the losses are very small as well…), otherwise there won’t be an early stop at all and the training epochs will just keep rolling…\nother dataset should bring more interesting results!\nagain butina split with shuffling will alter results on each refreshed run (only specific to the notebook I’m using, and this shouldn’t be an issue if the data produced in the end are of fixed or set values only)\n\n\nVersion 2:\nThe code below may need more tweaking. This one focusses more on the test loss trend rather than the gap between train loss and test loss (and to be honest, I somehow understand version 1 better than this one at the moment…)\n```{python}\nclass Early_stopping:\n\n    ## earlier version:\n    def __init__(self, epochs_to_wait = 5, delta = 0):\n        self.epochs_to_wait = epochs_to_wait\n        self.delta = delta\n        self.min_test_loss = np.inf\n        self.counter = 0\n    \n    def early_stop(self, test_loss):\n        if test_loss < self.min_test_loss: \n            self.min_test_loss = test_loss\n            self.counter = 0\n        elif test_loss > (self.min_test_loss + self.delta):\n            self.counter += 1\n            if self.counter >= self.epochs_to_wait:\n                return True\n        return False\n\n    ## alternative version: \n    # def __init__(self, epochs_to_wait = 1, delta = 0):\n    #     self.epochs_to_wait = epochs_to_wait\n    #     self.delta = delta\n    #     self.min_test_loss = 0\n    #     self.counter = 0\n    #     self.early_stop = False\n\n    # def __call__(self, test_loss):\n    #     if self.min_test_loss == None:\n    #         self.min_test_loss = test_loss\n    #     elif test_loss < self.min_test_loss:\n    #         self.min_test_loss = test_loss\n    #         self.counter = 0    # reset counter to zero if test loss improves\n    #     elif test_loss > (self.min_test_loss + self.delta):\n    #         self.counter += 1\n    #         #print(f\"Early stopping counter {self.counter} of {self.epochs_to_wait}\")\n    #         if self.counter >= self.epochs_to_wait:\n    #             #print(\"Early stopping\")\n    #             self.early_stop = True\n\nearly_stopper = Early_stopping()\n\nfor i in range(len(test_epoch_loss)):\n    #early_stopper(test_epoch_loss[i])\n    print(f\"train loss: {train_epoch_loss[i]} test loss: {test_epoch_loss[i]}\")\n    if early_stopper.early_stop:\n        print(f\"early stop at epoch: {i}\")\n        break\n```\nThe code output for one of the runs in the notebook (note: epoch 0 is first epoch):\ntrain loss: 0.4035276174545288 test loss: 0.919343888759613 early stop at epoch: 0\nIt is also possible to mix checkpoints along with early stoppings in the model training loops (set up your own functions/classes according to needs), a code example will be the section on “Checkpointing with Early Stopping” from the same link as provided above.\n\n\n\nOther related readings that might be of interest\n\nunsure how useful this may be, but I happen to come across a preprint paper while working on this note and it talks about how early stopping on validation loss is likely going to lead to problems with calibration and refinement errors (components of cross-entropy), and what they’re using to overcome this (its GitHub repo)\nand I’m sure there will be others in the literatures"
  },
  {
    "objectID": "posts/22_Simple_dnn_adrs/1_ADR_data.html",
    "href": "posts/22_Simple_dnn_adrs/1_ADR_data.html",
    "title": "Notes on adverse drug reactions (ADRs) data",
    "section": "",
    "text": "Here are the notes regarding the ADRs of strong and moderate cytochrome P450 (CYP) substrates used in the data in the accompanying notebook (post version or Jupyter notebook version). The dataset currently contains ADRs for CYP3A4, 2D6, 2C19, 2C9, 1A2, 2B6, 2E1 and 2C8 substrates.\n\n\nFor columns “drug_name” and “cyp_strength_of_evidence”\nnote:\n\n“cyp_strength_of_evidence” column has been renamed as “cyp_type_and_cyp_strength_of_evidence” in the cyp_substrates_adrs.csv file to include all the different CYP enzyme substrates\n“cyp_strength_of_evidence” column is only used in cyps3a4_substrates.csv as it’s a file specifically for CYP3A4 substrates\n\nAll drug names and CYP strengths of evidence are based on the Flockhart cytochrome P450 drug-drug interaction table (Flockhart et al. 2021), which is available at https://drug-interactions.medicine.iu.edu/MainTable.aspx.\nThe strengths of evidence that a drug is metabolised by a certain CYP enzyme are categorised as below (as quoted from above web link):\n\nStrong Evidence (denoted with s_ followed by CYP name e.g. s_3A4) - the enzyme is majorly responsible for drug metabolism.\nModerate Evidence (denoted with m_ followed by CYP name e.g. m_3A4) - the enzyme plays a significant but not exclusive role in drug metabolism or the supporting literature is not extensive.\n\n\n\n\nData sources for column “drug_class”\nThis information can be found in many different national drug formularies, drug reference textbooks e.g. Martindale, American society of health-system pharmacists’ (ASHP) drug information (DI) monographs, PubChem, ChEMBL, FDA, Micromedex etc. or online drug resources such as Drugs.com. For the particular small dataset used in the notebook, and also the later expanded dataset on all CYP substrates, the ADR reference sources listed below also contain information on therapeutic drug classes for all drugs.\n\n\n\nData sources for ADRs\n\n1st-line: Drugs.com\n\nusing the health professional version for ADRs which usually contains references from pharmaceutical manufacturers’ medicines information data sheets, ASHP DI monographs or journal paper references\nreason for choosing this web data source is that it is open to public (without login registrations or paywalls) and contains the last updated date along with all references used for the ADRs information on each drug\n\n2nd-line as separate data checks:\n\nNew Zealand formulary (nzf) - mainly adapted from the British national formulary (BNF) with drug information tailored to New Zealand (NZ) populations (influenced by government funding restrictions), and likely only available to NZ residents only due to licensing restrictions, other national formularies should contain very similar drug information\nelectronic medicines compendium (emc) - United Kingdom (UK)-based drug reference; equivalents of UK/Europe-based pharmaceutical manufacturers’ medicines data sheets (note: there may be limited numbers of free access each month, and may require sign ups to access drug information)\nDrugs@FDA - United States (US)-based drug reference from the Food and Drug Administration (FDA)\ndrugs.com_uk_di - UK drug information section in Drugs.com (equivalent to pharmaceutical manufacturers’ medicines information data sheets)\npharmaceutical manufacturers’ medicines information data sheets which are referenced as “data_sheet” in the data for each drug with notes (marked with asterisks)\nreason to include a 2nd-line ADRs source is to ensure that all ADRs recorded in this dataset is clinically relevant in real-life cases (although mainly in clinical trials; but this is where postmarketing reports come into place, and also I’m attempting to use my previous on-site clinical work experience when curating the dataset). It also acts as an information accuracy check from a different, independent, trustworthy drug information source that is often referred to and used by healthcare professionals around the globe\n\ntwo main types of occurrences/frequencies used:\n^^ - common > 10%,\n^ - less common 1% to 10%,\n(not going to include other ones with lower incidences e.g. less common at 0.1% to 1% or rare for less than 0.1% etc.)\n\n\n\n\nNotes for ADRs\n\nAbout similar ADR terms\n\nall minor ADRs are removed as the current focus will be more on ADRs that’ll affect qualities of lives or are potentially more life-threatening (e.g. dry skin, acne, chills, flatulence and abdominal discomforts are removed)\nnausea and vomiting applies to many drugs so won’t be included (almost every drug will have these ADRs, they can be alleviated with electrolytes replacements and anti-nausea meds or other non-med options; rash on the other hand can sometimes be serious and life-threatening e.g. Stevens-Johnson syndrome)\nsimilar or overlapping adverse effects will be removed to keep only one adverse effect for the same drug e.g. adverse skin reactions, rash, urticaria - rash and urticaria will be removed as adverse skin reactions encompass both symptoms\nfor ADR terms with similar meanings, e.g. pyrexia/fever - fever is used instead (only one will be used); attempts have been made to use just one ADR term to represent various other similar-meaning ADRs to minimise duplications\ndeduplications of ADR data have been attempted e.g. for fatigue, malaise, lethary or asthenia, I’ve decided to use fatigue only to cover all of these similar-meaning terms; the only exception is when the same term is reported as an ADR and also during postmarketing period, then both terms are kept (there may still be some duplicated terms that I’ve missed… but this can be sorted during the data preprocessing step if needed)\n\n\n\n\nRegarding ADRs and categories\n\nADRs mentioned in common ADRs category and repeated in the less common one will have the ADR recorded in the higher incidence rate (at > 10%) only\nsome ADRs can be dose-related or formulations-related e.g. injection site irritations or allergic reactions caused by excipients/fillers, since my very initial (and naive) aim is to investigate the relationships between ADRs and drugs via computational tools e.g. any patterns between ADRs and drugs, so these types of ADRs will not be recorded in the dataset; all ADRs are currently not formulation-specific (i.e. not differentiated between solid oral dosage forms such as tablets or capsules, suspensions/liquids, subcutaneous, intravenous or intramuscular injections or topical formulations)\nSome of the ADRs recorded for some of the drugs may apply to younger or paediatrics populations only - this may need to be taken care of when using these data to build machine learning models, specific drug notes with astericks in the dataset should be in place as reminders, otherwise most of the ADRs in the datset should be mainly applicable to adult and/or paediatric populations (individual drug information data sheet should hopefully provide more details about this)\nthis current ADRs dataset has not directly considered any pharmacogenetic/pharmacogenomic factors but this may be useful and interesting to look into in the future for relevant drug projects\n\n\n\n\nFor postmarketing reports\n\nsome postmarketing adverse effects are for different age populations e.g. paediatric patients of up to 12 years of age or elderly people - for now all of them are labelled as “(pm)” to denote postmarketing reports and are not differentiated in age groups\npostmarketing reports are limited to the experiences of certain unknown population sizes using the drug, therefore it is not possible to directly extrapolate the frequencies of these reports, and also not possible to confirm a direct causal relationship between the drug and its postmarketing reports (a potential downside of the ADRs data, but with more reportings in place, there’s a larger possibility to observe common ADRs traits or trends during data analysis that may help to decode possible causes or mechanisms in the future)\nnot all postmarketing reports are included for each drug in the dataset, but only ones that are relevant clinically or mentioned in the 1st-line or in both 1st-line and 2nd-line data sources (this can be expanded further in the future if needed e.g. for investigations on postmarketing ADRs reports only)\n\n\n\n\nMore on psychiatric medicines\n\nserotonergic drugs tend to induce serotonin syndrome (e.g. tremor, ataxia, restlestness, shivering, sweating, fever, tachycardia, tachypnoea, confusion, agitation, coma) especially if used in combinations concomitantly (monotherapy tends to have smaller risk)\ntypical ADRs of antipsychotics drugs can include extrapyramidal symptoms (parkinsonian symptoms e.g. tremors, dystonias or dyskinesia (abnormal muscular spasms), akathisia (restlessness) and tardive dyskinesia (most significant antipsychotic ADR causing abnormal involuntary movements of face, jaw and tongue; common in first generation antipsychotics)), constipation, sexual dysfunction, cardiovascular adverse effects, hyperglycaemia, problem with body temperature regulations and neuroleptic malignant syndrome (usually rare but potentially can be fatal)\n\n\n\n\nOther bits and pieces\n\none other thing I’d like to mention is that all the ADRs recorded in this repository are not merely a copy-and-paste action from the drug reference sources, they also include or are integrated with the ones I’ve encountered from my previous pharmacist work experience (in the hope to better reflect bedside or clinical ADRs, and this is also why collecting data has been taking a long time…)\none last thing to mention is that all the ADRs in the dataset are in US spellings, but this note and also any other notebooks or associated posts will be written in my more familiar UK/NZ-based spellings (in case anyone’s wondering)\n\n\n\n\nNotes for specific selected drugs\nnote: list of drugs not in alphabetical order; quick links for each drug in table of contents on the right\n\n\nhydrocortisone\n\nA moderate CYP3A4 substrate with no reported ADR frequencies at all for its ADRs as they are entirely dependent on the dosage and duration of use (ADRs tend to be unnoticeable at appropriate low doses for short durations)\n\n\n\nterfenadine\n\nA strong CYP3A4 substrate that is actually withdrawn from the market in 1990s due to QT prolongations\n\n\n\nlercanidipine\n\nA moderate CYP3A4 substrate that has nil reported ADRs of more than 1% but has a few postmarketing reports recorded\n\n\n\ntelaprevir\n\nA moderate CYP3A4 substrate that is usually administered within a combination therapy (e.g. along with peginterferon alfa and ribavirin)\n\n\n\nquinine\n\nA moderate CYP3A4 substrate that has all of its ADRs reported without frequencies. The most common ADRs are presented as a cluster of symptoms (known as cinchonism) and can occur during overdoses (usually very toxic) and also normal doses. These symptoms include “…tinnitus, hearing impairment, headache, nausea, vomiting, abdominal pain, diarrhoea, visual disturbances (including blindness), arrhythmias (which can have a very rapid onset), convulsions (which can be intractable), and rashes.” (as quoted from NZ formulary v150 - 01 Dec 2024)\n\n\n\nribociclib\n\nA moderate CYP3A4 substrate that has a listed ADR of on-treatment deaths, which were found to be associated with patients also taking letrozole or fulvestrant at the same time and/or in patients with underlying malignancy\n\n\n\nnortriptyline\n\nA strong CYP2D6 substrate with no frequencies recorded for all of its ADRs - the recorded ADRs in files will be mainly based on nzf which has stated these ADRs as common ones with varying risk and extent, a good rule of thumb is to be aware of the well-known tricyclic antidepressant-related ADRs e.g. antimuscarinic effects (dry mouth, blurred vision, constipation, urinary retention)\n\n\n\nperhexiline\n\nA strong CYP2D6 substrate with no records of medicines information in Drugs@FDA or Drugs.com so the main source of drug information is nzf and its pharmaceutical manufacturer’s medicines data sheet. The ADRs may be present for the first two to four weeks of treatment only\n\n\n\nescitalopram\n\nA moderate CYP2D6 substrate that is also known to induce selective serotonin reuptake inhibitor-related hyponatraemia (through inappropriate antidiuretic hormone secretion) when certain risk factors are also present at the same time e.g. diuretic use, female gender, low body weight, geriatric populations along with low baseline sodium level\n\n\n\nlidocaine\n\nA moderate CYP2D6 substrate that doesn’t have ADR frequencies recorded - ADRs for amide local anaesthetics apply instead (mainly central nervous and cardiovascular system-related) and toxicity is commonly dose-dependent (e.g. increased risk due to high plasma concentration); hypersensitivity reactions may sometimes be due to preservatives used (e.g. parabens)\n\n\n\nmetoclopramide\n\nA moderate CYP2D6 substrate that has ADRs of acute dystonic reaction and extrapyramidal disorders - more details about extrapyramidal effects here and this one about dystonic reactions\n\n\n\ncyclophosphamide\n\nA moderate CYP2C19 substrate that is also a cytotoxic drug in the class of aklyating agents. One of its notable ADRs is urothelial toxicity (presented as haemorrhagic cystitis) caused by acrolein (its urinary metabolite via hepatic metabolism). Ways to alleviate this is to increase fluid intake for at least 24 to 48 hours after intravenous injection or use mesna. High dose of cyclophosphamide may also cause cardiotoxicity\n\n\n\nr-mephobarbital\n\nA strong CYP2C19 substrate, manufactured previously as mephobarbital (also known as methylphenobarbital), is currently not commonly prescribed (discontinued from 2011-12). One of the likely reasons could be due to its metabolism by CYP enzymes to phenobarbital, which is also available as an antiepileptic drug. Other possible reasons are its higher risk from overdose and drug dependency, so often barbiturate-based drug is replaced with other antiepileptics or non-antiepileptics instead depending on indications. Its ADRs is based on this medicines data sheet link from its last pharmaceutical manufacturer (Lundbeck Inc.)\n\n\n\nflurbiprofen\n\nA moderate CYP2C9 substrate and also one of the non-steroidal anti-inflammatory drugs known to be associated with cardiovascular, gastrointestinal (cyclo-oxygenase-2 selective inhibitors may have lower risk) and renal-related risks, therefore most of the ADRs and postmarketing reports recorded will focus on these physiological influences mainly\n\n\n\nglimepiride\n\nA moderate CYP2C9 substrate which is also one of the sulfonylureas used for blood glucose control in type-2 diabetics. One of its postmarketing reports of “disulfiram-like reaction” is about the unpleasant effects (e.g. facial flushing, headache, palpitations, tachycardia) experienced after alcohol consumption (note: disulfiram is another drug often used for treating alcohol dependence)\n\n\n\nglyburide\n\nA moderate CYP2C9 substrate which is also known as glibenclamide in some of the countries around the world\n\n\n\nphenytoin\n\nA moderate CYP2C9 substrate that may cause severe cutaneous adverse reactions (SCAR), e.g. drug reaction with eosinophilia and systemic symptoms, Stevens-Johnson syndrome, toxic epidermal necrolysis, erythema multiforme, and acute generalised exanthematous pustulosis, which may require closer monitoring and drug discontinuation if required. Its occurrence is more likely in a genetic population with a particular human leukocyte antigen (HLA) allele present e.g. HLA-B^*15:02\n\n\n\nwarfarin\n\nA moderate CYP2C9 substrate that doesn’t have any ADR frequencies recorded as it’s a well-known vitamin K antagonist, often used as an oral anticoagulant, with a prominent ADR of causing fatal or non-fatal organ or tissue haemorrhage. The best strategy to prevent any haemorrhagic events is to monitor via international normalised ratio (INR) testing\n\n\n\ncaffeine\n\nA strong CYP1A2 substrate which is normally quite well tolerated orally; the ADRs recorded in the dataset here is mostly based on caffeine citrate 20mg/mL injection, which is often used in premature infants and may not be applicable to other populations\n\n\n\nclozpine\n\nA strong CYP1A2 substrate that is one of the second generation or atypical antipsychotics with many ADRs requiring close monitoring e.g. frequencies of bowel motions (contipation is one of the common ADRs that is potentially fatal), white cell counts and cardiac toxicity-related symptoms and/or cardiovascular-related lab marker changes; people with pre-existing diabetes or liver diseases are also prone to ADRs related to these diseases while on clozapine\n\n\n\nmelatonin\n\nA strong CYP1A2 substrate that has no ADRs with frequencies above 10% as it’s normally quite well tolerated at appropriate dose for short-term use (e.g. 3 months)\n\n\n\npomalidomide\n\nA moderate CYP1A2 substrate which is also an immunomodulating drug that has antineoplastic property to treat relapsed multiple myeloma and is structurally related to thalidomide\n\n\n\ntacrine\n\nA strong CYP1A2 substrate that has been withdrawn from the US market in May 2012. An archived LiverTox reference has explained in details about the highly common hepatoxicity caused by tacrine which eventually led to the market withdrawal of this drug (while there are also other anticholinesterase inhibitors available for use). For exact drug information references used by Drugs.com for the ADRs of tacrine, here’s a list of references (which included the old pharmaceutical manufacturer’s data sheet)\n\n\n\ntheophylline\n\nA moderate CYP1A2 substrate with ADRs that are more likely to occur in overdoses (therapeutic drug monitoring is recommended as therapeutic and toxic doses may be very close to each other)\n\n\n\nbupropion\n\nA strong CYP2B6 substrate that is also used for smoking cessation\n\n\n\nefavirenz\n\nA strong CYP2B6 substrate that has a very common ADR of rash that often occurs in the first 2 weeks of treatment, it could be minor if there are no blistering, desquamations or any other widespread signs and the drug can be continued with symptoms disappearing usually after about a month; alternatively, if the symptoms are severe, the drug should be discontinued. Central nervous system-type ADRs will usually slowly improve after continuous use of drug, but if there are pre-existing psychiatric conditions, the risk of psychiatric ADRs may need to be further considered before initiating or continuing the drug\n\n\n\nisoflurane\n\nA strong CYP2E1 substrate which is also a type of inhalational anaesthetic agent (in volatile liquid form) that is normally administered through vaporiser and requires highly trained staff for administration and resuscitation if needed\n\n\n\ncerivastatin\n\nA strong CYP2C8 substrate that has been withdrawn from the market since 2001 due to serious adverse effect of rhabdomyolysis leading to kidney failure and subsequently reported deaths (reference or alternative link)\n\n\n\nenzalutamide\n\nA moderate CYP2C8 substrate with a known postmarketing ADR report of posterior reversible encephalopathy syndrome, which include symptoms such as seizure, headache, confusion, other visual and neurological disturbances with or without associated hypertension (more details here or alternative link)\n\n\n\nrosiglitazone\n\nA moderate CYP2C8 substrate that has an ADR of increasing the risk of congestive heart failure and heart attack reported from postmarketing use and also one of its earlier clinical trials. It was withdrawn for medical use in several countries back in 2011 but US continued its use with restrictions and further removed the restriction (reference) when the drug was found not to increase cardiovascular risk in another clinical trial. Currently, the cardiovascular risk is still recommended to be considered before use\n\n\n\ntucatinib\n\nA moderate CYP2C8 substrate that has been tested along with trastuzumab and capecitabine in clinical trials, therefore its ADRs are based on these combination of treatments, and not solely on tucatinib. One of its ADRs, palmar plantar erythrodysesthesia syndrome is also known as hand-foot syndrome or chemotherapy-induced acral erythema, with symptoms such as tingling, numbness and redness of palms and soles (reference)\n\n\n\n\n\nAbbreviations used\nnote: not in alphabetical order\n\nws = withdrawal symptoms\nADH = antidiuretic hormone\npm = postmarketing reports\nCNS = central nervous system\nCFTR = cystic fibrosis transmembrane regulator\nc_diff = Clostridioides/Clostridium difficile\nZE = Zollinger-Ellison\nMTOR = mammalian target of rapamycin (protein kinase)\nAST = aspartate transaminase/aminotransferase\nALT = alanine transaminase/aminotransferase\nALP = alkaline phosphatase\nGGT = gamma-glutamyltransferase\nRTI = respiratory tract infection\nUTI = urinary tract infection\nLDH = lactate dehydrogenase\ndd = dose and duration-dependent\npm_HIV_pit = postmarketing reports for HIV protease inhibitor therapy\npm_hep_cyto = postmarketing reports in cancer patients where drug was taken with hepatotoxic/cytotoxic chemotherapy and antibiotics\nBUN = blood urea nitrogen\nNMS = neuroleptic malignant syndrome\nECG = electrocardiogram\nCPK = creatine phosphokinase\nINR = international normalised ratio\nLFT = liver funtion tests\nDRESS = drug reaction with eosinophilia and systemic symptoms\nWBC = white blood cells\nRBC = red blood cells\nIFIS = intraoperative floppy iris syndrome\nLVEF = left ventricular ejection fraction\nAGEP = acute generalized exanthematous pustulosis\nCOX-2 = cyclo-oxygenase-2\nNSAIDs = non-steroidal anti-inflammatory drugs\nSIADH = syndrome of inappropriate antidiuretic hormone secretion\nG6PD = glucose-6-phosphate dehydrogenase\nAV = atrioventricular\nSCAR = severe cutaneous adverse reactions\nGI = gastrointestinal\nEEG = electroencephalogram\nod = overdose\nNNRTIs = non-nucleoside reverse transcriptase inhibitors\nHDL = high-density lipoprotein\nPRES = posterior reversible encephalopathy syndrome\nCVS = cardiovascular\nTSH = thyroid stimulating hormone\nGERD = gastroesophageal reflux disease (also known as “GORD” due to alternative spelling of “gastro-oesophageal”)\nAF = atrial fibrillation\n\n\n\n\n\n\nReferences\n\nFlockhart, DA., D. Thacker, C. McDonald, and Z. Desta. 2021. “The Flockhart Cytochrome P450 Drug-Drug Interaction Table.” https://drug-interactions.medicine.iu.edu/."
  },
  {
    "objectID": "posts/02_Long_COVID_dashboard/Tableau_dashboard.html",
    "href": "posts/02_Long_COVID_dashboard/Tableau_dashboard.html",
    "title": "Long COVID dashboard",
    "section": "",
    "text": "Introduction\nThis project1 was entirely self-motivated and out of personal interests since COVID has widely and deeply affected many people nowadays. I was also learning Tableau while I worked on this project. This has also made me realised that I might have started from the harder end first by learning Python programming language first in 2019 and then picking up the rest of the data analytics tools towards late 2021. It was completely interesting and absolutely fascinating at how different softwares vary but with common themes in mind.\n Image: Rawpixel.com\n\n\nSource of dataset\nThe source of the dataset was from a relatively recent live systemic review paper: Michelen M, Manoharan L, Elkheir N, et al. Characterising long COVID: a living systematic review. BMJ Global Health 2021;6:e005427\n\n\nProject link\nThis project can be accessed at this link from Tableau Public.\n\n\nSummary\nThe data from this paper have shown a very heterogeneous variety of long COVID-related signs and symptoms. Among them, it appeared that female gender had higher risk of suffering from long COVID than the male populations. Other factors that might have contributed to higher risk of suffering from long COVID were people who were above 60-65 years old and also people who have multiple chronic illnesses such as cardiovascular diseases and diabetes. Since this paper only focussed on dataset up until March 2021, more recent variants of COVID would not be covered in the dataset, therefore, more work would be required to look into the long COVID risk inflicted by more recent COVID variants.\n\n\n\n\n\nFootnotes\n\n\nThe published date reflected the last day I worked on the associated files for this project, prior to the blog move. This work is under CC BY-SA 4.0 International License for anyone interested in exploring the topic further.↩︎"
  },
  {
    "objectID": "posts/Blog-Data_analytics/Focussing_on_data_analytics.html",
    "href": "posts/Blog-Data_analytics/Focussing_on_data_analytics.html",
    "title": "Focussing on data analytics",
    "section": "",
    "text": "So after a short period of trials and errors of job applications with serious thoughts into a career change, I’m planning to go for the more practical and realistic approach – starting from an entry-level data analyst role. However, I’m aware that I’ll need to build up a relatively decent portfolio of data analytics work before I’ll even be able to reach that very first stage.\n\n\n\nPhoto by Tobias Fischer on Unsplash\n\n\nSo I’m planning to work on other projects at the moment that are not from my certificate course, but are self-motivated ones which would be more relevant to data science and analytics and the ones that I have personal interests in. New projects will be showcased in the portfolio section when they’re ready. The most current one would be the Tableau project about characterising long COVID symptoms (more on this in portfolio section)."
  },
  {
    "objectID": "posts/Blog-Social_network/Embracing_social_network.html",
    "href": "posts/Blog-Social_network/Embracing_social_network.html",
    "title": "Embracing social network",
    "section": "",
    "text": "I’ve managed to post my first ever tweet on Twitter yesterday on the R project I’ve done recently on rare disease drugs. I’m not used to posting anything on social media as I almost always prefer to stay low-profile, rather than the opposite, and this may not be a good thing especially if I’m trying to transition into a different job field. So I did it finally…\n\n\n\nPhoto by visuals on Unsplash\n\n\nOne of the reasons that I’ve finally decided to post on Twitter is that I’ve heard about the active and friendly R community on Twitter and thought if I could get any feedbacks on my short piece of work in R then that’ll be helpful for me to see if I’ve missed or done anything incorrectly since there’s not really a mentor person around that is able to do this at the moment (I’ve dreadfully taken the self-learning route, rather than attending data science bootcamps or get “another” degree, which is something I’m not really fancied at doing again, after already having MPhil and PhD already…). Luckily, I did get one helpful response and with a small number of likes so perhaps I’m not doing it entirely wrong (hopefully). My future plans will likely be trying to do a #TidyTuesday data visualisation and post whenever I can to learn and grow.\nI’ve also recently edited my rare disease drug projects in R and Python to add summaries of findings from these two projects so it’s easier for anyone to read, especially if there’s not really much time to go through long threads of codes in GitHub. I’m also currently working on another project in the rare diseases series on phenotypes associated with rare diseases from Orphanet. My plan at the moment is to use Python to clean the data (I’ve tried to load it in RStudio via a URL with XML file, it’s >4000 rows and taking quite a long time to run on my laptop, so will stick to Python on Anaconda as it has loaded a lot faster than RStudio, then perhaps once it’s cleaned, I’ll re-import it back into RStudio for analysis and visualisations)."
  },
  {
    "objectID": "posts/13_Shiny_app_python/ShinyAppPy_PC_Cov19_app_embed.html",
    "href": "posts/13_Shiny_app_python/ShinyAppPy_PC_Cov19_app_embed.html",
    "title": "Shinylive app in Python",
    "section": "",
    "text": "Coding for Shinylive app in Python\nThe entire code for this Shiny app in Python were written in VS Code initially. When I was looking for places to deploy the app, I then migrated the code to RStudio IDE (note: recently I saw Python code in Quarto documents being used in VS Code after I’ve deployed this app, so this might be another option).\nFor data preparation stage, please visit this post for details.\n\n\nTrialling open-source large-language models\nThere have been a lot of hypes surrounding large-language models (LLMs) or generative pre-trained transformers (GPTs). I’m still somewhat both reserved and excited about them at present. The area I’m most concerned with is where are the relevant laws, regulations and ethics on using these tools in public domains, whether for private or commercial uses, and will they be country-specific or globally streamlined? While I have these questions in mind, I’m not denying the fact that they can be useful for a few well-known purposes in coding, such as requesting for regex code templates for text cleaning or asking for code snippets while programmers are busy with several tasks at the same time.\nI thought to trial out the open-source LLMs a little bit when I was working on this app, since they were the open and transparent versions with potentials for personal or commercial uses. So I’ve tested about 3 different open-source LLMs, which were H2OGPT, HuggingChat and StableLM. I decided to only give minimal amount of prompts (I’ve given H2OGPT three prompts, and only one prompt each for either HuggingChat and StableLM), and the question was framed around providing a code outline for building a Shiny app using Python and Polars dataframe libary, and see what answers they could each provide.\nAll of them produced answers that were close to what I’ve asked for, i.e. I could see a code outline for a Shiny app.py file at first but it was more like R code, with one case mixing both Python and R in the code concurrently. However, none of them actually reached exactly how I’ve asked them to provide, perhaps if I’ve given more prompts then they might manage to provide answers closer to the request. Also, none of them were able to pick up the more recent Polars dataframe library (which were probably more prominent from 2021 onwards) and also Shiny in Python (which was also quite new as well, only out of alpha phase recently). All of them only showed code using Pandas dataframe libray, even though I did mention Polars in all of the question prompts. Once I get to use more of these open-source LLMs in the future, which currently are gaining more traction from what I’ve read online, I think I might try to write another post about them later.\n\n\n\nUsing Shiny in Python documentations\nAfter trialling open-source LLMs a bit to help with the coding part (although not as helpful as I first imagined, but they still somewhat provided a rough code framework for Shiny apps), I completed the app.py script in the end by using mainly documents from Shiny for Python website. I still think thorough documentations for any products are still fundamental and inevitable, because these documentations will be sources to provide high-quality data for training these LLMs which means they’ll be of higher quality too.\nSeveral links I’ve used and found to be very informative:\n\n“Shiny for Python out of alpha” - quick summary on recent status update and new features such as shinyswatch and shinywidgets on Shiny for Python\n“Quickstart for R users” - a very useful link for people who are R users or already familiar with Shiny apps in R, and would like to build Shiny apps in Python\n“Shinylive: Shiny + WebAssembly” - great for understanding Shinylive\n“Shinylive applications embedded in Quarto documents” - this is all about embedding shinylive app in Quarto - the webpage link provided here is from this GitHub repository on Quarto extension for shinylive\n\n\n\n\n\nApp deployment\nAfter building the app in a workable condition, I started looking at where and how to deploy this Shiny app written in Python. Initially I used the easiest method as stated from the Shinylive link above, which was to deploy on Shinylive editor. One drawback for this was that the application URL was extremely long as the URL hash would store the entire app code inside. However, this was indeed one of the simplest ways to share the apps with others quickly, by simply providing the URL link with the intended audience.\nI then went on to try another method where I spent one afternoon trying to figure out that I had to add an install_certificate.command for my operating system since I installed Python by using Homebrew in the first place (which some clever users might already know to avoid…), so that I could resolve the SSL certificate issue if I’m trying to connect with Shinyapps.io.\nI also tried to follow another method from an earlier time which suggested to deploy the app directly on GitHub Pages, but since then the code was changed and updated to a different version and the old method no longer worked as nicely as mentioned (a lot of the code for Shiny in Python can still be experimental, and can change drastically, so check the sources to see the latest updates). I then stumbled upon another GitHub repository from the Quarto team at Posit/RStudio and looked into the possibility and tested it. Eventually, I settled on this method - embedding the app in a Quarto document, which provided both code and app itself on this very same webpage down below.\nOne of the downsides of the following code that I couldn’t quite get rid of yet was the poor file importation style. for loading a .csv file locally. I’ve added code annotations as comments to explain what I’ve done. The solution to import .csv file into app.py for the embedding version was from this discussion in the repository (thanks to that particular user who found this hacky way to do it). However, the plus side was that coding for the rest of the app was not bad at all and worked seamlessly. I’ll try to follow up later on whether importing .csv file for app embedding could be easier, perhaps this might be something the Quarto team is working right now.\nThe second downside was that shinyswatch package might not be functional yet for this embedding method (but most likely would work if deploying apps to shinyapps.io). This meant there would be no background visual themes yet for apps embedded in Quarto docs, but hopefully this would be possible in the future. Overall, I was amazed at how easy it was to build, deploy and embed a Shiny app in Python in a Quarto document.\nNote: if using Shinylive editor, make sure to include a requirement.txt file if using extra Python packages such as Pandas or Plotly. For embedding apps in Quarto docs, this appears not to be compulsory and only optional when I tried it down below.\nCode for this post (.qmd document) is available here.\n\n\nShinylive app in action\nNote: it may take a few minutes to load the app (code provided at the top, with app at the bottom).\nUpdate on 24/5/23: to avoid manual file input, see this updated post which uses pyodide.http.open_url() method (code change in editor section).\n\n#| standalone: true\n#| components: [editor, viewer]\n#| layout: vertical\n#| viewerHeight: 420\n\n## file: app.py\n# ***Import all libraries or packages needed***\n# Import shiny ui, app\nfrom shiny import ui, App\n# Import shinywidgets\nfrom shinywidgets import output_widget, render_widget\n# Import shinyswatch to add themes\n#import shinyswatch\n# Import plotly express\nimport plotly.express as px\n# Import pandas\nimport pandas as pd\nfrom pathlib import Path\n\n\n# User interface---\n# Add inputs & outputs\napp_ui = ui.page_fluid(\n        # Add theme - seems to only work in VS code and shinyapps.io\n        #shinyswatch.theme.superhero(),\n        # Add heading\n        ui.h3(\"Molecular properties of compounds used in COVID-19 clinical trials\"),\n        # Place selection boxes & texts in same row\n        ui.row(\n            # Divide the row into two columns\n            # Column 1 - selection drop-down boxes x 2\n            ui.column(\n                4, ui.input_select(\n                # Specify x variable input\n                \"x\", label = \"x axis:\", \n                choices = [\"Partition coefficients\", \n                           \"Complexity\",\n                           \"Heavy atom count\",\n                           \"Hydrogen bond donor count\",\n                           \"Hydrogen bond acceptor count\",\n                           \"Rotatable bond count\",\n                           \"Molecular weight\",\n                           \"Exact mass\", \n                           \"Polar surface area\", \n                           \"Total atom stereocenter count\", \n                           \"Total bond stereocenter count\"],\n                ), \n                ui.input_select(\n                # Specify y variable input\n                \"y\", label = \"y axis:\",\n                choices = [\"Partition coefficients\", \n                           \"Complexity\",\n                           \"Heavy atom count\",\n                           \"Hydrogen bond donor count\",\n                           \"Hydrogen bond acceptor count\",\n                           \"Rotatable bond count\", \n                           \"Molecular weight\",\n                           \"Exact mass\", \n                           \"Polar surface area\", \n                           \"Total atom stereocenter count\", \n                           \"Total bond stereocenter count\"]  \n                )),\n            # Column 2 - add texts regarding plots\n            ui.column(\n            8,\n            ui.p(\"Select different molecular properties as x and y axes to produce a scatter plot.\"),\n            ui.tags.ul(\n                ui.tags.li(\n                    \"\"\"\n                    Part_coef_group means groups of partition coefficient (xlogp) as shown in the legend on the right\"\"\" \n                ), \n                ui.tags.li(\n                    \"\"\"\n                    Toggle each partition coefficient category by clicking on the group names\"\"\"\n                ), \n                ui.tags.li(\n                    \"\"\"\n                    Hover over each data point to see compound name and relevant molecular properties\"\"\"\n                )\n            )),\n        # Output as a widget (interactive plot)\n        output_widget(\"my_widget\"), \n        # Add texts for data source\n        ui.row(\n            ui.p(\n                \"\"\"\n                Data curated by PubChem, accessed from: https://pubchem.ncbi.nlm.nih.gov/#tab=compound&query=covid-19%20clinicaltrials (last access date: 30th Apr 2023)\"\"\" \n            )         \n        ) \n    )\n)\n\n\n# Server---\n# Add plotting code within my_widget function within the server function\ndef server(input, output, session):\n    @output\n    @render_widget\n    def my_widget():\n        fig = px.scatter(\n            df, x = input.x(), y = input.y(),\n            color = \"Part_coef_group\", \n            hover_name = \"Compound name\"\n        )\n        fig.layout.height = 400\n        return fig\n        \n# Combine UI & server into Shiny app\napp = App(app_ui, server)\n\n\n# ***Specify data source***\n# --Not the best approach yet but works for now--\n# Currently this work-around only suits small to medium-size dataset\n# Not ideal for large dataset for sure\n# To load file locally use the following code\ninfile = Path(__file__).parent / \"pc_cov_pd.csv\"\ndf = pd.read_csv(infile)\n\n# Then manually paste in csv/txt file below\n## file: pc_cov_pd.csv\n,Compound name,Molecular weight,Polar surface area,Complexity,Partition coefficients,Heavy atom count,Hydrogen bond donor count,Hydrogen bond acceptor count,Rotatable bond count,Exact mass,Monoisotopic mass,Formal charge,Covalently-bonded unit count,Isotope atom count,Total atom stereocenter count,Defined atom stereocenter count,Undefined atoms stereocenter count,Total bond stereocenter count,Defined bond stereocenter count,Undefined bond stereocenter count,Part_coef_group\n0,Calcitriol,416.6,60.7,688.0,5.1,30,3,3,6,416.329,416.329,0,1,0,6,6,0,2,2,0,Larger than 6\n1,Ubiquinol,865.4,58.9,1600.0,20.2,63,2,4,31,864.7,864.7,0,1,0,0,0,0,9,9,0,Larger than 6\n2,Glutamine,146.14,106.0,146.0,-3.1,10,3,4,4,146.069,146.069,0,1,0,1,1,0,0,0,0,Between -11 and 5\n3,Aspirin,180.16,63.6,212.0,1.2,13,1,4,3,180.042,180.042,0,1,0,0,0,0,0,0,0,Between -11 and 5\n4,1-Methylnicotinamide,137.16,47.0,136.0,-0.1,10,1,1,1,137.071,137.071,1,1,0,0,0,0,0,0,0,Between -11 and 5\n5,Losartan,422.9,92.5,520.0,4.3,30,2,5,8,422.162,422.162,0,1,0,0,0,0,0,0,0,Between -11 and 5\n6,Vitamin E,430.7,29.5,503.0,10.7,31,1,2,12,430.381,430.381,0,1,0,3,3,0,0,0,0,Larger than 6\n7,Nicotinamide,122.12,56.0,114.0,-0.4,9,1,2,1,122.048,122.048,0,1,0,0,0,0,0,0,0,Between -11 and 5\n8,Adenosine,267.24,140.0,335.0,-1.1,19,4,8,2,267.097,267.097,0,1,0,4,4,0,0,0,0,Between -11 and 5\n9,Inosine,268.23,129.0,405.0,-1.3,19,4,7,2,268.081,268.081,0,1,0,4,4,0,0,0,0,Between -11 and 5\n10,Nicotinamide riboside,255.25,117.0,314.0,-1.8,18,4,5,3,255.098,255.098,1,1,0,4,4,0,0,0,0,Between -11 and 5\n11,Dimethyl Fumarate,144.12,52.6,141.0,0.7,10,0,4,4,144.042,144.042,0,1,0,0,0,0,1,1,0,Between -11 and 5\n12,Inosinic acid,348.21,176.0,555.0,-3.0,23,5,10,4,348.047,348.047,0,1,0,4,4,0,0,0,0,Between -11 and 5\n13,Acetyl-L-carnitine,203.24,66.4,214.0,0.4,14,0,4,5,203.116,203.116,0,1,0,1,1,0,0,0,0,Between -11 and 5\n14,Camostat,398.4,137.0,602.0,1.1,29,2,6,9,398.159,398.159,0,1,0,0,0,0,0,0,0,Between -11 and 5\n15,Estradiol,272.4,40.5,382.0,4.0,20,2,2,0,272.178,272.178,0,1,0,5,5,0,0,0,0,Between -11 and 5\n16,Aspartic Acid,133.1,101.0,133.0,-2.8,9,3,5,3,133.038,133.038,0,1,0,1,1,0,0,0,0,Between -11 and 5\n17,Ribavirin,244.2,144.0,304.0,-1.8,17,4,7,3,244.081,244.081,0,1,0,4,4,0,0,0,0,Between -11 and 5\n18,Angiotensin (1-7),899.0,380.0,1660.0,-3.0,64,12,14,25,898.466,898.466,0,1,0,8,8,0,0,0,0,Between -11 and 5\n19,alpha-Maltose,342.3,190.0,382.0,-4.7,23,8,11,4,342.116,342.116,0,1,0,10,10,0,0,0,0,Between -11 and 5\n20,Ambrisentan,378.4,81.5,475.0,3.8,28,1,6,7,378.158,378.158,0,1,0,1,1,0,0,0,0,Between -11 and 5\n21,Ciclosporin,1202.6,279.0,2330.0,7.5,85,5,12,15,1201.84,1201.84,0,1,0,12,12,0,1,1,0,Larger than 6\n22,Ergocalciferol,396.6,20.2,678.0,7.4,29,1,1,5,396.339,396.339,0,1,0,6,6,0,3,3,0,Larger than 6\n23,Docosahexaenoic Acid,328.5,37.3,462.0,6.2,24,1,2,14,328.24,328.24,0,1,0,0,0,0,6,6,0,Larger than 6\n24,Tacrolimus,804.0,178.0,1480.0,2.7,57,3,12,7,803.482,803.482,0,1,0,14,14,0,2,2,0,Between -11 and 5\n25,Budesonide,430.5,93.1,862.0,2.5,31,2,6,4,430.236,430.236,0,1,0,9,8,1,0,0,0,Between -11 and 5\n26,Calcifediol,400.6,40.5,655.0,6.2,29,2,2,6,400.334,400.334,0,1,0,5,5,0,2,2,0,Larger than 6\n27,Cepharanthine,606.7,61.9,994.0,6.5,45,0,8,2,606.273,606.273,0,1,0,2,2,0,0,0,0,Larger than 6\n28,Cholecalciferol,384.6,20.2,610.0,7.9,28,1,1,6,384.339,384.339,0,1,0,5,5,0,2,2,0,Larger than 6\n29,Coenzyme Q10,863.3,52.6,1840.0,19.4,63,0,4,31,862.684,862.684,0,1,0,0,0,0,9,9,0,Larger than 6\n30,Tacrolimus monohydrate,822.0,179.0,1480.0,,58,4,13,7,821.493,821.493,0,2,0,14,14,0,2,2,0,Larger than 6\n31,Alisporivir,1216.6,279.0,2360.0,7.9,86,5,12,15,1215.86,1215.86,0,1,0,13,13,0,1,1,0,Larger than 6\n32,Pacritinib,472.6,68.7,644.0,3.8,35,1,7,4,472.247,472.247,0,1,0,0,0,0,1,1,0,Between -11 and 5\n33,Topotecan,421.4,103.0,867.0,0.5,31,2,7,3,421.164,421.164,0,1,0,1,1,0,0,0,0,Between -11 and 5\n34,Voclosporin,1214.6,279.0,2380.0,7.9,86,5,12,16,1213.84,1213.84,0,1,0,12,12,0,1,1,0,Larger than 6\n35,\"(1R,4S,5'S,6R,6'R,8R,10E,12S,13S,14E,16E,20R,21R,24S)-6'-[(2R)-Butan-2-yl]-21,24-dihydroxy-12-[(2R,4S,5S,6S)-5-[(2S,4S,5S,6S)-5-hydroxy-4-methoxy-6-methyloxan-2-yl]oxy-4-methoxy-6-methyloxan-2-yl]oxy-5',11,13,22-tetramethylspiro[3,7,19-trioxatetracyclo[15.6.1.14,8.020,24]pentacosa-10,14,16,22-tetraene-6,2'-oxane]-2-one\",875.1,170.0,1680.0,4.1,62,3,14,8,874.508,874.508,0,1,0,20,20,0,3,3,0,Between -11 and 5\n36,Oxytocin,1007.2,450.0,1870.0,-2.6,69,12,15,17,1006.44,1006.44,0,1,0,9,9,0,0,0,0,Between -11 and 5\n37,\"(1R,4S,6R,10E,14E,16E,21R)-6'-butan-2-yl-21,24-dihydroxy-12-[(2R,4S,6S)-5-[(2S,4S,6S)-5-hydroxy-4-methoxy-6-methyloxan-2-yl]oxy-4-methoxy-6-methyloxan-2-yl]oxy-5',11,13,22-tetramethylspiro[3,7,19-trioxatetracyclo[15.6.1.14,8.020,24]pentacosa-10,14,16,22-tetraene-6,2'-oxane]-2-one\",875.1,170.0,1680.0,4.1,62,3,14,8,874.508,874.508,0,1,0,20,10,10,3,3,0,Between -11 and 5\n38,\"Manganese, dichloro((4aS,13aS,17aS,21aS)-1,2,3,4,4a,5,6,12,13,13a,14,15,16,17,17a,18,19,20,21,21a-eicosahydro-7,11-nitrilo-7H-dibenzo(b,H)-5,13,18,21-tetraazacycloheptadecine-kappaN5,kappaN13,kappaN18,kappaN21,kappaN22)-, (pb-7-11-2344'3')-\",483.4,61.0,381.0,,29,4,7,0,482.165,482.165,0,4,0,4,4,0,0,0,0,Larger than 6\n39,Ivermectin B1a,875.1,170.0,1680.0,4.1,62,3,14,8,874.508,874.508,0,1,0,20,20,0,3,3,0,Between -11 and 5\n40,Dipyridamole,504.6,145.0,561.0,0.7,36,4,12,12,504.317,504.317,0,1,0,0,0,0,0,0,0,Between -11 and 5\n41,Tetrandrine,622.7,61.9,979.0,6.4,46,0,8,4,622.304,622.304,0,1,0,2,2,0,0,0,0,Larger than 6\n42,Sirolimus,914.2,195.0,1760.0,6.0,65,3,13,6,913.555,913.555,0,1,0,15,15,0,4,4,0,Larger than 6\n43,Iloprost,360.5,77.8,606.0,2.8,26,3,4,8,360.23,360.23,0,1,0,6,5,1,2,2,0,Between -11 and 5\n44,Ramipril,416.5,95.9,619.0,1.4,30,2,6,10,416.231,416.231,0,1,0,5,5,0,0,0,0,Between -11 and 5\n45,Prasugrel hydrochloride,409.9,74.8,555.0,,27,1,6,6,409.091,409.091,0,2,0,1,0,1,0,0,0,Larger than 6\n46,Uproleselan,1304.5,383.0,1870.0,-2.0,90,9,27,52,1303.72,1303.72,0,1,0,15,15,0,0,0,0,Between -11 and 5\n47,MET-enkephalin,573.7,225.0,847.0,-2.1,40,7,9,16,573.226,573.226,0,1,0,3,3,0,0,0,0,Between -11 and 5\n48,\"(18Z)-1,14-dihydroxy-12-[(E)-1-(4-hydroxy-3-methoxycyclohexyl)prop-1-en-2-yl]-23,25-dimethoxy-13,19,21,27-tetramethyl-17-prop-2-enyl-11,28-dioxa-4-azatricyclo[22.3.1.04,9]octacos-18-ene-2,3,10,16-tetrone\",804.0,178.0,1480.0,2.7,57,3,12,7,803.482,803.482,0,1,0,14,0,14,2,2,0,Between -11 and 5\n49,\"(1R,4S,5'S,6R,6'R,8R,10E,13S,14E,16E,20R,21R,24S)-6'-[(2S)-butan-2-yl]-21,24-dihydroxy-12-[(2R,4S,5S,6S)-5-[(2S,4S,5S,6S)-5-hydroxy-4-methoxy-6-methyloxan-2-yl]oxy-4-methoxy-6-methyloxan-2-yl]oxy-5',11,13,22-tetramethylspiro[3,7,19-trioxatetracyclo[15.6.1.14,8.020,24]pentacosa-10,14,16,22-tetraene-6,2'-oxane]-2-one\",875.1,170.0,1680.0,4.1,62,3,14,8,874.508,874.508,0,1,0,20,19,1,3,3,0,Between -11 and 5\n50,Plitidepsin,1110.3,285.0,2200.0,5.7,79,4,15,15,1109.63,1109.63,0,1,0,12,12,0,0,0,0,Larger than 6\n51,\"(10Z,14Z,16Z)-6'-butan-2-yl-21,24-dihydroxy-12-[5-(5-hydroxy-4-methoxy-6-methyloxan-2-yl)oxy-4-methoxy-6-methyloxan-2-yl]oxy-5',11,13,22-tetramethylspiro[3,7,19-trioxatetracyclo[15.6.1.14,8.020,24]pentacosa-10,14,16,22-tetraene-6,2'-oxane]-2-one\",875.1,170.0,1680.0,4.1,62,3,14,8,874.508,874.508,0,1,0,20,0,20,3,3,0,Between -11 and 5\n52,\"(1R,4S,5'S,6R,6'R,8R,12S,13S,20R,21R,24S)-6'-[(2R)-butan-2-yl]-21,24-dihydroxy-12-[(2R,4S,5S,6S)-5-[(2S,4S,5S,6S)-5-hydroxy-4-methoxy-6-methyloxan-2-yl]oxy-4-methoxy-6-methyloxan-2-yl]oxy-5',11,13,22-tetramethylspiro[3,7,19-trioxatetracyclo[15.6.1.14,8.020,24]pentacosa-10,14,16,22-tetraene-6,2'-oxane]-2-one\",875.1,170.0,1680.0,4.1,62,3,14,8,874.508,874.508,0,1,0,20,20,0,3,0,3,Between -11 and 5\n53,Rubramin,1355.4,476.0,3220.0,,93,9,21,16,1354.57,1354.57,-3,3,0,14,14,0,3,3,0,Larger than 6\n54,\"(1R,4S,5'S,6R,6'S,8R,10E,12S,13S,14E,16E,20R,21R,24S)-6'-[(2S)-butan-2-yl]-21,24-dihydroxy-12-[(2R,4S,5S,6S)-5-[(2S,4S,5S,6S)-5-hydroxy-4-methoxy-6-methyloxan-2-yl]oxy-4-methoxy-6-methyloxan-2-yl]oxy-5',11,13,22-tetramethylspiro[3,7,19-trioxatetracyclo[15.6.1.14,8.020,24]pentacosa-10,14,16,22-tetraene-6,2'-oxane]-2-one\",875.1,170.0,1680.0,4.1,62,3,14,8,874.508,874.508,0,1,0,20,20,0,3,3,0,Between -11 and 5\n55,Zidovudine,267.24,93.2,484.0,0.0,19,2,6,3,267.097,267.097,0,1,0,3,3,0,0,0,0,Between -11 and 5\n56,Resveratrol,228.24,60.7,246.0,3.1,17,3,3,2,228.079,228.079,0,1,0,0,0,0,1,1,0,Between -11 and 5\n57,Curcumin,368.4,93.1,507.0,3.2,27,2,6,8,368.126,368.126,0,1,0,0,0,0,2,2,0,Between -11 and 5\n58,\"6'-Butan-2-yl-21,24-dihydroxy-12-[5-(5-hydroxy-4-methoxy-6-methyloxan-2-yl)oxy-4-methoxy-6-methyloxan-2-yl]oxy-5',11,13,22-tetramethylspiro[3,7,19-trioxatetracyclo[15.6.1.14,8.020,24]pentacosa-10,14,16,22-tetraene-6,2'-oxane]-2-one\",875.1,170.0,1680.0,4.1,62,3,14,8,874.508,874.508,0,1,0,20,0,20,3,0,3,Between -11 and 5\n59,Regorafenib,482.8,92.4,686.0,4.2,33,3,8,5,482.077,482.077,0,1,0,0,0,0,0,0,0,Between -11 and 5\n60,Pharmakon1600-01300027,875.1,170.0,1680.0,4.1,62,3,14,8,874.508,874.508,0,1,0,20,17,3,3,3,0,Between -11 and 5\n61,\"(1R,4S,5'S,6R,6'R,8R,10Z,12S,13S,14Z,20R,21R,24S)-6'-[(2S)-butan-2-yl]-21,24-dihydroxy-12-[(2R,4S,5S,6S)-5-[(2S,4S,5S,6S)-5-hydroxy-4-methoxy-6-methyloxan-2-yl]oxy-4-methoxy-6-methyloxan-2-yl]oxy-5',11,13,22-tetramethylspiro[3,7,19-trioxatetracyclo[15.6.1.14,8.020,24]pentacosa-10,14,16,22-tetraene-6,2'-oxane]-2-one\",875.1,170.0,1680.0,4.1,62,3,14,8,874.508,874.508,0,1,0,20,20,0,3,2,1,Between -11 and 5\n62,\"(1R,4S,5'S,6R,6'R,8R,10E,12S,13S,14E,16E,20R,21R,24S)-6'-[(2S)-butan-2-yl]-21,24-dihydroxy-12-[(2R,4R,5S,6S)-5-[(2S,4R,5S,6S)-5-hydroxy-4-methoxy-6-methyloxan-2-yl]oxy-4-methoxy-6-methyloxan-2-yl]oxy-5',11,13,22-tetramethylspiro[3,7,19-trioxatetracyclo[15.6.1.14,8.020,24]pentacosa-10,14,16,22-tetraene-6,2'-oxane]-2-one\",875.1,170.0,1680.0,4.1,62,3,14,8,874.508,874.508,0,1,0,20,20,0,3,3,0,Between -11 and 5\n63,Methylcobalamin,1345.4,449.0,3160.0,,92,10,20,26,1344.6,1344.6,0,3,0,14,13,1,3,3,0,Larger than 6\n64,Spironolactone,416.6,85.7,818.0,2.9,29,0,5,2,416.202,416.202,0,1,0,7,7,0,0,0,0,Between -11 and 5\n65,Prednisone,358.4,91.7,764.0,1.5,26,2,5,2,358.178,358.178,0,1,0,6,6,0,0,0,0,Between -11 and 5\n66,Quercetin,302.23,127.0,488.0,1.5,22,5,7,1,302.043,302.043,0,1,0,0,0,0,0,0,0,Between -11 and 5\n67,Calderol,418.7,41.5,655.0,,30,3,3,6,418.345,418.345,0,2,0,5,5,0,2,2,0,Larger than 6\n68,Dactolisib,469.5,73.1,872.0,5.2,36,0,4,3,469.19,469.19,0,1,0,0,0,0,0,0,0,Larger than 6\n69,Enzalutamide,464.4,109.0,839.0,3.6,32,1,8,3,464.093,464.093,0,1,0,0,0,0,0,0,0,Between -11 and 5\n70,Selinexor,443.3,97.6,621.0,3.0,31,2,12,5,443.093,443.093,0,1,0,0,0,0,1,1,0,Between -11 and 5\n71,Chlorpromazine,318.9,31.8,339.0,5.2,21,0,3,4,318.096,318.096,0,1,0,0,0,0,0,0,0,Larger than 6\n72,Itraconazolum [Latin],705.6,101.0,1120.0,5.7,49,0,9,11,704.239,704.239,0,1,0,3,0,3,0,0,0,Larger than 6\n73,Loratadine,382.9,42.4,569.0,5.2,27,0,3,2,382.145,382.145,0,1,0,0,0,0,0,0,0,Larger than 6\n74,Nifedipine,346.3,110.0,608.0,2.2,25,1,7,5,346.116,346.116,0,1,0,0,0,0,0,0,0,Between -11 and 5\n75,Prazosin,383.4,107.0,544.0,2.0,28,1,8,4,383.159,383.159,0,1,0,0,0,0,0,0,0,Between -11 and 5\n76,Alizarin,240.21,74.6,378.0,3.2,18,2,4,0,240.042,240.042,0,1,0,0,0,0,0,0,0,Between -11 and 5\n77,Methylprednisolone,374.5,94.8,754.0,1.9,27,3,5,2,374.209,374.209,0,1,0,8,8,0,0,0,0,Between -11 and 5\n78,Chloroquine sulfate,418.0,111.0,390.0,,27,3,7,8,417.149,417.149,0,2,0,1,0,1,0,0,0,Larger than 6\n79,Bardoxolone methyl,505.7,84.2,1210.0,6.7,37,0,5,2,505.319,505.319,0,1,0,7,7,0,0,0,0,Larger than 6\n80,\"(1R,4S,5'S,6R,6'R,8R,12S,13S,20R,21R,24S)-6'-[(2S)-butan-2-yl]-21,24-dihydroxy-12-[(2R,4S,5S,6S)-5-[(2S,4S,5S,6S)-5-hydroxy-4-methoxy-6-methyloxan-2-yl]oxy-4-methoxy-6-methyloxan-2-yl]oxy-5',11,13,22-tetramethylspiro[3,7,19-trioxatetracyclo[15.6.1.14,8.020,24]pentacosa-10,14,16,22-tetraene-6,2'-oxane]-2-one\",875.1,170.0,1680.0,4.1,62,3,14,8,874.508,874.508,0,1,0,20,20,0,3,0,3,Between -11 and 5\n81,Heartgard-30,1736.2,340.0,3340.0,,123,6,28,15,1736.0,1735.0,0,2,0,39,34,5,6,6,0,Larger than 6\n82,Ivermectine 100 microg/mL in Acetonitrile,1736.2,340.0,3340.0,,123,6,28,15,1736.0,1735.0,0,2,0,39,39,0,6,6,0,Larger than 6\n83,Duvelisib,416.9,86.8,668.0,4.1,30,2,5,4,416.115,416.115,0,1,0,1,1,0,0,0,0,Between -11 and 5\n84,\"(4S,5'S,6R,6'R,8R,10E,12S,13S,14E,16E,20R,21R,24S)-6'-[(2S)-butan-2-yl]-21,24-dihydroxy-12-[(2R,4S,5S,6S)-5-[(2S,4S,5S,6S)-5-hydroxy-4-methoxy-6-methyloxan-2-yl]oxy-4-methoxy-6-methyloxan-2-yl]oxy-5',11,13,22-tetramethylspiro[3,7,19-trioxatetracyclo[15.6.1.14,8.020,24]pentacosa-10,14,16,22-tetraene-6,2'-oxane]-2-one\",875.1,170.0,1680.0,4.1,62,3,14,8,874.508,874.508,0,1,0,20,19,1,3,3,0,Between -11 and 5\n85,Zotatifin,487.5,108.0,819.0,2.4,36,2,8,6,487.211,487.211,0,1,0,5,5,0,0,0,0,Between -11 and 5\n86,MaxEPA,645.0,74.6,874.0,,47,2,4,28,644.48,644.48,0,2,0,0,0,0,11,11,0,Larger than 6\n87,\"(1R,4S,5'S,6R,6'R,8R,12S,13S,14E,16E,20R,21R,24S)-6'-[(2S)-butan-2-yl]-21,24-dihydroxy-12-[(2R,4S,5S,6S)-5-[(2S,4S,5S,6S)-5-hydroxy-4-methoxy-6-methyloxan-2-yl]oxy-4-methoxy-6-methyloxan-2-yl]oxy-5',11,13,22-tetramethylspiro[3,7,19-trioxatetracyclo[15.6.1.14,8.020,24]pentacosa-10,14,16,22-tetraene-6,2'-oxane]-2-one\",875.1,170.0,1680.0,4.1,62,3,14,8,874.508,874.508,0,1,0,20,20,0,3,2,1,Between -11 and 5\n88,\"(1S,4S,5'S,6R,6'R,8R,10E,12S,13S,14E,20R,21R,24S)-6'-[(2S)-butan-2-yl]-21,24-dihydroxy-12-[(2R,4S,5S,6S)-5-[(2S,4S,5S,6S)-5-hydroxy-4-methoxy-6-methyloxan-2-yl]oxy-4-methoxy-6-methyloxan-2-yl]oxy-5',11,13,22-tetramethylspiro[3,7,19-trioxatetracyclo[15.6.1.14,8.020,24]pentacosa-10,14,16,22-tetraene-6,2'-oxane]-2-one\",875.1,170.0,1680.0,4.1,62,3,14,8,874.508,874.508,0,1,0,20,20,0,3,2,1,Between -11 and 5\n89,Indomethacin,357.8,68.5,506.0,4.3,25,1,4,4,357.077,357.077,0,1,0,0,0,0,0,0,0,Between -11 and 5\n90,Methylene Blue,319.9,43.9,483.0,,21,0,4,1,319.091,319.091,0,2,0,0,0,0,0,0,0,Larger than 6\n91,Bromocresol green,698.0,92.2,742.0,6.5,31,2,5,2,697.725,693.73,0,1,0,0,0,0,0,0,0,Larger than 6\n92,Hydroxychloroquine sulfate,434.0,131.0,413.0,,28,4,8,9,433.144,433.144,0,2,0,1,0,1,0,0,0,Larger than 6\n93,Ritonavir,720.9,202.0,1040.0,6.0,50,4,9,18,720.313,720.313,0,1,0,4,4,0,0,0,0,Larger than 6\n94,Fisetin,286.24,107.0,459.0,2.0,21,4,6,1,286.048,286.048,0,1,0,0,0,0,0,0,0,Between -11 and 5\n95,Palbociclib,447.5,103.0,775.0,1.8,33,2,8,5,447.238,447.238,0,1,0,0,0,0,0,0,0,Between -11 and 5\n96,Ruxolitinib,306.4,83.2,453.0,2.1,23,1,4,4,306.159,306.159,0,1,0,1,1,0,0,0,0,Between -11 and 5\n97,Sildenafil Citrate,666.7,250.0,1070.0,,46,5,15,12,666.232,666.232,0,2,0,0,0,0,0,0,0,Larger than 6\n98,Nintedanib,539.6,102.0,892.0,4.3,40,2,7,8,539.253,539.253,0,1,0,0,0,0,0,0,0,Between -11 and 5\n99,Melatonin,232.28,54.1,270.0,0.8,17,2,2,4,232.121,232.121,0,1,0,0,0,0,0,0,0,Between -11 and 5\n100,Carbamazepine,236.27,46.3,326.0,2.5,18,1,1,0,236.095,236.095,0,1,0,0,0,0,0,0,0,Between -11 and 5\n101,Clofazimine,473.4,40.0,829.0,7.1,33,1,4,4,472.122,472.122,0,1,0,0,0,0,0,0,0,Larger than 6\n102,Diphenhydramine,255.35,12.5,211.0,3.3,19,0,2,6,255.162,255.162,0,1,0,0,0,0,0,0,0,Between -11 and 5\n103,Thalidomide,258.23,83.6,449.0,0.3,19,1,4,1,258.064,258.064,0,1,0,1,0,1,0,0,0,Between -11 and 5\n104,Hydrocortisone,362.5,94.8,684.0,1.6,26,3,5,2,362.209,362.209,0,1,0,7,7,0,0,0,0,Between -11 and 5\n105,Progesterone,314.5,34.1,589.0,3.9,23,0,2,1,314.225,314.225,0,1,0,6,6,0,0,0,0,Between -11 and 5\n106,o-Aminoazotoluene,225.29,50.7,264.0,3.7,17,1,3,2,225.127,225.127,0,1,0,0,0,0,0,0,0,Between -11 and 5\n107,Clonitralid,388.2,141.0,414.0,,25,4,6,3,387.039,387.039,0,2,0,0,0,0,0,0,0,Larger than 6\n108,Pimozide,461.5,35.6,632.0,6.3,34,1,4,7,461.228,461.228,0,1,0,0,0,0,0,0,0,Larger than 6\n109,Nitazoxanide,307.28,142.0,428.0,2.0,21,1,7,4,307.026,307.026,0,1,0,0,0,0,0,0,0,Between -11 and 5\n110,Deferoxamine hydrochloride,597.1,206.0,739.0,,40,7,9,23,596.33,596.33,0,2,0,0,0,0,0,0,0,Larger than 6\n111,Chloroquine monophosphate,417.9,106.0,359.0,,27,4,7,8,417.158,417.158,0,2,0,1,0,1,0,0,0,Larger than 6\n112,Retinol,286.5,20.2,496.0,5.7,21,1,1,5,286.23,286.23,0,1,0,0,0,0,4,4,0,Larger than 6\n113,Melphalan,305.2,66.6,265.0,-0.5,19,2,4,8,304.075,304.075,0,1,0,1,1,0,0,0,0,Between -11 and 5\n114,Dasatinib,488.0,135.0,642.0,3.6,33,3,9,7,487.156,487.156,0,1,0,0,0,0,0,0,0,Between -11 and 5\n115,Masitinib,498.6,102.0,696.0,4.3,36,2,7,7,498.22,498.22,0,1,0,0,0,0,0,0,0,Between -11 and 5\n116,Acrivastine and pseudoephedrine hydrochloride,550.1,85.7,635.0,,39,4,6,9,549.276,549.276,0,3,0,2,2,0,2,2,0,Larger than 6\n117,\"4-(carboxymethyl)-2-((R)-1-(2-(2,5-dichlorobenzamido)acetamido)-3-methylbutyl)-6-oxo-1,3,2-dioxaborinane-4-carboxylic acid\",517.1,168.0,815.0,,34,4,9,10,516.087,516.087,0,1,0,2,1,1,0,0,0,Larger than 6\n118,Remdesivir,602.6,204.0,1010.0,1.9,42,4,13,14,602.225,602.225,0,1,0,6,6,0,0,0,0,Between -11 and 5\n119,\"Ivermectin B1a, epi-\",875.1,170.0,1680.0,4.1,62,3,14,8,874.508,874.508,0,1,0,20,20,0,3,3,0,Between -11 and 5\n120,Hydroxocobalamin,1270.4,452.0,3140.0,-3.4,90,9,19,26,1269.63,1269.63,-2,1,0,14,0,14,3,3,0,Between -11 and 5\n121,Zanubrutinib,471.5,103.0,756.0,3.5,35,2,5,6,471.227,471.227,0,1,0,1,1,0,0,0,0,Between -11 and 5\n122,Gamma-Aminobutyric Acid,103.12,63.3,62.7,-3.2,7,2,3,3,103.063,103.063,0,1,0,0,0,0,0,0,0,Between -11 and 5\n123,Caffeine,194.19,58.4,293.0,-0.1,14,0,3,0,194.08,194.08,0,1,0,0,0,0,0,0,0,Between -11 and 5\n124,Dapsone,248.3,94.6,306.0,1.0,17,2,4,2,248.062,248.062,0,1,0,0,0,0,0,0,0,Between -11 and 5\n125,Leflunomide,270.21,55.1,327.0,2.5,19,1,6,2,270.062,270.062,0,1,0,0,0,0,0,0,0,Between -11 and 5\n126,Raloxifene,473.6,98.2,655.0,6.1,34,2,6,7,473.166,473.166,0,1,0,0,0,0,0,0,0,Larger than 6\n127,Imatinib,493.6,86.3,706.0,3.5,37,2,7,7,493.259,493.259,0,1,0,0,0,0,0,0,0,Between -11 and 5\n128,Dexamethasone,392.5,94.8,805.0,1.9,28,3,6,2,392.2,392.2,0,1,0,8,8,0,0,0,0,Between -11 and 5\n129,Colchicine,399.4,83.1,740.0,1.0,29,1,6,5,399.168,399.168,0,1,0,1,1,0,0,0,0,Between -11 and 5\n130,Estradiol cypionate,396.6,46.5,597.0,7.1,29,1,3,5,396.266,396.266,0,1,0,5,5,0,0,0,0,Larger than 6\n131,Cetylpyridinium Chloride,340.0,3.9,208.0,,23,0,1,15,339.269,339.269,0,2,0,0,0,0,0,0,0,Larger than 6\n132,Plerixafor,502.8,78.7,456.0,0.0,36,6,8,4,502.447,502.447,0,1,0,0,0,0,0,0,0,Between -11 and 5\n133,Telmisartan,514.6,72.9,831.0,6.9,39,1,4,7,514.237,514.237,0,1,0,0,0,0,0,0,0,Larger than 6\n134,Sorafenib,464.8,92.4,646.0,4.1,32,3,7,5,464.086,464.086,0,1,0,0,0,0,0,0,0,Between -11 and 5\n135,Bacitracin zinc,1488.1,552.0,2950.0,,101,16,21,31,1485.68,1485.68,0,2,0,16,0,16,0,0,0,Larger than 6\n136,Hymecromone,176.17,46.5,257.0,1.9,13,1,3,0,176.047,176.047,0,1,0,0,0,0,0,0,0,Between -11 and 5\n137,Cob(II)alamin,1329.3,452.0,3150.0,,91,9,19,16,1328.56,1328.56,-2,2,0,14,14,0,3,3,0,Larger than 6\n138,Tofacitinib,312.37,88.9,488.0,1.5,23,1,5,3,312.17,312.17,0,1,0,2,2,0,0,0,0,Between -11 and 5\n139,Elsulfavirine,629.3,134.0,977.0,5.2,37,2,7,8,626.943,626.943,0,1,0,0,0,0,0,0,0,Larger than 6\n140,Fostamatinib,580.5,187.0,904.0,1.6,40,4,15,10,580.148,580.148,0,1,0,0,0,0,0,0,0,Between -11 and 5\n141,3-(4-chlorophenyl)-N-(pyridin-4-ylmethyl)adamantane-1-carboxamide,380.9,42.0,551.0,4.7,27,1,2,4,380.166,380.166,0,1,0,2,0,2,0,0,0,Between -11 and 5\n142,Adenosylcobalamin,1579.6,571.0,3730.0,,109,12,27,17,1578.66,1578.66,-3,3,0,18,18,0,3,3,0,Larger than 6\n143,Solnatide,1923.1,861.0,4170.0,-10.7,134,27,32,27,1921.81,1921.81,0,1,0,16,16,0,0,0,0,Smaller than -10\n144,Subasumstat,578.1,193.0,942.0,3.5,38,4,11,8,577.122,577.122,0,1,0,4,4,0,0,0,0,Between -11 and 5\n145,Lactoferrin,3125.8,1360.0,7330.0,6.8,219,51,65,108,3124.68,3123.68,0,1,0,26,26,0,0,0,0,Larger than 6\n146,Compstatin 40,1789.1,692.0,3770.0,-2.1,126,21,23,30,1787.84,1787.84,0,1,0,15,15,0,0,0,0,Between -11 and 5\n147,Celecoxib,381.4,86.4,577.0,3.4,26,1,7,3,381.076,381.076,0,1,0,0,0,0,0,0,0,Between -11 and 5\n148,Eucalyptol,154.25,9.2,164.0,2.5,11,0,1,0,154.136,154.136,0,1,0,0,0,0,0,0,0,Between -11 and 5\n149,Disulfiram,296.5,121.0,201.0,3.9,16,0,4,7,296.051,296.051,0,1,0,0,0,0,0,0,0,Between -11 and 5\n150,Ibuprofen,206.28,37.3,203.0,3.5,15,1,2,4,206.131,206.131,0,1,0,1,0,1,0,0,0,Between -11 and 5\n151,Niclosamide,327.12,95.2,404.0,4.0,21,2,4,2,325.986,325.986,0,1,0,0,0,0,0,0,0,Between -11 and 5\n152,Simvastatin,418.6,72.8,706.0,4.7,30,1,5,7,418.272,418.272,0,1,0,7,7,0,0,0,0,Between -11 and 5\n153,Methotrexate,454.4,211.0,704.0,-1.8,33,5,12,9,454.171,454.171,0,1,0,1,1,0,0,0,0,Between -11 and 5\n154,Angiotensin II,1046.2,409.0,1980.0,-1.7,75,13,15,29,1045.53,1045.53,0,1,0,9,9,0,0,0,0,Between -11 and 5\n155,Lenalidomide,259.26,92.5,437.0,-0.5,19,2,4,1,259.096,259.096,0,1,0,1,0,1,0,0,0,Between -11 and 5\n156,Aspartyl-alanyl-diketopiperazine,186.17,95.5,263.0,-1.4,13,3,4,2,186.064,186.064,0,1,0,2,2,0,0,0,0,Between -11 and 5\n157,Silmitasertib,349.8,75.1,491.0,4.4,25,2,5,3,349.062,349.062,0,1,0,0,0,0,0,0,0,Between -11 and 5\n158,Ibrutinib,440.5,99.2,678.0,3.6,33,1,6,5,440.196,440.196,0,1,0,1,1,0,0,0,0,Between -11 and 5\n159,Bemcentinib,506.6,97.8,775.0,5.5,38,2,7,4,506.291,506.291,0,1,0,1,1,0,0,0,0,Larger than 6\n160,Teriflunomide,270.21,73.1,426.0,3.3,19,2,6,2,270.062,270.062,0,1,0,0,0,0,1,1,0,Between -11 and 5\n161,Tazemetostat,572.7,83.1,992.0,4.2,42,2,6,9,572.336,572.336,0,1,0,0,0,0,0,0,0,Between -11 and 5\n162,Acalabrutinib,465.5,119.0,845.0,3.0,35,2,6,4,465.191,465.191,0,1,0,1,1,0,0,0,0,Between -11 and 5\n163,Ifenprodil,325.4,43.7,353.0,3.9,24,2,3,5,325.204,325.204,0,1,0,2,0,2,0,0,0,Between -11 and 5\n164,Ursodeoxycholic acid,392.6,77.8,605.0,4.9,28,3,4,4,392.293,392.293,0,1,0,10,10,0,0,0,0,Between -11 and 5\n165,Metoprolol succinate,652.8,176.0,308.0,,46,6,12,21,652.393,652.393,0,3,0,2,0,2,0,0,0,Larger than 6\n166,Merimepodib,452.5,124.0,652.0,2.1,33,3,7,8,452.17,452.17,0,1,0,1,1,0,0,0,0,Between -11 and 5\n167,Fludrocortisone acetate,422.5,101.0,838.0,1.7,30,2,7,4,422.21,422.21,0,1,0,7,7,0,0,0,0,Between -11 and 5\n168,Triazavirin,228.19,141.0,435.0,0.4,15,1,6,1,228.007,228.007,0,1,0,0,0,0,0,0,0,Between -11 and 5\n169,Ceftriaxone sodium,598.6,297.0,1120.0,,38,2,14,7,598.01,598.01,0,3,0,2,2,0,1,1,0,Larger than 6\n170,Rivaroxaban,435.9,116.0,645.0,2.5,29,1,6,5,435.066,435.066,0,1,0,1,1,0,0,0,0,Between -11 and 5\n171,Ventolin,337.39,156.0,309.0,,22,6,8,5,337.12,337.12,0,2,0,1,0,1,0,0,0,Larger than 6\n172,Apixaban,459.5,111.0,777.0,2.2,34,1,5,5,459.191,459.191,0,1,0,0,0,0,0,0,0,Between -11 and 5\n173,Ceftriaxone disodium salt hemiheptahydrate,1323.2,601.0,1120.0,,83,11,35,14,1322.09,1322.09,0,13,0,4,4,0,2,2,0,Larger than 6\n174,Vadadustat,306.7,99.5,393.0,2.5,21,3,5,4,306.041,306.041,0,1,0,0,0,0,0,0,0,Between -11 and 5\n175,Carbohydrate moiety of bromelain,1026.9,483.0,1680.0,-11.6,70,18,29,16,1026.38,1026.38,0,1,0,29,28,1,0,0,0,Smaller than -10\n176,Siponimod fumarate,1149.3,199.0,896.0,,82,4,20,20,1148.53,1148.53,0,3,0,0,0,0,3,3,0,Larger than 6\n177,(s)-1-(3-Chloro-4-fluorophenyl)ethanamine hydrochloride,210.07,26.0,131.0,,12,2,2,1,209.017,209.017,0,2,0,1,1,0,0,0,0,Larger than 6\n178,Prezcobix,1323.7,343.0,1980.0,,92,6,19,32,1322.59,1322.59,0,2,0,8,8,0,0,0,0,Larger than 6\n179,\"[(2R,3R,4R,5R)-5-(4-amino-5-deuteriopyrrolo[2,1-f][1,2,4]triazin-7-yl)-5-cyano-3,4-bis(2-methylpropanoyloxy)oxolan-2-yl]methyl 2-methylpropanoate;hydrobromide\",583.4,168.0,887.0,,37,2,11,11,582.155,582.155,0,2,1,4,4,0,0,0,0,Larger than 6\n180,Berberine,336.4,40.8,488.0,3.6,25,0,4,2,336.124,336.124,1,1,0,0,0,0,0,0,0,Between -11 and 5\n181,Cyproheptadine,287.4,3.2,423.0,4.7,22,0,1,0,287.167,287.167,0,1,0,0,0,0,0,0,0,Between -11 and 5\n182,Doxazosin,451.5,112.0,678.0,2.5,33,1,9,4,451.186,451.186,0,1,0,1,0,1,0,0,0,Between -11 and 5\n183,Fluconazole,306.27,81.6,358.0,0.4,22,1,7,5,306.104,306.104,0,1,0,0,0,0,0,0,0,Between -11 and 5\n184,Irbesartan,428.5,87.1,682.0,4.1,32,1,5,7,428.232,428.232,0,1,0,0,0,0,0,0,0,Between -11 and 5\n185,Sulfamethoxazole,253.28,107.0,346.0,0.9,17,2,6,3,253.052,253.052,0,1,0,0,0,0,0,0,0,Between -11 and 5\n186,D-Glucose,180.16,110.0,151.0,-2.6,12,5,6,1,180.063,180.063,0,1,0,5,4,1,0,0,0,Between -11 and 5\n187,N-Vinyl-2-pyrrolidone,111.14,20.3,120.0,0.4,8,0,1,1,111.068,111.068,0,1,0,0,0,0,0,0,0,Between -11 and 5\n188,Trimetazidine,266.34,43.0,259.0,1.0,19,1,5,5,266.163,266.163,0,1,0,0,0,0,0,0,0,Between -11 and 5\n189,Estetrol,304.4,80.9,441.0,1.5,22,4,4,0,304.167,304.167,0,1,0,7,7,0,0,0,0,Between -11 and 5\n190,Deferoxamine mesylate,656.8,269.0,832.0,,44,7,12,23,656.341,656.341,0,2,0,0,0,0,0,0,0,Larger than 6\n191,Tramadol Hydrochloride,299.83,32.7,282.0,,20,2,3,4,299.165,299.165,0,2,0,2,2,0,0,0,0,Larger than 6\n192,Nebivolol,405.4,71.0,483.0,3.0,29,3,7,6,405.175,405.175,0,1,0,4,0,4,0,0,0,Between -11 and 5\n193,Argatroban monohydrate,526.7,190.0,887.0,,36,6,9,9,526.257,526.257,0,2,0,4,3,1,0,0,0,Larger than 6\n194,Sulfamethoxazole and trimethoprim,543.6,212.0,653.0,,38,4,13,8,543.19,543.19,0,2,0,0,0,0,0,0,0,Larger than 6\n195,Zinc Gluconate,455.7,283.0,165.0,,27,10,14,8,454.03,454.03,0,3,0,8,8,0,0,0,0,Larger than 6\n196,\"Zinc;(2R,3S,4R,5R)-2,3,4,5,6-pentahydroxyhexanoate\",455.7,283.0,385.0,,27,10,14,8,454.03,454.03,0,3,0,8,8,0,0,0,0,Larger than 6\n197,(+)-Mefloquine,378.31,45.2,483.0,3.6,26,2,9,2,378.117,378.117,0,1,0,2,2,0,0,0,0,Between -11 and 5\n198,\"(2S,5R,6R)-6-[[(2S)-2-[(4-ethyl-2,3-dioxo-piperazine-1-carbonyl)amino]-2-phenyl-propanoyl]amino]-3,3-dimethyl-7-oxo-4-thia-1-azabicyclo[3.2.0]heptane-2-carboxylic acid; (2S,3S,5R)-3-methyl-4,4,7-trioxo-3-(triazol-1-ylmethyl)-4$l^{6}-thia-1-azabicyclo[3.2.0]heptane-2-carboxylic acid\",831.9,313.0,1600.0,,57,4,15,9,831.232,831.232,0,2,0,7,7,0,0,0,0,Larger than 6\n199,Favipiravir,157.1,84.6,282.0,-0.6,11,2,4,1,157.029,157.029,0,1,0,0,0,0,0,0,0,Between -11 and 5\n200,Maraviroc,513.7,63.0,751.0,5.1,37,1,6,8,513.328,513.328,0,1,0,3,3,0,0,0,0,Larger than 6\n201,Toremifene,406.0,12.5,483.0,7.2,29,0,2,9,405.186,405.186,0,1,0,0,0,0,1,1,0,Larger than 6\n202,\"(3-methyl-2,4-dioxo-3,4-dihydroquinazolin-1(2H)-yl)acetic acid\",234.21,77.9,369.0,0.4,17,1,4,2,234.064,234.064,0,1,0,0,0,0,0,0,0,Between -11 and 5\n203,Enalapril maleate,492.5,171.0,638.0,,35,4,10,12,492.211,492.211,0,2,0,3,3,0,1,1,0,Larger than 6\n204,Naltrexone hydrochloride,377.9,70.0,621.0,,26,3,5,2,377.139,377.139,0,2,0,4,4,0,0,0,0,Larger than 6\n205,Chlorhexidine Gluconate,897.8,455.0,819.0,,60,18,16,23,896.32,896.32,0,3,0,8,8,0,2,2,0,Larger than 6\n206,Piperacillin/tazobactam,817.9,313.0,1550.0,,56,4,15,9,817.216,817.216,0,2,0,7,7,0,0,0,0,Larger than 6\n207,3-[5-(azetidine-1-carbonyl)pyrazin-2-yl]oxy-5-[(2S)-1-methoxypropan-2-yl]oxy-N-(5-methylpyrazin-2-yl)benzamide,478.5,129.0,710.0,1.3,35,1,9,9,478.196,478.196,0,1,0,1,1,0,0,0,0,Between -11 and 5\n208,Degarelix,1632.3,513.0,3390.0,3.5,117,17,18,41,1630.75,1630.75,0,1,0,11,11,0,0,0,0,Between -11 and 5\n209,(3S)-3-amino-6-(diaminomethylideneazaniumyl)hex-1-en-2-olate,172.23,115.0,174.0,-0.8,12,4,2,5,172.132,172.132,0,1,0,1,1,0,0,0,0,Between -11 and 5\n210,Sivelestat sodium,528.5,154.0,738.0,,35,6,12,9,528.139,528.139,0,6,0,0,0,0,0,0,0,Larger than 6\n211,CID 23679441,576.6,291.0,1120.0,,37,3,13,8,576.028,576.028,0,2,0,2,2,0,1,1,0,Larger than 6\n212,Masitinib mesylate,594.8,164.0,788.0,,41,3,10,7,594.208,594.208,0,2,0,0,0,0,0,0,0,Larger than 6\n213,\"[(1S,4R,6S,7Z,18R)-4-(cyclopropylsulfonylcarbamoyl)-14-[(2-methylpropan-2-yl)oxycarbonylamino]-2,15-dioxo-3,16-diazatricyclo[14.3.0.04,6]nonadec-7-en-18-yl] 4-fluoro-1,3-dihydroisoindole-2-carboxylate\",731.8,189.0,1530.0,3.3,51,3,10,8,731.3,731.3,0,1,0,5,4,1,1,1,0,Between -11 and 5\n214,Natrii chloridi solutio composita,309.11,63.4,24.8,,13,4,8,0,307.852,307.852,0,10,0,0,0,0,0,0,0,Larger than 6\n215,CID 87060529,577.6,288.0,1110.0,,37,4,13,8,577.036,577.036,0,2,0,2,2,0,1,1,0,Larger than 6\n216,\"(2S,3R)-3-[(2-aminopyridin-4-yl)methyl]-1-[[(1R)-1-cyclooctylethyl]carbamoyl]-4-oxoazetidine-2-carboxylic acid\",402.5,126.0,606.0,3.7,29,3,6,5,402.227,402.227,0,1,0,3,3,0,0,0,0,Between -11 and 5\n217,Sinapultide acetate,2529.5,813.0,4910.0,,178,28,30,93,2528.85,2527.85,0,2,0,21,21,0,0,0,0,Larger than 6\n218,Bemnifosbuvir hemisulfate,1261.1,453.0,1000.0,,85,10,32,24,1260.4,1260.4,0,3,0,12,12,0,0,0,0,Larger than 6\n219,Reamberin,357.27,193.0,216.0,,23,6,10,7,357.101,357.101,0,4,0,4,4,0,0,0,0,Larger than 6\n220,Pomotrelvir,455.9,127.0,779.0,3.1,32,4,4,8,455.172,455.172,0,1,0,3,3,0,0,0,0,Between -11 and 5\n221,Selenious acid,128.99,57.5,26.3,,4,2,3,0,129.917,129.917,0,1,0,0,0,0,0,0,0,Larger than 6\n222,Spermidine,145.25,64.099,56.8,-1.0,10,3,3,7,145.158,145.158,0,1,0,0,0,0,0,0,0,Between -11 and 5\n223,Salbutamol,239.31,72.7,227.0,0.3,17,4,4,5,239.152,239.152,0,1,0,1,0,1,0,0,0,Between -11 and 5\n224,Bromhexine,376.13,29.3,256.0,4.3,18,1,2,3,375.997,373.999,0,1,0,0,0,0,0,0,0,Between -11 and 5\n225,Ebselen,274.19,20.3,275.0,,16,0,1,1,274.985,274.985,0,1,0,0,0,0,0,0,0,Larger than 6\n226,Fluoxetine,309.33,21.3,308.0,4.0,22,1,5,6,309.134,309.134,0,1,0,1,0,1,0,0,0,Between -11 and 5\n227,Ketotifen,309.4,48.6,476.0,3.2,22,0,3,0,309.119,309.119,0,1,0,0,0,0,0,0,0,Between -11 and 5\n228,Mefloquine,378.31,45.2,483.0,3.6,26,2,9,2,378.117,378.117,0,1,0,2,0,2,0,0,0,Between -11 and 5\n229,Midazolam,325.8,30.2,471.0,2.5,23,0,3,1,325.078,325.078,0,1,0,0,0,0,0,0,0,Between -11 and 5\n230,Nitroglycerin,227.09,165.0,219.0,1.6,15,0,9,5,227.003,227.003,0,1,0,0,0,0,0,0,0,Between -11 and 5\n231,Quetiapine,383.5,73.6,496.0,2.1,27,1,5,6,383.167,383.167,0,1,0,0,0,0,0,0,0,Between -11 and 5\n232,Liothyronine,650.97,92.8,402.0,1.7,23,3,5,5,650.79,650.79,0,1,0,1,1,0,0,0,0,Between -11 and 5\n233,Pyridostigmine bromide,261.12,33.4,183.0,,14,0,3,2,260.016,260.016,0,2,0,0,0,0,0,0,0,Larger than 6\n234,Psilocybine,284.25,85.8,347.0,-1.6,19,3,5,5,284.093,284.093,0,1,0,0,0,0,0,0,0,Between -11 and 5\n235,Luminol,177.16,84.2,254.0,0.3,13,3,3,0,177.054,177.054,0,1,0,0,0,0,0,0,0,Between -11 and 5\n236,Acetylcysteine,163.2,67.4,148.0,0.4,10,3,4,3,163.03,163.03,0,1,0,1,1,0,0,0,0,Between -11 and 5\n237,Cyproheptadine hydrochloride,323.9,3.2,423.0,,23,1,1,0,323.144,323.144,0,2,0,0,0,0,0,0,0,Larger than 6\n238,Carmoisine,502.4,176.0,854.0,,33,1,9,2,501.988,501.988,0,3,0,0,0,0,0,0,0,Larger than 6\n239,Etoposide,588.6,161.0,969.0,0.6,42,3,13,5,588.184,588.184,0,1,0,10,10,0,0,0,0,Between -11 and 5\n240,Albuterol Sulfate,576.7,228.0,309.0,,39,10,12,10,576.272,576.272,0,3,0,2,0,2,0,0,0,Larger than 6\n241,Dexbudesonide,430.5,93.1,862.0,2.5,31,2,6,4,430.236,430.236,0,1,0,9,9,0,0,0,0,Between -11 and 5\n242,\"2,2-Dimethyl-4-(chloromethyl)-1,3-dioxa-2-silacyclopentane\",166.68,18.5,107.0,,9,0,2,1,166.022,166.022,0,1,0,1,0,1,0,0,0,Larger than 6\n243,Clopidogrel,321.8,57.8,381.0,3.8,21,0,4,4,321.059,321.059,0,1,0,1,1,0,0,0,0,Between -11 and 5\n244,Valsartan,435.5,112.0,608.0,4.4,32,2,6,10,435.227,435.227,0,1,0,1,1,0,0,0,0,Between -11 and 5\n245,Tirofiban,440.6,113.0,579.0,1.4,30,3,7,14,440.234,440.234,0,1,0,1,1,0,0,0,0,Between -11 and 5\n246,Voriconazole,349.31,76.7,448.0,1.5,25,1,8,5,349.115,349.115,0,1,0,2,2,0,0,0,0,Between -11 and 5\n247,N-Phenylethylenediamine,136.19,38.0,77.3,0.6,10,2,2,3,136.1,136.1,0,1,0,0,0,0,0,0,0,Between -11 and 5\n248,Oseltamivir phosphate,410.4,168.0,468.0,,27,5,9,8,410.182,410.182,0,2,0,3,3,0,0,0,0,Larger than 6\n249,Nicotine,162.23,16.1,147.0,1.2,12,0,2,1,162.116,162.116,0,1,0,1,1,0,0,0,0,Between -11 and 5\n250,Lactose monohydrate,360.31,191.0,382.0,,24,9,12,4,360.127,360.127,0,2,0,10,10,0,0,0,0,Larger than 6\n251,\"2,4-Dioxaspiro[5.5]undec-8-ene, 3-(2-furanyl)-\",220.26,31.6,266.0,2.1,16,0,3,1,220.11,220.11,0,1,0,0,0,0,0,0,0,Between -11 and 5\n252,Sivelestat,434.5,147.0,731.0,3.0,30,3,8,9,434.115,434.115,0,1,0,0,0,0,0,0,0,Between -11 and 5\n253,Tafenoquine,463.5,78.6,597.0,5.4,33,2,9,9,463.208,463.208,0,1,0,1,0,1,0,0,0,Larger than 6\n254,IB-Meca,510.3,134.0,589.0,0.9,29,4,8,5,510.051,510.051,0,1,0,4,4,0,0,0,0,Between -11 and 5\n255,\"(S)-Hexahydropyrrolo[1,2-a]pyrazine-1,4-dione\",154.17,49.4,215.0,-0.6,11,1,2,0,154.074,154.074,0,1,0,1,1,0,0,0,0,Between -11 and 5\n256,Arbidol,477.4,80.0,546.0,4.4,29,1,5,8,476.077,476.077,0,1,0,0,0,0,0,0,0,Between -11 and 5\n257,Tempol,172.24,24.5,159.0,0.9,12,1,2,0,172.134,172.134,0,1,0,0,0,0,0,0,0,Between -11 and 5\n258,Atazanavir,704.9,171.0,1110.0,5.6,51,5,9,18,704.39,704.39,0,1,0,4,4,0,0,0,0,Larger than 6\n259,Centhaquine,331.5,19.4,404.0,4.5,25,0,3,4,331.205,331.205,0,1,0,0,0,0,0,0,0,Between -11 and 5\n260,Regadenoson,390.35,187.0,587.0,-1.5,28,5,10,4,390.14,390.14,0,1,0,4,4,0,0,0,0,Between -11 and 5\n261,Teprotide,1101.3,387.0,2330.0,-0.9,79,10,13,24,1100.58,1100.58,0,1,0,10,10,0,0,0,0,Between -11 and 5\n262,Azithromycin,749.0,180.0,1150.0,4.0,52,5,14,7,748.509,748.509,0,1,0,18,18,0,0,0,0,Between -11 and 5\n263,Posaconazole,700.8,112.0,1170.0,4.6,51,1,11,12,700.33,700.33,0,1,0,4,4,0,0,0,0,Between -11 and 5\n264,Cannabidiol,314.5,40.5,414.0,6.5,23,2,2,6,314.225,314.225,0,1,0,2,2,0,0,0,0,Larger than 6\n265,\"(R)-[2,8-bis(trifluoromethyl)-4-quinolyl]-[(2R)-2-piperidyl]methanol\",378.31,45.2,483.0,3.6,26,2,9,2,378.117,378.117,0,1,0,2,2,0,0,0,0,Between -11 and 5\n266,Tetramethylol-melamin-dioxy-propylen [German],358.35,170.0,377.0,-0.8,25,6,12,11,358.16,358.16,0,1,0,2,0,2,0,0,0,Between -11 and 5\n267,Heme arginate,792.7,260.0,1180.0,,55,8,10,13,792.305,792.305,2,3,0,1,1,0,0,0,0,Larger than 6\n268,Zincacetate,185.5,74.6,78.6,,9,2,4,0,183.971,183.971,0,3,0,0,0,0,0,0,0,Larger than 6\n269,Montelukast,586.2,95.7,891.0,7.7,41,2,5,12,585.21,585.21,0,1,0,1,1,0,1,1,0,Larger than 6\n270,Crocetin,328.4,74.6,608.0,5.4,24,2,4,8,328.167,328.167,0,1,0,0,0,0,7,7,0,Larger than 6\n271,Fondaparinux,1508.3,873.0,3450.0,-14.7,91,19,52,30,1506.95,1506.95,0,1,0,25,25,0,0,0,0,Smaller than -10\n272,Fluvoxamine,318.33,56.8,327.0,2.6,22,1,7,9,318.156,318.156,0,1,0,0,0,0,1,1,0,Between -11 and 5\n273,Naltrexone,341.4,70.0,621.0,1.9,25,2,5,2,341.163,341.163,0,1,0,4,4,0,0,0,0,Between -11 and 5\n274,20-Hydroxyecdysone,480.6,138.0,869.0,0.5,34,6,7,5,480.309,480.309,0,1,0,10,10,0,0,0,0,Between -11 and 5\n275,Ceftriaxone,554.6,288.0,1110.0,-1.3,36,4,13,8,554.046,554.046,0,1,0,2,2,0,1,1,0,Between -11 and 5\n276,\"(3E,4S)-4-Hydroxy-3-{2-[(1R,4aS,5R,6R,8aS)-6-hydroxy-5-(hydroxymethyl)-5,8a-dimethyl-2-methylenedecahydronaphthalen-1-yl]ethylidene}dihydrofuran-2(3H)-one\",350.4,87.0,597.0,2.2,25,3,5,3,350.209,350.209,0,1,0,6,2,4,1,1,0,Between -11 and 5\n277,Artemether and lumefantrine,827.3,69.6,1100.0,,56,1,7,11,825.333,825.333,0,2,0,9,7,2,1,1,0,Larger than 6\n278,Isavuconazonium,717.8,188.0,1210.0,4.1,51,2,13,15,717.242,717.242,1,1,0,3,2,1,0,0,0,Between -11 and 5\n279,Luminol sodium salt,200.15,84.2,254.0,,14,3,3,0,200.044,200.044,0,2,0,0,0,0,0,0,0,Larger than 6\n280,Dapagliflozin,408.9,99.4,472.0,2.3,28,4,6,6,408.134,408.134,0,1,0,5,5,0,0,0,0,Between -11 and 5\n281,Zinc Picolinate,309.6,106.0,108.0,,19,0,6,0,307.978,307.978,0,3,0,0,0,0,0,0,0,Larger than 6\n282,\"Pregna-1,4-diene-3,20-dione,21-(3-carboxy-1-oxopropoxy)-11,17-dihydroxy-6-methyl-, monosodiumsalt, (6a,11b)-\",497.5,138.0,981.0,,35,3,8,7,497.215,497.215,0,2,0,8,8,0,0,0,0,Larger than 6\n283,Vortioxetine,298.4,40.6,316.0,4.2,21,1,3,3,298.15,298.15,0,1,0,0,0,0,0,0,0,Between -11 and 5\n284,Enisamium iodide,354.19,33.0,241.0,,18,1,2,3,354.023,354.023,0,2,0,0,0,0,0,0,0,Larger than 6\n285,Cenicriviroc,696.9,105.0,1060.0,7.5,50,1,7,17,696.371,696.371,0,1,0,1,1,0,1,1,0,Larger than 6\n286,Apremilast,460.5,128.0,825.0,1.8,32,1,7,8,460.13,460.13,0,1,0,1,1,0,0,0,0,Between -11 and 5\n287,Empagliflozin,450.9,109.0,558.0,2.0,31,4,7,6,450.145,450.145,0,1,0,6,6,0,0,0,0,Between -11 and 5\n288,N6-ethanimidoyl-D-lysine,187.24,102.0,192.0,-3.1,13,3,4,6,187.132,187.132,0,1,0,1,1,0,0,0,0,Between -11 and 5\n289,Emricasan,569.5,151.0,934.0,3.6,40,4,11,11,569.179,569.179,0,1,0,2,2,0,0,0,0,Between -11 and 5\n290,Aviptadil Acetate,3344.9,1480.0,7510.0,-13.7,234,51,51,116,3343.74,3342.73,0,1,0,31,0,31,0,0,0,Smaller than -10\n291,Quinine sulfate dihydrate,782.9,176.0,538.0,,55,6,14,8,782.356,782.356,0,5,0,8,8,0,0,0,0,Larger than 6\n292,Hydrocortisone 21-hemisuccinate sodium salt,485.5,138.0,908.0,,34,3,8,7,485.215,485.215,0,2,0,7,7,0,0,0,0,Larger than 6\n293,Liothyronine sodium,672.95,95.6,408.0,,24,2,5,5,672.772,672.772,0,2,0,1,1,0,0,0,0,Larger than 6\n294,sodium;8-amino-4-oxo-3H-phthalazin-1-olate,199.14,90.5,269.0,,14,2,4,0,199.036,199.036,0,2,0,0,0,0,0,0,0,Larger than 6\n295,Edoxaban tosylate monohydrate,738.3,229.0,1090.0,,49,5,12,6,737.207,737.207,0,3,0,3,3,0,0,0,0,Larger than 6\n296,Daclatasvir,738.9,175.0,1190.0,5.1,54,4,8,13,738.385,738.385,0,1,0,4,4,0,0,0,0,Larger than 6\n297,\"2-[(4S)-4-amino-5,5-dihydroxyhexyl]guanidine\",190.24,131.0,177.0,-2.5,13,5,4,5,190.143,190.143,0,1,0,1,1,0,0,0,0,Between -11 and 5\n298,Fosmanogepix,468.4,148.0,644.0,1.6,33,2,9,9,468.12,468.12,0,1,0,0,0,0,0,0,0,Between -11 and 5\n299,Larazotide acetate,785.9,339.0,1320.0,,55,10,13,21,785.428,785.428,0,2,0,5,5,0,0,0,0,Larger than 6\n300,Thymosin,3051.3,1370.0,6930.0,-22.0,212,47,57,109,3050.5,3049.5,0,1,0,30,30,0,0,0,0,Smaller than -10\n301,Sofosbuvir,529.5,153.0,913.0,1.0,36,3,11,11,529.163,529.163,0,1,0,6,6,0,0,0,0,Between -11 and 5\n302,Razuprotafib,586.7,212.0,906.0,3.7,39,4,10,12,586.101,586.101,0,1,0,2,2,0,0,0,0,Between -11 and 5\n303,Nalpha-[(4-Methylpiperazin-1-Yl)carbonyl]-N-[(3s)-1-Phenyl-5-(Phenylsulfonyl)pentan-3-Yl]-L-Phenylalaninamide,576.8,107.0,897.0,4.4,41,2,5,12,576.277,576.277,0,1,0,2,2,0,0,0,0,Between -11 and 5\n304,Ascorbic Acid,176.12,107.0,232.0,-1.6,12,4,6,2,176.032,176.032,0,1,0,2,2,0,0,0,0,Between -11 and 5\n305,Doxycycline,444.4,182.0,956.0,-0.7,32,6,9,2,444.153,444.153,0,1,0,6,6,0,0,0,0,Between -11 and 5\n306,Rabeximod,409.9,63.0,590.0,3.9,29,1,4,5,409.167,409.167,0,1,0,0,0,0,0,0,0,Between -11 and 5\n307,Kaolin,258.16,98.0,167.0,,13,2,9,4,257.902,257.902,0,3,0,0,0,0,0,0,0,Larger than 6\n308,H-Ile-OH.H-Thr-OH.H-Leu-OH.H-Val-OH.H-Met-OH.H-Phe-OH.H-Trp-OH.H-Lys-OH,1163.4,594.0,988.0,,80,19,27,25,1162.65,1162.65,0,8,0,10,10,0,0,0,0,Larger than 6\n309,Semaglutide,4114.0,1650.0,9590.0,-5.8,291,57,63,151,4112.12,4111.12,0,1,0,30,30,0,0,0,0,Between -11 and 5\n310,Isuzinaxib hydrochloride,315.8,45.2,412.0,,22,2,3,4,315.114,315.114,0,2,0,0,0,0,0,0,0,Larger than 6\n311,CID 66726979,457.5,147.0,731.0,,31,3,8,9,457.105,457.105,0,2,0,0,0,0,0,0,0,Larger than 6\n312,Desidustat,332.31,116.0,583.0,1.9,24,3,6,6,332.101,332.101,0,1,0,0,0,0,0,0,0,Between -11 and 5\n313,\"7-[[2-Ethoxyimino-2-[5-(phosphonoamino)-1,2,4-thiadiazol-3-yl]acetyl]amino]-3-[[4-(1-methylpyridin-1-ium-4-yl)-1,3-thiazol-2-yl]sulfanyl]-8-oxo-5-thia-1-azabicyclo[4.2.0]oct-2-ene-2-carboxylic acid;acetate\",744.7,368.0,1240.0,,47,5,19,11,744.031,744.031,0,2,0,2,0,2,1,0,1,Larger than 6\n314,1-(4-(((6-Amino-5-(4-phenoxyphenyl)pyrimidin-4-yl)amino)methyl)-4-fluoropiperidin-1-yl)prop-2-en-1-one,447.5,93.4,643.0,4.1,33,2,7,7,447.207,447.207,0,1,0,0,0,0,0,0,0,Between -11 and 5\n315,Ceftriaxone disodium hemiheptahydrate,600.6,288.0,1110.0,,38,4,13,8,600.026,600.026,0,3,0,2,2,0,1,1,0,Larger than 6\n316,Descovy,723.7,257.0,1050.0,,49,4,15,14,723.236,723.236,0,2,0,5,5,0,0,0,0,Larger than 6\n317,Zimlovisertib,361.4,104.0,535.0,2.0,26,2,6,6,361.144,361.144,0,1,0,3,3,0,0,0,0,Between -11 and 5\n318,CID 131673872,202.17,84.2,254.0,,14,3,3,0,202.059,202.059,0,3,0,0,0,0,0,0,0,Larger than 6\n319,\"Sodium;5-amino-2,3-dihydrophthalazine-1,4-dione;hydride\",201.16,84.2,254.0,,14,3,4,0,201.051,201.051,0,3,0,0,0,0,0,0,0,Larger than 6\n320,Zilucoplan,3562.0,1070.0,6980.0,4.8,251,28,57,142,3560.97,3559.97,0,1,0,16,16,0,0,0,0,Between -11 and 5\n321,Defibrotide,444.4,137.0,773.0,1.8,31,4,7,5,444.12,444.12,0,1,0,0,0,0,0,0,0,Between -11 and 5\n322,\"7-[(3s,4r)-4-(3-Chlorophenyl)carbonylpyrrolidin-3-Yl]-3h-Quinazolin-4-One\",353.8,70.6,567.0,2.1,25,2,4,3,353.093,353.093,0,1,0,2,2,0,0,0,0,Between -11 and 5\n323,Unii-7kyp9tkt70,879.6,484.0,1210.0,,58,15,24,13,879.205,879.205,0,4,0,8,0,8,0,0,0,Larger than 6\n324,\"4-acetamidobenzoic acid;9-[(2R,3R,4R,5R)-3,4-dihydroxy-5-(hydroxymethyl)oxolan-2-yl]-1H-purin-6-one;1-(dimethylamino)propan-2-ol\",1115.2,399.0,658.0,,79,13,22,14,1114.55,1114.55,0,7,0,7,4,3,0,0,0,Larger than 6\n325,\"[(1S,4R,6S)-4-(cyclopropylsulfonylcarbamoyl)-14-[(2-methylpropan-2-yl)oxycarbonylamino]-2,15-dioxo-3,16-diazatricyclo[14.3.0.04,6]nonadec-7-en-18-yl] 4-fluoro-1,3-dihydroisoindole-2-carboxylate\",731.8,189.0,1530.0,3.3,51,3,10,8,731.3,731.3,0,1,0,5,3,2,1,0,1,Between -11 and 5\n326,example 13 [US20210284598A1],257.279,40.5,287.0,2.7,18,1,4,4,257.123,257.123,0,1,0,0,0,0,0,0,0,Between -11 and 5\n327,Stannous protoporphyrin,679.4,102.0,1010.0,,43,2,8,8,680.145,680.145,0,2,0,0,0,0,0,0,0,Larger than 6\n328,\"3,6-Di-O-acetyl-2-deoxy-d-glucopyranose\",248.23,110.0,276.0,-1.7,17,2,7,9,248.09,248.09,0,1,0,3,3,0,0,0,0,Between -11 and 5\n329,X6 hydrobromide [PMID: 34584244],502.5,168.0,887.0,2.3,36,1,11,11,502.229,502.229,0,1,1,4,4,0,0,0,0,Between -11 and 5\n330,Enoxaparin,1134.9,652.0,2410.0,-10.8,70,15,38,21,1134.01,1134.01,0,1,0,20,0,20,0,0,0,Smaller than -10\n331,Amantadine,151.25,26.0,144.0,2.4,11,1,1,0,151.136,151.136,0,1,0,0,0,0,0,0,0,Between -11 and 5\n332,Amlodipine,408.9,99.9,647.0,3.0,28,2,7,10,408.145,408.145,0,1,0,1,0,1,0,0,0,Between -11 and 5\n333,Bicalutamide,430.4,116.0,750.0,2.3,29,2,9,5,430.061,430.061,0,1,0,1,0,1,0,0,0,Between -11 and 5\n334,Candesartan cilexetil,610.7,143.0,962.0,7.0,45,1,10,13,610.254,610.254,0,1,0,1,0,1,0,0,0,Larger than 6\n335,Formoterol,344.4,90.8,388.0,1.8,25,4,5,8,344.174,344.174,0,1,0,2,0,2,0,0,0,Between -11 and 5\n336,Hydroxychloroquine,335.9,48.4,331.0,3.6,23,2,4,9,335.176,335.176,0,1,0,1,0,1,0,0,0,Between -11 and 5\n337,Ibudilast,230.31,34.4,288.0,3.0,17,0,2,3,230.142,230.142,0,1,0,0,0,0,0,0,0,Between -11 and 5\n338,Lidocaine,234.34,32.299,228.0,2.3,17,1,2,5,234.173,234.173,0,1,0,0,0,0,0,0,0,Between -11 and 5\n339,Modafinil,273.4,79.4,302.0,1.7,19,1,3,5,273.082,273.082,0,1,0,1,0,1,0,0,0,Between -11 and 5\n340,Omeprazole,345.4,96.3,453.0,2.2,24,1,6,5,345.115,345.115,0,1,0,1,0,1,0,0,0,Between -11 and 5\n341,Pentoxifylline,278.31,75.5,426.0,0.3,20,0,4,5,278.138,278.138,0,1,0,0,0,0,0,0,0,Between -11 and 5\n342,Arginine,174.2,128.0,176.0,-4.2,12,4,4,5,174.112,174.112,0,1,0,1,1,0,0,0,0,Between -11 and 5\n343,\"4,4'-Diphenylmethane diisocyanate\",250.25,58.9,332.0,5.4,19,0,4,4,250.074,250.074,0,1,0,0,0,0,0,0,0,Larger than 6\n344,Carvacrol,150.22,20.2,120.0,3.1,11,1,1,1,150.104,150.104,0,1,0,0,0,0,0,0,0,Between -11 and 5\n345,Silver,107.868,0.0,0.0,,1,0,0,0,106.905,106.905,0,1,0,0,0,0,0,0,0,Larger than 6\n346,Phorbol 12-myristate 13-acetate,616.8,130.0,1150.0,6.5,44,3,8,17,616.398,616.398,0,1,0,8,8,0,0,0,0,Larger than 6\n347,(-)-Mefloquine,378.31,45.2,483.0,3.6,26,2,9,2,378.117,378.117,0,1,0,2,2,0,0,0,0,Between -11 and 5\n348,Atorvastatin,558.6,112.0,822.0,5.0,41,4,6,12,558.253,558.253,0,1,0,2,2,0,0,0,0,Between -11 and 5\n349,Propranolol Hydrochloride,295.8,41.5,257.0,,20,3,3,6,295.134,295.134,0,2,0,1,0,1,0,0,0,Larger than 6\n350,Oseltamivir,312.4,90.6,418.0,1.1,22,2,5,8,312.205,312.205,0,1,0,3,3,0,0,0,0,Between -11 and 5\n351,\"2,4,6-Trinitro-m-xylene\",241.16,138.0,317.0,2.0,17,0,6,0,241.033,241.033,0,1,0,0,0,0,0,0,0,Between -11 and 5\n352,Argatroban,508.6,189.0,887.0,1.3,35,5,8,9,508.247,508.247,0,1,0,4,3,1,0,0,0,Between -11 and 5\n353,Lopinavir,628.8,120.0,940.0,5.9,46,4,5,15,628.362,628.362,0,1,0,4,4,0,0,0,0,Larger than 6\n354,Allopregnanolone,318.5,37.3,500.0,4.9,23,1,2,1,318.256,318.256,0,1,0,8,8,0,0,0,0,Between -11 and 5\n355,Fingolimod,307.5,66.5,258.0,4.2,22,3,3,12,307.251,307.251,0,1,0,0,0,0,0,0,0,Between -11 and 5\n356,Imatinib Mesylate,589.7,149.0,799.0,,42,3,10,7,589.247,589.247,0,2,0,0,0,0,0,0,0,Larger than 6\n357,Meldonium,146.19,52.2,112.0,-2.1,10,1,3,3,146.106,146.106,0,1,0,0,0,0,0,0,0,Between -11 and 5\n358,Ramatroban,416.5,96.8,689.0,2.9,29,2,6,6,416.121,416.121,0,1,0,1,1,0,0,0,0,Between -11 and 5\n359,Ivabradine,468.6,60.5,663.0,2.4,34,0,6,10,468.262,468.262,0,1,0,1,1,0,0,0,0,Between -11 and 5\n360,Moxifloxacin,401.4,82.1,727.0,0.6,29,2,8,4,401.175,401.175,0,1,0,2,2,0,0,0,0,Between -11 and 5\n361,Varespladib,380.4,112.0,589.0,2.8,28,2,5,8,380.137,380.137,0,1,0,0,0,0,0,0,0,Between -11 and 5\n362,Naproxen,230.26,46.5,277.0,3.3,17,1,3,3,230.094,230.094,0,1,0,1,1,0,0,0,0,Between -11 and 5\n363,Dabigatran,471.5,150.0,757.0,1.7,35,4,7,9,471.202,471.202,0,1,0,0,0,0,0,0,0,Between -11 and 5\n364,Senicapoc,323.3,43.1,397.0,4.1,24,1,3,4,323.112,323.112,0,1,0,0,0,0,0,0,0,Between -11 and 5\n365,Povidone iodine,364.95,20.3,120.0,,10,0,1,1,364.877,364.877,0,2,0,0,0,0,0,0,0,Larger than 6\n366,beta-L-Arabinose,150.13,90.2,117.0,-2.5,10,4,5,0,150.053,150.053,0,1,0,4,4,0,0,0,0,Between -11 and 5\n367,Quinidine,324.4,45.6,457.0,2.9,24,1,4,4,324.184,324.184,0,1,0,4,4,0,0,0,0,Between -11 and 5\n368,Pectin,194.14,127.0,205.0,-2.3,13,5,7,1,194.043,194.043,0,1,0,5,5,0,0,0,0,Between -11 and 5\n369,Fluticasone Propionate,500.6,106.0,984.0,4.0,34,1,9,6,500.184,500.184,0,1,0,9,9,0,0,0,0,Between -11 and 5\n370,Decitabine,228.21,121.0,356.0,-1.2,16,3,4,2,228.086,228.086,0,1,0,3,3,0,0,0,0,Between -11 and 5\n371,Bucillamine,223.3,68.4,218.0,0.4,13,4,5,4,223.034,223.034,0,1,0,1,1,0,0,0,0,Between -11 and 5\n372,Canrenoic acid,358.5,74.6,707.0,1.9,26,2,4,3,358.214,358.214,0,1,0,6,6,0,0,0,0,Between -11 and 5\n373,\"(S)-[2,8-bis(trifluoromethyl)quinolin-4-yl]-[(2S)-piperidin-2-yl]methanol\",378.31,45.2,483.0,3.6,26,2,9,2,378.117,378.117,0,1,0,2,2,0,0,0,0,Between -11 and 5\n374,\"(-)-(S)-9-Fluoro-2,3-dihydro-3-methyl-10-(4-methyl-1-piperazinyl)-7-oxo-7H-pyrido(1,2,3-de)-1,4-benzoxazine-6-carboxylic acid, hemihydrate\",740.7,148.0,634.0,,53,3,17,4,740.298,740.298,0,3,0,2,2,0,0,0,0,Larger than 6\n375,\"(S,S)-Formoterol\",344.4,90.8,388.0,1.8,25,4,5,8,344.174,344.174,0,1,0,2,2,0,0,0,0,Between -11 and 5\n376,Glatiramer acetate,623.7,374.0,519.0,,43,12,18,13,623.301,623.301,0,5,0,4,4,0,0,0,0,Larger than 6\n377,Isoquercetin,464.4,207.0,758.0,0.4,33,8,12,4,464.095,464.095,0,1,0,5,5,0,0,0,0,Between -11 and 5\n378,Pitavastatin,421.5,90.6,631.0,3.5,31,3,6,8,421.169,421.169,0,1,0,2,2,0,1,1,0,Between -11 and 5\n379,Deoxy-methyl-arginine,172.23,108.0,174.0,-1.8,12,3,3,5,172.132,172.132,0,1,0,1,1,0,0,0,0,Between -11 and 5\n380,Dexmedetomidine,200.28,28.7,205.0,3.1,15,1,1,2,200.131,200.131,0,1,0,1,1,0,0,0,0,Between -11 and 5\n381,Nafamostat mesylate,539.6,266.0,645.0,,36,6,10,5,539.114,539.114,0,3,0,0,0,0,0,0,0,Larger than 6\n382,Bromhexine Hydrochloride,412.59,29.3,256.0,,19,2,2,3,411.974,409.976,0,2,0,0,0,0,0,0,0,Larger than 6\n383,Tenofovir Disoproxil Fumarate,635.5,260.0,817.0,,43,3,18,19,635.184,635.184,0,2,0,1,1,0,1,1,0,Larger than 6\n384,Eritoran,1313.7,294.0,1900.0,15.4,89,7,19,59,1312.84,1312.84,0,1,0,11,11,0,1,1,0,Larger than 6\n385,Icatibant acetate,1364.6,589.0,2750.0,,96,16,20,30,1363.68,1363.68,0,2,0,12,12,0,0,0,0,Larger than 6\n386,Dalcetrapib,389.6,71.5,481.0,7.1,27,1,3,9,389.239,389.239,0,1,0,0,0,0,0,0,0,Larger than 6\n387,\"7-[[(2Z)-2-ethoxyimino-2-[5-(phosphonoamino)-1,2,4-thiadiazol-3-yl]acetyl]amino]-3-[[4-(1-methylpyridin-1-ium-4-yl)-1,3-thiazol-2-yl]sulfanyl]-8-oxo-5-thia-1-azabicyclo[4.2.0]oct-2-ene-2-carboxylic acid\",685.7,328.0,1220.0,1.6,43,5,17,11,685.018,685.018,1,1,0,2,0,2,1,1,0,Between -11 and 5\n388,Icosapent ethyl,330.5,26.3,425.0,6.3,24,0,2,15,330.256,330.256,0,1,0,0,0,0,5,5,0,Larger than 6\n389,\"1-Piperazinecarboxamide, 4-methyl-N-((1S)-2-oxo-2-(((1S)-1-(2-phenylethyl)-3-(phenylsulfonyl)-2-propenyl)amino)-1-(phenylmethyl)ethyl)-\",574.7,107.0,939.0,4.1,41,2,5,11,574.261,574.261,0,1,0,2,2,0,1,1,0,Between -11 and 5\n390,Remimazolam,439.3,69.4,601.0,3.4,28,0,5,5,438.069,438.069,0,1,0,1,1,0,0,0,0,Between -11 and 5\n391,Azithromycin Monohydrate,767.0,181.0,1150.0,,53,6,15,7,766.519,766.519,0,2,0,18,18,0,0,0,0,Larger than 6\n392,Danoprevir,731.8,189.0,1530.0,3.3,51,3,10,8,731.3,731.3,0,1,0,5,5,0,1,1,0,Between -11 and 5\n393,Mitoquinone,583.7,52.6,886.0,9.4,42,0,4,16,583.298,583.298,1,1,0,0,0,0,0,0,0,Larger than 6\n394,Belnacasan,509.0,140.0,818.0,2.3,35,3,7,8,508.209,508.209,0,1,0,4,4,0,0,0,0,Between -11 and 5\n395,Apilimod mesylate,610.7,210.0,637.0,,41,3,14,8,610.188,610.188,0,3,0,0,0,0,1,1,0,Larger than 6\n396,Losmapimod,383.5,71.1,573.0,3.8,28,2,4,6,383.201,383.201,0,1,0,0,0,0,0,0,0,Between -11 and 5\n397,Emtricitabine and tenofovir disoproxil fumarate,882.8,374.0,1190.0,,59,5,23,21,882.227,882.227,0,3,0,3,3,0,1,1,0,Larger than 6\n398,Dapansutrile,133.17,66.3,190.0,-0.7,8,0,3,2,133.02,133.02,0,1,0,0,0,0,0,0,0,Between -11 and 5\n399,\"(S)-[2,8-bis(trifluoromethyl)quinolin-4-yl]-piperidin-2-ylmethanol\",378.31,45.2,483.0,3.6,26,2,9,2,378.117,378.117,0,1,0,2,1,1,0,0,0,Between -11 and 5\n400,Tridecactide,1623.8,659.0,3240.0,-6.2,115,23,24,50,1622.77,1622.77,0,1,0,12,12,0,0,0,0,Between -11 and 5\n401,Aviptadil,3326.8,1470.0,7580.0,-15.9,234,51,51,115,3325.74,3324.74,0,1,0,31,31,0,0,0,0,Smaller than -10\n402,Pamapimod,406.4,108.0,591.0,2.4,29,3,9,8,406.145,406.145,0,1,0,0,0,0,0,0,0,Between -11 and 5\n403,Sodium pyruvate,110.04,57.2,88.2,,7,0,3,1,109.998,109.998,0,2,0,0,0,0,0,0,0,Larger than 6\n404,Brequinar sodium,397.3,53.0,557.0,,29,0,5,3,397.089,397.089,0,2,0,0,0,0,0,0,0,Larger than 6\n405,Montelukast Sodium,608.2,98.6,898.0,,42,1,5,12,607.192,607.192,0,2,0,1,1,0,1,1,0,Larger than 6\n406,Sivelestat sodium anhydrous,456.4,150.0,738.0,,31,2,8,9,456.097,456.097,0,2,0,0,0,0,0,0,0,Larger than 6\n407,Methylprednisolone sodium succinate,496.5,141.0,988.0,,35,2,8,7,496.207,496.207,0,2,0,8,8,0,0,0,0,Larger than 6\n408,Bromelains,248.25,81.6,344.0,,17,1,3,4,248.114,248.114,0,2,0,2,0,2,0,0,0,Larger than 6\n409,Fostamatinib disodium,732.5,198.0,893.0,,48,8,21,9,732.176,732.176,0,9,0,0,0,0,0,0,0,Larger than 6\n410,Phosphate-Buffered Saline,411.04,164.0,96.3,,17,3,10,0,409.765,409.765,0,9,0,0,0,0,0,0,0,Larger than 6\n411,4'-C-Azido-2'-deoxy-2'-fluoro-b-D-arabinocytidine,286.22,123.0,533.0,-0.8,20,3,7,3,286.083,286.083,0,1,0,4,0,4,1,0,1,Between -11 and 5\n412,5-Chloro-2-([(2-([3-(furan-2-yl)phenyl]amino)-2-oxoethoxy)acetyl]amino)benzoic acid,428.8,118.0,618.0,3.3,30,3,6,8,428.078,428.078,0,1,0,0,0,0,0,0,0,Between -11 and 5\n413,\"[(2R,3S,4R)-4-acetyloxy-3,6-dihydroxyoxan-2-yl]methyl acetate\",248.23,102.0,290.0,-1.0,17,2,7,5,248.09,248.09,0,1,0,4,3,1,0,0,0,Between -11 and 5\n414,Ketone Ester,176.21,66.8,135.0,-0.1,12,2,4,6,176.105,176.105,0,1,0,2,2,0,0,0,0,Between -11 and 5\n415,CID 45114162,520.6,152.0,761.0,,34,2,10,9,520.123,520.123,1,2,0,2,2,0,1,1,0,Larger than 6\n416,Alvelestat,545.5,123.0,1100.0,2.5,38,1,9,6,545.134,545.134,0,1,0,0,0,0,0,0,0,Between -11 and 5\n417,Emvododstat,467.3,54.6,651.0,6.3,32,1,3,4,466.085,466.085,0,1,0,1,1,0,0,0,0,Larger than 6\n418,8-chloro-N-[4-(trifluoromethoxy)phenyl]quinolin-2-amine,338.71,34.2,388.0,5.9,23,1,6,3,338.043,338.043,0,1,0,0,0,0,0,0,0,Larger than 6\n419,Riamilovir sodium dihydrate,286.2,152.0,262.0,,18,2,10,1,286.01,286.01,0,4,0,0,0,0,0,0,0,Larger than 6\n420,Doxycycline hyclate,545.0,203.0,958.0,,37,9,11,2,544.182,544.182,0,4,0,6,6,0,0,0,0,Larger than 6\n421,Budesonide and formoterol fumarate dihydrate,774.9,184.0,1250.0,,56,6,11,12,774.409,774.409,0,2,0,11,10,1,0,0,0,Larger than 6\n422,Vafidemstat,336.4,86.2,410.0,2.2,25,2,6,7,336.159,336.159,0,1,0,2,2,0,0,0,0,Between -11 and 5\n423,Ledipasvir,889.0,175.0,1820.0,7.4,65,4,10,12,888.413,888.413,0,1,0,6,6,0,0,0,0,Larger than 6\n424,Telacebec,557.0,58.9,796.0,7.9,39,1,7,7,556.185,556.185,0,1,0,0,0,0,0,0,0,Larger than 6\n425,Acebilustat,481.5,79.0,728.0,2.2,36,1,7,8,481.2,481.2,0,1,0,2,2,0,0,0,0,Between -11 and 5\n426,Quinidine monohydrate,342.4,46.6,457.0,,25,2,5,4,342.194,342.194,0,2,0,4,4,0,0,0,0,Larger than 6\n427,Dexamethasone phosphate disodium,518.4,141.0,973.0,,34,4,9,4,518.146,518.146,0,3,0,8,8,0,0,0,0,Larger than 6\n428,Montmorillonite,360.31,141.0,18.3,,18,1,12,0,359.825,359.825,0,10,0,0,0,0,0,0,0,Larger than 6\n429,methyl N-[(2R)-2-[2-[5-[4-[4-[2-[1-[(2S)-2-(methoxycarbonylamino)-3-methyl-butanoyl]pyrrolidin-2-yl]-1H-imidazol-5-yl]phenyl]phenyl]-1H-imidazol-2-yl]pyrrolidine-1-carbonyl]-3-methyl-butyl]carbamate,752.9,175.0,1300.0,5.0,55,4,8,14,752.401,752.401,0,1,0,4,2,2,0,0,0,Between -11 and 5\n430,Nadide sodium,685.4,324.0,1110.0,,45,6,18,11,685.091,685.091,0,2,0,8,8,0,0,0,0,Larger than 6\n431,\"(6R,7R)-7-[[(2E)-2-ethoxyimino-2-[5-(phosphonoamino)-1,2,4-thiadiazol-3-yl]acetyl]amino]-3-[[4-(1-methylpyridin-1-ium-4-yl)-1,3-thiazol-2-yl]sulfanyl]-8-oxo-5-thia-1-azabicyclo[4.2.0]oct-2-ene-2-carboxylate\",684.7,330.0,1210.0,2.3,43,4,17,10,684.01,684.01,0,1,0,2,2,0,1,1,0,Between -11 and 5\n432,\"3-Deoxy-3-[4-(3-Fluorophenyl)-1h-1,2,3-Triazol-1-Yl]-Beta-D-Galactopyranosyl 3-Deoxy-3-[4-(3-Fluorophenyl)-1h-1,2,3-Triazol-1-Yl]-1-Thio-Beta-D-Galactopyranoside\",648.6,227.0,903.0,0.2,45,6,15,8,648.181,648.181,0,1,0,10,10,0,0,0,0,Between -11 and 5\n433,\"N-[(2S,3S,4R)-1-(alpha-D-galactopyranosyloxy)-3,4-dihydroxyoctadecan-2-yl]undecanamide\",647.9,169.0,700.0,7.9,45,7,9,29,647.497,647.497,0,1,0,8,8,0,0,0,0,Larger than 6\n434,Brensocatib,420.5,104.0,699.0,2.0,31,2,6,5,420.18,420.18,0,1,0,2,2,0,0,0,0,Between -11 and 5\n435,Ezurpimtrostat,423.0,40.2,520.0,5.9,30,2,4,6,422.224,422.224,0,1,0,0,0,0,0,0,0,Larger than 6\n436,Dexamethasone 21-phosphate disodium salt,548.5,141.0,973.0,,36,4,9,4,548.193,548.193,0,4,0,8,8,0,0,0,0,Larger than 6\n437,Enpatoran,320.31,65.9,472.0,2.7,23,1,7,1,320.125,320.125,0,1,0,2,2,0,0,0,0,Between -11 and 5\n438,H-D-Lys-D-Leu-D-Leu-D-Leu-D-Leu-D-Lys-D-Leu-D-Leu-D-Leu-D-Leu-D-Lys-D-Leu-D-Leu-D-Leu-D-Leu-D-Lys-D-Leu-D-Leu-D-Leu-D-Leu-D-Lys-OH,2469.4,775.0,4880.0,11.9,174,27,28,93,2468.83,2467.83,0,1,0,21,21,0,0,0,0,Larger than 6\n439,CID 131844884,1738.2,873.0,3450.0,,101,19,52,30,1736.85,1736.85,0,11,0,25,25,0,0,0,0,Larger than 6\n440,Folic Acid,441.4,209.0,767.0,-1.1,32,6,10,9,441.14,441.14,0,1,0,1,1,0,0,0,0,Between -11 and 5\n441,Inosine pranobex,1115.2,399.0,658.0,,79,13,22,14,1114.55,1114.55,0,7,0,7,4,3,0,0,0,Larger than 6\n442,Eltrombopag,442.5,115.0,812.0,5.4,33,3,7,5,442.164,442.164,0,1,0,0,0,0,0,0,0,Larger than 6\n443,Rintatolimod,995.6,517.0,1600.0,,65,15,27,12,995.135,995.135,0,3,0,12,12,0,0,0,0,Larger than 6\n444,Normosang,792.7,260.0,1180.0,,55,8,10,13,792.305,792.305,2,3,0,1,1,0,0,0,0,Larger than 6\n445,Artecom,1294.4,485.0,1380.0,,84,15,31,12,1293.31,1293.31,0,6,0,8,8,0,0,0,0,Larger than 6\n446,Imunovir; Delimmun; Groprinosin;Inosine pranobex,1115.2,399.0,658.0,,79,13,22,14,1114.55,1114.55,0,7,0,7,0,7,0,0,0,Larger than 6\n447,\"1-(4-fluorobenzene-6-id-1-yl)-N-phenylmethanimine;iridium(3+);1,2,3,4,5-pentamethylcyclopenta-1,3-diene;chloride\",561.1,12.4,601.0,,27,0,5,1,561.121,561.121,0,4,0,0,0,0,0,0,0,Larger than 6\n448,EIDD-2801,329.31,141.0,534.0,-0.8,23,4,7,6,329.122,329.122,0,1,0,4,4,0,0,0,0,Between -11 and 5\n449,CID 154701548,287.21,143.0,435.0,,18,3,8,1,287.017,287.017,0,4,0,0,0,0,0,0,0,Larger than 6\n450,\"alpha-D-Glucopyranoside, methyl O-2-deoxy-6-O-sulfo-2-(sulfoamino)-alpha-D-glucopyranosyl-(1-->4)-O-beta-D-glucopyranuronosyl-(1-->4)-O-2-deoxy-3,6-di-O-sulfo-2-(sulfoamino)-alpha-D-glucopyranosyl-(1-->4)-O-2-O-sulfo-alpha-L-idopyranuronosyl-(1-->4)-2-deoxy-2-(sulfoamino)-, 6-(hydrogen sulfate), sodium salt (1:10)\",1531.3,873.0,3450.0,,92,19,52,30,1529.94,1529.94,0,2,0,25,25,0,0,0,0,Larger than 6\n451,\"propan-2-yl (2S)-2-[[[(2R,3R,4R,5R)-5-[2-amino-6-(methylamino)purin-9-yl]-4-fluoro-3-hydroxy-4-methyloxolan-2-yl]methoxy-phenoxyphosphoryl]amino]propanoate;sulfuric acid\",679.6,268.0,1000.0,,45,6,18,12,679.184,679.184,0,2,0,6,5,1,0,0,0,Larger than 6\n452,Ensitrelvir,531.9,114.0,919.0,2.5,37,1,8,6,531.115,531.115,0,1,0,0,0,0,0,0,0,Between -11 and 5\n453,\"3,4-Methylenedioxymethamphetamine\",193.24,30.5,186.0,2.2,14,1,3,3,193.11,193.11,0,1,0,1,0,1,0,0,0,Between -11 and 5\n454,Acetaminophen,151.16,49.3,139.0,0.5,11,2,2,1,151.063,151.063,0,1,0,0,0,0,0,0,0,Between -11 and 5\n455,Amiodarone,645.3,42.7,547.0,7.6,31,0,4,11,645.024,645.024,0,1,0,0,0,0,0,0,0,Larger than 6\n456,Verapamil,454.6,64.0,606.0,3.8,33,0,6,13,454.283,454.283,0,1,0,1,0,1,0,0,0,Between -11 and 5\n457,Candesartan,440.5,119.0,660.0,4.1,33,2,7,7,440.16,440.16,0,1,0,0,0,0,0,0,0,Between -11 and 5\n458,Chlordiazepoxide,299.75,48.2,580.0,2.4,21,1,3,1,299.083,299.083,0,1,0,0,0,0,0,0,0,Between -11 and 5\n459,Chloroquine,319.9,28.2,309.0,4.6,22,1,3,8,319.182,319.182,0,1,0,1,0,1,0,0,0,Between -11 and 5\n460,Deferoxamine,560.7,206.0,739.0,-2.1,39,6,9,23,560.353,560.353,0,1,0,0,0,0,0,0,0,Between -11 and 5\n461,Famotidine,337.5,238.0,469.0,-0.6,20,4,8,7,337.045,337.045,0,1,0,0,0,0,1,0,1,Between -11 and 5\n462,Fenofibrate,360.8,52.6,458.0,5.2,25,0,4,7,360.113,360.113,0,1,0,0,0,0,0,0,0,Larger than 6\n463,Ketamine,237.72,29.1,269.0,2.2,16,1,2,2,237.092,237.092,0,1,0,1,0,1,0,0,0,Between -11 and 5\n464,Lansoprazole,369.4,87.1,480.0,2.8,25,1,8,5,369.076,369.076,0,1,0,1,0,1,0,0,0,Between -11 and 5\n465,Metformin,129.16,91.5,132.0,-1.3,9,3,1,2,129.101,129.101,0,1,0,0,0,0,0,0,0,Between -11 and 5\n466,Nafamostat,347.4,141.0,552.0,2.0,26,4,4,5,347.138,347.138,0,1,0,0,0,0,0,0,0,Between -11 and 5\n467,Palmitoylethanolamide,299.5,49.3,219.0,6.2,21,2,2,16,299.282,299.282,0,1,0,0,0,0,0,0,0,Larger than 6\n468,Pioglitazone,356.4,93.6,466.0,3.8,25,1,5,7,356.119,356.119,0,1,0,1,0,1,0,0,0,Between -11 and 5\n469,Propofol,178.27,20.2,135.0,3.8,13,1,1,2,178.136,178.136,0,1,0,0,0,0,0,0,0,Between -11 and 5\n470,Sevoflurane,200.05,9.2,121.0,2.8,12,0,8,2,200.007,200.007,0,1,0,0,0,0,0,0,0,Between -11 and 5\n471,Tranexamic acid,157.21,63.3,139.0,-2.0,11,2,3,2,157.11,157.11,0,1,0,0,0,0,0,0,0,Between -11 and 5\n472,Prednisolone,360.4,94.8,724.0,1.6,26,3,5,2,360.194,360.194,0,1,0,7,7,0,0,0,0,Between -11 and 5\n473,Levothyroxine,776.87,92.8,420.0,2.4,24,3,5,5,776.687,776.687,0,1,0,1,1,0,0,0,0,Between -11 and 5\n474,Mannitol,182.17,121.0,105.0,-3.1,12,6,6,5,182.079,182.079,0,1,0,4,4,0,0,0,0,Between -11 and 5\n475,Dexamethasone phosphate,472.4,141.0,973.0,0.1,32,4,9,4,472.166,472.166,0,1,0,8,8,0,0,0,0,Between -11 and 5\n476,Citrulline,175.19,118.0,171.0,-4.3,12,4,4,5,175.096,175.096,0,1,0,1,1,0,0,0,0,Between -11 and 5\n477,Hesperidin,610.6,234.0,940.0,-1.1,43,8,15,7,610.19,610.19,0,1,0,11,11,0,0,0,0,Between -11 and 5\n478,Zinc Citrate,574.3,281.0,211.0,,29,2,14,4,571.791,569.794,0,5,0,0,0,0,0,0,0,Larger than 6\n479,Zinc Acetate,183.5,80.3,25.5,,9,0,4,0,181.956,181.956,0,3,0,0,0,0,0,0,0,Larger than 6\n480,Canrenone,340.5,43.4,719.0,2.7,25,0,3,0,340.204,340.204,0,1,0,6,6,0,0,0,0,Between -11 and 5\n481,Hydrocortisone hemisuccinate,462.5,138.0,908.0,1.8,33,3,8,7,462.225,462.225,0,1,0,7,7,0,0,0,0,Between -11 and 5\n482,Methylprednisolone hemisuccinate,474.5,138.0,981.0,2.2,34,3,8,7,474.225,474.225,0,1,0,8,8,0,0,0,0,Between -11 and 5\n483,Azo rubin S,458.5,170.0,880.0,3.3,31,3,9,4,458.024,458.024,0,1,0,0,0,0,0,0,0,Between -11 and 5\n484,\"Zinc, bis(D-gluconato-kappaO1,kappaO2)-, (T-4)-\",457.7,277.0,385.0,,27,12,14,10,456.046,456.046,0,3,0,8,8,0,0,0,0,Larger than 6\n485,2-acetamido-2-deoxy-beta-D-glucopyranose,221.21,119.0,235.0,-1.7,15,5,6,2,221.09,221.09,0,1,0,5,5,0,0,0,0,Between -11 and 5\n486,Zinc Sulfate,161.4,88.6,62.2,,6,0,4,0,159.881,159.881,0,2,0,0,0,0,0,0,0,Larger than 6\n487,Sodium Thiosulfate,158.11,104.0,82.6,,7,0,4,0,157.908,157.908,0,3,0,0,0,0,0,0,0,Larger than 6\n488,Diacerein,368.3,124.0,683.0,1.9,27,1,8,5,368.053,368.053,0,1,0,0,0,0,0,0,0,Between -11 and 5\n489,Levamisole,204.29,40.9,246.0,1.8,14,0,2,1,204.072,204.072,0,1,0,1,1,0,0,0,0,Between -11 and 5\n490,Cromolyn sodium,512.299,172.0,824.0,,36,1,11,6,512.033,512.033,0,3,0,0,0,0,0,0,0,Larger than 6\n491,Calcium dobesilate,418.4,212.0,228.0,,25,4,10,0,417.934,417.934,0,3,0,0,0,0,0,0,0,Larger than 6\n492,Amoxicillin,365.4,158.0,590.0,-2.0,25,4,7,4,365.105,365.105,0,1,0,4,4,0,0,0,0,Between -11 and 5\n493,Tramadol,263.37,32.7,282.0,2.6,19,1,3,4,263.189,263.189,0,1,0,2,2,0,0,0,0,Between -11 and 5\n494,Almitrine,477.6,69.2,602.0,5.6,35,2,9,10,477.245,477.245,0,1,0,0,0,0,0,0,0,Larger than 6\n495,Pirfenidone,185.22,20.3,285.0,1.9,14,0,1,1,185.084,185.084,0,1,0,0,0,0,0,0,0,Between -11 and 5\n496,Piperacillin,517.6,182.0,982.0,0.5,36,3,8,6,517.163,517.163,0,1,0,4,4,0,0,0,0,Between -11 and 5\n497,Captopril,217.29,58.6,244.0,0.3,14,2,4,3,217.077,217.077,0,1,0,2,2,0,0,0,0,Between -11 and 5\n498,Nicorandil,211.17,97.0,228.0,0.8,15,1,5,4,211.059,211.059,0,1,0,0,0,0,0,0,0,Between -11 and 5\n499,Brequinar,375.4,50.2,551.0,5.6,28,1,5,3,375.107,375.107,0,1,0,0,0,0,0,0,0,Larger than 6\n500,Amantadine hydrochloride,187.71,26.0,144.0,,12,2,1,0,187.113,187.113,0,2,0,0,0,0,0,0,0,Larger than 6\n501,Chloroquine Phosphate,515.9,184.0,359.0,,32,7,11,8,515.135,515.135,0,3,0,1,0,1,0,0,0,Larger than 6\n502,Epigallocatechin Gallate,458.4,197.0,667.0,1.2,33,8,11,4,458.085,458.085,0,1,0,2,2,0,0,0,0,Between -11 and 5\n503,Artemisinin,282.33,54.0,452.0,2.8,20,0,5,0,282.147,282.147,0,1,0,7,7,0,0,0,0,Between -11 and 5\n504,\"1-((2S,3R,4S,5S)-3-Fluoro-4-hydroxy-5-(hydroxymethyl)tetrahydrofuran-2-yl)-5-methylpyrimidine-2,4(1H,3H)-dione\",260.22,99.1,413.0,-0.9,18,3,6,2,260.081,260.081,0,1,0,4,4,0,0,0,0,Between -11 and 5\n505,Bis (2-Carboxyethylgermanium)sesquioxide,339.4,118.0,259.0,,15,2,7,8,339.886,341.885,0,1,0,0,0,0,0,0,0,Larger than 6\n506,Clarithromycin,748.0,183.0,1190.0,3.2,52,4,14,8,747.477,747.477,0,1,0,18,18,0,0,0,0,Between -11 and 5\n507,\"2,6-Difluorophenol\",130.09,20.2,87.1,2.0,9,1,3,0,130.023,130.023,0,1,0,0,0,0,0,0,0,Between -11 and 5\n508,Moxifloxacin Hydrochloride,437.9,82.1,727.0,,30,3,8,4,437.152,437.152,0,2,0,2,2,0,0,0,0,Larger than 6\n509,Levofloxacin,361.4,73.3,634.0,-0.4,26,1,8,2,361.144,361.144,0,1,0,1,1,0,0,0,0,Between -11 and 5\n510,Olmesartan,446.5,130.0,656.0,3.2,33,3,7,8,446.207,446.207,0,1,0,0,0,0,0,0,0,Between -11 and 5\n511,Tetrasul sulfoxide,340.0,36.3,307.0,5.2,18,0,2,2,339.886,337.889,0,1,0,1,0,1,0,0,0,Larger than 6\n512,Ramelteon,259.339,38.3,331.0,2.7,19,1,2,4,259.157,259.157,0,1,0,1,1,0,0,0,0,Between -11 and 5\n513,Darunavir,547.7,149.0,853.0,2.9,38,3,9,12,547.235,547.235,0,1,0,5,5,0,0,0,0,Between -11 and 5\n514,Galactomannan,504.4,269.0,641.0,-6.3,34,11,16,7,504.169,504.169,0,1,0,15,15,0,0,0,0,Between -11 and 5\n515,Mometasone furoate,521.4,93.8,1020.0,3.9,35,1,6,5,520.142,520.142,0,1,0,8,8,0,0,0,0,Between -11 and 5\n516,Rosuvastatin,481.5,149.0,767.0,1.6,33,3,10,10,481.168,481.168,0,1,0,2,2,0,1,1,0,Between -11 and 5\n517,Tenofovir,287.21,136.0,354.0,-1.6,19,3,8,5,287.078,287.078,0,1,0,1,1,0,0,0,0,Between -11 and 5\n518,3-Cyclopentyl-1-(piperazin-1-yl)propan-1-one,210.32,32.299,206.0,1.6,15,1,2,3,210.173,210.173,0,1,0,0,0,0,0,0,0,Between -11 and 5\n519,Azithromycin Dihydrate,785.0,182.0,1150.0,,54,7,16,7,784.53,784.53,0,3,0,18,18,0,0,0,0,Larger than 6\n520,\"D-Alanine, N-methylglycyl-L-arginyl-L-valyl-L-tyrosyl-L-isoleucyl-L-histidyl-L-prolyl-\",926.1,358.0,1690.0,-2.3,66,12,13,26,925.513,925.513,0,1,0,8,8,0,0,0,0,Between -11 and 5\n521,Arformoterol,344.4,90.8,388.0,1.8,25,4,5,8,344.174,344.174,0,1,0,2,2,0,0,0,0,Between -11 and 5\n522,3-Hydroxybutyrate,103.1,60.4,63.8,0.1,7,1,3,1,103.04,103.04,-1,1,0,1,0,1,0,0,0,Between -11 and 5\n523,Sitagliptin,407.31,77.0,566.0,0.7,28,1,10,4,407.118,407.118,0,1,0,1,1,0,0,0,0,Between -11 and 5\n524,Best,572.3,101.0,412.0,,18,0,4,0,573.618,575.617,0,1,0,0,0,0,0,0,0,Larger than 6\n525,Eprosartan,424.5,121.0,618.0,4.5,30,2,6,10,424.146,424.146,0,1,0,0,0,0,1,1,0,Between -11 and 5\n526,Isotretinoin,300.4,37.3,567.0,6.3,22,1,2,5,300.209,300.209,0,1,0,0,0,0,4,4,0,Larger than 6\n527,Epoprostenol,352.5,87.0,485.0,2.9,25,3,5,10,352.225,352.225,0,1,0,5,5,0,2,2,0,Between -11 and 5\n528,Camostat mesylate,494.5,200.0,695.0,,34,3,9,9,494.147,494.147,0,2,0,0,0,0,0,0,0,Larger than 6\n529,Fluticasone,444.5,99.9,861.0,3.2,30,2,8,3,444.158,444.158,0,1,0,9,9,0,0,0,0,Between -11 and 5\n530,Tenofovir disoproxil,519.4,185.0,698.0,1.6,35,1,14,17,519.173,519.173,0,1,0,1,1,0,0,0,0,Between -11 and 5\n531,Refanalin,176.24,56.9,170.0,2.2,12,1,2,2,176.041,176.041,0,1,0,0,0,0,1,1,0,Between -11 and 5\n532,Sulodexide,295.29,115.0,363.0,0.2,21,3,8,4,295.128,295.128,0,1,0,4,4,0,0,0,0,Between -11 and 5\n533,Metampicillin,361.4,124.0,603.0,3.0,25,2,6,5,361.11,361.11,0,1,0,4,4,0,0,0,0,Between -11 and 5\n534,Ciclesonide,540.7,99.1,1100.0,5.3,39,1,7,6,540.309,540.309,0,1,0,9,9,0,0,0,0,Larger than 6\n535,Dutasteride,528.5,58.2,964.0,5.4,37,2,8,2,528.221,528.221,0,1,0,7,7,0,0,0,0,Larger than 6\n536,Prasugrel,373.4,74.8,555.0,3.6,26,0,6,6,373.115,373.115,0,1,0,1,0,1,0,0,0,Between -11 and 5\n537,Almitrine mesylate,669.8,195.0,694.0,,45,4,15,10,669.221,669.221,0,3,0,0,0,0,0,0,0,Larger than 6\n538,Ile-Ser,218.25,113.0,232.0,-3.3,15,4,5,6,218.127,218.127,0,1,0,3,3,0,0,0,0,Between -11 and 5\n539,butyl (3-(4-((1H-imidazol-1-yl)methyl)phenyl)-5-isobutylthiophen-2-yl)sulfonylcarbamate,475.6,127.0,690.0,5.3,32,1,6,11,475.16,475.16,0,1,0,0,0,0,0,0,0,Larger than 6\n540,Vidofludimus,355.4,75.6,576.0,3.4,26,2,5,5,355.122,355.122,0,1,0,0,0,0,0,0,0,Between -11 and 5\n541,Reparixin,283.39,71.6,389.0,2.9,19,1,3,5,283.124,283.124,0,1,0,1,1,0,0,0,0,Between -11 and 5\n542,Ticagrelor,522.6,164.0,736.0,2.0,36,4,12,10,522.186,522.186,0,1,0,6,6,0,0,0,0,Between -11 and 5\n543,Anhydrous Ceftriaxone Sodium,577.6,288.0,1110.0,,37,4,13,8,577.036,577.036,0,2,0,2,2,0,1,1,0,Larger than 6\n544,Tradipitant,587.9,73.6,865.0,6.2,41,0,11,6,587.095,587.095,0,1,0,0,0,0,0,0,0,Larger than 6\n545,CID 9939931,701.6,316.0,819.0,,47,12,9,18,700.261,700.261,0,2,0,4,4,0,2,2,0,Larger than 6\n546,1-Palmitoyl-2-linoleoyl-3-acetyl-rac-glycerol,635.0,78.9,744.0,14.1,45,0,6,36,634.517,634.517,0,1,0,1,0,1,2,2,0,Larger than 6\n547,Zinforo,744.7,368.0,1240.0,,47,5,19,10,744.031,744.031,0,2,0,2,2,0,1,1,0,Larger than 6\n548,Linagliptin,472.5,114.0,885.0,1.9,35,1,7,4,472.234,472.234,0,1,0,1,1,0,0,0,0,Between -11 and 5\n549,\"2-(2-Chloro-4-iodophenylamino)-3,4-difluorobenzoic acid\",409.55,49.3,363.0,5.0,20,2,5,3,408.918,408.918,0,1,0,0,0,0,0,0,0,Between -11 and 5\n550,Edoxaban,548.1,165.0,880.0,1.4,37,3,8,5,547.177,547.177,0,1,0,3,3,0,0,0,0,Between -11 and 5\n551,Transcrocetinate sodium,372.4,80.3,597.0,,26,0,4,6,372.131,372.131,0,3,0,0,0,0,7,7,0,Larger than 6\n552,Galidesivir,265.27,140.0,334.0,-2.1,19,6,7,2,265.117,265.117,0,1,0,4,4,0,0,0,0,Between -11 and 5\n553,\"4,5-Dihydro-3-phenyl-5-isoxazoleacetic acid\",205.21,58.9,269.0,1.3,15,1,4,3,205.074,205.074,0,1,0,1,0,1,0,0,0,Between -11 and 5\n554,5-Cholesten-3beta-25-diol-3-sulfate,482.7,92.2,858.0,6.4,33,2,5,7,482.307,482.307,0,1,0,8,8,0,0,0,0,Larger than 6\n555,\"disodium;(6R,7R)-7-[[(2Z)-2-(2-amino-1,3-thiazol-4-yl)-2-methoxyiminoacetyl]amino]-3-[(2-methyl-6-oxido-5-oxo-1,2,4-triazin-3-yl)sulfanylmethyl]-8-oxo-5-thia-1-azabicyclo[4.2.0]oct-2-ene-2-carboxylate;hydrate\",616.6,298.0,1120.0,,39,3,15,7,616.021,616.021,0,4,0,2,2,0,1,1,0,Larger than 6\n556,Losartan potassium,461.0,77.7,526.0,,31,1,6,8,460.118,460.118,0,2,0,0,0,0,0,0,0,Larger than 6\n557,Lopinavir and ritonavir,1349.7,322.0,1980.0,,96,8,14,33,1348.68,1348.68,0,2,0,8,8,0,0,0,0,Larger than 6\n558,\"N-[5-[[2-(2,6-dimethylphenoxy)acetyl]amino]-4-hydroxy-1,6-diphenylhexan-2-yl]-3-methyl-2-(2-oxo-1,3-diazinan-1-yl)butanamide;1,3-thiazol-5-ylmethyl N-[(2S,3S,5S)-3-hydroxy-5-[[(2S)-3-methyl-2-[[methyl-[(2-propan-2-yl-1,3-thiazol-4-yl)methyl]carbamoyl]amino]butanoyl]amino]-1,6-diphenylhexan-2-yl]carbamate\",1349.7,322.0,1980.0,,96,8,14,33,1348.68,1348.68,0,2,0,8,4,4,0,0,0,Larger than 6\n559,\"S-[2-[3-[[(2R)-4-[[[(2R,3S,4R,5R)-5-(6-aminopurin-9-yl)-4-hydroxy-3-phosphonooxyoxolan-2-yl]methoxy-hydroxyphosphoryl]oxy-hydroxyphosphoryl]oxy-2-hydroxy-3,3-dimethylbutanoyl]amino]propanoylamino]ethyl] (2S)-2-[4-(2-methylpropyl)phenyl]propanethioate\",955.8,389.0,1660.0,-1.9,62,9,22,24,955.235,955.235,0,1,0,6,6,0,0,0,0,Between -11 and 5\n560,Bivalirudin,2180.3,902.0,4950.0,-7.1,155,28,35,67,2179.99,2178.99,0,1,0,16,16,0,0,0,0,Between -11 and 5\n561,Thymalfasin,3108.3,1460.0,7190.0,-24.0,217,49,59,111,3107.51,3106.5,0,1,0,32,32,0,0,0,0,Smaller than -10\n562,CID 16219160,397.6,74.6,707.0,,27,2,4,3,397.178,397.178,0,2,0,6,6,0,0,0,0,Larger than 6\n563,Sodium valproate,166.19,40.1,98.3,,11,0,2,5,166.097,166.097,0,2,0,0,0,0,0,0,0,Larger than 6\n564,\"N,N-Diethyl-(2-(4-(2-(18F)fluoroethoxy)phenyl)-5,7-dimethylpyrazolo(1,5-A)pyrimidine-3-YL)acetamide\",397.5,59.7,525.0,3.2,29,0,5,8,397.214,397.214,0,1,1,0,0,0,0,0,0,Between -11 and 5\n565,Amoxicillin sodium,387.4,161.0,596.0,,26,3,7,4,387.086,387.086,0,2,0,4,4,0,0,0,0,Larger than 6\n566,Potassium canrenoate,396.6,77.4,713.0,,27,1,4,3,396.17,396.17,0,2,0,6,6,0,0,0,0,Larger than 6\n567,Hydrocortisone sodium succinate,484.5,141.0,915.0,,34,2,8,7,484.207,484.207,0,2,0,7,7,0,0,0,0,Larger than 6\n568,Piperacillin-tazobactam,839.8,315.0,1560.0,,57,3,15,9,839.198,839.198,0,3,0,7,7,0,0,0,0,Larger than 6\n569,Antroquinonol,390.6,55.8,648.0,5.8,28,1,4,10,390.277,390.277,0,1,0,3,3,0,2,2,0,Larger than 6\n570,Brilacidin,936.9,314.0,1560.0,0.3,66,10,18,20,936.394,936.394,0,1,0,2,2,0,0,0,0,Between -11 and 5\n571,Ruxolitinib phosphate,404.4,161.0,503.0,,28,4,8,4,404.136,404.136,0,2,0,1,1,0,0,0,0,Larger than 6\n572,Baricitinib,371.4,129.0,678.0,-0.5,26,1,7,5,371.116,371.116,0,1,0,0,0,0,0,0,0,Between -11 and 5\n573,\"(2R,3R,4S,5R)-2-(4-aminopyrrolo[2,1-f][1,2,4]triazin-7-yl)-3,4-dihydroxy-5-(hydroxymethyl)tetrahydrofuran-2-carbonitrile\",291.26,150.0,456.0,-1.4,21,4,8,2,291.097,291.097,0,1,0,4,4,0,0,0,0,Between -11 and 5\n574,Metformin glycinate,204.23,155.0,175.0,,14,5,4,3,204.133,204.133,0,2,0,0,0,0,0,0,0,Larger than 6\n575,1-Palmityl-2-(4-carboxybutyl)-SN-glycero-3-phosphocholine,581.8,114.0,606.0,6.7,39,1,8,30,581.406,581.406,0,1,0,1,1,0,0,0,0,Larger than 6\n576,3-phenyl-4-propyl-1-(pyridin-2-yl)-1H-pyrazol-5-ol,279.34,45.2,412.0,3.7,21,1,3,4,279.137,279.137,0,1,0,0,0,0,0,0,0,Between -11 and 5\n577,Ozanimod,404.5,104.0,609.0,3.1,30,2,7,7,404.185,404.185,0,1,0,1,1,0,0,0,0,Between -11 and 5\n578,Sabizabulin,377.4,89.2,534.0,3.4,28,2,5,6,377.138,377.138,0,1,0,0,0,0,0,0,0,Between -11 and 5\n579,Zavegepant,638.8,117.0,1160.0,3.1,47,3,6,6,638.369,638.369,0,1,0,1,1,0,0,0,0,Between -11 and 5\n580,CID 53477736,749.0,180.0,1150.0,4.0,52,5,14,7,748.509,748.509,0,1,0,18,18,0,0,0,0,Between -11 and 5\n581,Danoprevir (RG7227),731.8,189.0,1530.0,3.3,51,3,10,8,731.3,731.3,0,1,0,5,5,0,1,1,0,Between -11 and 5\n582,Solu-Medrol,497.5,138.0,981.0,,35,3,8,7,497.215,497.215,1,2,0,8,8,0,0,0,0,Larger than 6\n583,Vericiguat,426.4,147.0,622.0,1.5,31,3,10,5,426.136,426.136,0,1,0,0,0,0,0,0,0,Between -11 and 5\n584,Aldose reductase-IN-1,421.4,137.0,706.0,2.3,29,1,11,4,421.046,421.046,0,1,0,0,0,0,0,0,0,Between -11 and 5\n585,Ixazomib citrate,517.1,168.0,797.0,,34,4,9,11,516.087,516.087,0,1,0,1,1,0,0,0,0,Larger than 6\n586,Vidofludimus calcium anhydrous,748.8,157.0,571.0,,53,2,10,8,748.191,748.191,0,3,0,0,0,0,0,0,0,Larger than 6\n587,Upadacitinib,380.4,78.3,561.0,2.7,27,2,6,3,380.157,380.157,0,1,0,2,2,0,0,0,0,Between -11 and 5\n588,Asapiprant,501.6,131.0,789.0,3.1,35,1,10,9,501.157,501.157,0,1,0,0,0,0,0,0,0,Between -11 and 5\n589,\"1,1'-hexamethylene bis[5-(p-chlorophenyl) biguanide] di-D-gluconate\",735.7,317.0,819.0,,48,13,10,18,734.249,734.249,0,3,0,4,4,0,2,2,0,Larger than 6\n590,Proxalutamide,517.5,118.0,894.0,4.3,36,0,10,6,517.12,517.12,0,1,0,0,0,0,0,0,0,Between -11 and 5\n591,Rocefin,652.6,300.0,1120.0,,41,5,17,7,652.042,652.042,0,6,0,2,2,0,1,1,0,Larger than 6\n592,Galidesivir hydrochloride,301.73,140.0,334.0,,20,7,7,2,301.094,301.094,0,2,0,4,4,0,0,0,0,Larger than 6\n593,Entresto,1916.0,396.0,1140.0,,135,7,29,40,1915.81,1914.81,0,15,0,6,6,0,0,0,0,Larger than 6\n594,\"(2R,6S,12Z,13aS,14aR,16aS)-6-[(tert-Butoxycarbonyl)amino]-14a-[(cyclopropylsulfonyl)carbamoyl]-5,16-dioxo-1,2,3,5,6,7,8,9,10,11,13a,14,14a,15,16,16a-hexadecahydrocyclopropa[e]pyrrolo[1,2-a][1,4]diazacyclopentadecin-2-yl 4-fluoro-1,3-dihydro-2H-isoindole-2-carboxylate\",731.8,189.0,1530.0,3.3,51,3,10,8,731.3,731.3,0,1,0,5,5,0,1,1,0,Between -11 and 5\n595,Harvoni,1418.4,327.0,2730.0,,101,7,21,23,1417.58,1417.58,0,2,0,12,12,0,0,0,0,Larger than 6\n596,Abivertinib,487.5,98.4,752.0,4.2,36,3,8,7,487.213,487.213,0,1,0,0,0,0,0,0,0,Between -11 and 5\n597,Legalon SIL,1453.1,495.0,1200.0,,102,6,32,24,1452.23,1452.23,0,6,0,8,8,0,0,0,0,Larger than 6\n598,Maltofer,449.16,200.0,367.0,,27,11,14,8,449.059,449.059,0,5,0,9,9,0,0,0,0,Larger than 6\n599,Zunsemetinib,513.9,101.0,888.0,2.5,36,1,9,6,513.138,513.138,0,1,0,0,0,0,0,0,0,Between -11 and 5\n600,Treamid,318.37,116.0,345.0,-0.7,23,4,4,10,318.18,318.18,0,1,0,0,0,0,0,0,0,Between -11 and 5\n601,CID 87071853,1003.2,299.0,767.0,,67,6,20,20,1002.3,1002.3,0,3,0,4,4,0,2,2,0,Larger than 6\n602,\"disodium;[2-[(8S,9R,10S,11S,13S,14S,16R,17R)-9-fluoro-11,17-dihydroxy-10,13,16-trimethyl-3-oxo-6,7,8,11,12,14,15,16-octahydrocyclopenta[a]phenanthren-17-yl]-2-oxoethyl] phosphate;hydrate\",534.4,148.0,962.0,,35,3,10,3,534.141,534.141,0,4,0,8,8,0,0,0,0,Larger than 6\n603,Heparin sodium,1157.9,652.0,2410.0,,71,15,38,21,1157.0,1157.0,1,2,0,20,0,20,0,0,0,Larger than 6\n604,CID 101731853,2088.6,933.0,4400.0,3.1,140,40,48,73,2086.96,2086.96,0,1,0,18,16,2,0,0,0,Between -11 and 5\n605,\"N-(5-Oxidanyl-1,3-Benzothiazol-2-Yl)ethanamide\",208.24,90.5,237.0,1.5,14,2,4,1,208.031,208.031,0,1,0,0,0,0,0,0,0,Between -11 and 5\n606,Danicopan,580.4,123.0,891.0,3.3,38,1,8,6,579.103,579.103,0,1,0,2,2,0,0,0,0,Between -11 and 5\n607,\"Disodium;2-[[2-[[4-(2,2-dimethylpropanoyloxy)phenyl]sulfonylamino]benzoyl]amino]acetate\",479.4,150.0,726.0,,32,2,8,8,479.086,479.086,1,3,0,0,0,0,0,0,0,Larger than 6\n608,\"propan-2-yl (2S)-2-[[[(3R,4R,5R)-5-[2-amino-6-(methylamino)purin-9-yl]-4-fluoro-3-hydroxy-4-methyloxolan-2-yl]methoxy-phenoxyphosphoryl]amino]propanoate\",581.5,185.0,919.0,1.7,40,4,14,12,581.216,581.216,0,1,0,6,5,1,0,0,0,Between -11 and 5\n609,\"[(1S,4R,6S,7E,18R)-4-(cyclopropylsulfonylcarbamoyl)-14-[(2-methylpropan-2-yl)oxycarbonylamino]-2,15-dioxo-3,16-diazatricyclo[14.3.0.04,6]nonadec-7-en-18-yl] 4-fluoro-1,3-dihydroisoindole-2-carboxylate\",731.8,189.0,1530.0,3.3,51,3,10,8,731.3,731.3,0,1,0,5,4,1,1,1,0,Between -11 and 5\n610,Eclitasertib,378.4,113.0,570.0,1.7,28,2,6,4,378.144,378.144,0,1,0,1,1,0,0,0,0,Between -11 and 5\n611,Dazcapistat,395.4,115.0,611.0,2.9,29,2,6,7,395.128,395.128,0,1,0,1,0,1,0,0,0,Between -11 and 5\n612,Bexotegrast,492.6,113.0,655.0,1.8,36,3,9,14,492.285,492.285,0,1,0,1,1,0,0,0,0,Between -11 and 5\n613,Estetrol monohydrate,322.4,81.9,441.0,,23,5,5,0,322.178,322.178,0,2,0,7,7,0,0,0,0,Larger than 6\n614,Sildenafil,474.6,118.0,838.0,1.5,33,1,8,7,474.205,474.205,0,1,0,0,0,0,0,0,0,Between -11 and 5\n615,Azilsartan,456.4,115.0,783.0,4.4,34,2,7,7,456.143,456.143,0,1,0,0,0,0,0,0,0,Between -11 and 5\n616,Echinochrome A,266.2,135.0,455.0,2.0,19,5,7,1,266.043,266.043,0,1,0,0,0,0,0,0,0,Between -11 and 5\n617,F-Arag F-18,284.23,135.0,449.0,-0.9,20,4,7,2,284.09,284.09,0,1,1,4,4,0,0,0,0,Between -11 and 5\n618,Apabetalone,370.4,89.4,543.0,2.3,27,2,6,6,370.153,370.153,0,1,0,0,0,0,0,0,0,Between -11 and 5\n619,\"4-acetamidobenzoic acid;9-[(2R,3R,4S,5R)-3,4-dihydroxy-5-(hydroxymethyl)oxolan-2-yl]-1H-purin-6-one;(2R)-1-(dimethylamino)propan-2-ol\",1115.2,399.0,658.0,,79,13,22,14,1114.55,1114.55,0,7,0,7,7,0,0,0,0,Larger than 6\n620,\"[(1R,3R)-4-[(15Z,17E)-16-formyl-18-(4-hydroxy-2,2,6,6-tetramethylcyclohexyl)-3,7,12-trimethyl-14-oxooctadeca-2,4,6,8,10,12,15,17-octaenylidene]-3-hydroxy-3,5,5-trimethylcyclohexyl] acetate\",672.9,101.0,1480.0,9.3,49,2,6,13,672.439,672.439,0,1,0,2,2,0,9,2,7,Larger than 6\n621,Abivertinib maleate,639.6,175.0,871.0,,46,7,14,9,639.245,639.245,0,4,0,0,0,0,1,1,0,Larger than 6\n622,\"7-[[2-(2-Amino-1,3-thiazol-4-yl)-2-(2,2-dimethylpropanoyloxymethoxyimino)acetyl]amino]-3-ethenyl-8-oxo-5-thia-1-azabicyclo[4.2.0]oct-2-ene-2-carboxylic acid\",509.6,227.0,961.0,1.1,34,3,12,10,509.104,509.104,0,1,0,2,0,2,1,0,1,Between -11 and 5\n623,Unii-T5UX5skk2S,452.5,120.0,723.0,3.5,33,4,4,9,452.242,452.242,0,1,0,3,3,0,0,0,0,Between -11 and 5\n624,\"azane;(2R,3S,4S,5R,6R)-2-(hydroxymethyl)-6-[(2R,3S,4R,5R,6S)-4,5,6-trihydroxy-2-(hydroxymethyl)oxan-3-yl]oxyoxane-3,4,5-triol\",359.33,191.0,382.0,,24,9,12,4,359.143,359.143,0,2,0,10,10,0,0,0,0,Larger than 6\n625,Nezulcitinib,527.7,104.0,866.0,3.6,39,3,6,6,527.301,527.301,0,1,0,1,1,0,0,0,0,Between -11 and 5\n626,P9Zqs28F8C,403.5,86.9,712.0,3.6,28,2,4,4,403.193,403.193,0,1,0,1,1,0,1,1,0,Between -11 and 5\n627,Lufotrelvir,552.5,196.0,927.0,0.5,38,6,9,13,552.199,552.199,0,1,0,3,3,0,0,0,0,Between -11 and 5\n628,Nirmatrelvir,499.5,131.0,964.0,2.2,35,3,8,7,499.241,499.241,0,1,0,6,6,0,0,0,0,Between -11 and 5\n629,\"hexasodium;4-[[(2S,4R)-5-ethoxy-4-methyl-5-oxo-1-(4-phenylphenyl)pentan-2-yl]amino]-4-oxobutanoate;hydride;(2S)-3-methyl-2-[pentanoyl-[[4-[2-(1,2,3-triaza-4-azanidacyclopenta-2,5-dien-5-yl)phenyl]phenyl]methyl]amino]butanoate;pentahydrate\",1922.0,396.0,1140.0,,135,7,35,40,1921.86,1920.85,-6,21,0,6,6,0,0,0,0,Larger than 6\n630,Nangibotide,1342.5,634.0,2630.0,-8.3,92,20,24,45,1341.53,1341.53,0,1,0,10,10,0,0,0,0,Between -11 and 5"
  },
  {
    "objectID": "posts/13_Shiny_app_python/ShinyAppPy_PC_Cov19_app_embed_pyodide_http.html",
    "href": "posts/13_Shiny_app_python/ShinyAppPy_PC_Cov19_app_embed_pyodide_http.html",
    "title": "Shinylive app in Python",
    "section": "",
    "text": "Quick update\nI’ve changed the way of importing a local text/csv file from manually copying-and-pasting to using pyodide.http.open_url() in the shinylive app, which works great and avoids the clumsy manual file input. I couldn’t quite grasp the code back then, but managed to get it this time when I re-visited the problem, while also figured out that I could use the raw content link for the file from my GitHub repository. This method was also inspired by the same user answering the query in this GitHub discussion. So I’ve basically trialled both ways as suggested, which have all worked.\nNote: if importing binary files, use pyodide.http.pyfetch() instead - check out Pyodide for details and latest changes.\n\n\nShinylive app in action\nNote: it may take a few minutes to load the app (code provided at the top, with app at the bottom).\n\n#| standalone: true\n#| components: [editor, viewer]\n#| layout: vertical\n#| viewerHeight: 420\n\n## file: app.py\n# ***Import all libraries or packages needed***\n# Import shiny ui, app\nfrom shiny import ui, App\n# Import shinywidgets\nfrom shinywidgets import output_widget, render_widget\n# Import shinyswatch to add themes\n#import shinyswatch\n# Import plotly express\nimport plotly.express as px\n# Import pandas\nimport pandas as pd\n# Import pyodide http - for importing file via URL\nimport pyodide.http\nfrom pyodide.http import open_url\n\n\n# ***Specify data source***\n# Using pyodide.http.open_url\ndf = pd.read_csv(open_url('https://raw.githubusercontent.com/jhylin/Data_in_life_blog/main/posts/13_Shiny_app_python/pc_cov_pd.csv'))\n\n\n# User interface---\n# Add inputs & outputs\napp_ui = ui.page_fluid(\n        # Add theme - seems to only work in VS code and shinyapps.io\n        #shinyswatch.theme.superhero(),\n        # Add heading\n        ui.h3(\"Molecular properties of compounds used in COVID-19 clinical trials\"),\n        # Place selection boxes & texts in same row\n        ui.row(\n            # Divide the row into two columns\n            # Column 1 - selection drop-down boxes x 2\n            ui.column(\n                4, ui.input_select(\n                # Specify x variable input\n                \"x\", label = \"x axis:\", \n                choices = [\"Partition coefficients\", \n                           \"Complexity\",\n                           \"Heavy atom count\",\n                           \"Hydrogen bond donor count\",\n                           \"Hydrogen bond acceptor count\",\n                           \"Rotatable bond count\",\n                           \"Molecular weight\",\n                           \"Exact mass\", \n                           \"Polar surface area\", \n                           \"Total atom stereocenter count\", \n                           \"Total bond stereocenter count\"],\n                ), \n                ui.input_select(\n                # Specify y variable input\n                \"y\", label = \"y axis:\",\n                choices = [\"Partition coefficients\", \n                           \"Complexity\",\n                           \"Heavy atom count\",\n                           \"Hydrogen bond donor count\",\n                           \"Hydrogen bond acceptor count\",\n                           \"Rotatable bond count\", \n                           \"Molecular weight\",\n                           \"Exact mass\", \n                           \"Polar surface area\", \n                           \"Total atom stereocenter count\", \n                           \"Total bond stereocenter count\"]  \n                )),\n            # Column 2 - add texts regarding plots\n            ui.column(\n            8,\n            ui.p(\"Select different molecular properties as x and y axes to produce a scatter plot.\"),\n            ui.tags.ul(\n                ui.tags.li(\n                    \"\"\"\n                    Part_coef_group means groups of partition coefficient (xlogp) as shown in the legend on the right\"\"\" \n                ), \n                ui.tags.li(\n                    \"\"\"\n                    Toggle each partition coefficient category by clicking on the group names\"\"\"\n                ), \n                ui.tags.li(\n                    \"\"\"\n                    Hover over each data point to see compound name and relevant molecular properties\"\"\"\n                )\n            )),\n        # Output as a widget (interactive plot)\n        output_widget(\"my_widget\"), \n        # Add texts for data source\n        ui.row(\n            ui.p(\n                \"\"\"\n                Data curated by PubChem, accessed from: https://pubchem.ncbi.nlm.nih.gov/#tab=compound&query=covid-19%20clinicaltrials (last access date: 30th Apr 2023)\"\"\" \n            )         \n        ) \n    )\n)\n\n\n# Server---\n# Add plotting code within my_widget function within the server function\ndef server(input, output, session):\n    @output\n    @render_widget\n    def my_widget():\n        fig = px.scatter(\n            df, x = input.x(), y = input.y(),\n            color = \"Part_coef_group\", \n            hover_name = \"Compound name\"\n        )\n        fig.layout.height = 400\n        return fig\n        \n# Combine UI & server into Shiny app\napp = App(app_ui, server)"
  },
  {
    "objectID": "posts/13_Shiny_app_python/ShinyAppPy_PC_Cov19_data_prep.html",
    "href": "posts/13_Shiny_app_python/ShinyAppPy_PC_Cov19_data_prep.html",
    "title": "Shinylive app in Python",
    "section": "",
    "text": "Brief introduction\nSince I’ve had a lot of fun building a Shiny app in R last time, I was on track to build another Shiny app again but using Python instead. So here in this post, I’ll talk about the data wrangling process to prepare the final dataset needed to build a Shinylive app in Python. The actual Shinylive app deployment and access will be shown in a separate post after this one.\n\n\n\nSource of data\nThe dataset used for this Shiny app in Python was from PubChem (link here). There were a total of 631 compounds at the time when I downloaded them as .csv file, along with their relevant compound data. I only picked this dataset randomly, as the focus would be more on app building, but it was nice to see an interactive web app being built and used for a domain such as pharmaceutical research.\n\n\n\nImport Polars\nPolars dataframe library was used again this time.\n\nimport polars as pl\n\n\n\n\nReading .csv file\n\npc = pl.read_csv(\"pubchem.csv\")\npc.head()\n\n\n\n\nshape: (5, 38)\n\n\n\n\ncid\n\n\ncmpdname\n\n\ncmpdsynonym\n\n\nmw\n\n\nmf\n\n\npolararea\n\n\ncomplexity\n\n\nxlogp\n\n\nheavycnt\n\n\nhbonddonor\n\n\nhbondacc\n\n\nrotbonds\n\n\ninchi\n\n\nisosmiles\n\n\ncanonicalsmiles\n\n\ninchikey\n\n\niupacname\n\n\nexactmass\n\n\nmonoisotopicmass\n\n\ncharge\n\n\ncovalentunitcnt\n\n\nisotopeatomcnt\n\n\ntotalatomstereocnt\n\n\ndefinedatomstereocnt\n\n\nundefinedatomstereocnt\n\n\ntotalbondstereocnt\n\n\ndefinedbondstereocnt\n\n\nundefinedbondstereocnt\n\n\npclidcnt\n\n\ngpidcnt\n\n\nmeshheadings\n\n\nannothits\n\n\nannothitcnt\n\n\naids\n\n\ncidcdate\n\n\nsidsrcname\n\n\ndepcatg\n\n\nannotation\n\n\n\n\ni64\n\n\nstr\n\n\nstr\n\n\nf64\n\n\nstr\n\n\nf64\n\n\nf64\n\n\nstr\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nf64\n\n\nf64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\nstr\n\n\nstr\n\n\ni64\n\n\nstr\n\n\ni64\n\n\nstr\n\n\nstr\n\n\nstr\n\n\n\n\n\n\n5280453\n\n\n\"Calcitriol\"\n\n\n\"calcitriol|322...\n\n\n416.6\n\n\n\"C27H44O3\"\n\n\n60.7\n\n\n688.0\n\n\n\"5.100\"\n\n\n30\n\n\n3\n\n\n3\n\n\n6\n\n\n\"InChI=1S/C27H4...\n\n\n\"C[C@H](CCCC(C)...\n\n\n\"CC(CCCC(C)(C)O...\n\n\n\"GMRQFYUYWCNGIN...\n\n\n\"(1R,3S,5Z)-5-[...\n\n\n416.329\n\n\n416.329\n\n\n0\n\n\n1\n\n\n0\n\n\n6\n\n\n6\n\n\n0\n\n\n2\n\n\n2\n\n\n0\n\n\n22311\n\n\n46029\n\n\n\"Calcitriol\"\n\n\n\"Biological Tes...\n\n\n12\n\n\n\"485|631|731|78...\n\n\n20040916\n\n\n\"A2B Chem|AA BL...\n\n\n\"Chemical Vendo...\n\n\n\"COVID-19, COVI...\n\n\n\n\n9962735\n\n\n\"Ubiquinol\"\n\n\n\"ubiquinol|992-...\n\n\n865.4\n\n\n\"C59H92O4\"\n\n\n58.9\n\n\n1600.0\n\n\n\"20.200\"\n\n\n63\n\n\n2\n\n\n4\n\n\n31\n\n\n\"InChI=1S/C59H9...\n\n\n\"CC1=C(C(=C(C(=...\n\n\n\"CC1=C(C(=C(C(=...\n\n\n\"QNTNKSLOFHEFPK...\n\n\n\"2-[(2E,6E,10E,...\n\n\n864.7\n\n\n864.7\n\n\n0\n\n\n1\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n9\n\n\n9\n\n\n0\n\n\n2732\n\n\n21358\n\n\n\"NULL\"\n\n\n\"Chemical and P...\n\n\n7\n\n\n\"NULL\"\n\n\n20061025\n\n\n\"001Chemical|A2...\n\n\n\"Chemical Vendo...\n\n\n\"COVID-19, COVI...\n\n\n\n\n5961\n\n\n\"Glutamine\"\n\n\n\"L-glutamine|gl...\n\n\n146.14\n\n\n\"C5H10N2O3\"\n\n\n106.0\n\n\n146.0\n\n\n\"-3.100\"\n\n\n10\n\n\n3\n\n\n4\n\n\n4\n\n\n\"InChI=1S/C5H10...\n\n\n\"C(CC(=O)N)[C@@...\n\n\n\"C(CC(=O)N)C(C(...\n\n\n\"ZDXPYRJPNDTMRX...\n\n\n\"(2S)-2,5-diami...\n\n\n146.069\n\n\n146.069\n\n\n0\n\n\n1\n\n\n0\n\n\n1\n\n\n1\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n88218\n\n\n399\n\n\n\"Glutamine\"\n\n\n\"Biological Tes...\n\n\n12\n\n\n\"422|429|436|54...\n\n\n20040916\n\n\n\"001Chemical|3B...\n\n\n\"Chemical Vendo...\n\n\n\"COVID-19, COVI...\n\n\n\n\n2244\n\n\n\"Aspirin\"\n\n\n\"aspirin|ACETYL...\n\n\n180.16\n\n\n\"C9H8O4\"\n\n\n63.6\n\n\n212.0\n\n\n\"1.200\"\n\n\n13\n\n\n1\n\n\n4\n\n\n3\n\n\n\"InChI=1S/C9H8O...\n\n\n\"CC(=O)OC1=CC=C...\n\n\n\"CC(=O)OC1=CC=C...\n\n\n\"BSYNRYMUTXBXSQ...\n\n\n\"2-acetyloxyben...\n\n\n180.042\n\n\n180.042\n\n\n0\n\n\n1\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n127012\n\n\n364455\n\n\n\"Aspirin\"\n\n\n\"Biological Tes...\n\n\n12\n\n\n\"1|3|9|15|19|21...\n\n\n20040916\n\n\n\"001Chemical|3B...\n\n\n\"Chemical Vendo...\n\n\n\"COVID-19, COVI...\n\n\n\n\n457\n\n\n\"1-Methylnicoti...\n\n\n\"1-methylnicoti...\n\n\n137.16\n\n\n\"C7H9N2O+\"\n\n\n47.0\n\n\n136.0\n\n\n\"-0.100\"\n\n\n10\n\n\n1\n\n\n1\n\n\n1\n\n\n\"InChI=1S/C7H8N...\n\n\n\"C[N+]1=CC=CC(=...\n\n\n\"C[N+]1=CC=CC(=...\n\n\n\"LDHMAVIPBRSVRG...\n\n\n\"1-methylpyridi...\n\n\n137.071\n\n\n137.071\n\n\n1\n\n\n1\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n310\n\n\n674\n\n\n\"NULL\"\n\n\n\"Biological Tes...\n\n\n8\n\n\n\"61001|61002|14...\n\n\n20040916\n\n\n\"001Chemical|3B...\n\n\n\"Chemical Vendo...\n\n\n\"COVID-19, COVI...\n\n\n\n\n\n\n\n\n\n\nQuick look at the data\nI decided to comment out the code below to keep the post at a reasonable length for reading purpose, but they were very handy for a quick glimpse of the data content.\n\n# Quick overview of the variables in each column in the dataset\n# Uncomment line below if needed to run\n#print(pc.glimpse())\n\n# Quick look at all column names\n# Uncomment line below if needed to run\n#pc.columns\n\n\n\n\nCheck for nulls in dataset\n\npc.null_count()\n\n\n\n\nshape: (1, 38)\n\n\n\n\ncid\n\n\ncmpdname\n\n\ncmpdsynonym\n\n\nmw\n\n\nmf\n\n\npolararea\n\n\ncomplexity\n\n\nxlogp\n\n\nheavycnt\n\n\nhbonddonor\n\n\nhbondacc\n\n\nrotbonds\n\n\ninchi\n\n\nisosmiles\n\n\ncanonicalsmiles\n\n\ninchikey\n\n\niupacname\n\n\nexactmass\n\n\nmonoisotopicmass\n\n\ncharge\n\n\ncovalentunitcnt\n\n\nisotopeatomcnt\n\n\ntotalatomstereocnt\n\n\ndefinedatomstereocnt\n\n\nundefinedatomstereocnt\n\n\ntotalbondstereocnt\n\n\ndefinedbondstereocnt\n\n\nundefinedbondstereocnt\n\n\npclidcnt\n\n\ngpidcnt\n\n\nmeshheadings\n\n\nannothits\n\n\nannothitcnt\n\n\naids\n\n\ncidcdate\n\n\nsidsrcname\n\n\ndepcatg\n\n\nannotation\n\n\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\nu32\n\n\n\n\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n\n\n\n\n\n\n\n\nChange column names as needed\n\n# Change column names\npc_cov = pc.rename(\n    {\n        \"cmpdname\": \"Compound name\",\n        \"cmpdsynonym\": \"Synonyms\",\n        \"mw\": \"Molecular weight\",\n        \"mf\": \"Molecular formula\",\n        \"polararea\": \"Polar surface area\",\n        \"complexity\": \"Complexity\",\n        \"xlogp\": \"Partition coefficients\",\n        \"heavycnt\": \"Heavy atom count\",\n        \"hbonddonor\": \"Hydrogen bond donor count\",\n        \"hbondacc\": \"Hydrogen bond acceptor count\",\n        \"rotbonds\": \"Rotatable bond count\",\n        \"exactmass\": \"Exact mass\",\n        \"monoisotopicmass\": \"Monoisotopic mass\",\n        \"charge\": \"Formal charge\",\n        \"covalentunitcnt\": \"Covalently-bonded unit count\",\n        \"isotopeatomcnt\": \"Isotope atom count\",\n        \"totalatomstereocnt\": \"Total atom stereocenter count\",\n        \"definedatomstereocnt\": \"Defined atom stereocenter count\",\n        \"undefinedatomstereocnt\": \"Undefined atoms stereocenter count\",\n        \"totalbondstereocnt\": \"Total bond stereocenter count\",\n        \"definedbondstereocnt\": \"Defined bond stereocenter count\",\n        \"undefinedbondstereocnt\": \"Undefined bond stereocenter count\",\n        \"meshheadings\": \"MeSH headings\"\n    }\n)\n\npc_cov.head()\n\n\n\n\nshape: (5, 38)\n\n\n\n\ncid\n\n\nCompound name\n\n\nSynonyms\n\n\nMolecular weight\n\n\nMolecular formula\n\n\nPolar surface area\n\n\nComplexity\n\n\nPartition coefficients\n\n\nHeavy atom count\n\n\nHydrogen bond donor count\n\n\nHydrogen bond acceptor count\n\n\nRotatable bond count\n\n\ninchi\n\n\nisosmiles\n\n\ncanonicalsmiles\n\n\ninchikey\n\n\niupacname\n\n\nExact mass\n\n\nMonoisotopic mass\n\n\nFormal charge\n\n\nCovalently-bonded unit count\n\n\nIsotope atom count\n\n\nTotal atom stereocenter count\n\n\nDefined atom stereocenter count\n\n\nUndefined atoms stereocenter count\n\n\nTotal bond stereocenter count\n\n\nDefined bond stereocenter count\n\n\nUndefined bond stereocenter count\n\n\npclidcnt\n\n\ngpidcnt\n\n\nMeSH headings\n\n\nannothits\n\n\nannothitcnt\n\n\naids\n\n\ncidcdate\n\n\nsidsrcname\n\n\ndepcatg\n\n\nannotation\n\n\n\n\ni64\n\n\nstr\n\n\nstr\n\n\nf64\n\n\nstr\n\n\nf64\n\n\nf64\n\n\nstr\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nf64\n\n\nf64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\nstr\n\n\nstr\n\n\ni64\n\n\nstr\n\n\ni64\n\n\nstr\n\n\nstr\n\n\nstr\n\n\n\n\n\n\n5280453\n\n\n\"Calcitriol\"\n\n\n\"calcitriol|322...\n\n\n416.6\n\n\n\"C27H44O3\"\n\n\n60.7\n\n\n688.0\n\n\n\"5.100\"\n\n\n30\n\n\n3\n\n\n3\n\n\n6\n\n\n\"InChI=1S/C27H4...\n\n\n\"C[C@H](CCCC(C)...\n\n\n\"CC(CCCC(C)(C)O...\n\n\n\"GMRQFYUYWCNGIN...\n\n\n\"(1R,3S,5Z)-5-[...\n\n\n416.329\n\n\n416.329\n\n\n0\n\n\n1\n\n\n0\n\n\n6\n\n\n6\n\n\n0\n\n\n2\n\n\n2\n\n\n0\n\n\n22311\n\n\n46029\n\n\n\"Calcitriol\"\n\n\n\"Biological Tes...\n\n\n12\n\n\n\"485|631|731|78...\n\n\n20040916\n\n\n\"A2B Chem|AA BL...\n\n\n\"Chemical Vendo...\n\n\n\"COVID-19, COVI...\n\n\n\n\n9962735\n\n\n\"Ubiquinol\"\n\n\n\"ubiquinol|992-...\n\n\n865.4\n\n\n\"C59H92O4\"\n\n\n58.9\n\n\n1600.0\n\n\n\"20.200\"\n\n\n63\n\n\n2\n\n\n4\n\n\n31\n\n\n\"InChI=1S/C59H9...\n\n\n\"CC1=C(C(=C(C(=...\n\n\n\"CC1=C(C(=C(C(=...\n\n\n\"QNTNKSLOFHEFPK...\n\n\n\"2-[(2E,6E,10E,...\n\n\n864.7\n\n\n864.7\n\n\n0\n\n\n1\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n9\n\n\n9\n\n\n0\n\n\n2732\n\n\n21358\n\n\n\"NULL\"\n\n\n\"Chemical and P...\n\n\n7\n\n\n\"NULL\"\n\n\n20061025\n\n\n\"001Chemical|A2...\n\n\n\"Chemical Vendo...\n\n\n\"COVID-19, COVI...\n\n\n\n\n5961\n\n\n\"Glutamine\"\n\n\n\"L-glutamine|gl...\n\n\n146.14\n\n\n\"C5H10N2O3\"\n\n\n106.0\n\n\n146.0\n\n\n\"-3.100\"\n\n\n10\n\n\n3\n\n\n4\n\n\n4\n\n\n\"InChI=1S/C5H10...\n\n\n\"C(CC(=O)N)[C@@...\n\n\n\"C(CC(=O)N)C(C(...\n\n\n\"ZDXPYRJPNDTMRX...\n\n\n\"(2S)-2,5-diami...\n\n\n146.069\n\n\n146.069\n\n\n0\n\n\n1\n\n\n0\n\n\n1\n\n\n1\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n88218\n\n\n399\n\n\n\"Glutamine\"\n\n\n\"Biological Tes...\n\n\n12\n\n\n\"422|429|436|54...\n\n\n20040916\n\n\n\"001Chemical|3B...\n\n\n\"Chemical Vendo...\n\n\n\"COVID-19, COVI...\n\n\n\n\n2244\n\n\n\"Aspirin\"\n\n\n\"aspirin|ACETYL...\n\n\n180.16\n\n\n\"C9H8O4\"\n\n\n63.6\n\n\n212.0\n\n\n\"1.200\"\n\n\n13\n\n\n1\n\n\n4\n\n\n3\n\n\n\"InChI=1S/C9H8O...\n\n\n\"CC(=O)OC1=CC=C...\n\n\n\"CC(=O)OC1=CC=C...\n\n\n\"BSYNRYMUTXBXSQ...\n\n\n\"2-acetyloxyben...\n\n\n180.042\n\n\n180.042\n\n\n0\n\n\n1\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n127012\n\n\n364455\n\n\n\"Aspirin\"\n\n\n\"Biological Tes...\n\n\n12\n\n\n\"1|3|9|15|19|21...\n\n\n20040916\n\n\n\"001Chemical|3B...\n\n\n\"Chemical Vendo...\n\n\n\"COVID-19, COVI...\n\n\n\n\n457\n\n\n\"1-Methylnicoti...\n\n\n\"1-methylnicoti...\n\n\n137.16\n\n\n\"C7H9N2O+\"\n\n\n47.0\n\n\n136.0\n\n\n\"-0.100\"\n\n\n10\n\n\n1\n\n\n1\n\n\n1\n\n\n\"InChI=1S/C7H8N...\n\n\n\"C[N+]1=CC=CC(=...\n\n\n\"C[N+]1=CC=CC(=...\n\n\n\"LDHMAVIPBRSVRG...\n\n\n\"1-methylpyridi...\n\n\n137.071\n\n\n137.071\n\n\n1\n\n\n1\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n310\n\n\n674\n\n\n\"NULL\"\n\n\n\"Biological Tes...\n\n\n8\n\n\n\"61001|61002|14...\n\n\n20040916\n\n\n\"001Chemical|3B...\n\n\n\"Chemical Vendo...\n\n\n\"COVID-19, COVI...\n\n\n\n\n\n\n\n\n\n\nDefinitions of molecular properties in this PubChem dataset\nThe definitions for some of the column names were shown below, which were mainly derived and adapted from PubChem:\nNote: please refer to PubChem documentations for full definitions\n\nMolecular weight - molecular mass of compounds measured in daltons\nTopological polar surface area - measured as an estimate of polar surface area of a molecule (i.e. the surface sum over polar atoms in a molecule), with units in angstrom squared (Å2)\nComplexity - complexity rating for compounds, based on Bertz/Hendrickson/Ihlenfeldt formula as a rough estimation of how complex a compound was structurally\nPartition coefficients (xlogp) - predicted octanol-water partition coefficient as a measure of the hydrophilicity or hydrophobicity of a molecule\nHeavy atom count - number of heavy atoms e.g. non-hydrogen atoms in the compound\nHydrogen bond donor count - number of hydrogen bond donors in the compound\nHydrogen bond acceptor count - number of hydrogen bond acceptors in the compound\nRotatable bond count - defined as any single-order non-ring bond, where atoms on either side of the bond were in turn bound to non-terminal heavy atoms (e.g. non-hydrogen). Rotation around the bond axis would change overall molecule shape and generate conformers which could be distinguished by standard spectroscopic methods\nExact mass - exact mass of an isotopic species, obtained by summing masses of individual isotopes of the molecule\nMonoisotopic mass - sum of the masses of atoms in a molecule, using unbound, ground-state, rest mass of principal (or most abundant) isotope for each element instead of isotopic average mass\nFormal charge - the difference between the number of valence electrons of each atom, and the number of electrons the atom was associated with, assumed any shared electrons were equally shared between the two bonded atoms\nCovalently-bonded unit count - a group of atoms connected by covalent bonds, ignoring other bond types (or a single atom without covalent bonds), representing number of such units in the compound\nIsotope atom count - number of isotopes that were not most abundant for the corresponding chemical elements. Isotopes were variants of a chemical element that differed in neutron number\nDefined atom stereocenter count - atom stereocenter (or chiral center) was where an atom was attached to 4 different types of atoms or groups of atoms in a tetrahedral arrangement. It could either be (R)- or (S)- configurations. Some of the compounds e.g. racemic mixtures, could have undefined atom stereocenter, where (R/S)-config was not specifically defined. Defined atom stereocenter count was the number of atom stereocenters where configurations were specifically defined\nUndefined atoms stereocenter count - this was the undefined version of the atoms stereocenter count\nDefined bond stereocenter count - bond stereocenter (or non-rotatable bond) was where two atoms could have different arrangement e.g. in cis- & trans- forms of butene around its double bond. Some compounds could have an undefined bond stereocenter (stereochemistry not specifically defined). Defined bond stereocenter count was the number of bond stereocenters where configurations were specifically defined.\nUndefined bond stereocenter count - this was the undefined version of the bond stereocenter count\n\n\n\n\nConvert data type for selected columns\n\n# Convert data type - only for partition coefficients column (rest were okay)\npc_cov = pc_cov.with_column((pl.col(\"Partition coefficients\")).cast(pl.Float64, strict = False))\npc_cov.head()\n\n\n\n\nshape: (5, 38)\n\n\n\n\ncid\n\n\nCompound name\n\n\nSynonyms\n\n\nMolecular weight\n\n\nMolecular formula\n\n\nPolar surface area\n\n\nComplexity\n\n\nPartition coefficients\n\n\nHeavy atom count\n\n\nHydrogen bond donor count\n\n\nHydrogen bond acceptor count\n\n\nRotatable bond count\n\n\ninchi\n\n\nisosmiles\n\n\ncanonicalsmiles\n\n\ninchikey\n\n\niupacname\n\n\nExact mass\n\n\nMonoisotopic mass\n\n\nFormal charge\n\n\nCovalently-bonded unit count\n\n\nIsotope atom count\n\n\nTotal atom stereocenter count\n\n\nDefined atom stereocenter count\n\n\nUndefined atoms stereocenter count\n\n\nTotal bond stereocenter count\n\n\nDefined bond stereocenter count\n\n\nUndefined bond stereocenter count\n\n\npclidcnt\n\n\ngpidcnt\n\n\nMeSH headings\n\n\nannothits\n\n\nannothitcnt\n\n\naids\n\n\ncidcdate\n\n\nsidsrcname\n\n\ndepcatg\n\n\nannotation\n\n\n\n\ni64\n\n\nstr\n\n\nstr\n\n\nf64\n\n\nstr\n\n\nf64\n\n\nf64\n\n\nf64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nf64\n\n\nf64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\nstr\n\n\nstr\n\n\ni64\n\n\nstr\n\n\ni64\n\n\nstr\n\n\nstr\n\n\nstr\n\n\n\n\n\n\n5280453\n\n\n\"Calcitriol\"\n\n\n\"calcitriol|322...\n\n\n416.6\n\n\n\"C27H44O3\"\n\n\n60.7\n\n\n688.0\n\n\n5.1\n\n\n30\n\n\n3\n\n\n3\n\n\n6\n\n\n\"InChI=1S/C27H4...\n\n\n\"C[C@H](CCCC(C)...\n\n\n\"CC(CCCC(C)(C)O...\n\n\n\"GMRQFYUYWCNGIN...\n\n\n\"(1R,3S,5Z)-5-[...\n\n\n416.329\n\n\n416.329\n\n\n0\n\n\n1\n\n\n0\n\n\n6\n\n\n6\n\n\n0\n\n\n2\n\n\n2\n\n\n0\n\n\n22311\n\n\n46029\n\n\n\"Calcitriol\"\n\n\n\"Biological Tes...\n\n\n12\n\n\n\"485|631|731|78...\n\n\n20040916\n\n\n\"A2B Chem|AA BL...\n\n\n\"Chemical Vendo...\n\n\n\"COVID-19, COVI...\n\n\n\n\n9962735\n\n\n\"Ubiquinol\"\n\n\n\"ubiquinol|992-...\n\n\n865.4\n\n\n\"C59H92O4\"\n\n\n58.9\n\n\n1600.0\n\n\n20.2\n\n\n63\n\n\n2\n\n\n4\n\n\n31\n\n\n\"InChI=1S/C59H9...\n\n\n\"CC1=C(C(=C(C(=...\n\n\n\"CC1=C(C(=C(C(=...\n\n\n\"QNTNKSLOFHEFPK...\n\n\n\"2-[(2E,6E,10E,...\n\n\n864.7\n\n\n864.7\n\n\n0\n\n\n1\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n9\n\n\n9\n\n\n0\n\n\n2732\n\n\n21358\n\n\n\"NULL\"\n\n\n\"Chemical and P...\n\n\n7\n\n\n\"NULL\"\n\n\n20061025\n\n\n\"001Chemical|A2...\n\n\n\"Chemical Vendo...\n\n\n\"COVID-19, COVI...\n\n\n\n\n5961\n\n\n\"Glutamine\"\n\n\n\"L-glutamine|gl...\n\n\n146.14\n\n\n\"C5H10N2O3\"\n\n\n106.0\n\n\n146.0\n\n\n-3.1\n\n\n10\n\n\n3\n\n\n4\n\n\n4\n\n\n\"InChI=1S/C5H10...\n\n\n\"C(CC(=O)N)[C@@...\n\n\n\"C(CC(=O)N)C(C(...\n\n\n\"ZDXPYRJPNDTMRX...\n\n\n\"(2S)-2,5-diami...\n\n\n146.069\n\n\n146.069\n\n\n0\n\n\n1\n\n\n0\n\n\n1\n\n\n1\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n88218\n\n\n399\n\n\n\"Glutamine\"\n\n\n\"Biological Tes...\n\n\n12\n\n\n\"422|429|436|54...\n\n\n20040916\n\n\n\"001Chemical|3B...\n\n\n\"Chemical Vendo...\n\n\n\"COVID-19, COVI...\n\n\n\n\n2244\n\n\n\"Aspirin\"\n\n\n\"aspirin|ACETYL...\n\n\n180.16\n\n\n\"C9H8O4\"\n\n\n63.6\n\n\n212.0\n\n\n1.2\n\n\n13\n\n\n1\n\n\n4\n\n\n3\n\n\n\"InChI=1S/C9H8O...\n\n\n\"CC(=O)OC1=CC=C...\n\n\n\"CC(=O)OC1=CC=C...\n\n\n\"BSYNRYMUTXBXSQ...\n\n\n\"2-acetyloxyben...\n\n\n180.042\n\n\n180.042\n\n\n0\n\n\n1\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n127012\n\n\n364455\n\n\n\"Aspirin\"\n\n\n\"Biological Tes...\n\n\n12\n\n\n\"1|3|9|15|19|21...\n\n\n20040916\n\n\n\"001Chemical|3B...\n\n\n\"Chemical Vendo...\n\n\n\"COVID-19, COVI...\n\n\n\n\n457\n\n\n\"1-Methylnicoti...\n\n\n\"1-methylnicoti...\n\n\n137.16\n\n\n\"C7H9N2O+\"\n\n\n47.0\n\n\n136.0\n\n\n-0.1\n\n\n10\n\n\n1\n\n\n1\n\n\n1\n\n\n\"InChI=1S/C7H8N...\n\n\n\"C[N+]1=CC=CC(=...\n\n\n\"C[N+]1=CC=CC(=...\n\n\n\"LDHMAVIPBRSVRG...\n\n\n\"1-methylpyridi...\n\n\n137.071\n\n\n137.071\n\n\n1\n\n\n1\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n310\n\n\n674\n\n\n\"NULL\"\n\n\n\"Biological Tes...\n\n\n8\n\n\n\"61001|61002|14...\n\n\n20040916\n\n\n\"001Chemical|3B...\n\n\n\"Chemical Vendo...\n\n\n\"COVID-19, COVI...\n\n\n\n\n\n\n\n\n\n\nSelect columns for data visualisations\nThe idea was really only keeping all the numerical columns for some data visualisations later. So I’ve dropped all the other columns in texts or of the string types.\n\n# Drop unused columns in preparation for data visualisations\npc_cov = pc_cov.drop([\n    \"cid\", \n    \"Synonyms\",\n    \"Molecular formula\",\n    \"inchi\",\n    \"isosmiles\",\n    \"canonicalsmiles\",\n    \"inchikey\",\n    \"iupacname\",\n    \"pclidcnt\",\n    \"gpidcnt\",\n    \"MeSH headings\",\n    \"annothits\",\n    \"annothitcnt\",\n    \"aids\",\n    \"cidcdate\",\n    \"sidsrcname\",\n    \"depcatg\",\n    \"annotation\"\n])\n\npc_cov.head()\n\n\n\n\nshape: (5, 20)\n\n\n\n\nCompound name\n\n\nMolecular weight\n\n\nPolar surface area\n\n\nComplexity\n\n\nPartition coefficients\n\n\nHeavy atom count\n\n\nHydrogen bond donor count\n\n\nHydrogen bond acceptor count\n\n\nRotatable bond count\n\n\nExact mass\n\n\nMonoisotopic mass\n\n\nFormal charge\n\n\nCovalently-bonded unit count\n\n\nIsotope atom count\n\n\nTotal atom stereocenter count\n\n\nDefined atom stereocenter count\n\n\nUndefined atoms stereocenter count\n\n\nTotal bond stereocenter count\n\n\nDefined bond stereocenter count\n\n\nUndefined bond stereocenter count\n\n\n\n\nstr\n\n\nf64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\nf64\n\n\nf64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\n\n\n\n\n\"Calcitriol\"\n\n\n416.6\n\n\n60.7\n\n\n688.0\n\n\n5.1\n\n\n30\n\n\n3\n\n\n3\n\n\n6\n\n\n416.329\n\n\n416.329\n\n\n0\n\n\n1\n\n\n0\n\n\n6\n\n\n6\n\n\n0\n\n\n2\n\n\n2\n\n\n0\n\n\n\n\n\"Ubiquinol\"\n\n\n865.4\n\n\n58.9\n\n\n1600.0\n\n\n20.2\n\n\n63\n\n\n2\n\n\n4\n\n\n31\n\n\n864.7\n\n\n864.7\n\n\n0\n\n\n1\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n9\n\n\n9\n\n\n0\n\n\n\n\n\"Glutamine\"\n\n\n146.14\n\n\n106.0\n\n\n146.0\n\n\n-3.1\n\n\n10\n\n\n3\n\n\n4\n\n\n4\n\n\n146.069\n\n\n146.069\n\n\n0\n\n\n1\n\n\n0\n\n\n1\n\n\n1\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n\n\n\"Aspirin\"\n\n\n180.16\n\n\n63.6\n\n\n212.0\n\n\n1.2\n\n\n13\n\n\n1\n\n\n4\n\n\n3\n\n\n180.042\n\n\n180.042\n\n\n0\n\n\n1\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n\n\n\"1-Methylnicoti...\n\n\n137.16\n\n\n47.0\n\n\n136.0\n\n\n-0.1\n\n\n10\n\n\n1\n\n\n1\n\n\n1\n\n\n137.071\n\n\n137.071\n\n\n1\n\n\n1\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n\n\n\n\n\n\n\n\nQuick summary statistics of columns\n\n# Overall descriptive statistics of kept columns\npc_cov.describe()\n\n\n\n\nshape: (7, 21)\n\n\n\n\ndescribe\n\n\nCompound name\n\n\nMolecular weight\n\n\nPolar surface area\n\n\nComplexity\n\n\nPartition coefficients\n\n\nHeavy atom count\n\n\nHydrogen bond donor count\n\n\nHydrogen bond acceptor count\n\n\nRotatable bond count\n\n\nExact mass\n\n\nMonoisotopic mass\n\n\nFormal charge\n\n\nCovalently-bonded unit count\n\n\nIsotope atom count\n\n\nTotal atom stereocenter count\n\n\nDefined atom stereocenter count\n\n\nUndefined atoms stereocenter count\n\n\nTotal bond stereocenter count\n\n\nDefined bond stereocenter count\n\n\nUndefined bond stereocenter count\n\n\n\n\nstr\n\n\nstr\n\n\nf64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\n\n\n\n\n\"count\"\n\n\n\"631\"\n\n\n631.0\n\n\n631.0\n\n\n631.0\n\n\n631.0\n\n\n631.0\n\n\n631.0\n\n\n631.0\n\n\n631.0\n\n\n631.0\n\n\n631.0\n\n\n631.0\n\n\n631.0\n\n\n631.0\n\n\n631.0\n\n\n631.0\n\n\n631.0\n\n\n631.0\n\n\n631.0\n\n\n631.0\n\n\n\n\n\"null_count\"\n\n\n\"0\"\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n173.0\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n\n\n\"mean\"\n\n\nnull\n\n\n549.539675\n\n\n163.915368\n\n\n864.755626\n\n\n2.25917\n\n\n37.770206\n\n\n4.066561\n\n\n9.210777\n\n\n9.518225\n\n\n549.095022\n\n\n549.06013\n\n\n-0.004754\n\n\n1.578447\n\n\n0.006339\n\n\n4.017433\n\n\n3.551506\n\n\n0.465927\n\n\n0.381933\n\n\n0.343899\n\n\n0.038035\n\n\n\n\n\"std\"\n\n\nnull\n\n\n455.236826\n\n\n192.256415\n\n\n1000.220379\n\n\n3.926459\n\n\n31.821967\n\n\n6.348004\n\n\n8.694184\n\n\n15.393131\n\n\n455.064211\n\n\n454.958033\n\n\n0.358537\n\n\n1.610416\n\n\n0.079429\n\n\n6.128363\n\n\n5.787792\n\n\n2.364089\n\n\n1.181171\n\n\n1.107245\n\n\n0.363159\n\n\n\n\n\"min\"\n\n\n\"(+)-Mefloquine...\n\n\n103.1\n\n\n0.0\n\n\n0.0\n\n\n-24.0\n\n\n1.0\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n103.04\n\n\n103.04\n\n\n-6.0\n\n\n1.0\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n\n\n\"max\"\n\n\n\"sodium;8-amino...\n\n\n4114.0\n\n\n1650.0\n\n\n9590.0\n\n\n20.2\n\n\n291.0\n\n\n57.0\n\n\n65.0\n\n\n151.0\n\n\n4112.12\n\n\n4111.12\n\n\n2.0\n\n\n21.0\n\n\n1.0\n\n\n39.0\n\n\n39.0\n\n\n31.0\n\n\n11.0\n\n\n11.0\n\n\n7.0\n\n\n\n\n\"median\"\n\n\nnull\n\n\n435.9\n\n\n110.0\n\n\n635.0\n\n\n2.5\n\n\n30.0\n\n\n3.0\n\n\n7.0\n\n\n6.0\n\n\n435.227\n\n\n435.227\n\n\n0.0\n\n\n1.0\n\n\n0.0\n\n\n1.0\n\n\n1.0\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n0.0\n\n\n\n\n\n\n\n\n\n\nConditional assignments in Polars\nThe longer I’ve used Polars, the more I like its coding styles of chaining a string of different code functions together to manipulate dataframes in one go. This usually might mean that we could avoid writing some repeated loop functions to achieve the same results. In the example below, I’d like to show how to chain “when-then-otherwise” expressions by using Polars.\n\n\nChaining when-then-otherwise expressions - creating groups in data\nI had the idea of separating all data into 3 different ranges of partition coefficients, so that this could be shown visually in plots. One of the possible ways (other than writing a loop function), or really the long way, to do this might be like the code shown below:\n```{python}\npart_coef_1 = pc_cov.filter(pl.col(\"Partition_coef\") <= -10)\npart_coef_2 = pc_cov.filter((pl.col(\"Partition_coef\") >= -11) & (pl.col(\"Partition_coef\") <= 5))\npart_coef_3 = pc_cov.filter(pl.col(\"Partition_coef\") >= 6)\n```\nA shorter and probably more elegant way was to use the “when-then-otherwise” expression in Polars for conditional assignments (the following code snippet was adapted with thanks to the author of Polars, Ritchie Vink and also the good old Stack Overflow):\n\npc_cov = pc_cov.with_column(\n    pl.when((pl.col(\"Partition coefficients\") <= -10))\n    .then(\"Smaller than -10\")\n    .when((pl.col(\"Partition coefficients\") >= -11) & (pl.col(\"Partition coefficients\") <= 5))\n    .then(\"Between -11 and 5\")\n    .otherwise(\"Larger than 6\")\n    .alias(\"Part_coef_group\")\n)\n\npc_cov.head(10)\n\n# a new column would be added to the end of the dataframe \n# with a new column name, \"Part_coef_group\" \n# (scroll to the very right to see the added column)\n\n\n\n\nshape: (10, 21)\n\n\n\n\nCompound name\n\n\nMolecular weight\n\n\nPolar surface area\n\n\nComplexity\n\n\nPartition coefficients\n\n\nHeavy atom count\n\n\nHydrogen bond donor count\n\n\nHydrogen bond acceptor count\n\n\nRotatable bond count\n\n\nExact mass\n\n\nMonoisotopic mass\n\n\nFormal charge\n\n\nCovalently-bonded unit count\n\n\nIsotope atom count\n\n\nTotal atom stereocenter count\n\n\nDefined atom stereocenter count\n\n\nUndefined atoms stereocenter count\n\n\nTotal bond stereocenter count\n\n\nDefined bond stereocenter count\n\n\nUndefined bond stereocenter count\n\n\nPart_coef_group\n\n\n\n\nstr\n\n\nf64\n\n\nf64\n\n\nf64\n\n\nf64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\nf64\n\n\nf64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\nstr\n\n\n\n\n\n\n\"Calcitriol\"\n\n\n416.6\n\n\n60.7\n\n\n688.0\n\n\n5.1\n\n\n30\n\n\n3\n\n\n3\n\n\n6\n\n\n416.329\n\n\n416.329\n\n\n0\n\n\n1\n\n\n0\n\n\n6\n\n\n6\n\n\n0\n\n\n2\n\n\n2\n\n\n0\n\n\n\"Larger than 6\"\n\n\n\n\n\"Ubiquinol\"\n\n\n865.4\n\n\n58.9\n\n\n1600.0\n\n\n20.2\n\n\n63\n\n\n2\n\n\n4\n\n\n31\n\n\n864.7\n\n\n864.7\n\n\n0\n\n\n1\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n9\n\n\n9\n\n\n0\n\n\n\"Larger than 6\"\n\n\n\n\n\"Glutamine\"\n\n\n146.14\n\n\n106.0\n\n\n146.0\n\n\n-3.1\n\n\n10\n\n\n3\n\n\n4\n\n\n4\n\n\n146.069\n\n\n146.069\n\n\n0\n\n\n1\n\n\n0\n\n\n1\n\n\n1\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n\"Between -11 an...\n\n\n\n\n\"Aspirin\"\n\n\n180.16\n\n\n63.6\n\n\n212.0\n\n\n1.2\n\n\n13\n\n\n1\n\n\n4\n\n\n3\n\n\n180.042\n\n\n180.042\n\n\n0\n\n\n1\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n\"Between -11 an...\n\n\n\n\n\"1-Methylnicoti...\n\n\n137.16\n\n\n47.0\n\n\n136.0\n\n\n-0.1\n\n\n10\n\n\n1\n\n\n1\n\n\n1\n\n\n137.071\n\n\n137.071\n\n\n1\n\n\n1\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n\"Between -11 an...\n\n\n\n\n\"Losartan\"\n\n\n422.9\n\n\n92.5\n\n\n520.0\n\n\n4.3\n\n\n30\n\n\n2\n\n\n5\n\n\n8\n\n\n422.162\n\n\n422.162\n\n\n0\n\n\n1\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n\"Between -11 an...\n\n\n\n\n\"Vitamin E\"\n\n\n430.7\n\n\n29.5\n\n\n503.0\n\n\n10.7\n\n\n31\n\n\n1\n\n\n2\n\n\n12\n\n\n430.381\n\n\n430.381\n\n\n0\n\n\n1\n\n\n0\n\n\n3\n\n\n3\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n\"Larger than 6\"\n\n\n\n\n\"Nicotinamide\"\n\n\n122.12\n\n\n56.0\n\n\n114.0\n\n\n-0.4\n\n\n9\n\n\n1\n\n\n2\n\n\n1\n\n\n122.048\n\n\n122.048\n\n\n0\n\n\n1\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n\"Between -11 an...\n\n\n\n\n\"Adenosine\"\n\n\n267.24\n\n\n140.0\n\n\n335.0\n\n\n-1.1\n\n\n19\n\n\n4\n\n\n8\n\n\n2\n\n\n267.097\n\n\n267.097\n\n\n0\n\n\n1\n\n\n0\n\n\n4\n\n\n4\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n\"Between -11 an...\n\n\n\n\n\"Inosine\"\n\n\n268.23\n\n\n129.0\n\n\n405.0\n\n\n-1.3\n\n\n19\n\n\n4\n\n\n7\n\n\n2\n\n\n268.081\n\n\n268.081\n\n\n0\n\n\n1\n\n\n0\n\n\n4\n\n\n4\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n\"Between -11 an...\n\n\n\n\n\n\n\n\n\n\n\nImport Plotly\nTime for some data vizzes - importing Plotly first.\n\nimport plotly.express as px\n\n\n\n\nSome examples of data visualisations\nBelow were some of the examples of building plots by using Plotly.\n\nPartition coefficients vs. Molecular weights\n\nfig = px.scatter(x = pc_cov[\"Partition coefficients\"], \n                 y = pc_cov[\"Molecular weight\"], \n                 hover_name = pc_cov[\"Compound name\"],\n                 color = pc_cov[\"Part_coef_group\"],\n                 width = 800, \n                 height = 400,\n                 title = \"Partition coefficients vs. molecular weights for compounds used in COVID-19 clinical trials\")\n\nfig.update_layout(\n    title = dict(\n        font = dict(\n            size = 15)),\n    title_x = 0.5,\n    margin = dict(\n        l = 20, r = 20, t = 40, b = 3),\n    xaxis = dict(\n        tickfont = dict(size = 9), \n        title = \"Partition coefficients\"\n    ),\n    yaxis = dict(\n        tickfont = dict(size = 9), \n        title = \"Molecular weights\"\n    ),\n    legend = dict(\n        font = dict(\n            size = 9)))\n\nfig.show()\n\n\n                                                \n\n\n\n\n\nMolecular weights vs. Complexity\n\nfig = px.scatter(x = pc_cov[\"Molecular weight\"], \n                 y = pc_cov[\"Complexity\"], \n                 hover_name = pc_cov[\"Compound name\"],\n                 #color = pc_cov[\"Part_coef_group\"],\n                 width = 800, \n                 height = 400,\n                 title = \"Molecular weights vs. complexity for compounds used in COVID-19 clinical trials\")\n\nfig.update_layout(\n    title = dict(\n        font = dict(\n            size = 15)),\n    title_x = 0.5,\n    margin = dict(\n        l = 20, r = 20, t = 40, b = 3),\n    xaxis = dict(\n        tickfont = dict(size = 9), \n        title = \"Molecular weights\"\n    ),\n    yaxis = dict(\n        tickfont = dict(size = 9), \n        title = \"Complexity\"\n    ),\n    legend = dict(\n        font = dict(\n            size = 9)))\n\nfig.show()\n\n\n                                                \n\n\n\n\n\n\nExport prepared dataset\nTwo of the possible options to export the dataset for use in a Shiny app could be:\n\nConvert Polars dataframe into a Pandas dataframe, so that it could be imported into the app for use (Polars not directly supported in Shiny for Python yet, but we could use its to_pandas() function to coerce an object e.g. a dataframe to be converted into a Pandas dataframe).\nAnother option was to save Polars dataframe as .csv file, then read in this file in the app.py script by using Pandas (which was the method I used for this particular app)\n\n```{python}\n# --If preferring to use Pandas--\n# Convert Polars df into a Pandas df if needed\ndf_name = df_name.to_pandas()\n\n# Convert the Pandas df into a csv file using Pandas \ndf_name.to_csv(\"csv_file_name.csv\", sep = \",\")\n\n# --If preferring to use Polars--\n# Simply write a Polars dataframe into a .csv file\ndf_name.write_csv(\"csv_file_name.csv\", separator = \",\")\n```"
  },
  {
    "objectID": "posts/05_Phenotypes_associated_with_rare_diseases/Phenotypes_rare_diseases.html",
    "href": "posts/05_Phenotypes_associated_with_rare_diseases/Phenotypes_rare_diseases.html",
    "title": "Phenotypes associated with rare diseases",
    "section": "",
    "text": "Initial data wrangling\nThis dataset was also derived and downloaded from Orphanet, as another part in the “rare diseases” series. It contained 37 columns with 112,243 rows originally, which took quite a long time to load on RStudio (or could be due to my laptop capacity…). It loaded relatively faster on Jupyter notebook from Anaconda, so I then decided to clean it up first using Python1 there. Some columns were removed which reduced the total number of columns from 37 to 13, while not changing any of the rows at all. The columns were also renamed to make it easier to read.\n\n\nSource of dataset\nOrphadata: Free access data from Orphanet. © INSERM 1999. Available on http://www.orphadata.org. Data version (XML data version). Dataset (.xml file) from http://www.orphadata.org/cgi-bin/epidemio.html. Latest date of update for the dataset: 14/6/2022 (last accessed 24/7/2022). Creative Commons Attribution 4.0 International.\n\nPhoto by Sangharsh Lohakare on Unsplash\nThe following libraries were used for the exploratory data analysis:\n\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(ggplot2)\nlibrary(knitr)\n\nRead imported .csv file after data cleaning in Python.\n\ndf <- read_csv(\"rare_disease_phenotypes.csv\")\n\nRows: 112243 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (10): Disorder group, Disorder type, Diagnostic criteria, HPO frequency...\ndbl   (2): HPO disorder & clinical entity association count, Disorder Orphacode\ndttm  (1): Validation date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nNote: HPO = human phenotype ontology\n\nspec(df)\n\ncols(\n  `Disorder group` = col_character(),\n  `Disorder type` = col_character(),\n  `HPO disorder & clinical entity association count` = col_double(),\n  `Diagnostic criteria` = col_character(),\n  `HPO frequency` = col_character(),\n  `HPO ID` = col_character(),\n  `Preferred HPO term` = col_character(),\n  `Disorder name` = col_character(),\n  `Disorder Orphacode` = col_double(),\n  Online = col_character(),\n  Source = col_character(),\n  `Validation date` = col_datetime(format = \"\"),\n  `Validation status` = col_character()\n)\n\n\n\n\nExploratory data analysis\nSince I wasn’t intending for this project2 to be extremely long (as most people would likely lose interests by then), I’d like to first ask a question about the dataset, in order to keep it at a reasonably short but informative length. So, here’s the question: what are the most common rare disorders and their associated phenotypic features?\nTo answer it, let’s observe the spread of the disorder groups and types first by formulating a contingency table.\n\ndf_type <- df %>% \n  group_by(`Disorder group`,`Disorder type`) %>% \n  summarise(Number = n())\ndf_type\n\n# A tibble: 11 × 3\n# Groups:   Disorder group [3]\n   `Disorder group`    `Disorder type`                                    Number\n   <chr>               <chr>                                               <int>\n 1 Disorder            Biological anomaly                                     41\n 2 Disorder            Clinical syndrome                                     661\n 3 Disorder            Disease                                             57920\n 4 Disorder            Malformation syndrome                               37634\n 5 Disorder            Morphological anomaly                                2644\n 6 Disorder            Particular clinical situation in a disease or syn…    418\n 7 Group of disorders  Category                                              479\n 8 Group of disorders  Clinical group                                        952\n 9 Subtype of disorder Clinical subtype                                     7394\n10 Subtype of disorder Etiological subtype                                  4060\n11 Subtype of disorder Histopathological subtype                              40\n\n\nAfter a quick view on the column of “Disorder group”, it mainly provided different disorder types a group label for each, which to a certain extent, was not necessary at this early stage. So this column was removed for now from the contingency table, in order to focus solely on, “Disorder type” with the number of counts (or times it appeared in the dataset).\n\ndf_type <- df %>% \n  group_by(`Disorder type`) %>% \n  summarise(Number = n())\ndf_type\n\n# A tibble: 11 × 2\n   `Disorder type`                                        Number\n   <chr>                                                   <int>\n 1 Biological anomaly                                         41\n 2 Category                                                  479\n 3 Clinical group                                            952\n 4 Clinical subtype                                         7394\n 5 Clinical syndrome                                         661\n 6 Disease                                                 57920\n 7 Etiological subtype                                      4060\n 8 Histopathological subtype                                  40\n 9 Malformation syndrome                                   37634\n10 Morphological anomaly                                    2644\n11 Particular clinical situation in a disease or syndrome    418\n\n\nThen to visualise this in a graphic way, a lollypop chart was built horizontally, with different types of rare disorders on the y-axis and the number of each type on the x-axis.\n\nggplot(data = df_type, aes(x = `Disorder type`, y = `Number`)) +\n  geom_segment(aes(x = `Disorder type`, xend = `Disorder type`, y = 0, yend = `Number`), colour = \"dark blue\") +\n  geom_point(colour = \"dark green\", size = 2, alpha = 0.6) +\n  theme_light() +\n  coord_flip() \n\n\n\n\nTwo disorder types stood out the most, with “Disease” type appeared 57,920 times and “Malformation syndrome” at 37,634 times. To understand further what each of these two disorder types were, a direct reference3 was used. According to the source of the dataset:\nThe definition of “Disease” in the rare disorder context was “a disorder with homogeneous therapeutic possibilities and an identified physiopathological mechanism…”, one thing also worth noting was that this type did not include any developmental anomalies.\nFor “Malformation syndrome”, this was defined as, “A disorder resulting from a developmental anomaly involving more than one morphogenetic field. Malformative sequences and associations are included.”\nTo demonstrate this in a tabular form, with corresponding proportions of each disorder type in the dataset, the following code were used:\n\ndf1 <- df %>% \n  group_by(`Disorder type`) %>% \n  summarise(n = n()) %>% \n  mutate(prop = n/sum(n))\ndf1\n\n# A tibble: 11 × 3\n   `Disorder type`                                            n     prop\n   <chr>                                                  <int>    <dbl>\n 1 Biological anomaly                                        41 0.000365\n 2 Category                                                 479 0.00427 \n 3 Clinical group                                           952 0.00848 \n 4 Clinical subtype                                        7394 0.0659  \n 5 Clinical syndrome                                        661 0.00589 \n 6 Disease                                                57920 0.516   \n 7 Etiological subtype                                     4060 0.0362  \n 8 Histopathological subtype                                 40 0.000356\n 9 Malformation syndrome                                  37634 0.335   \n10 Morphological anomaly                                   2644 0.0236  \n11 Particular clinical situation in a disease or syndrome   418 0.00372 \n\n\nThe table was then rearranged with proportions in descending order (from highest to lowest). It also showed the top two were “Disease” (51.6%) and “Malformation syndrome” (33.5%).\n\ndf1 %>% arrange(desc(prop))\n\n# A tibble: 11 × 3\n   `Disorder type`                                            n     prop\n   <chr>                                                  <int>    <dbl>\n 1 Disease                                                57920 0.516   \n 2 Malformation syndrome                                  37634 0.335   \n 3 Clinical subtype                                        7394 0.0659  \n 4 Etiological subtype                                     4060 0.0362  \n 5 Morphological anomaly                                   2644 0.0236  \n 6 Clinical group                                           952 0.00848 \n 7 Clinical syndrome                                        661 0.00589 \n 8 Category                                                 479 0.00427 \n 9 Particular clinical situation in a disease or syndrome   418 0.00372 \n10 Biological anomaly                                        41 0.000365\n11 Histopathological subtype                                 40 0.000356\n\n\n\nDistributions of HPO frequency\nThis was followed by checking out the distributions of HPO frequency to see which categories had the most and least number of counts.\n\ndf_freq <- df %>% \n  count(`HPO frequency`) %>% \n  arrange(desc(n))\ndf_freq\n\n# A tibble: 7 × 2\n  `HPO frequency`            n\n  <chr>                  <int>\n1 Occasional (29-5%)     41140\n2 Frequent (79-30%)      37480\n3 Very frequent (99-80%) 25892\n4 Very rare (<4-1%)       6414\n5 Excluded (0%)            705\n6 Obligate (100%)          610\n7 <NA>                       2\n\n\nResults for rare disorders with obligate or 100% frequency in patient’s populations were then filtered, showing disorder type, HPO frequency and disorder name. Specifically, I wanted to find out the disorder names associated with the “Disease” disorder type with HPO frequency of “Obligate (100%)”.\n\ndf_freq_ob <- df %>% \n  filter(`Disorder type` == \"Disease\", `HPO frequency` == \"Obligate (100%)\") %>% \n  select(`Disorder type`, `HPO frequency`, `Disorder name`)\ndf_freq_ob\n\n# A tibble: 404 × 3\n   `Disorder type` `HPO frequency` `Disorder name`                              \n   <chr>           <chr>           <chr>                                        \n 1 Disease         Obligate (100%) Retinoblastoma                               \n 2 Disease         Obligate (100%) Parathyroid carcinoma                        \n 3 Disease         Obligate (100%) Pituitary carcinoma                          \n 4 Disease         Obligate (100%) Familial hypocalciuric hypercalcemia         \n 5 Disease         Obligate (100%) Familial hypocalciuric hypercalcemia         \n 6 Disease         Obligate (100%) Ravine syndrome                              \n 7 Disease         Obligate (100%) Ravine syndrome                              \n 8 Disease         Obligate (100%) Interstitial granulomatous dermatitis with a…\n 9 Disease         Obligate (100%) Interstitial granulomatous dermatitis with a…\n10 Disease         Obligate (100%) PLIN1-related familial partial lipodystrophy \n# … with 394 more rows\n# ℹ Use `print(n = ...)` to see more rows\n\n\nI’d then like to look into associated counts of appearance of each disorder name. When I cross-checked with the full dataset in table view, I’ve noted that the number of appearance of each disorder name is linked to the number of preferred HPO phenotype terms for each of these disorder types.\n\ndf2 <- df_freq_ob %>% \n  count(`Disorder name`) \ndf2 %>% arrange(desc(n))\n\n# A tibble: 239 × 2\n   `Disorder name`                                                             n\n   <chr>                                                                   <int>\n 1 Autosomal recessive complex spastic paraplegia due to Kennedy pathway …    10\n 2 STT3A-CDG                                                                   9\n 3 STT3B-CDG                                                                   9\n 4 Spastic paraplegia-Paget disease of bone syndrome                           8\n 5 Oculocutaneous albinism type 5                                              7\n 6 PLIN1-related familial partial lipodystrophy                                7\n 7 Plummer-Vinson syndrome                                                     5\n 8 SSR4-CDG                                                                    5\n 9 Cholesterol-ester transfer protein deficiency                               4\n10 Isolated follicle stimulating hormone deficiency                            4\n# … with 229 more rows\n# ℹ Use `print(n = ...)` to see more rows\n\n\nTo show this, let’s link preferred HPO terms to a disorder name such as this one, “Autosomal recessive complex spastic paraplegia due to Kennedy pathway dysfunction”, which had the “Disease” disorder type with obligate or 100% HPO frequency.\n\ndf_disease <- df %>% \n  filter(`Disorder type` == \"Disease\", `HPO frequency` == \"Obligate (100%)\", `Disorder name` == \"Autosomal recessive complex spastic paraplegia due to Kennedy pathway dysfunction\") %>% \n  select(`Disorder type`, `HPO frequency`, `Disorder name`, `Preferred HPO term`)\nkable(df_disease)\n\n\n\n\n\n\n\n\n\n\nDisorder type\nHPO frequency\nDisorder name\nPreferred HPO term\n\n\n\n\nDisease\nObligate (100%)\nAutosomal recessive complex spastic paraplegia due to Kennedy pathway dysfunction\nProgressive spastic paraplegia\n\n\nDisease\nObligate (100%)\nAutosomal recessive complex spastic paraplegia due to Kennedy pathway dysfunction\nMicrocephaly\n\n\nDisease\nObligate (100%)\nAutosomal recessive complex spastic paraplegia due to Kennedy pathway dysfunction\nModerately short stature\n\n\nDisease\nObligate (100%)\nAutosomal recessive complex spastic paraplegia due to Kennedy pathway dysfunction\nNasal, dysarthic speech\n\n\nDisease\nObligate (100%)\nAutosomal recessive complex spastic paraplegia due to Kennedy pathway dysfunction\nDelayed gross motor development\n\n\nDisease\nObligate (100%)\nAutosomal recessive complex spastic paraplegia due to Kennedy pathway dysfunction\nProgressive spasticity\n\n\nDisease\nObligate (100%)\nAutosomal recessive complex spastic paraplegia due to Kennedy pathway dysfunction\nLower limb hyperreflexia\n\n\nDisease\nObligate (100%)\nAutosomal recessive complex spastic paraplegia due to Kennedy pathway dysfunction\nAnkle clonus\n\n\nDisease\nObligate (100%)\nAutosomal recessive complex spastic paraplegia due to Kennedy pathway dysfunction\nRetinal pigment epithelial mottling\n\n\nDisease\nObligate (100%)\nAutosomal recessive complex spastic paraplegia due to Kennedy pathway dysfunction\nProgressive spastic paraparesis\n\n\n\n\n\nAs shown in the dataframe above, under the column name, “Preferred HPO term”, there were a total of ten different HPO phenotype terms associated with this particular rare disease with 100% HPO frequency within the patient population for this specific type of spastic paraplegia.\nBy using similar filtering method, we could quickly narrow down any particular rare disease of interest to find out specific phenotype or clinical features, along with associated HPO phenotype frequency, for further investigations.\nFor “Malformation syndrome”, a similar search process was used to find out what was the most common phenotypes associated with it.\n\ndf_freq_ma <- df %>% \n  filter(`Disorder type` == \"Malformation syndrome\", `HPO frequency` == \"Obligate (100%)\") %>%\n  select(`Disorder type`, `HPO frequency`, `Disorder name`)\ndf_freq_ma\n\n# A tibble: 125 × 3\n   `Disorder type`       `HPO frequency` `Disorder name`                  \n   <chr>                 <chr>           <chr>                            \n 1 Malformation syndrome Obligate (100%) CLAPO syndrome                   \n 2 Malformation syndrome Obligate (100%) CLAPO syndrome                   \n 3 Malformation syndrome Obligate (100%) Weaver-Williams syndrome         \n 4 Malformation syndrome Obligate (100%) Weaver-Williams syndrome         \n 5 Malformation syndrome Obligate (100%) Weaver-Williams syndrome         \n 6 Malformation syndrome Obligate (100%) Weaver-Williams syndrome         \n 7 Malformation syndrome Obligate (100%) Weaver-Williams syndrome         \n 8 Malformation syndrome Obligate (100%) Weaver-Williams syndrome         \n 9 Malformation syndrome Obligate (100%) Lethal recessive chondrodysplasia\n10 Malformation syndrome Obligate (100%) Lethal recessive chondrodysplasia\n# … with 115 more rows\n# ℹ Use `print(n = ...)` to see more rows\n\n\nCount() was used to find out the number of appearance of each disorder name in descending order.\n\ndf3 <- df_freq_ma %>% \n  count(`Disorder name`)\ndf3 %>% arrange(desc(n))\n\n# A tibble: 40 × 2\n   `Disorder name`                                                             n\n   <chr>                                                                   <int>\n 1 Hydrocephalus-obesity-hypogonadism syndrome                                12\n 2 Pelviscapular dysplasia                                                    11\n 3 46,XX disorder of sex development-skeletal anomalies syndrome               9\n 4 X-linked microcephaly-growth retardation-prognathism-cryptorchidism sy…     9\n 5 Severe intellectual disability-hypotonia-strabismus-coarse face-planov…     7\n 6 Lethal recessive chondrodysplasia                                           6\n 7 Weaver-Williams syndrome                                                    6\n 8 SERKAL syndrome                                                             5\n 9 Patent ductus arteriosus-bicuspid aortic valve-hand anomalies syndrome      4\n10 46,XX gonadal dysgenesis                                                    3\n# … with 30 more rows\n# ℹ Use `print(n = ...)` to see more rows\n\n\nTo show one of the examples of the most common malformation syndrome with the most associated phenotypic features (with a total of 12 different phenotypic descriptions):\n\ndf_mal_syn <- df %>%\n  filter(`Disorder type` == \"Malformation syndrome\", `HPO frequency` == \"Obligate (100%)\", `Disorder name` == \"Hydrocephalus-obesity-hypogonadism syndrome\") %>% \n  select(`Disorder type`, `HPO frequency`, `Disorder name`, `Preferred HPO term`)\nkable(df_mal_syn)\n\n\n\n\n\n\n\n\n\n\nDisorder type\nHPO frequency\nDisorder name\nPreferred HPO term\n\n\n\n\nMalformation syndrome\nObligate (100%)\nHydrocephalus-obesity-hypogonadism syndrome\nHydrocephalus\n\n\nMalformation syndrome\nObligate (100%)\nHydrocephalus-obesity-hypogonadism syndrome\nShort neck\n\n\nMalformation syndrome\nObligate (100%)\nHydrocephalus-obesity-hypogonadism syndrome\nGynecomastia\n\n\nMalformation syndrome\nObligate (100%)\nHydrocephalus-obesity-hypogonadism syndrome\nHypergonadotropic hypogonadism\n\n\nMalformation syndrome\nObligate (100%)\nHydrocephalus-obesity-hypogonadism syndrome\nIntellectual disability, mild\n\n\nMalformation syndrome\nObligate (100%)\nHydrocephalus-obesity-hypogonadism syndrome\nObesity\n\n\nMalformation syndrome\nObligate (100%)\nHydrocephalus-obesity-hypogonadism syndrome\nMitral valve prolapse\n\n\nMalformation syndrome\nObligate (100%)\nHydrocephalus-obesity-hypogonadism syndrome\nLow posterior hairline\n\n\nMalformation syndrome\nObligate (100%)\nHydrocephalus-obesity-hypogonadism syndrome\nHigh, narrow palate\n\n\nMalformation syndrome\nObligate (100%)\nHydrocephalus-obesity-hypogonadism syndrome\nCubitus valgus\n\n\nMalformation syndrome\nObligate (100%)\nHydrocephalus-obesity-hypogonadism syndrome\nShort stature\n\n\nMalformation syndrome\nObligate (100%)\nHydrocephalus-obesity-hypogonadism syndrome\nShort 4th metacarpal\n\n\n\n\n\n\n\nExplore rare disease validation date\nNow, to add one more piece of work towards this exploratory data analysis, I thought to check out the Validation date column. “Validation date” in this context meant the dates when the annotations of HPO terms were made for each rare disorder, which were based on the source articles listed (as shown in the Source column).\nFirstly, I started with the “Disease” disorder type and singled out the year component from the Validation date column.\n\ndf_val_date <- df %>% \n  mutate(year = year(`Validation date`), label = TRUE, abbr = FALSE)\ndf_val_date\n\n# A tibble: 112,243 × 16\n   Disorder gr…¹ Disor…² HPO d…³ Diagn…⁴ HPO f…⁵ HPO I…⁶ Prefe…⁷ Disor…⁸ Disor…⁹\n   <chr>         <chr>     <dbl> <chr>   <chr>   <chr>   <chr>   <chr>     <dbl>\n 1 Disorder      Disease      59 Diagno… Very f… HP:000… Pectus… Marfan…     558\n 2 Disorder      Disease      59 Diagno… Very f… HP:000… Striae… Marfan…     558\n 3 Disorder      Disease      59 Diagno… Very f… HP:000… Arachn… Marfan…     558\n 4 Disorder      Disease      59 Diagno… Very f… HP:000… Dispro… Marfan…     558\n 5 Disorder      Disease      59 Diagno… Very f… HP:000… Pes pl… Marfan…     558\n 6 Disorder      Disease      59 Diagno… Very f… HP:000… Sponta… Marfan…     558\n 7 Disorder      Disease      59 Diagno… Very f… HP:000… Dilata… Marfan…     558\n 8 Disorder      Disease      59 Diagno… Freque… HP:000… Myopia  Marfan…     558\n 9 Disorder      Disease      59 Diagno… Freque… HP:000… Dental… Marfan…     558\n10 Disorder      Disease      59 Diagno… Freque… HP:000… Pectus… Marfan…     558\n# … with 112,233 more rows, 7 more variables: Online <chr>, Source <chr>,\n#   `Validation date` <dttm>, `Validation status` <chr>, year <dbl>,\n#   label <lgl>, abbr <lgl>, and abbreviated variable names ¹​`Disorder group`,\n#   ²​`Disorder type`, ³​`HPO disorder & clinical entity association count`,\n#   ⁴​`Diagnostic criteria`, ⁵​`HPO frequency`, ⁶​`HPO ID`, ⁷​`Preferred HPO term`,\n#   ⁸​`Disorder name`, ⁹​`Disorder Orphacode`\n# ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names\n\n\nTo show this in a dataframe, observations for “Disease” disorder type were shown by using a filter:\n\ndf_val_date_d <- df_val_date %>% \n  select(`Disorder type`, year) %>% \n  filter(`Disorder type` == \"Disease\")\ndf_val_date_d\n\n# A tibble: 57,920 × 2\n   `Disorder type`  year\n   <chr>           <dbl>\n 1 Disease          2016\n 2 Disease          2016\n 3 Disease          2016\n 4 Disease          2016\n 5 Disease          2016\n 6 Disease          2016\n 7 Disease          2016\n 8 Disease          2016\n 9 Disease          2016\n10 Disease          2016\n# … with 57,910 more rows\n# ℹ Use `print(n = ...)` to see more rows\n\n\nThen to make it easier to visualise, the year counts were plotted in a bar graph. Interestingly, 2016 seemed to be the year for rare disorders to be annotated with the most phenotypic features (if referring back to the original dataset, each observation or row was present for a unique “Preferred HPO term” or phenotypic abnormality).\n\ndf_val_date_d %>% \n  ggplot(aes(x = year)) +\n  geom_bar()\n\nWarning: Removed 49 rows containing non-finite values (stat_count).\n\n\n\n\n\nIt was also worth noting that there were 49 rows of non-finite values excluded from the bar graph above. To look into this, a count on the year column of the dataframe df_val_date_d was done, which confirmed that these were the “NA” or missing values in the validation date column.\n\ndf_val_date_d %>% \n  count(year)\n\n# A tibble: 8 × 2\n   year     n\n  <dbl> <int>\n1  2015   567\n2  2016 14193\n3  2017  5419\n4  2018  6297\n5  2019 10525\n6  2020  9402\n7  2021 11468\n8    NA    49\n\n\n\n\n\nSummary\nTo quickly summarise key findings from this work4 regarding phenotypes associated with rare diseases:\n\nAutosomal recessive complex spastic paraplegia due to Kennedy pathway dysfunction was one of the most common rare diseases under the Disease disorder type with the most phenotypic abnormalities recorded, which were:\n\n\nprogressive spastic paraplegia\nmicrocephaly\nmoderately short stature\nnasal, dysarthic speech\ndelayed gross motor development\nprogressive spasticity\nlower limb hyperreflexia\nankle clonus\nretinal pigment epithelial mottling\nprogressive spastic paraparesis\n\n\nFor malformation syndrome of the rare disorder type, Hydrocephalus-obesity-hypogonadism syndrome was found to be one of the most common rare diseases with the most phenotypic abnormalities recorded, which were:\n\n\nhydrocephalus\nshort neck\ngynecomastia\nhypergonadotropic hypogonadism\nintellectual disability, mild\nobesity\nmitral valve prolapse\nlow posterior hairline\nhigh, narrow palate\ncubitus valgus\nshort stature\nshort 4th metacarpal\n\n\nThe year of 2016 had the highest number of HPO terms or phenotypic abnormalities annotated to rare disorders from specific named source articles, and on the contrary, 2015 had the lowest counts from the dataset\n\n\n\n\n\n\nFootnotes\n\n\nUsed only for initial data cleaning stage - please see this GitHub link for details. R was used for the rest of the analysis↩︎\nThis work is under CC BY-SA 4.0 International License if anyone is interested in exploring the dataset further↩︎\n“Orphadata: Free access products description” - April 2020. http://www.orphadata.org/cgi-bin/img/PDF/OrphadataFreeAccessProductsDescription.pdf. Version 2↩︎\nIt’s possible to dig further into the dataset e.g. diagnostic criterion and perhaps even bring back some of the columns removed initially, however due to time constraints (due to being a one-person team and also I’d like to start on the COVID-19 antiviral work soon), I’ll leave some room here for the interested to work on the data↩︎"
  },
  {
    "objectID": "posts/18_Notes_molstar_quarto/Molstar_quarto.html",
    "href": "posts/18_Notes_molstar_quarto/Molstar_quarto.html",
    "title": "Using Molstar in Quarto",
    "section": "",
    "text": "Background\nThis is really a short post (note) for myself and probably for others who may be interested in software tools to visualise in silico macromolecules and small molecules.\nMost bioinformaticians or structural biologists are probably already familiar with this software package, Molstar or Mol* (Sehnal et al. 2021). Molstar is a 3D viewer for large macromolecules (e.g. proteins), which are commonly used in structural biology and drug discovery (and also other related scientific disciplines).\nA Quarto extension has been developed to embed the Molstar interactive 3D viewer inside Quarto markdown documents, which can be rendered as HTML pages. The main advantage of this is that it’s useful for reports or presentations.\n\n\n\nSome useful links\n\nMolstar webpage: https://molstar.org/\nGitHub repository for the Quarto extension (thanks to the contributing team for this extension!): https://github.com/jmbuhr/quarto-molstar - example provided https://jmbuhr.de/quarto-molstar/\nOther Molstar example: https://ljmartin.github.io/sideprojects/dockviz2.html\nR Shiny and Molstar example (for people who prefer using R and R Shiny): https://www.appsilon.com/post/shiny-molstar-r-package-molecular-structures-visualizations\nStreamlit and Dash integrations are also possible, this also makes me think that I could probably try integrating Molstar with Shiny for Python, it’ll likely be a future side project.\n\n\n\n\nAn example using Molstar with RCSB PDB\nThe following example retrieves a protein (PDB ID: 4MQT) from RCSB PDB.\n{{< mol-rcsb 4mqt >}}\n    \n    \n    \nHover over protein structure to see details of amino acid residues or ligands present in the structure.\nTo focus or zoom-in on the ligand bound to the receptor, just click on the ligand first. This shows most of the chemical interactions between the receptor and ligand bound to it (e.g. hydrogen bondings, other chemical interactions will appear if present e.g. pi-pi stacking).\nScreenshots or state snapshots are also available from the viewer (other utility functions can be found on the top right corner of the viewer).\n\n\n\nAn close-up screenshot of 4MQT showing bound ligand\n\n\nMD trajectories are also available, although I haven’t quite got there yet but it’s useful to know this may be possible (see example C from https://molstar.org/viewer-docs/examples/).\nIt’s also possible to upload AlphaFold-sourced proteins, or from other file sources (see examples shown from Molstar example).\n\n\n\n\n\nReferences\n\nSehnal, David, Sebastian Bittrich, Mandar Deshpande, Radka Svobodová, Karel Berka, Václav Bazgier, Sameer Velankar, Stephen K Burley, Jaroslav Koča, and Alexander S Rose. 2021. “Mol* Viewer: Modern Web App for 3D Visualization and Analysis of Large Biomolecular Structures.” Nucleic Acids Research 49 (W1): W431–37. https://doi.org/10.1093/nar/gkab314."
  },
  {
    "objectID": "posts/SERCA_project/SERCA_project.html",
    "href": "posts/SERCA_project/SERCA_project.html",
    "title": "SERCA project",
    "section": "",
    "text": "Essentially, having completed this MPhil project1 was more like a warm-up before participating in a real research project at a grand scale. This was a new project at the time (between 2012 – 2014) as no one in my previous lab group was working on it so it was literally a one-person project but we were collaborating with a distant research group. Unfortunately this project came to an early stop during my PhD stage (when I was working part-time still as a pharmacist to support my own cost of living while receiving a puny amount of scholarship plus working on this project at the time and then one extra project added on during PhD). The main reason that this project did no progress was that our collaborators decided to pull out from testing further compounds for us. Although it came as a bit of shock but later it felt less so. Later, I’ve decided that it would still be part of my portfolio to showcase a project that did not proceed further (or in plain words, in the “failed” section).\nReflecting back to the whole experience for this project, I’ve learned my lessons about working with collaborators whose research focus was on entirely different but related field (their one was on molecular biology, while our side was on chemistry, I’ve been spending time working in both computer and chemistry labs, trying to identify likely compound candidate from molecular modelling and then synthesise the compounds in the lab for them to test). There should have been more communications if possible and perhaps we could’ve terminated the project earlier if needed so that we could allocate more time to work on other research project that better suited to the situation of our lab group. To have a closure for this project, I’ve written up a chapter about it in my PhD thesis to show what have been done and what other future work can be added if we have all the time and money in the world.\n Image: Rawpixel.com\nLink to MPhil thesis (beware: quite long)\nAbstract of this project:\nThe goal of this research project was to discover potential chemical compounds that could be further developed to become lead compounds to target secretory pathway calcium ATPase 1 (SPCA1) and also sarcoplasmic-endoplasmic reticulum calcium ATPase (SERCA) pumps. The drug design process would need to be robust enough to ask the question; could a SERCA inhibitor be developed based on the drug design process involving molecular modelling, chemical synthesis and biological testing? If this first step was achieved then the next critical step was to design a SPCA1 inhibitor as SPCA1 was found to be highly involved in basal-like breast cancer. The potential lead compounds would then have the opportunity to become novel anti-cancer agents targeting basal-like breast cancer in this context. The ultimate aim was to widen the current therapeutic agents available for patients with basal-like subtype of breast cancer in the hope to further improve their quality of life and life expectancy.\n\n\n\n\nFootnotes\n\n\nthis was not a perfect example of drug discovery, I was a complete research newbie prior to this MPhil project and thinking back, I think I was far too ambitious…↩︎"
  },
  {
    "objectID": "posts/Publications/Side_projects.html",
    "href": "posts/Publications/Side_projects.html",
    "title": "Publications",
    "section": "",
    "text": "Throughout my PhD, I’ve also collaborated with the lab group members and also other research groups in other academic research projects. The following publications1 were the ones I was involved in:\n\n\n\nPhoto by Clark Young on Unsplash\n\n\n\nHsuan-Yu J. Lin, Rachana Rao Battaje, Jinlong Tan, Munikumar Doddareddy, Hemendra Pal Singh Dhaked, Shalini Srivastava, Bryson A. Hawkins, Laith Mohammad Hilal Al-Shdifat, David E. Hibbs, Dulal Panda, Paul W. Groundwater. Discovery of 20,6-Bis(4-hydroxybenzyl)-2-acetylcyclohexanone, a Novel FtsZ Inhibitor. Molecules. 2022; 27(20), 6993. (IF = 4.927)\nPalanimuthu D, Poon R, Sahni S, Anjum R, Hibbs D, Lin JHY, Bernhardt PV, Kalinowski DS, Richardson DR. A novel class of thiosemicarbazones show multi-functional activity for the treatment of Alzheimer’s disease. Eur J Med Chem. 2017; 139: 612-632. (IF = 4.816)\nPanda D, Bhattacharya D, Gao QH, Oza PM, Lin JHY, Hawkins B, Hibbs DE, Groundwater PW. Identification of agents targeting FtsZ assembly. Future Med Chem. 2016; 8(10):1111-32. (IF = 3.969)\nGao Q, Hanh J, Váradi L, Cairns R, Sjöström H, Liao VW, Wood P, Balaban S, Ong JA, Lin JHY, Lai F, Hoy AJ, Grewal T, Groundwater PW, Hibbs DE. Identification of dual PPARα/γ agonists and their effects on lipid metabolism. Bioorg Med Chem. 2015; 23(24):7676-84. (IF = 2.881)\n\n\n\n\n\nFootnotes\n\n\nNot a large number of publications there, perhaps due to the research topics I’ve chosen, they tend to require months or years to see tangible results… so here is my very humble list as some others may be more productive than me…↩︎"
  },
  {
    "objectID": "posts/01_Drugs_in_rare_diseases/Rare_diseases_drugs.html",
    "href": "posts/01_Drugs_in_rare_diseases/Rare_diseases_drugs.html",
    "title": "Drugs in rare diseases",
    "section": "",
    "text": "Introduction\nSince it is common knowledge that it takes a very long time to discover and develop novel therpapeutic drugs. I’ve also often wondered about drugs for rare diseases and how they’re often for the minorities in the diseased populations. So here is the initial Python and R projects1 about rare disease drugs by using data extracted from FDA’s Orphan Drug Product designation database. I also have to acknowledge “Data Is Plural” website, which has inspired me to look into this dataset.\nUnfortunately this particular dataset I’ve obtained does not contain information on incentives for pharmaceutical companies (from US’s Orphan Drug Act of 1983), which could mean that I might be able to draw some preliminary, basic or raw correlations between incentives and rare disease drug marketing approvals (this might lead to other controversial discussions about this area, which was not my initial aim for this project as I just wanted to explore a dataset on rare disease drugs at the moment).\nThe datatset was for the period from 1983 till present, for approved rare disease drugs only.\n\n\nPython project\nFor Python project2, there was one question in mind to answer:\nHow long did it take on average for a rare disease drug to reach marketing approval?\nPython version of the data analysis: link\nShort summary of findings from this dataset using Python:\n\nThe orphan designation for rare disease drug that had the highest counts between 1983 till present was for the treatment of multiple myeloma\nThe highest counts of final approved indication for rare disease drugs spanned across several different clinical indications – it often ended up with more indication details than the initial orphan designation phase\nThe average time required for a rare disease drug to progress from the initial designation phase to the final approval for marketing was about 1932 days (~5 years)\nThe horizontal bar graph (access from link above) showed the top ten rare disease drugs with the longest time taken to reach the market Tiopronin was the one that took the longest time of 12,215 days (~33 years)\nThe data for Tiopronin appeared to be duplicates, but note that the two were formulated differently as one of them was the enteric-coated (EC) version (marketed as delayed-release tablets under the actual trade name of “Thiola EC”, but recorded in the dataset as “Thiola” only), while the other one was the immediate-release form (Thiola)\n\n Image: Rawpixel.com\n\n\nR project\nFor R project3, there were two questions in mind to answer:\n\nWhat countries were involved in rare disease drug developments?\nHow would the time from designation to approval be displayed in timeline style for selected rare disease drugs?\n\nR versions of the data analysis:\n\nbase R methods via Jupyter notebook with link\nTidyverse version via RStudio with link - done using RMarkdown\n\nShort summary of findings from this dataset using R:\n\nUS was the country that had the most involvement in rare disease drug developments, which was followed by Ireland and the UK, and also a number of other countries\nMore work could possibly go into looking at the duplicates of brand names of the same generic drug e.g. cannabidiol with trade name as Epidiolex that had 5 repeated timelines (shown in link above), which appeared to be different clinical indications for each of these entries after further checks\nThe timelines have also implied that drug discovery and development is a very timely process, which could span many years, such as 10 – 20 years or more, before a drug actually reaches the market for public use\n\n\n\n\n\n\nFootnotes\n\n\nThis work is under CC BY-SA 4.0 International License for anyone interested in exploring the topic further.↩︎\nThe published date of this project would be based on the last day I’ve worked on associated file, prior to the blog move↩︎\nThe R versions, base R and Tidyverse projects, were done after the Python one was completed↩︎"
  },
  {
    "objectID": "posts/Blog-DS_journey/Beginning_of_DS_journey.html",
    "href": "posts/Blog-DS_journey/Beginning_of_DS_journey.html",
    "title": "The beginning of the data science journey",
    "section": "",
    "text": "After my PhD study came to an end at around the end of 2018 to early 2019, I’ve decided to return to New Zealand. This was followed by my tumultuous postdoc searching story and also a solitude time for myself to dig deeper into what I would really like to do research-wise. This, of course, then led to the beginning of the COVID-19 pandemic in early 2020, which in a sense has been world-changing (I don’t know what other words or terms can better describe it) and its after-effect is still hanging around until this very moment…\nRegarding to the postdoc job searching, this has made me ponder really hard about what sort of research I would really like to work on. As I’ve spent time preparing my CV, writing different cover letters, applying for different postdoc-related roles and also after being invited to five job interviews, I’ve decided that it was not quite enough about what I’ve done so far in Masters and PhD work… I’m still lacking some skills. I’ve also realised that I do not necessarily like the traditional academic postdoc work (discovered while and after I’ve applied for numerous postdoc posts in 2019) and also I’m more inclined to work on computational chemistry and cheminformatics side of research.\nAnother “elephant-in-the-room” issue was that it has been very difficult to publish a first-author paper from my PhD research work, due to the impact from the development of COVID-19 pandemic for the last two years (my overseas-based collaborators have been hit hard particularly and they were still working on part of the experiments until the first quarter of the year 2021) and hence probably this was the most likely the reason that I did not get final offers in some academic postdoc positions, due to the lack of first-author papers.\n\n\n\nPhoto by Sergi Kabrera on Unsplash\n\n\nBecause of all the issues and problems, I’ve still kept my old pharmacist job as my side job while I start on a new journey in learning data science. I’ve tested the water since 2019 and temporarily ceased the learning in 2020 due to the pandemic (I worked full-time in hospital which was also another unforgettable experience of course). From the last quarter of 2021, I’ve made up my mind to go full board with data science (as I can’t see my PhD research work being published any time soon so it’s time to consider a possible change in direction). I thought I’d like to learn about it systematically with some sort of logical structures in the course so that I can understand a basic full picture about it in a reasonably short time (I realise data science itself is a profound field) and if there are some sort of accreditations, this would be even better. This was also the sole reason why I started on Coursera’s IBM data science professional certificate in the last quarter of 2021. After learning more about it, I’ve realised how much it has overlapped with cheminformatics and my interests in both areas grew more and more as time goes.\nI have now completed the data science professional certificate, which consisted of a total of 10 courses with assessments, assignments and portfolios (certificates and/or IBM badges viewable from my LinkedIn profile). I have managed to finish the course within about 5 months (from mid-September 2021 till end of January 2022) while working part-time as a locum pharmacist. Although it’s not a perfect course, I think it reflects very nicely what the reality will be like when working as a data scientist or cheminformatician – imperfections in data sources, data analyses and presentations that need to be corrected or problems that need to be solved by looking for answers and working on possible solutions. I think it’s a useful course for newcomers who want to learn more about data science and also for the professionals who would like to refresh or reaffirm knowledge and skills (this is by no means a promotion about Coursera’s data science course but just a personal learning experience only, other course providers may equally provide similar experiences and I would encourage anyone who’s interested to look around and see what other courses are available)."
  },
  {
    "objectID": "posts/Blog-Blog_move/Blog_move.html",
    "href": "posts/Blog-Blog_move/Blog_move.html",
    "title": "Blog move",
    "section": "",
    "text": "I’ve been working on my data analytics portfolio for the last few months, on and off, as I’ve also got another work commitment going on at the same time. While working on my very first portfolio blog at WordPress, I’ve also stumbled across R programming language (due to a data analytics work interview where they actually tested me R!). This then opened up a whole new R world with its friendly online community. Since my interests in R grew further and further, I’ve been looking for places where I can use RStudio IDE and/or R to build blogs and gladly I found Quarto which led me to its Quarto blogs.\n\n\n\nPhoto by Lia Trevarthen on Unsplash\n\n\nSo here is my very first Quarto blog, deployed using Netlify initially and then I also figured out how to deploy it on GitHub Pages, so now I’ve actually got two extra sites running. The process to deploy on Netlify was quite simple as many people have already mentioned (GitHub Pages were also not too complicated as well once I’ve grasped the deployment workflow). I’m still pondering if I should write something on how I started Quarto blogs, but considering so many talented people have already talked about it, I may not go down this route (consider visiting Bea Milz’s lovely post on “Creating a blog with Quarto in 10 steps” - this was what I followed to get my Quarto blog up and running).\nI will be slowly moving my current posts and portfolio projects from WordPress to Quarto blogs. Who knows, maybe I may end up working on building websites, or doing other things that I’ve never imagined I would do before!"
  },
  {
    "objectID": "posts/09_Pills/Rust_evcxr_polars_plotly_final.html",
    "href": "posts/09_Pills/Rust_evcxr_polars_plotly_final.html",
    "title": "Pills dataset - Part 3",
    "section": "",
    "text": "Background\nThe aim of this final part (part 3) for the pills dataset was really for me to start using Rust in a beginner-friendly way. Overall, this trilogy (parts 1 - 3) for the pills dataset formulated an overview of how to use Polars in Python (mainly), Pandas in Python (smaller section) and Polars in Rust (even little less as this was new to me) with Plotly. Over time, I’ve been finding myself learning more optimally by doing and applying, rather than just reading and thinking, so I’ve got myself started in this very new programming language, Rust, to get some familiarities. I anticipated that I would still work with Python and R mainly in the near future, so that I’m not diverting too much and would be at least proficient in at least one programming language.\nMy very initial idea was to integrate Rust-Polars, Plotly in Rust (Plotly.rs) and Jupyter-Evcxr together, and see if I could get a simple data visualisation out of a small dataset. Although the idea sounded simple enough, I was actually quite stuck at the step of importing one of the columns as x-axis variables in Rust-Polars to Plotly.rs. I figured it might possibly be due to my very lack-of-knowledge and lack-of-familiarities with Rust (I do need to continue reading the Rust programming language book), Polars (I’m better with Python-Polars actually), Plotly.rs and also Evcxr. Another possibility could be that Plotly.rs mainly had ndarray support, and Polars was not mentioned explicitly in Plotly.rs so my guess was that these two might not flow very well together. Also, Polars itself was constantly evolving and growing as well.\nSo I’ve decided to leave things as how it would be for now, before I delayed this post any further. If I happened to figure out how to do this in the future, then I’ll come back to update this last part of the project. While I was tackling this little issue mentioned above, somehow I’ve managed to deconstruct Polars dataframe in Rust in Evcxr. So I’ll show a little bit about it below. One slightly good news that came out from all of this, was that I’ve managed to import the other column as y-axis variables, which contained numbers, without problems. I’ve also figured out the Rust code to convert Series/ChunkedArray to vectors in Rust IDEs (e.g. VS Code, and quite a few others). So I did learn a few things while completing this post, and hoped I could expand further on this later.\nNote: I’ve published all Rust code as print-only in Quarto markdown file, since it’s not possible to run them in RStudio IDE (Rust was not supported). So all Rust code were originally run on Jupyter Lab in MacOS, with code outputs being captured as screenshots, which were shown as photos in this post. Here’s the link to the .ipynb file in the GitHub repository for this portfolio website (or alternatively, you could access it from the GitHub icon link at the top of the web page), in case anyone wanted to see the full .ipynb version.\n\n\n\nImport dependencies\nThese dependencies were known as crates in the world of Rust. I’d also like to think of them as libraries or packages we would install or import in Python and R. So this step was necessary before I even started anything decent in Rust. Similar things would also apply to Rust IDEs as well since I’ve played a little bit in VS Code previously.\n```{rust}\n// Set up required dependencies\n:dep ndarray = \"0.15.6\"\n```\n```{rust}\n:dep plotly = { version = \">=0.8.0\", features = [\"plotly_ndarray\"]}\n```\n```{rust}\n// May take a few minutes to load polars crate (might depend on your machine specs)\n:dep polars = { version = \">=0.26.0\", features = [\"lazy\", \"csv-file\", \"strings\", \"dtype-duration\", \"dtype-categorical\", \"concat_str\", \"rank\", \"lazy_regex\", \"ndarray\"]}\n```\n```{rust}\n:dep itertools = {version = \"0.9.0\"}\n```\n\n\n\nImport external crates\n```{rust}\n// Import external crates needed\nextern crate ndarray;\nextern crate plotly;\nextern crate polars;\n```\n\n\n\nSpecify imports or modules required\n```{rust}\nuse ndarray::prelude::*;\nuse polars::prelude::*;\nuse plotly::common::{\n    ColorScale, ColorScalePalette, DashType, Fill, Font, Line, LineShape, Marker, Mode, Title,\n};\nuse plotly::layout::{Axis, BarMode, Layout, Legend, TicksDirection};\nuse plotly::{Plot, Scatter, Bar};\nuse itertools::Itertools;\n```\n\n\n\nReading csv file\nHere, I’ve imported the .csv file saved from part 2 of the project.\n```{rust}\n// Reading .csv file\nlet df = CsvReader::from_path(\"ace_para_count.csv\").unwrap().finish().unwrap();\n```\n```{rust}\ndf\n```\n\n\n\nPhoto by author\n\n\n\n\n\nConverting columns into ndarrays\nI’ve tested plotting in Plotly.rs after a few trials and errors at the beginning, but luckily I’ve spotted the ndarray support from the Plotly.rs book soon enough to figure out that I could convert the “count” column into a ndarray first, which was shown in the code below.\n```{rust}\n// Switch Polars dataframe into 2D array\n// Ensure \"ndarray\" was added as one of the features for polars under dependencies\n\n/*Example from Polars documentation:\nlet df = DataFrame::new(vec![a, b]).unwrap();\nlet ndarray = df.to_ndarray::<Float64Type>().unwrap();\nprintln!(\"{:?}\", ndarray);\n*/\n\n//Note: ndarray for numbers only, not strings, so only \"count\" column was converted\nlet ndarray = df.to_ndarray::<Float64Type>().unwrap();\nprintln!(\"{:?}\", ndarray);\n```\n\n\n\nPhoto by author\n\n\n\n\n\nDeconstructing Polars dataframe in Rust\nBecause “to_ndarray” was only for numerics and not strings, I ran into a problem trying to figure out how to best import this other “Colour” column into Plotly.rs. This led to my little convoluted journey to work with Polars dataframe in Rust, trying to see if I could convert the “Colour” column into a vector (which might not be the best way to do it, but as part of my Rust learning, I went for it anyway). I’ve subsequently tried plotting the “count” column in ndarray as a vector with success, based on the reference from Plotly.rs book that variables for x or y-axis could be placed into a vector by using a vector macro. Eventually, I didn’t quite achieve my goal but I’ve managed to break down or convert the Polars dataframe into different formats.\n```{rust}\n// Select specific column or series by position\nlet Colours = df[0].clone();\n\n//Alternative way to select specific column or series by name\n//let u = df.select_series(&[\"Colour\"]);\n```\n```{rust}\nColours\n```\n\n\n\nPhoto by author\n\n\nThere was a mention of storing series (column) in a vec (as series vector, not vector for strings) in Polars’ documentation, which I’ve tried to plot in Plotly.rs, but it unfortunately failed to work. One of my guesses could be due to the data type used for vector, as Rust was a very type-specific programming language, which also brought its well-known memory safety and other benefits in the long run. My immediate thought was that it probably needed to be a vector for strings, not series, which might make it work. Then I was searching on StackOverflow for similar questions and answers, then I found something related to what I wanted to do from Polars documentations as shown below.\n```{rust}\n// Adapted from: https://docs.rs/polars/latest/polars/docs/eager/index.html#series \n// Extracting data: \n// To be able to extract data out of Series, \n// either by iterating over them or converting them to other datatypes like a Vec<T>, \n// we first need to downcast them to a ChunkedArray<T>. \n// This is needed because we don't know the data type that is held by the Series.\n\n/*use polars::prelude::*; \n  use polars::df;\n\n  fn extract_data() -> PolarsResult<()> { \n  let df = df! [ \"a\" => [None, Some(1.0f32), Some(2.0)], \"str\" => [\"foo\", \"bar\", \"ham\"]]?;\n\n// first extract ChunkedArray to get the inner type.\n\n  let ca = df.column(\"a\")?.f32()?;\n\n// Then convert to vec\n\n  let _to_vec: Vec<Option<f32>> = Vec::from(ca);\n\n// We can also do this with iterators\n\n  let ca = df.column(\"str\")?.utf8()?; \n  let _to_vec: Vec<Option<&str>> = ca.into_iter().collect(); \n  let _to_vec_no_options: Vec<&str> = ca.into_no_null_iter().collect();\n\n  Ok(())\n\n}*/\n```\nInitially, I trialled the iterator function first.\n```{rust}\n// Print out items in column by applying an iterator to it\nprintln!(\"{}\", &Colours.iter().format(\"\\n\"));\n```\n\n\n\nPhoto by author\n\n\nThen, it took me quite a long time to just downcast Series into ChunkedArray, but somehow I’ve managed to figure out the code myself below. One of the likely reasons was due to my choice of using Evcxr, which required Rust code in slightly different formats than the ones in Rust IDEs (although almost the same).\n```{rust}\n// Somehow worked out how to convert series to chunkedarray by accident!\nprintln!(\"{:?}\", Colours.utf8().unwrap());\n```\n\n\n\nPhoto by author\n\n\nThen I moved onto trying to figure out how to convert or place a ChunkedArray into a vector, with the closest answer shown below. However, bear in mind that these Rust code were for Rust IDEs, and not for Evcxr, so this added slightly more complexities to what I was trying to do (perhaps I should just stick with Rust IDEs in the future…).\n```{rust}\n//Adpated from StackOverflow - How to get a Vec from polars Series or ChunkedArray?\n//You can collect the values into a Vec.\n\n/*use polars::prelude::*;\n\nfn main() -> Result<()> { let s = Series::new(\"a\", 0..10i32);\n\n    let as_vec: Vec<Option<i32>> = s.i32()?.into_iter().collect();\n\n    //if we are certain we don't have missing values\n    let as_vec: Vec<i32> = s.i32()?.into_no_null_iter().collect();\n    Ok(())\n\n}*/\n```\nI also found another way to iterate the ChunkedArray.\n```{rust}\n//fn iter_forward(ca: &Float32Chunked) { ca.into_iter().for_each(|opt_v| println!(\"{:?}\", opt_v)) } \n```\nI then tested another iterator method, and came up with another line of code as shown below, which listed the colours in the “Colour” column.\n```{rust}\nColours.utf8().unwrap().into_iter().for_each(|array|println!(\"{:?}\", array));\n```\n\n\n\nPhoto by author\n\n\nI also found out, randomly, how to slice strings for Series in Polars. By changing the number of letters to slice through in Some(), the strings or words would vary length accordingly. Here, I’ve used “15” so it covered all the colours (note: the longest would be 12 characters for combination colours).\n```{rust}\n// Another method to use if needing to slice strings\nlet x = Colours.utf8().unwrap().str_slice(0, Some(15));\nx\n```\n\n\n\nPhoto by author\n\n\nLastly, before I got too carried away, I just wanted to show the method from Polars documentations that this was the Polars’ way to select a specific column from Polars dataframe.\n```{rust}\nlet ca = df.clone().lazy().select([cols([\"Colour\"])]).collect()?;\nca\n```\n\n\n\nPhoto by author\n\n\n\n\n\nPlotting Polars dataframe in Plotly.rs\nFor the x-axis, eventually, I reverted for manual input due to the issue mentioned in the background section. So the colours from the “Colour” column were stored in a vector set up manually, rather than coming directly from the dataframe. While searching for answers, I’ve also learnt several other tricks, although not really solving the problem, they might still be useful in the future. For the y-axis, the ndarray for the “count” column was converted into a vector first before being fed into the trace (graph module), and thankfully the plot worked nicely.\n```{rust}\n// MANUAL method:\n// Use vec! macro to create new vectors to hold x variables (words as strings)\n// Manually input the colour names (as ndarray is only for numbers)\nlet x = vec![\"RED\", \"ORANGE;BROWN\", \"YELLOW;WHITE\", \"ORANGE\", \"WHITE\", \"BLUE\"];\n\n// Plot using ndarray, which is supported by Plotly.rs \n// Polars likely not supported yet\n// Convert ndarray (holding counts as y variables) into vector \nlet y = ndarray.column(1).to_vec();\n\n// Use trace as a graph module,\n// choose type of plots needed for x & y variables called\n// Graph options e.g. Scatter, Line or Bar\nlet trace = Scatter::new(x, y);\n\n// Set plot variable as mutable and initiate a plot\nlet mut plot = Plot::new();\n// Add trace (graph) into the plot variable\nplot.add_trace(trace);\n\n// Specify the specs for plot\nlet layout = Layout::new()\n    // Choose height of graph\n    .height(500)\n    // Name x-axis\n    .x_axis(Axis::new().title(Title::new(\"Colours\")))\n    // Name y-axis\n    .y_axis(Axis::new().title(Title::new(\"Count\")))\n    // Add title of graph\n    .title(Title::new(\"Frequency of colours in acetaminophen (paracetamol) oral dosage forms\"));\n\n// Set the layout of the plot\nplot.set_layout(layout);\n\n// Display the plot in Jupyter Lab format \n// For Jupyter Notebook, use: plot.notebook_display();\nplot.lab_display();\nformat!(\"EVCXR_BEGIN_CONTENT application/vnd.plotly.v1+json\\n{}\\nEVCXR_END_CONTENT\", plot.to_json())\n```\n\n\n\nPhoto by author\n\n\n\n\n\nConclusion\nThis last part was the hardest for me to execute out of all 3 parts (it likely took me a good whole week to figure out deconstructing Polars dataframe and trying to work with vectors), as Rust was completely new to me. At one point I thought about jumping back to Python, but I persisted and although I didn’t quite solve the string importation issue, I was somehow happy that I was at least able to see how this programming language could be applied in Polars dataframe library. I also got a taste of using Rust in data visualisations. All I wanted to show was that there were a variety of data tools to use, and knowing your tools of trade would be the most critical when working on different data projects as certain tools would only work the best for certain tasks and scenarios. This warm-up lesson in Rust was quite interesting and I might continue either in VS Code or Evcxr depending on my next topic of interest.\n\n\n\nReferences\nRust programming language book: https://doc.rust-lang.org/book/title-page.html\nPolars crate documentations: https://docs.rs/polars/latest/polars/\nPlotly.rs GitHub repository: https://github.com/igiagkiozis/plotly (link to the Plotly.rs book can be found in “Converting columns into ndarrays” section)\nEvcxr GitHub repository: https://github.com/google/evcxr"
  },
  {
    "objectID": "posts/09_Pills/Rust_polars_pills_df.html",
    "href": "posts/09_Pills/Rust_polars_pills_df.html",
    "title": "Pills dataset - Part 2",
    "section": "",
    "text": "Quick overview\nPart 2 of this project aimed to look at the pills data up close, particularly into the types of dosage forms, colours, shapes and inactive excipients used in oral medications. Plotly was used as the main data visualisation library, which was followed by some text cleaning for a particularly busy column in the dataset. This was then completed with a section in the end to generate a small dataframe, preparing for a simple data visualisation in Rust-Evcxr for the final part of this project (part 3).\n\n\n\n\nPhoto by Myriam Zilles on Unsplash\n\n\n\n\n\nImport libraries and pills dataset\n\nimport polars as pl\nimport plotly.express as px\n\nThe pills.csv file saved from part 1 was imported as shown below.\n\ndf = pl.read_csv(\"pills.csv\")\ndf\n\n\n\n\nshape: (83925, 5)\n\n\n\n\nsplshape_text\n\n\nsplcolor_text\n\n\nspl_strength\n\n\nspl_inactive_ing\n\n\nDosageForm\n\n\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\n\n\n\n\n\"CAPSULE\"\n\n\n\"PINK\"\n\n\n\"TEMAZEPAM 15 m...\n\n\n\"SILICON DIOXID...\n\n\n\"CAPSULE\"\n\n\n\n\n\"ROUND\"\n\n\n\"ORANGE\"\n\n\n\"IBUPROFEN 200 ...\n\n\n\"SILICON DIOXID...\n\n\n\"TABLET, FILM C...\n\n\n\n\n\"PENTAGON (5 SI...\n\n\n\"GREEN\"\n\n\n\"DEXAMETHASONE ...\n\n\n\"ANHYDROUS LACT...\n\n\n\"TABLET\"\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"Nickel Sulfate...\n\n\nnull\n\n\n\"TABLET\"\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"CLONAZEPAM 0.2...\n\n\n\"SORBITOL;ASPAR...\n\n\n\"TABLET, ORALLY...\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"SILDENAFIL CIT...\n\n\n\"ANHYDROUS DIBA...\n\n\n\"TABLET, FILM C...\n\n\n\n\n\"OVAL\"\n\n\n\"YELLOW\"\n\n\n\"RISPERIDONE 3 ...\n\n\n\"LACTOSE MONOHY...\n\n\n\"TABLET, FILM C...\n\n\n\n\n\"CAPSULE\"\n\n\n\"BLUE\"\n\n\n\"IBUPROFEN 200 ...\n\n\n\"FD&C BLUE NO. ...\n\n\n\"CAPSULE, LIQUI...\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"Iloperidone 12...\n\n\n\"silicon dioxid...\n\n\n\"TABLET\"\n\n\n\n\n\"CAPSULE\"\n\n\n\"YELLOW;WHITE\"\n\n\n\"FENOPROFEN CAL...\n\n\n\"CROSPOVIDONE;M...\n\n\n\"CAPSULE\"\n\n\n\n\n\"ROUND\"\n\n\n\"YELLOW\"\n\n\n\"BUTALBITAL 50 ...\n\n\n\"STARCH, CORN;C...\n\n\n\"TABLET\"\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"ESTRADIOL 0.5 ...\n\n\n\"COPOVIDONE K25...\n\n\n\"TABLET\"\n\n\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"MEMANTINE HYDR...\n\n\n\"SILICON DIOXID...\n\n\n\"TABLET\"\n\n\n\n\n\"CAPSULE\"\n\n\n\"ORANGE\"\n\n\n\"ACETAMINOPHEN ...\n\n\n\"BUTYLATED HYDR...\n\n\n\"CAPSULE, LIQUI...\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"LAMOTRIGINE 25...\n\n\n\"MAGNESIUM CARB...\n\n\n\"TABLET, CHEWAB...\n\n\n\n\n\"OVAL\"\n\n\n\"BLUE\"\n\n\n\"ACETAMINOPHEN ...\n\n\n\"ACESULFAME POT...\n\n\n\"TABLET, COATED...\n\n\n\n\n\"OVAL\"\n\n\n\"WHITE\"\n\n\n\"AZITHROMYCIN D...\n\n\n\"CROSCARMELLOSE...\n\n\n\"TABLET, FILM C...\n\n\n\n\n\"OVAL\"\n\n\n\"BLUE\"\n\n\n\"IBUPROFEN 200 ...\n\n\n\"FD&C BLUE NO. ...\n\n\n\"CAPSULE, LIQUI...\n\n\n\n\n\"OVAL\"\n\n\n\"WHITE\"\n\n\n\"CETIRIZINE HYD...\n\n\n\"STARCH, CORN;H...\n\n\n\"TABLET\"\n\n\n\n\n\"OVAL\"\n\n\n\"BROWN\"\n\n\n\"OMEPRAZOLE 20 ...\n\n\n\"CARNAUBA WAX;F...\n\n\n\"TABLET, DELAYE...\n\n\n\n\n\"ROUND\"\n\n\n\"PINK;ORANGE;YE...\n\n\n\"CALCIUM CARBON...\n\n\n\"CITRIC ACID MO...\n\n\n\"TABLET, CHEWAB...\n\n\n\n\n\"OVAL\"\n\n\n\"GREEN\"\n\n\n\"ACETAMINOPHEN ...\n\n\n\"STARCH, CORN;D...\n\n\n\"TABLET, FILM C...\n\n\n\n\n\"CAPSULE\"\n\n\n\"BLUE\"\n\n\n\"Amlodipine bes...\n\n\n\"Cellulose, mic...\n\n\n\"CAPSULE\"\n\n\n\n\n\"ROUND\"\n\n\n\"ORANGE\"\n\n\n\"DARIFENACIN 15...\n\n\n\"ANHYDROUS DIBA...\n\n\n\"TABLET, EXTEND...\n\n\n\n\n\n\n\n\n\n\nChange column names\nAgain, column names were changed to something easier to read.\n\n# Rename all column names\ndf_new = df.rename({\"splcolor_text\": \"Colour\", \n                    \"splshape_text\": \"Shape\", \n                    \"spl_strength\": \"Drug_strength\", \n                    \"spl_inactive_ing\": \"Inactive_excipients\", \n                    \"DosageForm\": \"Dosage_form\"}\n                  )\ndf_new\n\n\n\n\nshape: (83925, 5)\n\n\n\n\nShape\n\n\nColour\n\n\nDrug_strength\n\n\nInactive_excipients\n\n\nDosage_form\n\n\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\n\n\n\n\n\"CAPSULE\"\n\n\n\"PINK\"\n\n\n\"TEMAZEPAM 15 m...\n\n\n\"SILICON DIOXID...\n\n\n\"CAPSULE\"\n\n\n\n\n\"ROUND\"\n\n\n\"ORANGE\"\n\n\n\"IBUPROFEN 200 ...\n\n\n\"SILICON DIOXID...\n\n\n\"TABLET, FILM C...\n\n\n\n\n\"PENTAGON (5 SI...\n\n\n\"GREEN\"\n\n\n\"DEXAMETHASONE ...\n\n\n\"ANHYDROUS LACT...\n\n\n\"TABLET\"\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"Nickel Sulfate...\n\n\nnull\n\n\n\"TABLET\"\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"CLONAZEPAM 0.2...\n\n\n\"SORBITOL;ASPAR...\n\n\n\"TABLET, ORALLY...\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"SILDENAFIL CIT...\n\n\n\"ANHYDROUS DIBA...\n\n\n\"TABLET, FILM C...\n\n\n\n\n\"OVAL\"\n\n\n\"YELLOW\"\n\n\n\"RISPERIDONE 3 ...\n\n\n\"LACTOSE MONOHY...\n\n\n\"TABLET, FILM C...\n\n\n\n\n\"CAPSULE\"\n\n\n\"BLUE\"\n\n\n\"IBUPROFEN 200 ...\n\n\n\"FD&C BLUE NO. ...\n\n\n\"CAPSULE, LIQUI...\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"Iloperidone 12...\n\n\n\"silicon dioxid...\n\n\n\"TABLET\"\n\n\n\n\n\"CAPSULE\"\n\n\n\"YELLOW;WHITE\"\n\n\n\"FENOPROFEN CAL...\n\n\n\"CROSPOVIDONE;M...\n\n\n\"CAPSULE\"\n\n\n\n\n\"ROUND\"\n\n\n\"YELLOW\"\n\n\n\"BUTALBITAL 50 ...\n\n\n\"STARCH, CORN;C...\n\n\n\"TABLET\"\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"ESTRADIOL 0.5 ...\n\n\n\"COPOVIDONE K25...\n\n\n\"TABLET\"\n\n\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"MEMANTINE HYDR...\n\n\n\"SILICON DIOXID...\n\n\n\"TABLET\"\n\n\n\n\n\"CAPSULE\"\n\n\n\"ORANGE\"\n\n\n\"ACETAMINOPHEN ...\n\n\n\"BUTYLATED HYDR...\n\n\n\"CAPSULE, LIQUI...\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"LAMOTRIGINE 25...\n\n\n\"MAGNESIUM CARB...\n\n\n\"TABLET, CHEWAB...\n\n\n\n\n\"OVAL\"\n\n\n\"BLUE\"\n\n\n\"ACETAMINOPHEN ...\n\n\n\"ACESULFAME POT...\n\n\n\"TABLET, COATED...\n\n\n\n\n\"OVAL\"\n\n\n\"WHITE\"\n\n\n\"AZITHROMYCIN D...\n\n\n\"CROSCARMELLOSE...\n\n\n\"TABLET, FILM C...\n\n\n\n\n\"OVAL\"\n\n\n\"BLUE\"\n\n\n\"IBUPROFEN 200 ...\n\n\n\"FD&C BLUE NO. ...\n\n\n\"CAPSULE, LIQUI...\n\n\n\n\n\"OVAL\"\n\n\n\"WHITE\"\n\n\n\"CETIRIZINE HYD...\n\n\n\"STARCH, CORN;H...\n\n\n\"TABLET\"\n\n\n\n\n\"OVAL\"\n\n\n\"BROWN\"\n\n\n\"OMEPRAZOLE 20 ...\n\n\n\"CARNAUBA WAX;F...\n\n\n\"TABLET, DELAYE...\n\n\n\n\n\"ROUND\"\n\n\n\"PINK;ORANGE;YE...\n\n\n\"CALCIUM CARBON...\n\n\n\"CITRIC ACID MO...\n\n\n\"TABLET, CHEWAB...\n\n\n\n\n\"OVAL\"\n\n\n\"GREEN\"\n\n\n\"ACETAMINOPHEN ...\n\n\n\"STARCH, CORN;D...\n\n\n\"TABLET, FILM C...\n\n\n\n\n\"CAPSULE\"\n\n\n\"BLUE\"\n\n\n\"Amlodipine bes...\n\n\n\"Cellulose, mic...\n\n\n\"CAPSULE\"\n\n\n\n\n\"ROUND\"\n\n\n\"ORANGE\"\n\n\n\"DARIFENACIN 15...\n\n\n\"ANHYDROUS DIBA...\n\n\n\"TABLET, EXTEND...\n\n\n\n\n\n\n\n\n\n\nVisualising oral dosage forms & colours in pills\nGrabbing only unique drugs in the dataset to minimise duplications.\n\ndf_viz = df_new.unique(subset = \"Drug_strength\")\ndf_viz\n\n\n\n\nshape: (9287, 5)\n\n\n\n\nShape\n\n\nColour\n\n\nDrug_strength\n\n\nInactive_excipients\n\n\nDosage_form\n\n\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\n\n\n\n\n\"CAPSULE\"\n\n\n\"PINK\"\n\n\n\"TEMAZEPAM 15 m...\n\n\n\"SILICON DIOXID...\n\n\n\"CAPSULE\"\n\n\n\n\n\"ROUND\"\n\n\n\"ORANGE\"\n\n\n\"IBUPROFEN 200 ...\n\n\n\"SILICON DIOXID...\n\n\n\"TABLET, FILM C...\n\n\n\n\n\"PENTAGON (5 SI...\n\n\n\"GREEN\"\n\n\n\"DEXAMETHASONE ...\n\n\n\"ANHYDROUS LACT...\n\n\n\"TABLET\"\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"Nickel Sulfate...\n\n\nnull\n\n\n\"TABLET\"\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"CLONAZEPAM 0.2...\n\n\n\"SORBITOL;ASPAR...\n\n\n\"TABLET, ORALLY...\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"SILDENAFIL CIT...\n\n\n\"ANHYDROUS DIBA...\n\n\n\"TABLET, FILM C...\n\n\n\n\n\"OVAL\"\n\n\n\"YELLOW\"\n\n\n\"RISPERIDONE 3 ...\n\n\n\"LACTOSE MONOHY...\n\n\n\"TABLET, FILM C...\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"Iloperidone 12...\n\n\n\"silicon dioxid...\n\n\n\"TABLET\"\n\n\n\n\n\"CAPSULE\"\n\n\n\"YELLOW;WHITE\"\n\n\n\"FENOPROFEN CAL...\n\n\n\"CROSPOVIDONE;M...\n\n\n\"CAPSULE\"\n\n\n\n\n\"ROUND\"\n\n\n\"YELLOW\"\n\n\n\"BUTALBITAL 50 ...\n\n\n\"STARCH, CORN;C...\n\n\n\"TABLET\"\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"ESTRADIOL 0.5 ...\n\n\n\"COPOVIDONE K25...\n\n\n\"TABLET\"\n\n\n\n\n\"CAPSULE\"\n\n\n\"YELLOW\"\n\n\n\"BENZONATATE 20...\n\n\n\"D&C YELLOW NO....\n\n\n\"CAPSULE\"\n\n\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"BUSULFAN 2 mg\"\n\n\n\"HYPROMELLOSES ...\n\n\n\"TABLET, FILM C...\n\n\n\n\n\"OVAL\"\n\n\n\"ORANGE\"\n\n\n\"AMPHETAMINE SU...\n\n\n\"CELLULOSE, MIC...\n\n\n\"TABLET\"\n\n\n\n\n\"ROUND\"\n\n\n\"GREEN\"\n\n\n\"FOLIC ACID 800...\n\n\n\"MICROCRYSTALLI...\n\n\n\"TABLET\"\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"ACONITUM NAPEL...\n\n\n\"LACTOSE / MAGN...\n\n\n\"TABLET\"\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"MATRICARIA CHA...\n\n\n\"ACACIA;LACTOSE...\n\n\n\"TABLET\"\n\n\n\n\n\"OVAL\"\n\n\n\"RED\"\n\n\n\"FOLIC ACID 1 m...\n\n\n\"CELLULOSE, MIC...\n\n\n\"TABLET\"\n\n\n\n\n\"ROUND\"\n\n\n\"BLUE\"\n\n\n\"Labetalol 300 ...\n\n\n\"ANHYDROUS LACT...\n\n\n\"TABLET, FILM C...\n\n\n\n\n\"CAPSULE\"\n\n\n\"YELLOW;BLUE\"\n\n\n\"POMALIDOMIDE 1...\n\n\n\"MANNITOL;STARC...\n\n\n\"CAPSULE\"\n\n\n\n\n\"CAPSULE\"\n\n\n\"PURPLE\"\n\n\n\"CALCIUM CITRAT...\n\n\n\"GELATIN;\"\n\n\n\"CAPSULE, GELAT...\n\n\n\n\n\"CAPSULE\"\n\n\n\"GREEN;YELLOW\"\n\n\n\"LENALIDOMIDE 1...\n\n\n\"ANHYDROUS LACT...\n\n\n\"CAPSULE\"\n\n\n\n\n\"OVAL\"\n\n\n\"WHITE\"\n\n\n\"folic acid 1 m...\n\n\n\"cellulose, mic...\n\n\n\"TABLET\"\n\n\n\n\n\"CAPSULE\"\n\n\n\"BLUE\"\n\n\n\"Amlodipine bes...\n\n\n\"Cellulose, mic...\n\n\n\"CAPSULE\"\n\n\n\n\n\n\n\nOne way to avoid switching Polars dataframe to a Pandas one, which could be one of the options to plot data from Polars dataframes in Plotly, was to call the x-axis and y-axis data directly from the dataframe as shown in the code below.\n\n# scatter plot for colours, dosage forms & drug strengths \nfig = px.scatter(x = df_viz[\"Colour\"], \n                 y = df_viz[\"Dosage_form\"], \n                 color = df_viz[\"Colour\"],\n                 hover_name = df_viz[\"Drug_strength\"],\n                 width = 900, \n                 height = 400,\n                 title = \"Oral dosage forms and colours of pills\")\n\n# Update layout of the plot\nfig.update_layout(\n    # Change title font size\n    title = dict(\n        font = dict(\n            size = 15)),\n    # Centre the title\n    title_x = 0.5,\n    # Edit margins\n    margin = dict(\n        l = 20, r = 20, t = 40, b = 3),\n    # Change x-axis\n    xaxis = dict(\n        tickfont = dict(size = 9), \n        title = \"Colours\"\n    ),\n    # Change y-axis\n    yaxis = dict(\n        tickfont = dict(size = 9), \n        title = \"Dosage forms\"\n    ),\n    # Edit lengend font size\n    legend = dict(\n        font = dict(\n            size = 9)))\n\nfig.show()\n\n\n                                                \n\n\n\nWhite was the most common colour, especially after zooming in the plot. Capsule was very commonly used as the oral dosage form of choice in this dataset.\n\n\n\nVisualising shapes & colours in pills\n\nfig = px.scatter(x = df_viz[\"Colour\"], \n                 y = df_viz[\"Shape\"], \n                 color = df_viz[\"Colour\"],\n                 hover_name = df_viz[\"Drug_strength\"],\n                 width = 900, \n                 height = 400,\n                 title = \"Shapes and colours of pills\")\n\n# Update layout of the plot\nfig.update_layout(\n    # Change title font size\n    title = dict(\n        font = dict(\n            size = 15)),\n    # Centre the title\n    title_x = 0.5,\n    # Edit margins\n    margin = dict(\n        l = 20, r = 20, t = 40, b = 3),\n    # Change x-axis\n    xaxis = dict(\n        tickfont = dict(size = 9), \n        title = \"Colours\"\n    ),\n    # Change y-axis\n    yaxis = dict(\n        tickfont = dict(size = 9), \n        title = \"Shapes\"\n    ),\n    # Edit lengend font size\n    legend = dict(\n        font = dict(\n            size = 9)))\n\nfig.show()\n\n\n                                                \n\n\n\nCapsule was again the most common oral dosage shape used for pills in the dataset. Common colours included red, brown, blue, purple, pink, orange, green, white and yellow. Combination colours followed these common ones, which had a mixture of a variety of colours used simultaneously, likely to avoid confusions and errors in dispensings or administrations.\n\n\n\nVisualising inactive excipients in pills\nThe messiest part of the data actually lied in the column of “Inactive_excipients”, with numerous different punctuations used inconsistently, such as forward slashes, commas and semi-colons. There were vast quantities of different inactive components used for oral dosage forms. Because of this, I had to spend a bit more time cleaning up the texts in order to find out what were the commonly used inactive ingredients in the end.\n\n# Formulated a separate dataframe with just \"Inactive_excipients\"\ndf_ie = df_new.select([pl.col(\"Inactive_excipients\")])\ndf_ie\n\n\n\n\nshape: (83925, 1)\n\n\n\n\nInactive_excipients\n\n\n\n\nstr\n\n\n\n\n\n\n\"SILICON DIOXID...\n\n\n\n\n\"SILICON DIOXID...\n\n\n\n\n\"ANHYDROUS LACT...\n\n\n\n\nnull\n\n\n\n\n\"SORBITOL;ASPAR...\n\n\n\n\n\"ANHYDROUS DIBA...\n\n\n\n\n\"LACTOSE MONOHY...\n\n\n\n\n\"FD&C BLUE NO. ...\n\n\n\n\n\"silicon dioxid...\n\n\n\n\n\"CROSPOVIDONE;M...\n\n\n\n\n\"STARCH, CORN;C...\n\n\n\n\n\"COPOVIDONE K25...\n\n\n\n\n...\n\n\n\n\n\"SILICON DIOXID...\n\n\n\n\n\"BUTYLATED HYDR...\n\n\n\n\n\"MAGNESIUM CARB...\n\n\n\n\n\"ACESULFAME POT...\n\n\n\n\n\"CROSCARMELLOSE...\n\n\n\n\n\"FD&C BLUE NO. ...\n\n\n\n\n\"STARCH, CORN;H...\n\n\n\n\n\"CARNAUBA WAX;F...\n\n\n\n\n\"CITRIC ACID MO...\n\n\n\n\n\"STARCH, CORN;D...\n\n\n\n\n\"Cellulose, mic...\n\n\n\n\n\"ANHYDROUS DIBA...\n\n\n\n\n\n\n\n\nText cleaning for inactive excipients column\nTo prepare this column for data visualisations, I used Polars’ string expressions (or more commonly known as regex - regular expressions) to try and tidy up the raw texts. When I did the text cleaning in Jupyter Lab initially, the line of code for .str.strip(” ,“) worked, but when I converted the .ipynb file into a .qmd (Quarto markdown) one, and used the same line, it failed to work due to the extra space in front of the comma. However, I got around the error by splitting it into two separate units as space and comma, and it worked without problem. One possible reason would be due to the reticulate package needed to run Python in RStudio IDE, and how Polars dataframe library was relatively newer than Pandas dataframe library, which meant certain features in Polars might not have been taken on board in the reticulate package (only my guess).\n\n# Clean string texts \n# Convert uppercase letters into lowercase ones in the excipients column\ndf_de = (df_ie.with_column(pl.col(\"Inactive_excipients\").str.to_lowercase(\n    # replace old punctuations (1st position) with new one (2nd position)\n    ).str.replace_all(\n        \";\", \", \"\n    ).str.replace_all(\n        \" /\", \", \"\n    ).str.replace_all(\n        \"/\", \", \"\n    # Remove extra space & comma by stripping\n    # In Jupyter notebook/lab - can combine space & comma: .str.strip(\" ,\")\n    # For RStudio IDE - separate into two for this to work\n    ).str.strip(\n        \" \"\n    ).str.strip(\n        \",\"\n    # Split the texts by the specified punctuation e.g. comma with space\n    ).str.split(\n        by = \", \"\n    # Create a new column with a new name\n    ).alias(\n        \"Inactive\"\n    )\n# Explode the splitted texts into separate rows within the new column\n).explode(\n    \"Inactive\"\n)\n)\n\ndf_de\n\n\n\n\nshape: (840029, 2)\n\n\n\n\nInactive_excipients\n\n\nInactive\n\n\n\n\nstr\n\n\nstr\n\n\n\n\n\n\n\"SILICON DIOXID...\n\n\n\"silicon dioxid...\n\n\n\n\n\"SILICON DIOXID...\n\n\n\"edetate disodi...\n\n\n\n\n\"SILICON DIOXID...\n\n\n\"lactose monohy...\n\n\n\n\n\"SILICON DIOXID...\n\n\n\"magnesium stea...\n\n\n\n\n\"SILICON DIOXID...\n\n\n\"cellulose\"\n\n\n\n\n\"SILICON DIOXID...\n\n\n\"microcrystalli...\n\n\n\n\n\"SILICON DIOXID...\n\n\n\"starch\"\n\n\n\n\n\"SILICON DIOXID...\n\n\n\"corn\"\n\n\n\n\n\"SILICON DIOXID...\n\n\n\"sodium lauryl ...\n\n\n\n\n\"SILICON DIOXID...\n\n\n\"fd&c blue no. ...\n\n\n\n\n\"SILICON DIOXID...\n\n\n\"fd&c red no. 4...\n\n\n\n\n\"SILICON DIOXID...\n\n\n\"gelatin\"\n\n\n\n\n...\n\n\n...\n\n\n\n\n\"Cellulose, mic...\n\n\n\"shellac\"\n\n\n\n\n\"Cellulose, mic...\n\n\n\"propylene glyc...\n\n\n\n\n\"Cellulose, mic...\n\n\n\"ammonia\"\n\n\n\n\n\"Cellulose, mic...\n\n\n\"fd&c blue no. ...\n\n\n\n\n\"ANHYDROUS DIBA...\n\n\n\"anhydrous diba...\n\n\n\n\n\"ANHYDROUS DIBA...\n\n\n\"ferric oxide r...\n\n\n\n\n\"ANHYDROUS DIBA...\n\n\n\"hypromelloses\"\n\n\n\n\n\"ANHYDROUS DIBA...\n\n\n\"polyethylene g...\n\n\n\n\n\"ANHYDROUS DIBA...\n\n\n\"magnesium stea...\n\n\n\n\n\"ANHYDROUS DIBA...\n\n\n\"titanium dioxi...\n\n\n\n\n\"ANHYDROUS DIBA...\n\n\n\"talc\"\n\n\n\n\n\"ANHYDROUS DIBA...\n\n\n\"ferric oxide y...\n\n\n\n\n\n\n\n\n# Quick look at the dataframe to see before and after text cleaning\nprint(df_de.glimpse())\n\nRows: 840029\nColumns: 2\n$ Inactive_excipients <Utf8> SILICON DIOXIDE;EDETATE DISODIUM;LACTOSE MONOHYDRATE;MAGNESIUM STEARATE;CELLULOSE, MICROCRYSTALLINE;STARCH, CORN;SODIUM LAURYL SULFATE;FD&C BLUE NO. 1;FD&C RED NO. 40;GELATIN;TITANIUM DIOXIDE;BUTYL ALCOHOL;, SILICON DIOXIDE;EDETATE DISODIUM;LACTOSE MONOHYDRATE;MAGNESIUM STEARATE;CELLULOSE, MICROCRYSTALLINE;STARCH, CORN;SODIUM LAURYL SULFATE;FD&C BLUE NO. 1;FD&C RED NO. 40;GELATIN;TITANIUM DIOXIDE;BUTYL ALCOHOL;, SILICON DIOXIDE;EDETATE DISODIUM;LACTOSE MONOHYDRATE;MAGNESIUM STEARATE;CELLULOSE, MICROCRYSTALLINE;STARCH, CORN;SODIUM LAURYL SULFATE;FD&C BLUE NO. 1;FD&C RED NO. 40;GELATIN;TITANIUM DIOXIDE;BUTYL ALCOHOL;, SILICON DIOXIDE;EDETATE DISODIUM;LACTOSE MONOHYDRATE;MAGNESIUM STEARATE;CELLULOSE, MICROCRYSTALLINE;STARCH, CORN;SODIUM LAURYL SULFATE;FD&C BLUE NO. 1;FD&C RED NO. 40;GELATIN;TITANIUM DIOXIDE;BUTYL ALCOHOL;, SILICON DIOXIDE;EDETATE DISODIUM;LACTOSE MONOHYDRATE;MAGNESIUM STEARATE;CELLULOSE, MICROCRYSTALLINE;STARCH, CORN;SODIUM LAURYL SULFATE;FD&C BLUE NO. 1;FD&C RED NO. 40;GELATIN;TITANIUM DIOXIDE;BUTYL ALCOHOL;, SILICON DIOXIDE;EDETATE DISODIUM;LACTOSE MONOHYDRATE;MAGNESIUM STEARATE;CELLULOSE, MICROCRYSTALLINE;STARCH, CORN;SODIUM LAURYL SULFATE;FD&C BLUE NO. 1;FD&C RED NO. 40;GELATIN;TITANIUM DIOXIDE;BUTYL ALCOHOL;, SILICON DIOXIDE;EDETATE DISODIUM;LACTOSE MONOHYDRATE;MAGNESIUM STEARATE;CELLULOSE, MICROCRYSTALLINE;STARCH, CORN;SODIUM LAURYL SULFATE;FD&C BLUE NO. 1;FD&C RED NO. 40;GELATIN;TITANIUM DIOXIDE;BUTYL ALCOHOL;, SILICON DIOXIDE;EDETATE DISODIUM;LACTOSE MONOHYDRATE;MAGNESIUM STEARATE;CELLULOSE, MICROCRYSTALLINE;STARCH, CORN;SODIUM LAURYL SULFATE;FD&C BLUE NO. 1;FD&C RED NO. 40;GELATIN;TITANIUM DIOXIDE;BUTYL ALCOHOL;, SILICON DIOXIDE;EDETATE DISODIUM;LACTOSE MONOHYDRATE;MAGNESIUM STEARATE;CELLULOSE, MICROCRYSTALLINE;STARCH, CORN;SODIUM LAURYL SULFATE;FD&C BLUE NO. 1;FD&C RED NO. 40;GELATIN;TITANIUM DIOXIDE;BUTYL ALCOHOL;, SILICON DIOXIDE;EDETATE DISODIUM;LACTOSE MONOHYDRATE;MAGNESIUM STEARATE;CELLULOSE, MICROCRYSTALLINE;STARCH, CORN;SODIUM LAURYL SULFATE;FD&C BLUE NO. 1;FD&C RED NO. 40;GELATIN;TITANIUM DIOXIDE;BUTYL ALCOHOL;\n$ Inactive            <Utf8> silicon dioxide, edetate disodium, lactose monohydrate, magnesium stearate, cellulose, microcrystalline, starch, corn, sodium lauryl sulfate, fd&c blue no. 1\n\n\n\nAs shown above, the “Inactive_excipients” column was the original column for excipients, where the second column named, “Inactive” was the new column shown after the punctuation tidy-ups, string strip and row text explosion. The excipients were broken down into individual terms, rather than in massively long strings which might not make sense to some readers.\n\n# Re-organise the dataframe to choose the cleaned \"Inactive\" column\ndf_final = df_de.select([\"Inactive\"])\ndf_final\n\n\n\n\nshape: (840029, 1)\n\n\n\n\nInactive\n\n\n\n\nstr\n\n\n\n\n\n\n\"silicon dioxid...\n\n\n\n\n\"edetate disodi...\n\n\n\n\n\"lactose monohy...\n\n\n\n\n\"magnesium stea...\n\n\n\n\n\"cellulose\"\n\n\n\n\n\"microcrystalli...\n\n\n\n\n\"starch\"\n\n\n\n\n\"corn\"\n\n\n\n\n\"sodium lauryl ...\n\n\n\n\n\"fd&c blue no. ...\n\n\n\n\n\"fd&c red no. 4...\n\n\n\n\n\"gelatin\"\n\n\n\n\n...\n\n\n\n\n\"shellac\"\n\n\n\n\n\"propylene glyc...\n\n\n\n\n\"ammonia\"\n\n\n\n\n\"fd&c blue no. ...\n\n\n\n\n\"anhydrous diba...\n\n\n\n\n\"ferric oxide r...\n\n\n\n\n\"hypromelloses\"\n\n\n\n\n\"polyethylene g...\n\n\n\n\n\"magnesium stea...\n\n\n\n\n\"titanium dioxi...\n\n\n\n\n\"talc\"\n\n\n\n\n\"ferric oxide y...\n\n\n\n\n\n\n\n\n# Remove all cells with null values\ndf_final = df_final.drop_nulls()\n\n\n# Group the data by different inactive excipients with counts shown\ndf_final = df_final.groupby(\"Inactive\").agg(pl.count())\ndf_final.head()\n\n\n\n\nshape: (5, 2)\n\n\n\n\nInactive\n\n\ncount\n\n\n\n\nstr\n\n\nu32\n\n\n\n\n\n\n\"low-substitute...\n\n\n4\n\n\n\n\n\"sodium starch ...\n\n\n118\n\n\n\n\n\" glyceryl dibe...\n\n\n3\n\n\n\n\n\"aluminum chlor...\n\n\n27\n\n\n\n\n\"mentha piperit...\n\n\n7\n\n\n\n\n\n\n\n\n\nInactive excipient counts\n\n# Count each excipient and cast the whole column into integers\ndf_final = df_final.with_column((pl.col(\"count\")).cast(pl.Int64, strict = False))\ndf_final\n\n\n\n\nshape: (1674, 2)\n\n\n\n\nInactive\n\n\ncount\n\n\n\n\nstr\n\n\ni64\n\n\n\n\n\n\n\"low-substitute...\n\n\n4\n\n\n\n\n\"sodium starch ...\n\n\n118\n\n\n\n\n\" glyceryl dibe...\n\n\n3\n\n\n\n\n\"aluminum chlor...\n\n\n27\n\n\n\n\n\"mentha piperit...\n\n\n7\n\n\n\n\n\"epimedium gran...\n\n\n1\n\n\n\n\n\" ethyl acetate...\n\n\n2\n\n\n\n\n\"rutin\"\n\n\n1\n\n\n\n\n\"methacrylic ac...\n\n\n2106\n\n\n\n\n\" calcium phosp...\n\n\n12\n\n\n\n\n\"carbomer homop...\n\n\n28\n\n\n\n\n\" tocopherol\"\n\n\n2\n\n\n\n\n...\n\n\n...\n\n\n\n\n\"methylcellulos...\n\n\n62\n\n\n\n\n\"carbomer homop...\n\n\n27\n\n\n\n\n\" red ferric ox...\n\n\n3\n\n\n\n\n\"anhydrous lact...\n\n\n4\n\n\n\n\n\"sorbic acid\"\n\n\n195\n\n\n\n\n\"ilex pedunculo...\n\n\n2\n\n\n\n\n\" aminobenzoic ...\n\n\n1\n\n\n\n\n\"polyvinyl alco...\n\n\n55\n\n\n\n\n\"3-hexenyl acet...\n\n\n4\n\n\n\n\n\"methacrylic ac...\n\n\n2\n\n\n\n\n\"dihydroxyalumi...\n\n\n2\n\n\n\n\n\"hydroxypropyl ...\n\n\n46\n\n\n\n\n\n\n\n\n\nOverview of inactive excipients used in oral dosage forms\n\nfig = px.scatter(x = df_final[\"Inactive\"], \n                 y = df_final[\"count\"], \n                 hover_name = df_final[\"Inactive\"],\n                 title = \"Inactive excipients and their respective counts in pills\")\n\nfig.update_layout(\n    title = dict(\n        font = dict(\n            size = 15)),\n    title_x = 0.5,\n    margin = dict(\n        l = 20, r = 20, t = 40, b = 10),\n    xaxis = dict(\n        tickfont = dict(size = 9), \n        title = \"Inactive excipients\"\n    ),\n    yaxis = dict(\n        tickfont = dict(size = 9), \n        title = \"Counts\"\n    ),\n    legend = dict(\n        font = dict(\n            size = 9)))\n\n\nfig.show()\n\n\n                                                \n\n\n\n\nFrequently used inactive excipients\n\n# Re-order the excipients with counts in descending order\n# Filter out only the ones with counts over 10,000\ndf_ex = df_final.sort(\"count\", reverse = True).filter((pl.col(\"count\")) >= 10000)\ndf_ex.head()\n\n\n\n\nshape: (5, 2)\n\n\n\n\nInactive\n\n\ncount\n\n\n\n\nstr\n\n\ni64\n\n\n\n\n\n\n\"magnesium stea...\n\n\n58908\n\n\n\n\n\"titanium dioxi...\n\n\n43241\n\n\n\n\n\"unspecified\"\n\n\n35744\n\n\n\n\n\"silicon dioxid...\n\n\n34037\n\n\n\n\n\"starch\"\n\n\n32501\n\n\n\n\n\n\n\n\nfig = px.bar(x = df_ex[\"Inactive\"], \n             y = df_ex[\"count\"], \n             color = df_ex[\"Inactive\"],\n             title = \"Commonly used inactive excipients in pills\")\n\nfig.update_layout(\n    title = dict(\n        font = dict(\n            size = 15)),\n    title_x = 0.5,\n    margin = dict(\n        l = 10, r = 10, t = 40, b = 5),\n    xaxis = dict(\n        tickfont = dict(size = 9), \n        title = \"Inactive excipients\"\n    ),\n    yaxis = dict(\n        tickfont = dict(size = 9), \n        title = \"Counts\"\n    ),\n    legend = dict(\n        font = dict(\n            size = 9)))\n\nfig.show()\n\n\n                                                \n\n\n\nThe text cleaning might not be perfect at this stage, but I think I’ve managed to get most of the core texts cleaned into a more sensible and readable formats. From what I’ve worked out here, the most frequently used inactive ingredient was magnesium stearate, which was followed by titanium dioxide, and then interestingly “unspecified”, which was exactly how it was documented in the original pillbox dataset at the beginning. I didn’t go further digging into what this “unspecified” inactive excipients might be, as in whether it meant it in a singular or plural forms. So this still remained a mystery at this stage, but if all these oral medications were FDA-approved, we would’ve hoped each and everyone of these pills would be verified in safety, quality and effectiveness before they entered into the market for wide prescriptions. In the worst case, each therapeutic drug should also have post-marketing surveillance, for long-term safety monitoring.\n\n\n\n\nCreate a small dataframe for data visualisation in Rust-Evcxr\nAll acetaminophens were filtered out in the “Drug_strength” column and all duplicates were removed in the dataset.\n\ndf_ac = df_new.filter(\n    pl.col(\"Drug_strength\")\n    .str.starts_with(\"acetam\")).unique(subset = [\"Drug_strength\"])\n\ndf_ac\n\n\n\n\nshape: (13, 5)\n\n\n\n\nShape\n\n\nColour\n\n\nDrug_strength\n\n\nInactive_excipients\n\n\nDosage_form\n\n\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\n\n\n\n\n\"CAPSULE\"\n\n\n\"RED\"\n\n\n\"acetaminophen ...\n\n\n\"starch, corn /...\n\n\n\"CAPSULE\"\n\n\n\n\n\"OVAL\"\n\n\n\"WHITE\"\n\n\n\"acetaminophen ...\n\n\n\"anhydrous citr...\n\n\n\"TABLET, FILM C...\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"acetaminophen ...\n\n\n\"powdered cellu...\n\n\n\"TABLET\"\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"acetaminophen ...\n\n\n\"hydroxypropyl ...\n\n\n\"TABLET\"\n\n\n\n\n\"OVAL\"\n\n\n\"ORANGE\"\n\n\n\"acetaminophen ...\n\n\nnull\n\n\n\"TABLET, FILM C...\n\n\n\n\n\"ROUND\"\n\n\n\"BLUE\"\n\n\n\"acetaminophen ...\n\n\n\"FD&C BLUE NO. ...\n\n\n\"TABLET\"\n\n\n\n\n\"ROUND\"\n\n\n\"YELLOW;WHITE\"\n\n\n\"acetaminophen ...\n\n\n\"calcium steara...\n\n\n\"TABLET\"\n\n\n\n\n\"OVAL\"\n\n\n\"WHITE\"\n\n\n\"acetaminophen ...\n\n\n\"carnauba wax;s...\n\n\n\"TABLET, FILM C...\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"acetaminophen ...\n\n\n\"powdered cellu...\n\n\n\"TABLET\"\n\n\n\n\n\"CAPSULE\"\n\n\n\"ORANGE;BROWN\"\n\n\n\"acetaminophen ...\n\n\n\"CALCIUM PHOSPH...\n\n\n\"CAPSULE\"\n\n\n\n\n\"OVAL\"\n\n\n\"WHITE\"\n\n\n\"acetaminophen ...\n\n\n\"carnauba wax;H...\n\n\n\"TABLET, FILM C...\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"acetaminophen ...\n\n\n\"calcium steara...\n\n\n\"TABLET\"\n\n\n\n\n\"OVAL\"\n\n\n\"BLUE\"\n\n\n\"acetaminophen ...\n\n\n\"carnauba wax;C...\n\n\n\"TABLET, FILM C...\n\n\n\n\n\n\n\nI’ve opted for finding out the different types of colours with their respective counts in oral acetaminophen, or also known as paracetamol in some other countries.\n\ndf_ac = df_ac.groupby(\"Colour\").agg(pl.count())\ndf_ac\n\n\n\n\nshape: (6, 2)\n\n\n\n\nColour\n\n\ncount\n\n\n\n\nstr\n\n\nu32\n\n\n\n\n\n\n\"ORANGE;BROWN\"\n\n\n1\n\n\n\n\n\"YELLOW;WHITE\"\n\n\n1\n\n\n\n\n\"WHITE\"\n\n\n7\n\n\n\n\n\"ORANGE\"\n\n\n1\n\n\n\n\n\"RED\"\n\n\n1\n\n\n\n\n\"BLUE\"\n\n\n2\n\n\n\n\n\n\n\n\nfig = px.scatter(x = df_ac[\"Colour\"], \n                 y = df_ac[\"count\"], \n                 size = df_ac[\"count\"], \n                 color = df_ac[\"Colour\"],\n                 title = \"Frequency of colours in acetaminophen (paracetamol) oral dosage forms\"\n                )\n\nfig.update_layout(\n    xaxis = dict(\n        title = \"Colours\"\n    ), \n    yaxis = dict(\n        title = \"Counts\"\n    )\n)\n\nfig.show()\n\n\n                                                \n\n\n\nI’ve decided to keep the dataframe very simple for part 3 as my original intention was to trial plotting a graph in Evcxr only (nothing fancy at this stage), and also to gain some familiarities with Rust as another new programming language for me. Readers might notice that I’ve opted for a scatter plot in Plotly (in Python3 kernel) here for this last dataframe, and when we finally got to part 3 (hopefully coming soon as I needed to figure how to publish Rust code in Quarto…), I might very likely revert this to a bar graph (in Rust kernel), due to some technical issues (slow dependency loading, and somehow with Plotly.rs in Evcxr, the scatter graph looked more like scatter line graph instead… more stories to follow) and being a new Rust-Evcxr user. At the very least, I’ve kind of tried something I’ve planned for, although not looking very elegant yet, with rooms for improvements in the future."
  },
  {
    "objectID": "posts/09_Pills/Rust_polars_pills_ws.html",
    "href": "posts/09_Pills/Rust_polars_pills_ws.html",
    "title": "Pills dataset - Part 1",
    "section": "",
    "text": "Introduction\nAs mentioned in my last project, I’ve tried using Evcxr, which provided a way to use Rust interactively in a Jupyter environment. The name, “Evcxr”, was quite hard to remember at first. It was pronounced as “e-vic-ser” according to the author, which I’ve randomly come across in an online tech interview when I was looking into it. I’ve also sort of worked out a way to memorise its spelling by taking specific letters out of “evaluation context for rust” (which was what it was called in its GitHub repository).\nFor users of Jupyter Notebook/Lab and Python, they might be quite used to the working speed of the cell outputs. However, one thing I’ve noticed when I was using Evcxr or Rust kernel in Jupyter Lab was that the speed of cell outputs was noticeably slower (especially at the beginning while loading all the dependencies required). The speed improved when loading external crates and modules, and generally it was faster afterward.\nDue to this reason (note: I did not look into any other optimising strategies for this and this could be restricted to my computer hardware specs, so this might differ for other users), I think Evcxr was not ideal for a very large and complex data science project yet (however if its ecosystem kept developing, it might be improved in the future). One thing of note was that when I was combing through issues in Evcxr’s GitHub repository, someone mentioned the slow compile time of the Rust compiler, which would have likely caused the snail speed, but knowing that the actual program running speed was blazingly fast, some sacrifice at the beginning made sense to me. Overall, Rust was really a systems programming language with memory efficiency (with no garbage collector), type safety and concurrency as some of its notable advantages.\nBecause of the dependency loading issue in the Jupyter environment, and also knowing there was already a dataframe library built from Rust, I’ve opted to use Polars-Python again for the data wrangling part of this project. This was also accompanied by the good old Pandas library as well (under the section of “Transform web-scraped data into dataframe” if anyone wants to jump to that part to see the code). I then went on to trial using Rust via Evcxr for data visualisation based on a small dataframe by using Plotly.rs. This project would be separated into 3 parts:\n\nPart 1: Initial pillbox dataset loading and web-scraping\nPart 2: Data wrangling and mining for data visualisations\nPart 3: Using Rust for data visualisation\n\nThe main reason I wanted to try Evcxr was that I could see the potential of using Rust interactively to showcase the results in a relatively fast and efficient manner. This meant specific data exploratory results could reach wider audience, leading to more impacts in different fields, in a very broad term. Oppositely, for more specific users such as scientists or engineers, this meant experiments could be carried out in a safe and efficient manner, with test results readily available for future work planning.\n\n\n\nDownload dataset\nThis time the dataset was spotted from Data Is Plural, specifically the 2022.11.30 edition. The section I was interested in was the first paragraph at the top, about “Pills”. By going into one of the links provided in the paragraph, this brought me to the Pillbox dataset from the US National Library of Medicine (NLM). The .csv file was downloaded via the “Export” button at the top right of the webpage.\nThis pillbox dataset was actually retired since 28th January 2021, but was still available for educational or research purposes only. Therefore, it was not recommended for pill identifications as the dataset was not up-to-date. Alternative resources such as DailyMed would be more appropriate for readers in the US (as one of the examples). For readers in other countries, local health professionals and resources would be recommended for up-to-date information.\n\n\n\nImporting library & dataset\n\n# Install/upgrade polars if needed (uncomment the line below)\n#pip install --upgrade polars\n\n\nimport polars as pl\n\n\n# Check version of polars (uncomment line below)\n#pl.show_versions()\n\n\ndf = pl.read_csv(\"pillbox.csv\", ignore_errors = True)\ndf\n\n\n\n\nshape: (83925, 55)\n\n\n\n\nID\n\n\nEnabled?\n\n\ncreated at\n\n\nupdated at\n\n\nspp\n\n\nsetid\n\n\nsplsize\n\n\npillbox_size\n\n\nsplshape\n\n\nsplshape_text\n\n\npillbox_shape_text\n\n\nsplscore\n\n\npillbox_score\n\n\nsplimprint\n\n\npillbox_imprint\n\n\nsplcolor\n\n\nsplcolor_text\n\n\npillbox_color_text\n\n\nspl_strength\n\n\nspl_ingredients\n\n\nspl_inactive_ing\n\n\nsource\n\n\nrxtty\n\n\nrxstring\n\n\nrxcui\n\n\nRxNorm Update time\n\n\nproduct_code\n\n\npart_num\n\n\npart_medicine_name\n\n\nndc9\n\n\nndc_labeler_code\n\n\nndc_product_code\n\n\nmedicine_name\n\n\nmarketing_act_code\n\n\neffective_time\n\n\nfile_name\n\n\nequal_product_code\n\n\ndosage_form\n\n\ndocument_type\n\n\ndea_schedule_code\n\n\ndea_schedule_name\n\n\nauthor_type\n\n\nauthor\n\n\napproval_code\n\n\nimage_source\n\n\nsplimage\n\n\nhas_image\n\n\nepc_match\n\n\nversion_number\n\n\nlaberer_code\n\n\napplication_number\n\n\nupdated\n\n\nstale\n\n\nnew\n\n\nPillbox Value\n\n\n\n\ni64\n\n\nbool\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\ni64\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\ni64\n\n\ni64\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\ni64\n\n\nstr\n\n\nstr\n\n\ni64\n\n\nstr\n\n\ni64\n\n\ni64\n\n\ni64\n\n\nstr\n\n\nstr\n\n\ni64\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nbool\n\n\ni64\n\n\ni64\n\n\nstr\n\n\nstr\n\n\nbool\n\n\nbool\n\n\nbool\n\n\nbool\n\n\n\n\n\n\n41846\n\n\ntrue\n\n\n\"10/17/2017 05:...\n\n\n\"10/02/2020 05:...\n\n\n\"471fa2f1-73a0-...\n\n\n\"471fa2f1-73a0-...\n\n\n16\n\n\nnull\n\n\n\"C48336\"\n\n\n\"CAPSULE\"\n\n\nnull\n\n\n1\n\n\nnull\n\n\n\"5892;V\"\n\n\nnull\n\n\n\"C48328\"\n\n\n\"PINK\"\n\n\nnull\n\n\n\"TEMAZEPAM 15 m...\n\n\n\"TEMAZEPAM[TEMA...\n\n\n\"SILICON DIOXID...\n\n\n\"HRX\"\n\n\nnull\n\n\nnull\n\n\nnull\n\n\n\"10/02/2020 04:...\n\n\n\"0603-5892\"\n\n\n0\n\n\nnull\n\n\n6035892\n\n\n603\n\n\n5892\n\n\n\"Temazepam\"\n\n\n\"completed\"\n\n\n20160406\n\n\n\"d912ca54-6569-...\n\n\nnull\n\n\n\"C25158\"\n\n\nnull\n\n\n\"C48677\"\n\n\n\"CIV\"\n\n\n\"LABELER\"\n\n\n\"Qualitest Phar...\n\n\n\"C73584\"\n\n\nnull\n\n\nnull\n\n\nfalse\n\n\nnull\n\n\n5\n\n\nnull\n\n\nnull\n\n\ntrue\n\n\nfalse\n\n\nfalse\n\n\nfalse\n\n\n\n\n8100\n\n\ntrue\n\n\n\"10/17/2017 05:...\n\n\n\"10/02/2020 04:...\n\n\n\"116e13c1-ac50-...\n\n\n\"116e13c1-ac50-...\n\n\n10\n\n\nnull\n\n\n\"C48348\"\n\n\n\"ROUND\"\n\n\nnull\n\n\n1\n\n\nnull\n\n\n\"I2\"\n\n\nnull\n\n\n\"C48331\"\n\n\n\"ORANGE\"\n\n\nnull\n\n\n\"IBUPROFEN 200 ...\n\n\n\"IBUPROFEN[IBUP...\n\n\n\"SILICON DIOXID...\n\n\n\"HOTC\"\n\n\n\"SCD\"\n\n\n\"ibuprofen 200 ...\n\n\n310965\n\n\n\"10/02/2020 03:...\n\n\n\"59779-074\"\n\n\n0\n\n\nnull\n\n\n597790074\n\n\n59779\n\n\n74\n\n\n\"ibuprofen\"\n\n\n\"active\"\n\n\n20191120\n\n\n\"55de9f94-89b2-...\n\n\nnull\n\n\n\"C42931\"\n\n\n\"34390-5\"\n\n\nnull\n\n\nnull\n\n\n\"LABELER\"\n\n\n\"CVS Pharmacy\"\n\n\n\"C73584\"\n\n\nnull\n\n\nnull\n\n\nfalse\n\n\nnull\n\n\n4\n\n\nnull\n\n\nnull\n\n\ntrue\n\n\nfalse\n\n\nfalse\n\n\nfalse\n\n\n\n\n5258\n\n\ntrue\n\n\n\"10/17/2017 05:...\n\n\n\"10/17/2017 05:...\n\n\n\"827ce261-307b-...\n\n\n\"827ce261-307b-...\n\n\n7\n\n\nnull\n\n\n\"C48346\"\n\n\n\"PENTAGON (5 SI...\n\n\nnull\n\n\n1\n\n\n2\n\n\n\"par;129\"\n\n\nnull\n\n\n\"C48329\"\n\n\n\"GREEN\"\n\n\nnull\n\n\n\"DEXAMETHASONE ...\n\n\n\"DEXAMETHASONE[...\n\n\n\"ANHYDROUS LACT...\n\n\n\"HRX\"\n\n\nnull\n\n\n\"Dexamethasone ...\n\n\n197583\n\n\nnull\n\n\n\"49884-129\"\n\n\n0\n\n\nnull\n\n\n498840129\n\n\n49884\n\n\n129\n\n\n\"Dexamethasone\"\n\n\n\"active\"\n\n\n20120516\n\n\n\"85a9eebb-be74-...\n\n\nnull\n\n\n\"C42998\"\n\n\n\"34391-3\"\n\n\nnull\n\n\nnull\n\n\n\"LABELER\"\n\n\n\"Par Pharmaceut...\n\n\n\"C73584\"\n\n\n\"NLM\"\n\n\n\"498840129\"\n\n\ntrue\n\n\nnull\n\n\n4\n\n\nnull\n\n\nnull\n\n\nfalse\n\n\ntrue\n\n\nfalse\n\n\ntrue\n\n\n\n\n21271\n\n\ntrue\n\n\n\"10/17/2017 05:...\n\n\n\"10/02/2020 05:...\n\n\n\"f7f1c99e-1a67-...\n\n\n\"f7f1c99e-1a67-...\n\n\n11\n\n\nnull\n\n\n\"C48348\"\n\n\n\"ROUND\"\n\n\nnull\n\n\n2\n\n\nnull\n\n\n\"LL\"\n\n\nnull\n\n\n\"C48325\"\n\n\n\"WHITE\"\n\n\nnull\n\n\n\"Nickel Sulfate...\n\n\n\"Nickel Sulfate...\n\n\nnull\n\n\n\"HOMEO\"\n\n\nnull\n\n\nnull\n\n\nnull\n\n\n\"10/02/2020 04:...\n\n\n\"61480-137\"\n\n\n0\n\n\nnull\n\n\n614800137\n\n\n61480\n\n\n137\n\n\n\"Acunol\"\n\n\n\"active\"\n\n\n20190909\n\n\n\"029eaf64-e66f-...\n\n\nnull\n\n\n\"C42998\"\n\n\n\"34391-3\"\n\n\nnull\n\n\nnull\n\n\n\"LABELER\"\n\n\n\"PLYMOUTH HEALT...\n\n\n\"C73614\"\n\n\nnull\n\n\nnull\n\n\nfalse\n\n\nnull\n\n\n8\n\n\nnull\n\n\nnull\n\n\ntrue\n\n\nfalse\n\n\nfalse\n\n\nfalse\n\n\n\n\n77050\n\n\ntrue\n\n\n\"09/20/2019 09:...\n\n\n\"10/02/2020 05:...\n\n\n\"ecb28fcb-f0d1-...\n\n\n\"ecb28fcb-f0d1-...\n\n\n6\n\n\nnull\n\n\n\"C48348\"\n\n\n\"ROUND\"\n\n\nnull\n\n\n1\n\n\nnull\n\n\n\"L;524\"\n\n\nnull\n\n\n\"C48325\"\n\n\n\"WHITE\"\n\n\nnull\n\n\n\"CLONAZEPAM 0.2...\n\n\n\"CLONAZEPAM[CLO...\n\n\n\"SORBITOL;ASPAR...\n\n\n\"HRX\"\n\n\n\"SCD\"\n\n\n\"clonazepam 0.2...\n\n\n349195\n\n\n\"10/02/2020 04:...\n\n\n\"62332-365\"\n\n\n0\n\n\nnull\n\n\n623320365\n\n\n62332\n\n\n365\n\n\n\"CLONAZEPAM\"\n\n\n\"active\"\n\n\n20190701\n\n\n\"ba5120ce-ed74-...\n\n\nnull\n\n\n\"C42999\"\n\n\nnull\n\n\n\"C48677\"\n\n\n\"CIV\"\n\n\n\"LABELER\"\n\n\n\"Alembic Pharma...\n\n\n\"C73584\"\n\n\nnull\n\n\nnull\n\n\nfalse\n\n\nnull\n\n\n3\n\n\nnull\n\n\nnull\n\n\ntrue\n\n\nfalse\n\n\nfalse\n\n\nfalse\n\n\n\n\n76916\n\n\ntrue\n\n\n\"09/20/2019 09:...\n\n\n\"10/02/2020 05:...\n\n\n\"442e41da-24c2-...\n\n\n\"442e41da-24c2-...\n\n\n9\n\n\nnull\n\n\n\"C48348\"\n\n\n\"ROUND\"\n\n\nnull\n\n\n1\n\n\nnull\n\n\n\"LU;V06\"\n\n\nnull\n\n\n\"C48325\"\n\n\n\"WHITE\"\n\n\nnull\n\n\n\"SILDENAFIL CIT...\n\n\n\"SILDENAFIL CIT...\n\n\n\"ANHYDROUS DIBA...\n\n\n\"HRX\"\n\n\n\"SCD\"\n\n\n\"sildenafil 50 ...\n\n\n312950\n\n\n\"10/02/2020 04:...\n\n\n\"70748-132\"\n\n\n0\n\n\nnull\n\n\n707480132\n\n\n70748\n\n\n132\n\n\n\"SILDENAFIL\"\n\n\n\"active\"\n\n\n20191001\n\n\n\"17c537d9-b2e6-...\n\n\nnull\n\n\n\"C42931\"\n\n\nnull\n\n\nnull\n\n\nnull\n\n\n\"LABELER\"\n\n\n\"Lupin Pharmace...\n\n\n\"C73584\"\n\n\nnull\n\n\nnull\n\n\nfalse\n\n\nnull\n\n\n4\n\n\nnull\n\n\nnull\n\n\ntrue\n\n\nfalse\n\n\nfalse\n\n\nfalse\n\n\n\n\n20016\n\n\ntrue\n\n\n\"10/17/2017 05:...\n\n\n\"10/02/2020 05:...\n\n\n\"5f0bdf9d-fa78-...\n\n\n\"5f0bdf9d-fa78-...\n\n\n14\n\n\nnull\n\n\n\"C48345\"\n\n\n\"OVAL\"\n\n\nnull\n\n\n1\n\n\nnull\n\n\n\"A;73\"\n\n\nnull\n\n\n\"C48330\"\n\n\n\"YELLOW\"\n\n\nnull\n\n\n\"RISPERIDONE 3 ...\n\n\n\"RISPERIDONE[RI...\n\n\n\"LACTOSE MONOHY...\n\n\n\"HRX\"\n\n\n\"SCD\"\n\n\n\"risperidone 3 ...\n\n\n312832\n\n\n\"10/02/2020 04:...\n\n\n\"65862-123\"\n\n\n0\n\n\nnull\n\n\n658620123\n\n\n65862\n\n\n123\n\n\n\"Risperidone\"\n\n\n\"active\"\n\n\n20180924\n\n\n\"5d2750a4-025a-...\n\n\nnull\n\n\n\"C42931\"\n\n\n\"34391-3\"\n\n\nnull\n\n\nnull\n\n\n\"LABELER\"\n\n\n\"Aurobindo Phar...\n\n\n\"C73584\"\n\n\nnull\n\n\nnull\n\n\nfalse\n\n\nnull\n\n\n21\n\n\nnull\n\n\nnull\n\n\ntrue\n\n\nfalse\n\n\nfalse\n\n\nfalse\n\n\n\n\n67902\n\n\ntrue\n\n\n\"06/27/2019 10:...\n\n\n\"10/02/2020 05:...\n\n\n\"572e672e-b759-...\n\n\n\"572e672e-b759-...\n\n\n19\n\n\nnull\n\n\n\"C48336\"\n\n\n\"CAPSULE\"\n\n\nnull\n\n\n1\n\n\nnull\n\n\n\"AT146\"\n\n\nnull\n\n\n\"C48333\"\n\n\n\"BLUE\"\n\n\nnull\n\n\n\"IBUPROFEN 200 ...\n\n\n\"IBUPROFEN[IBUP...\n\n\n\"FD&C BLUE NO. ...\n\n\n\"HOTC\"\n\n\n\"SCD\"\n\n\n\"ibuprofen 200 ...\n\n\n310964\n\n\n\"10/02/2020 03:...\n\n\n\"50804-750\"\n\n\n0\n\n\nnull\n\n\n508040750\n\n\n50804\n\n\n750\n\n\n\"Ibuprofen\"\n\n\n\"active\"\n\n\n20191101\n\n\n\"148c7665-22d5-...\n\n\nnull\n\n\n\"C42954\"\n\n\nnull\n\n\nnull\n\n\nnull\n\n\n\"LABELER\"\n\n\n\"Good Sense (Ge...\n\n\n\"C73584\"\n\n\nnull\n\n\nnull\n\n\nfalse\n\n\nnull\n\n\n2\n\n\nnull\n\n\nnull\n\n\ntrue\n\n\nfalse\n\n\nfalse\n\n\nfalse\n\n\n\n\n75997\n\n\ntrue\n\n\n\"09/20/2019 09:...\n\n\n\"10/02/2020 05:...\n\n\n\"6f17cc91-86b3-...\n\n\n\"6f17cc91-86b3-...\n\n\n12\n\n\nnull\n\n\n\"C48348\"\n\n\n\"ROUND\"\n\n\nnull\n\n\n1\n\n\nnull\n\n\n\"T;12\"\n\n\nnull\n\n\n\"C48325\"\n\n\n\"WHITE\"\n\n\nnull\n\n\n\"Iloperidone 12...\n\n\n\"Iloperidone[Il...\n\n\n\"silicon dioxid...\n\n\n\"HRX\"\n\n\n\"SCD\"\n\n\n\"iloperidone 12...\n\n\n848732\n\n\n\"10/02/2020 04:...\n\n\n\"51672-4184\"\n\n\n0\n\n\nnull\n\n\n516724184\n\n\n51672\n\n\n4184\n\n\n\"Iloperidone\"\n\n\n\"active\"\n\n\n20190802\n\n\n\"6787555e-8a11-...\n\n\nnull\n\n\n\"C42998\"\n\n\nnull\n\n\nnull\n\n\nnull\n\n\n\"LABELER\"\n\n\n\"Taro Pharmaceu...\n\n\n\"C73584\"\n\n\nnull\n\n\nnull\n\n\nfalse\n\n\nnull\n\n\n1\n\n\nnull\n\n\nnull\n\n\ntrue\n\n\nfalse\n\n\nfalse\n\n\nfalse\n\n\n\n\n1288\n\n\ntrue\n\n\n\"10/17/2017 05:...\n\n\n\"10/17/2017 05:...\n\n\n\"02a23e48-f371-...\n\n\n\"02a23e48-f371-...\n\n\n23\n\n\nnull\n\n\n\"C48336\"\n\n\n\"CAPSULE\"\n\n\nnull\n\n\n1\n\n\nnull\n\n\n\"RX681\"\n\n\nnull\n\n\n\"C48330;C48325\"\n\n\n\"YELLOW;WHITE\"\n\n\nnull\n\n\n\"FENOPROFEN CAL...\n\n\n\"FENOPROFEN CAL...\n\n\n\"CROSPOVIDONE;M...\n\n\n\"HRX\"\n\n\nnull\n\n\n\"Fenoprofen 200...\n\n\n1799325\n\n\nnull\n\n\n\"54288-129\"\n\n\n0\n\n\nnull\n\n\n542880129\n\n\n54288\n\n\n129\n\n\n\"FENORTHO\"\n\n\n\"active\"\n\n\n20160614\n\n\n\"91b0ac5b-994c-...\n\n\nnull\n\n\n\"C25158\"\n\n\nnull\n\n\nnull\n\n\nnull\n\n\n\"LABELER\"\n\n\n\"BPI Labs LLC\"\n\n\n\"C73594\"\n\n\nnull\n\n\nnull\n\n\nfalse\n\n\nnull\n\n\n2\n\n\nnull\n\n\nnull\n\n\nfalse\n\n\ntrue\n\n\nfalse\n\n\nfalse\n\n\n\n\n53601\n\n\ntrue\n\n\n\"10/17/2017 09:...\n\n\n\"10/02/2020 05:...\n\n\n\"d2213ffd-18f6-...\n\n\n\"d2213ffd-18f6-...\n\n\n12\n\n\nnull\n\n\n\"C48348\"\n\n\n\"ROUND\"\n\n\nnull\n\n\n1\n\n\nnull\n\n\n\"BA;300\"\n\n\nnull\n\n\n\"C48330\"\n\n\n\"YELLOW\"\n\n\nnull\n\n\n\"BUTALBITAL 50 ...\n\n\n\"BUTALBITAL[BUT...\n\n\n\"STARCH, CORN;C...\n\n\n\"HRX\"\n\n\n\"SCD\"\n\n\n\"acetaminophen ...\n\n\n1249617\n\n\n\"10/02/2020 03:...\n\n\n\"68682-306\"\n\n\n0\n\n\nnull\n\n\n686820306\n\n\n68682\n\n\n306\n\n\n\"Butalbital and...\n\n\n\"active\"\n\n\n20200402\n\n\n\"18ee9ab7-9e5d-...\n\n\nnull\n\n\n\"C42998\"\n\n\nnull\n\n\n\"C48676\"\n\n\n\"CIII\"\n\n\n\"LABELER\"\n\n\n\"Oceanside Phar...\n\n\n\"C73584\"\n\n\nnull\n\n\nnull\n\n\nfalse\n\n\nnull\n\n\n3\n\n\nnull\n\n\nnull\n\n\ntrue\n\n\nfalse\n\n\nfalse\n\n\nfalse\n\n\n\n\n1528\n\n\ntrue\n\n\n\"10/17/2017 05:...\n\n\n\"10/02/2020 05:...\n\n\n\"3b8a7426-6f1c-...\n\n\n\"3b8a7426-6f1c-...\n\n\n6\n\n\nnull\n\n\n\"C48348\"\n\n\n\"ROUND\"\n\n\nnull\n\n\n1\n\n\nnull\n\n\n\"M53;LU\"\n\n\nnull\n\n\n\"C48325\"\n\n\n\"WHITE\"\n\n\nnull\n\n\n\"ESTRADIOL 0.5 ...\n\n\n\"ESTRADIOL[ESTR...\n\n\n\"COPOVIDONE K25...\n\n\n\"HRX\"\n\n\n\"BPCK\"\n\n\n\"{28 (estradiol...\n\n\n1806683\n\n\n\"10/02/2020 03:...\n\n\n\"68180-829\"\n\n\n0\n\n\nnull\n\n\n681800829\n\n\n68180\n\n\n829\n\n\n\"AMABELZ\"\n\n\n\"completed\"\n\n\n20200928\n\n\n\"34d4f5d6-6526-...\n\n\nnull\n\n\n\"C42998\"\n\n\nnull\n\n\nnull\n\n\nnull\n\n\n\"LABELER\"\n\n\n\"Lupin Pharmace...\n\n\n\"C73584\"\n\n\nnull\n\n\nnull\n\n\nfalse\n\n\nnull\n\n\n7\n\n\nnull\n\n\nnull\n\n\ntrue\n\n\nfalse\n\n\nfalse\n\n\nfalse\n\n\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n\n\n19475\n\n\ntrue\n\n\n\"10/17/2017 05:...\n\n\n\"10/02/2020 05:...\n\n\n\"be032f1e-c123-...\n\n\n\"be032f1e-c123-...\n\n\n8\n\n\nnull\n\n\n\"C48348\"\n\n\n\"ROUND\"\n\n\nnull\n\n\n1\n\n\nnull\n\n\n\"M;104\"\n\n\nnull\n\n\n\"C48325\"\n\n\n\"WHITE\"\n\n\nnull\n\n\n\"MEMANTINE HYDR...\n\n\n\"MEMANTINE HYDR...\n\n\n\"SILICON DIOXID...\n\n\n\"HRX\"\n\n\n\"SCD\"\n\n\n\"memantine hydr...\n\n\n996561\n\n\n\"10/02/2020 04:...\n\n\n\"0378-1104\"\n\n\n0\n\n\nnull\n\n\n3781104\n\n\n378\n\n\n1104\n\n\n\"Memantine Hydr...\n\n\n\"completed\"\n\n\n20140924\n\n\n\"4b207674-ac13-...\n\n\nnull\n\n\n\"C42998\"\n\n\nnull\n\n\nnull\n\n\nnull\n\n\n\"LABELER\"\n\n\n\"Mylan Pharmace...\n\n\n\"C73584\"\n\n\nnull\n\n\nnull\n\n\nfalse\n\n\nnull\n\n\n5\n\n\nnull\n\n\nnull\n\n\ntrue\n\n\nfalse\n\n\nfalse\n\n\nfalse\n\n\n\n\n78691\n\n\ntrue\n\n\n\"12/06/2019 06:...\n\n\n\"10/02/2020 05:...\n\n\n\"3c7ef3cf-f7f9-...\n\n\n\"3c7ef3cf-f7f9-...\n\n\n20\n\n\nnull\n\n\n\"C48336\"\n\n\n\"CAPSULE\"\n\n\nnull\n\n\n1\n\n\nnull\n\n\n\"P19\"\n\n\nnull\n\n\n\"C48331\"\n\n\n\"ORANGE\"\n\n\nnull\n\n\n\"ACETAMINOPHEN ...\n\n\n\"ACETAMINOPHEN[...\n\n\n\"BUTYLATED HYDR...\n\n\n\"HOTC\"\n\n\n\"SCD\"\n\n\n\"acetaminophen ...\n\n\n1086997\n\n\n\"10/02/2020 04:...\n\n\n\"72476-848\"\n\n\n0\n\n\nnull\n\n\n724760848\n\n\n72476\n\n\n848\n\n\n\"Multi-Symptom ...\n\n\n\"active\"\n\n\n20191029\n\n\n\"c4f51f20-dd42-...\n\n\nnull\n\n\n\"C42954\"\n\n\nnull\n\n\nnull\n\n\nnull\n\n\n\"LABELER\"\n\n\n\"Care One (Reta...\n\n\n\"C73603\"\n\n\nnull\n\n\nnull\n\n\nfalse\n\n\nnull\n\n\n1\n\n\nnull\n\n\nnull\n\n\ntrue\n\n\nfalse\n\n\nfalse\n\n\ntrue\n\n\n\n\n38030\n\n\ntrue\n\n\n\"10/17/2017 05:...\n\n\n\"10/02/2020 05:...\n\n\n\"e08920c2-04a3-...\n\n\n\"e08920c2-04a3-...\n\n\n9\n\n\nnull\n\n\n\"C48348\"\n\n\n\"ROUND\"\n\n\nnull\n\n\n1\n\n\nnull\n\n\n\"D99\"\n\n\nnull\n\n\n\"C48325\"\n\n\n\"WHITE\"\n\n\nnull\n\n\n\"LAMOTRIGINE 25...\n\n\n\"LAMOTRIGINE[LA...\n\n\n\"MAGNESIUM CARB...\n\n\n\"HRX\"\n\n\n\"SCD\"\n\n\n\"lamotrigine 25...\n\n\n311264\n\n\n\"10/02/2020 04:...\n\n\n\"65862-362\"\n\n\n0\n\n\nnull\n\n\n658620362\n\n\n65862\n\n\n362\n\n\n\"Lamotrigine\"\n\n\n\"active\"\n\n\n20191029\n\n\n\"59344318-d7b4-...\n\n\nnull\n\n\n\"C42893\"\n\n\n\"34391-3\"\n\n\nnull\n\n\nnull\n\n\n\"LABELER\"\n\n\n\"Aurobindo Phar...\n\n\n\"C73584\"\n\n\nnull\n\n\nnull\n\n\nfalse\n\n\nnull\n\n\n20\n\n\nnull\n\n\nnull\n\n\ntrue\n\n\nfalse\n\n\nfalse\n\n\nfalse\n\n\n\n\n78672\n\n\ntrue\n\n\n\"12/06/2019 06:...\n\n\n\"10/02/2020 05:...\n\n\n\"ee1477ed-00c4-...\n\n\n\"ee1477ed-00c4-...\n\n\n17\n\n\nnull\n\n\n\"C48345\"\n\n\n\"OVAL\"\n\n\nnull\n\n\n1\n\n\nnull\n\n\n\"AAA;1139\"\n\n\nnull\n\n\n\"C48333\"\n\n\n\"BLUE\"\n\n\nnull\n\n\n\"ACETAMINOPHEN ...\n\n\n\"ACETAMINOPHEN[...\n\n\n\"ACESULFAME POT...\n\n\n\"HOTC\"\n\n\n\"GPCK\"\n\n\n\"{8 (acetaminop...\n\n\n1801964\n\n\n\"10/02/2020 04:...\n\n\n\"37808-286\"\n\n\n2\n\n\n\"Acetaminophen,...\n\n\n378080286\n\n\n37808\n\n\n286\n\n\n\"Cold Flu Sever...\n\n\nnull\n\n\n20191004\n\n\n\"941e4166-0964-...\n\n\nnull\n\n\n\"C42897\"\n\n\nnull\n\n\nnull\n\n\nnull\n\n\n\"LABELER\"\n\n\n\"HEB\"\n\n\n\"C73603\"\n\n\nnull\n\n\nnull\n\n\nfalse\n\n\nnull\n\n\n2\n\n\nnull\n\n\nnull\n\n\ntrue\n\n\nfalse\n\n\nfalse\n\n\ntrue\n\n\n\n\n71471\n\n\ntrue\n\n\n\"06/29/2019 04:...\n\n\n\"10/02/2020 05:...\n\n\n\"a2754618-3df1-...\n\n\n\"a2754618-3df1-...\n\n\n19\n\n\nnull\n\n\n\"C48345\"\n\n\n\"OVAL\"\n\n\nnull\n\n\n1\n\n\nnull\n\n\n\"600\"\n\n\nnull\n\n\n\"C48325\"\n\n\n\"WHITE\"\n\n\nnull\n\n\n\"AZITHROMYCIN D...\n\n\n\"AZITHROMYCIN D...\n\n\n\"CROSCARMELLOSE...\n\n\n\"HRX\"\n\n\n\"SCD\"\n\n\n\"azithromycin 6...\n\n\n204844\n\n\n\"10/02/2020 03:...\n\n\n\"69452-173\"\n\n\n0\n\n\nnull\n\n\n694520173\n\n\n69452\n\n\n173\n\n\n\"Azithromycin\"\n\n\n\"active\"\n\n\n20200624\n\n\n\"a8d7dd04-c391-...\n\n\nnull\n\n\n\"C42931\"\n\n\nnull\n\n\nnull\n\n\nnull\n\n\n\"LABELER\"\n\n\n\"Bionpharma Inc...\n\n\n\"C73584\"\n\n\nnull\n\n\nnull\n\n\nfalse\n\n\nnull\n\n\n6\n\n\nnull\n\n\nnull\n\n\ntrue\n\n\nfalse\n\n\nfalse\n\n\nfalse\n\n\n\n\n68841\n\n\ntrue\n\n\n\"06/27/2019 10:...\n\n\n\"10/02/2020 05:...\n\n\n\"7af82ca5-ea36-...\n\n\n\"7af82ca5-ea36-...\n\n\n16\n\n\nnull\n\n\n\"C48345\"\n\n\n\"OVAL\"\n\n\nnull\n\n\n1\n\n\nnull\n\n\n\"1007\"\n\n\nnull\n\n\n\"C48333\"\n\n\n\"BLUE\"\n\n\nnull\n\n\n\"IBUPROFEN 200 ...\n\n\n\"IBUPROFEN[IBUP...\n\n\n\"FD&C BLUE NO. ...\n\n\n\"HOTC\"\n\n\n\"SCD\"\n\n\n\"diphenhydramin...\n\n\n901814\n\n\n\"10/02/2020 03:...\n\n\n\"36800-756\"\n\n\n0\n\n\nnull\n\n\n368000756\n\n\n36800\n\n\n756\n\n\n\"Ibuprofen PM\"\n\n\n\"active\"\n\n\n20191014\n\n\n\"b181db0f-8b6a-...\n\n\nnull\n\n\n\"C42954\"\n\n\nnull\n\n\nnull\n\n\nnull\n\n\n\"LABELER\"\n\n\n\"TOP CARE (Topc...\n\n\n\"C73584\"\n\n\nnull\n\n\nnull\n\n\nfalse\n\n\nnull\n\n\n2\n\n\nnull\n\n\nnull\n\n\ntrue\n\n\nfalse\n\n\nfalse\n\n\nfalse\n\n\n\n\n7862\n\n\ntrue\n\n\n\"10/17/2017 05:...\n\n\n\"10/02/2020 05:...\n\n\n\"edc05451-822e-...\n\n\n\"edc05451-822e-...\n\n\n10\n\n\nnull\n\n\n\"C48345\"\n\n\n\"OVAL\"\n\n\nnull\n\n\n1\n\n\nnull\n\n\n\"4H2\"\n\n\nnull\n\n\n\"C48325\"\n\n\n\"WHITE\"\n\n\nnull\n\n\n\"CETIRIZINE HYD...\n\n\n\"CETIRIZINE HYD...\n\n\n\"STARCH, CORN;H...\n\n\n\"HOTC\"\n\n\nnull\n\n\nnull\n\n\nnull\n\n\n\"10/02/2020 03:...\n\n\n\"49738-600\"\n\n\n0\n\n\nnull\n\n\n497380600\n\n\n49738\n\n\n600\n\n\n\"smart sense al...\n\n\n\"active\"\n\n\n20160721\n\n\n\"9ceb8c88-c221-...\n\n\nnull\n\n\n\"C42998\"\n\n\nnull\n\n\nnull\n\n\nnull\n\n\n\"LABELER\"\n\n\n\"Kmart Corporat...\n\n\n\"C73584\"\n\n\nnull\n\n\nnull\n\n\nfalse\n\n\nnull\n\n\n3\n\n\nnull\n\n\nnull\n\n\ntrue\n\n\nfalse\n\n\nfalse\n\n\nfalse\n\n\n\n\n69440\n\n\ntrue\n\n\n\"06/27/2019 10:...\n\n\n\"10/02/2020 05:...\n\n\n\"facd5359-fc48-...\n\n\n\"facd5359-fc48-...\n\n\n12\n\n\nnull\n\n\n\"C48345\"\n\n\n\"OVAL\"\n\n\nnull\n\n\n1\n\n\nnull\n\n\n\"20\"\n\n\nnull\n\n\n\"C48332\"\n\n\n\"BROWN\"\n\n\nnull\n\n\n\"OMEPRAZOLE 20 ...\n\n\n\"OMEPRAZOLE[OME...\n\n\n\"CARNAUBA WAX;F...\n\n\n\"HOTC\"\n\n\n\"SCD\"\n\n\n\"omeprazole 20 ...\n\n\n402014\n\n\n\"10/02/2020 03:...\n\n\n\"70000-0356\"\n\n\n0\n\n\nnull\n\n\n700000356\n\n\n70000\n\n\n356\n\n\n\"leader omepraz...\n\n\n\"active\"\n\n\n20180316\n\n\n\"facd5359-fc48-...\n\n\nnull\n\n\n\"C42905\"\n\n\nnull\n\n\nnull\n\n\nnull\n\n\n\"LABELER\"\n\n\n\"Cardinal Healt...\n\n\n\"C73594\"\n\n\nnull\n\n\nnull\n\n\nfalse\n\n\nnull\n\n\n1\n\n\nnull\n\n\nnull\n\n\ntrue\n\n\nfalse\n\n\nfalse\n\n\nfalse\n\n\n\n\n53092\n\n\ntrue\n\n\n\"10/17/2017 09:...\n\n\n\"10/02/2020 05:...\n\n\n\"b46f11ca-bd09-...\n\n\n\"b46f11ca-bd09-...\n\n\n19\n\n\nnull\n\n\n\"C48348\"\n\n\n\"ROUND\"\n\n\nnull\n\n\n1\n\n\nnull\n\n\n\"L9Y7\"\n\n\nnull\n\n\n\"C48328;C48331;...\n\n\n\"PINK;ORANGE;YE...\n\n\nnull\n\n\n\"CALCIUM CARBON...\n\n\n\"CALCIUM CARBON...\n\n\n\"CITRIC ACID MO...\n\n\n\"HOTC\"\n\n\n\"SCD\"\n\n\n\"calcium carbon...\n\n\n308915\n\n\n\"10/02/2020 04:...\n\n\n\"41163-508\"\n\n\n0\n\n\nnull\n\n\n411630508\n\n\n41163\n\n\n508\n\n\n\"equaline antac...\n\n\n\"active\"\n\n\n20181210\n\n\n\"10041dc3-e9bf-...\n\n\nnull\n\n\n\"C42893\"\n\n\nnull\n\n\nnull\n\n\nnull\n\n\n\"LABELER\"\n\n\n\"Supervalu Inc\"\n\n\n\"C73603\"\n\n\nnull\n\n\nnull\n\n\nfalse\n\n\nnull\n\n\n2\n\n\nnull\n\n\nnull\n\n\ntrue\n\n\nfalse\n\n\nfalse\n\n\nfalse\n\n\n\n\n4956\n\n\ntrue\n\n\n\"10/17/2017 05:...\n\n\n\"10/02/2020 05:...\n\n\n\"f8f84be1-e3b1-...\n\n\n\"f8f84be1-e3b1-...\n\n\n19\n\n\nnull\n\n\n\"C48345\"\n\n\n\"OVAL\"\n\n\nnull\n\n\n1\n\n\nnull\n\n\n\"44;677\"\n\n\nnull\n\n\n\"C48329\"\n\n\n\"GREEN\"\n\n\nnull\n\n\n\"ACETAMINOPHEN ...\n\n\n\"ACETAMINOPHEN[...\n\n\n\"STARCH, CORN;D...\n\n\n\"HOTC\"\n\n\n\"SCD\"\n\n\n\"acetaminophen ...\n\n\n1546881\n\n\n\"10/02/2020 04:...\n\n\n\"41250-877\"\n\n\n0\n\n\nnull\n\n\n412500877\n\n\n41250\n\n\n877\n\n\n\"Nite time Seve...\n\n\n\"active\"\n\n\n20200513\n\n\n\"a4d9c4a9-8e8f-...\n\n\nnull\n\n\n\"C42931\"\n\n\nnull\n\n\nnull\n\n\nnull\n\n\n\"LABELER\"\n\n\n\"Meijer Distrib...\n\n\n\"C73603\"\n\n\nnull\n\n\nnull\n\n\nfalse\n\n\nnull\n\n\n8\n\n\nnull\n\n\nnull\n\n\ntrue\n\n\nfalse\n\n\nfalse\n\n\nfalse\n\n\n\n\n19029\n\n\ntrue\n\n\n\"10/17/2017 05:...\n\n\n\"10/02/2020 05:...\n\n\n\"254b2202-b14d-...\n\n\n\"254b2202-b14d-...\n\n\n19\n\n\nnull\n\n\n\"C48336\"\n\n\n\"CAPSULE\"\n\n\nnull\n\n\n1\n\n\nnull\n\n\n\"APO;10;40\"\n\n\nnull\n\n\n\"C48333\"\n\n\n\"BLUE\"\n\n\nnull\n\n\n\"Amlodipine bes...\n\n\n\"Amlodipine bes...\n\n\n\"Cellulose, mic...\n\n\n\"HRX\"\n\n\nnull\n\n\nnull\n\n\nnull\n\n\n\"10/02/2020 03:...\n\n\n\"60505-3226\"\n\n\n0\n\n\nnull\n\n\n605053226\n\n\n60505\n\n\n3226\n\n\n\"Amlodipine and...\n\n\n\"active\"\n\n\n20170818\n\n\n\"b332e90b-8d4a-...\n\n\nnull\n\n\n\"C25158\"\n\n\nnull\n\n\nnull\n\n\nnull\n\n\n\"LABELER\"\n\n\n\"Apotex Corp.\"\n\n\n\"C73584\"\n\n\nnull\n\n\nnull\n\n\nfalse\n\n\nnull\n\n\n6\n\n\nnull\n\n\nnull\n\n\ntrue\n\n\nfalse\n\n\nfalse\n\n\nfalse\n\n\n\n\n13396\n\n\ntrue\n\n\n\"10/17/2017 05:...\n\n\n\"10/17/2017 05:...\n\n\n\"cec47488-ebad-...\n\n\n\"cec47488-ebad-...\n\n\n8\n\n\nnull\n\n\n\"C48348\"\n\n\n\"ROUND\"\n\n\nnull\n\n\n1\n\n\nnull\n\n\n\"DF;15\"\n\n\nnull\n\n\n\"C48331\"\n\n\n\"ORANGE\"\n\n\nnull\n\n\n\"DARIFENACIN 15...\n\n\n\"DARIFENACIN[DA...\n\n\n\"ANHYDROUS DIBA...\n\n\n\"HRX\"\n\n\nnull\n\n\n\"24 HR darifena...\n\n\n543021\n\n\nnull\n\n\n\"35356-272\"\n\n\n0\n\n\nnull\n\n\n353560272\n\n\n35356\n\n\n272\n\n\n\"Enablex\"\n\n\n\"active\"\n\n\n20120305\n\n\n\"85782ed3-ab22-...\n\n\n\"0078-0420\"\n\n\n\"C42927\"\n\n\n\"34391-3\"\n\n\nnull\n\n\nnull\n\n\n\"LABELER\"\n\n\n\"Lake Erie Medi...\n\n\n\"C73594\"\n\n\nnull\n\n\nnull\n\n\nfalse\n\n\n1\n\n\n3613\n\n\nnull\n\n\nnull\n\n\nfalse\n\n\ntrue\n\n\nfalse\n\n\nfalse\n\n\n\n\n\n\n\nWhen importing pillbox.csv file initially, an error message actually came up that showed, “…Could not parse ‘10.16’ as dtype Int64 at column 7…”. One way to get around this was to add “ignore_errors” to bypass this error first in order to load the dataset first. This error could be fixed when checking and converting data types for columns.\n\n\n\nInitial data wrangling\nThe Pillbox dataset link from NLM provided a list of column information for users. To quickly see what were the columns in the dataset, we could use “df.glimpse()” to read column names, data types and the first 10 items in each column.\n\nprint(df.glimpse())\n\nRows: 83925\nColumns: 55\n$ ID                   <Int64> 41846, 8100, 5258, 21271, 77050, 76916, 20016, 67902, 75997, 1288        \n$ Enabled?           <Boolean> True, True, True, True, True, True, True, True, True, True               \n$ created at            <Utf8> 10/17/2017 05:32:23 PM, 10/17/2017 05:29:56 PM, 10/17/2017 05:29:44 PM, 10/17/2017 05:30:52 PM, 09/20/2019 09:10:47 PM, 09/20/2019 09:10:41 PM, 10/17/2017 05:30:47 PM, 06/27/2019 10:45:17 PM, 09/20/2019 09:09:57 PM, 10/17/2017 05:29:25 PM\n$ updated at            <Utf8> 10/02/2020 05:14:07 PM, 10/02/2020 04:59:28 PM, 10/17/2017 05:29:44 PM, 10/02/2020 05:10:28 PM, 10/02/2020 05:14:51 PM, 10/02/2020 05:15:50 PM, 10/02/2020 05:12:38 PM, 10/02/2020 05:04:25 PM, 10/02/2020 05:12:06 PM, 10/17/2017 05:29:25 PM\n$ spp                   <Utf8> 471fa2f1-73a0-49be-89f3-d3e2cfdaeca0-0603-5892-0, 116e13c1-ac50-400f-880f-5779f0155b96-59779-074-0, 827ce261-307b-4398-8993-333c08e601fe-49884-129-0, f7f1c99e-1a67-4b34-b1f4-0ac38b9d8006-61480-137-0, ecb28fcb-f0d1-4558-b460-ecabd0f6009e-62332-365-0, 442e41da-24c2-412f-be6b-d549692943fd-70748-132-0, 5f0bdf9d-fa78-45e8-913a-81beff57cf34-65862-123-0, 572e672e-b759-4db1-9e8f-279b1f6f3c51-50804-750-0, 6f17cc91-86b3-42e3-9bf2-935dd360c3eb-51672-4184-0, 02a23e48-f371-448b-92b2-e2d010be1886-54288-129-0\n$ setid                 <Utf8> 471fa2f1-73a0-49be-89f3-d3e2cfdaeca0, 116e13c1-ac50-400f-880f-5779f0155b96, 827ce261-307b-4398-8993-333c08e601fe, f7f1c99e-1a67-4b34-b1f4-0ac38b9d8006, ecb28fcb-f0d1-4558-b460-ecabd0f6009e, 442e41da-24c2-412f-be6b-d549692943fd, 5f0bdf9d-fa78-45e8-913a-81beff57cf34, 572e672e-b759-4db1-9e8f-279b1f6f3c51, 6f17cc91-86b3-42e3-9bf2-935dd360c3eb, 02a23e48-f371-448b-92b2-e2d010be1886\n$ splsize              <Int64> 16, 10, 7, 11, 6, 9, 14, 19, 12, 23                                      \n$ pillbox_size          <Utf8> None, None, None, None, None, None, None, None, None, None               \n$ splshape              <Utf8> C48336, C48348, C48346, C48348, C48348, C48348, C48345, C48336, C48348, C48336\n$ splshape_text         <Utf8> CAPSULE, ROUND, PENTAGON (5 SIDED), ROUND, ROUND, ROUND, OVAL, CAPSULE, ROUND, CAPSULE\n$ pillbox_shape_text    <Utf8> None, None, None, None, None, None, None, None, None, None               \n$ splscore             <Int64> 1, 1, 1, 2, 1, 1, 1, 1, 1, 1                                             \n$ pillbox_score        <Int64> None, None, 2, None, None, None, None, None, None, None                  \n$ splimprint            <Utf8> 5892;V, I2, par;129, LL, L;524, LU;V06, A;73, AT146, T;12, RX681         \n$ pillbox_imprint       <Utf8> None, None, None, None, None, None, None, None, None, None               \n$ splcolor              <Utf8> C48328, C48331, C48329, C48325, C48325, C48325, C48330, C48333, C48325, C48330;C48325\n$ splcolor_text         <Utf8> PINK, ORANGE, GREEN, WHITE, WHITE, WHITE, YELLOW, BLUE, WHITE, YELLOW;WHITE\n$ pillbox_color_text    <Utf8> None, None, None, None, None, None, None, None, None, None               \n$ spl_strength          <Utf8> TEMAZEPAM 15 mg;, IBUPROFEN 200 mg;, DEXAMETHASONE 6 mg;, Nickel Sulfate 1 [hp_X];Potassium Bromide 1 [hp_X];Sodium Bromide 1 [hp_X];Zinc Sulfate Anhydrous 1 [hp_X];Sulfur 1 [hp_X];, CLONAZEPAM 0.25 mg;, SILDENAFIL CITRATE 50 mg;, RISPERIDONE 3 mg;, IBUPROFEN 200 mg;, Iloperidone 12 mg;, FENOPROFEN CALCIUM 200 mg;\n$ spl_ingredients       <Utf8> TEMAZEPAM[TEMAZEPAM];, IBUPROFEN[IBUPROFEN];, DEXAMETHASONE[DEXAMETHASONE];, Nickel Sulfate[NICKEL CATION];Potassium Bromide[BROMIDE ION];Sodium Bromide[BROMIDE ION];Zinc Sulfate Anhydrous[ZINC CATION];Sulfur[Sulfur];, CLONAZEPAM[CLONAZEPAM];, SILDENAFIL CITRATE[SILDENAFIL];, RISPERIDONE[RISPERIDONE];, IBUPROFEN[IBUPROFEN];, Iloperidone[Iloperidone];, FENOPROFEN CALCIUM[FENOPROFEN];\n$ spl_inactive_ing      <Utf8> SILICON DIOXIDE;EDETATE DISODIUM;LACTOSE MONOHYDRATE;MAGNESIUM STEARATE;CELLULOSE, MICROCRYSTALLINE;STARCH, CORN;SODIUM LAURYL SULFATE;FD&C BLUE NO. 1;FD&C RED NO. 40;GELATIN;TITANIUM DIOXIDE;BUTYL ALCOHOL;, SILICON DIOXIDE;STARCH, CORN;CROSCARMELLOSE SODIUM;FD&C RED NO. 40;FD&C YELLOW NO. 6;FERRIC OXIDE RED;MICROCRYSTALLINE CELLULOSE;POLYETHYLENE GLYCOL, UNSPECIFIED;POLYVINYL ALCOHOL, UNSPECIFIED;STEARIC ACID;TALC;TITANIUM DIOXIDE;, ANHYDROUS LACTOSE;CELLULOSE, MICROCRYSTALLINE;CROSCARMELLOSE SODIUM;STEARIC ACID;MAGNESIUM STEARATE;FD&C BLUE NO. 1;D&C YELLOW NO. 10;FD&C YELLOW NO. 6;, None, SORBITOL;ASPARTAME;SODIUM LAURYL SULFATE;CROSPOVIDONE;MANNITOL;SILICON DIOXIDE;TALC;MAGNESIUM STEARATE;, ANHYDROUS DIBASIC CALCIUM PHOSPHATE;CELLULOSE, MICROCRYSTALLINE;CROSCARMELLOSE SODIUM;HYPROMELLOSE 2910 (6 MPA.S);MAGNESIUM STEARATE;POLYETHYLENE GLYCOL 400;SILICON DIOXIDE;TITANIUM DIOXIDE;, LACTOSE MONOHYDRATE;MICROCRYSTALLINE CELLULOSE;SILICON DIOXIDE;MAGNESIUM STEARATE;HYPROMELLOSE 2910 (6 MPA.S);TITANIUM DIOXIDE;POLYETHYLENE GLYCOL 400;D&C YELLOW NO. 10;, FD&C BLUE NO. 1;GELATIN;POLYETHYLENE GLYCOL, UNSPECIFIED;POTASSIUM HYDROXIDE;WATER;SORBITOL;SORBITAN;MEDIUM-CHAIN TRIGLYCERIDES;FD&C YELLOW NO. 6;LECITHIN, SOYBEAN;, silicon dioxide;crospovidone (15 MPA.S AT 5%);hypromellose, unspecified;lactose monohydrate;magnesium stearate;microcrystalline cellulose;water;, CROSPOVIDONE;MAGNESIUM STEARATE;SODIUM LAURYL SULFATE;TALC;GELATIN;TITANIUM DIOXIDE;BROWN IRON OXIDE;\n$ source                <Utf8> HRX, HOTC, HRX, HOMEO, HRX, HRX, HRX, HOTC, HRX, HRX                     \n$ rxtty                 <Utf8> None, SCD, None, None, SCD, SCD, SCD, SCD, SCD, None                     \n$ rxstring              <Utf8> None, ibuprofen 200 MG Oral Tablet, Dexamethasone 6 MG Oral Tablet, None, clonazepam 0.25 MG Disintegrating Oral Tablet, sildenafil 50 MG Oral Tablet, risperidone 3 MG Oral Tablet, ibuprofen 200 MG Oral Capsule, iloperidone 12 MG Oral Tablet, Fenoprofen 200 MG Oral Capsule [Fenortho]\n$ rxcui                <Int64> None, 310965, 197583, None, 349195, 312950, 312832, 310964, 848732, 1799325\n$ RxNorm Update time    <Utf8> 10/02/2020 04:21:55 PM, 10/02/2020 03:07:40 PM, None, 10/02/2020 04:01:35 PM, 10/02/2020 04:25:40 PM, 10/02/2020 04:30:41 PM, 10/02/2020 04:13:39 PM, 10/02/2020 03:30:07 PM, 10/02/2020 04:10:33 PM, None\n$ product_code          <Utf8> 0603-5892, 59779-074, 49884-129, 61480-137, 62332-365, 70748-132, 65862-123, 50804-750, 51672-4184, 54288-129\n$ part_num             <Int64> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0                                             \n$ part_medicine_name    <Utf8> None, None, None, None, None, None, None, None, None, None               \n$ ndc9                 <Int64> 6035892, 597790074, 498840129, 614800137, 623320365, 707480132, 658620123, 508040750, 516724184, 542880129\n$ ndc_labeler_code     <Int64> 603, 59779, 49884, 61480, 62332, 70748, 65862, 50804, 51672, 54288       \n$ ndc_product_code     <Int64> 5892, 74, 129, 137, 365, 132, 123, 750, 4184, 129                        \n$ medicine_name         <Utf8> Temazepam, ibuprofen, Dexamethasone, Acunol, CLONAZEPAM, SILDENAFIL, Risperidone, Ibuprofen, Iloperidone, FENORTHO\n$ marketing_act_code    <Utf8> completed, active, active, active, active, active, active, active, active, active\n$ effective_time       <Int64> 20160406, 20191120, 20120516, 20190909, 20190701, 20191001, 20180924, 20191101, 20190802, 20160614\n$ file_name             <Utf8> d912ca54-6569-4e58-a8ef-620eddd03163.xml, 55de9f94-89b2-4bfb-a41d-6660ba6e7a6d.xml, 85a9eebb-be74-43a1-a36f-26ae4c4131aa.xml, 029eaf64-e66f-447e-9ac3-037620370f85.xml, ba5120ce-ed74-40be-936d-c172805d88d1.xml, 17c537d9-b2e6-4d71-a481-c7c7cafdb3a2.xml, 5d2750a4-025a-40a1-97d2-d9447a37afbb.xml, 148c7665-22d5-494c-9add-98428435f392.xml, 6787555e-8a11-481c-b05c-179b0aedcf5c.xml, 91b0ac5b-994c-468f-9331-542b8f92f9a8.xml\n$ equal_product_code    <Utf8> None, None, None, None, None, None, None, None, None, None               \n$ dosage_form           <Utf8> C25158, C42931, C42998, C42998, C42999, C42931, C42931, C42954, C42998, C25158\n$ document_type         <Utf8> None, 34390-5, 34391-3, 34391-3, None, None, 34391-3, None, None, None   \n$ dea_schedule_code     <Utf8> C48677, None, None, None, C48677, None, None, None, None, None           \n$ dea_schedule_name     <Utf8> CIV, None, None, None, CIV, None, None, None, None, None                 \n$ author_type           <Utf8> LABELER, LABELER, LABELER, LABELER, LABELER, LABELER, LABELER, LABELER, LABELER, LABELER\n$ author                <Utf8> Qualitest Pharmaceuticals, CVS Pharmacy, Par Pharmaceutical Inc., PLYMOUTH HEALTHCARE PRODUCTS LLC, Alembic Pharmaceuticals Inc., Lupin Pharmaceuticals, Inc., Aurobindo Pharma Limited, Good Sense (Geiss, Destin & Dunn, Inc.), Taro Pharmaceuticals U.S.A., Inc., BPI Labs LLC\n$ approval_code         <Utf8> C73584, C73584, C73584, C73614, C73584, C73584, C73584, C73584, C73584, C73594\n$ image_source          <Utf8> None, None, NLM, None, None, None, None, None, None, None                \n$ splimage              <Utf8> None, None, 498840129, None, None, None, None, None, None, None          \n$ has_image          <Boolean> False, False, True, False, False, False, False, False, False, False      \n$ epc_match            <Int64> None, None, None, None, None, None, None, None, None, None               \n$ version_number       <Int64> 5, 4, 4, 8, 3, 4, 21, 2, 1, 2                                            \n$ laberer_code          <Utf8> None, None, None, None, None, None, None, None, None, None               \n$ application_number    <Utf8> None, None, None, None, None, None, None, None, None, None               \n$ updated            <Boolean> True, True, False, True, True, True, True, True, True, False             \n$ stale              <Boolean> False, False, True, False, False, False, False, False, False, True       \n$ new                <Boolean> False, False, False, False, False, False, False, False, False, False     \n$ Pillbox Value      <Boolean> False, False, True, False, False, False, False, False, False, False      \n\n\n\nA relatively simple dataset would be extracted first for these pills data since I was an inexperienced user of Rust. Therefore, I’ve selected only certain columns for this purpose.\n\ndf_med = df.select([# shapes of medicines\n                    \"splshape_text\", \n                    # colours of medicines\n                    \"splcolor_text\",\n                    # strengths of medicines\n                    \"spl_strength\", \n                    # inactive ingredients/excipients in medicines  \n                    \"spl_inactive_ing\",\n                    # dosage forms of medicines e.g. capsules or tablets etc.\n                    \"dosage_form\"]\n                  )\ndf_med\n\n\n\n\nshape: (83925, 5)\n\n\n\n\nsplshape_text\n\n\nsplcolor_text\n\n\nspl_strength\n\n\nspl_inactive_ing\n\n\ndosage_form\n\n\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\n\n\n\n\n\"CAPSULE\"\n\n\n\"PINK\"\n\n\n\"TEMAZEPAM 15 m...\n\n\n\"SILICON DIOXID...\n\n\n\"C25158\"\n\n\n\n\n\"ROUND\"\n\n\n\"ORANGE\"\n\n\n\"IBUPROFEN 200 ...\n\n\n\"SILICON DIOXID...\n\n\n\"C42931\"\n\n\n\n\n\"PENTAGON (5 SI...\n\n\n\"GREEN\"\n\n\n\"DEXAMETHASONE ...\n\n\n\"ANHYDROUS LACT...\n\n\n\"C42998\"\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"Nickel Sulfate...\n\n\nnull\n\n\n\"C42998\"\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"CLONAZEPAM 0.2...\n\n\n\"SORBITOL;ASPAR...\n\n\n\"C42999\"\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"SILDENAFIL CIT...\n\n\n\"ANHYDROUS DIBA...\n\n\n\"C42931\"\n\n\n\n\n\"OVAL\"\n\n\n\"YELLOW\"\n\n\n\"RISPERIDONE 3 ...\n\n\n\"LACTOSE MONOHY...\n\n\n\"C42931\"\n\n\n\n\n\"CAPSULE\"\n\n\n\"BLUE\"\n\n\n\"IBUPROFEN 200 ...\n\n\n\"FD&C BLUE NO. ...\n\n\n\"C42954\"\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"Iloperidone 12...\n\n\n\"silicon dioxid...\n\n\n\"C42998\"\n\n\n\n\n\"CAPSULE\"\n\n\n\"YELLOW;WHITE\"\n\n\n\"FENOPROFEN CAL...\n\n\n\"CROSPOVIDONE;M...\n\n\n\"C25158\"\n\n\n\n\n\"ROUND\"\n\n\n\"YELLOW\"\n\n\n\"BUTALBITAL 50 ...\n\n\n\"STARCH, CORN;C...\n\n\n\"C42998\"\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"ESTRADIOL 0.5 ...\n\n\n\"COPOVIDONE K25...\n\n\n\"C42998\"\n\n\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"MEMANTINE HYDR...\n\n\n\"SILICON DIOXID...\n\n\n\"C42998\"\n\n\n\n\n\"CAPSULE\"\n\n\n\"ORANGE\"\n\n\n\"ACETAMINOPHEN ...\n\n\n\"BUTYLATED HYDR...\n\n\n\"C42954\"\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"LAMOTRIGINE 25...\n\n\n\"MAGNESIUM CARB...\n\n\n\"C42893\"\n\n\n\n\n\"OVAL\"\n\n\n\"BLUE\"\n\n\n\"ACETAMINOPHEN ...\n\n\n\"ACESULFAME POT...\n\n\n\"C42897\"\n\n\n\n\n\"OVAL\"\n\n\n\"WHITE\"\n\n\n\"AZITHROMYCIN D...\n\n\n\"CROSCARMELLOSE...\n\n\n\"C42931\"\n\n\n\n\n\"OVAL\"\n\n\n\"BLUE\"\n\n\n\"IBUPROFEN 200 ...\n\n\n\"FD&C BLUE NO. ...\n\n\n\"C42954\"\n\n\n\n\n\"OVAL\"\n\n\n\"WHITE\"\n\n\n\"CETIRIZINE HYD...\n\n\n\"STARCH, CORN;H...\n\n\n\"C42998\"\n\n\n\n\n\"OVAL\"\n\n\n\"BROWN\"\n\n\n\"OMEPRAZOLE 20 ...\n\n\n\"CARNAUBA WAX;F...\n\n\n\"C42905\"\n\n\n\n\n\"ROUND\"\n\n\n\"PINK;ORANGE;YE...\n\n\n\"CALCIUM CARBON...\n\n\n\"CITRIC ACID MO...\n\n\n\"C42893\"\n\n\n\n\n\"OVAL\"\n\n\n\"GREEN\"\n\n\n\"ACETAMINOPHEN ...\n\n\n\"STARCH, CORN;D...\n\n\n\"C42931\"\n\n\n\n\n\"CAPSULE\"\n\n\n\"BLUE\"\n\n\n\"Amlodipine bes...\n\n\n\"Cellulose, mic...\n\n\n\"C25158\"\n\n\n\n\n\"ROUND\"\n\n\n\"ORANGE\"\n\n\n\"DARIFENACIN 15...\n\n\n\"ANHYDROUS DIBA...\n\n\n\"C42927\"\n\n\n\n\n\n\n\n\n\n\n\nPhoto by Hans-Peter Gauster on Unsplash\n\n\n\n\nWeb scraping\nThis was not planned initially but this might make my life a lot easier if I could scrape the dosage form table found through the Pillbox link, since the dosage form column was full of C-letter code. These dosage form code were hard to understand, so once I’ve got the code along with corresponding dosage forms in texts, the web-scraped information would be converted into a dataframe for further data manipulations.\n\n# Uncomment lines below to install libraries needed for web-scraping\n#!pip install requests\n#!pip install beautifulsoup4\n\n\nImport libraries\n\nimport requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\n\nI’ve opted for using Beautiful Soup as the web-scraping library in Python, along with the requests library to be able to make a URL request call to retrieve web information. There were of course many other tools available as well. A caveat to be taken into consideration was that when web-scraping, it was always recommended to check whether the information being scraped were under a specific copyright license and so on. In this case, I’ve checked that the dosage form table link - https://www.fda.gov/industry/structured-product-labeling-resources/dosage-forms was from US FDA and it was stated that the information (both texts and graphs) were not copyrighted (unless otherwise stated, for this particular web page, there was nothing stated along those lines), but a link to this webpage should be provided so that readers could access most current information in the future.\n\n\nSend web requests\n\n# Specify URL address with information intended for web-scraping\nurl = \"https://www.fda.gov/industry/structured-product-labeling-resources/dosage-forms\"\n# Request the web information via requests library & save under a data object\ndata = requests.get(url)\n\n\n\nParse web content\n\n# Parse the web content from the URL link by using Beautiful Soup\nsoup = BeautifulSoup(data.content, \"html.parser\")\n\n\n\nPrint web content\n\n# Print out the scraped web information\nprint(soup.prettify())\n\n<!DOCTYPE html>\n<html dir=\"ltr\" lang=\"en\" prefix=\"content: http://purl.org/rss/1.0/modules/content/  dc: http://purl.org/dc/terms/  foaf: http://xmlns.com/foaf/0.1/  og: http://ogp.me/ns#  rdfs: http://www.w3.org/2000/01/rdf-schema#  schema: http://schema.org/  sioc: http://rdfs.org/sioc/ns#  sioct: http://rdfs.org/sioc/types#  skos: http://www.w3.org/2004/02/skos/core#  xsd: http://www.w3.org/2001/XMLSchema# \">\n <head>\n  <meta charset=\"utf-8\"/>\n  <script async=\"\" src=\"https://www.googletagmanager.com/gtag/js?id=UA-22737364-1\">\n  </script>\n  <meta content=\"This web page has a list of dosage form terms and National Cancer Institute Thesaurus concept codes associated with those term for use in Structured Product Labeling (SPL) documents submitted to FDA.\" name=\"description\"/>\n  <meta content=\"Dosage Forms\" name=\"dcterms.title\"/>\n  <meta content=\"Office of the Commissioner\" name=\"dcterms.creator\"/>\n  <meta content=\"This web page has a list of dosage form terms and National Cancer Institute Thesaurus concept codes associated with those term for use in Structured Product Labeling (SPL) documents submitted to FDA.\" name=\"dcterms.description\"/>\n  <meta content=\"FDA\" name=\"dcterms.publisher\"/>\n  <meta content=\"DO NOT USE - Office of Health Informatics\" name=\"dcterms.contributor\"/>\n  <meta content=\"Article\" name=\"dcterms.type\"/>\n  <meta content=\"FDA\" name=\"dcterms.source\"/>\n  <meta content=\"Manufacturers\" name=\"dcterms.audience\"/>\n  <meta content=\"U.S. Food and Drug Administration\" property=\"og:site_name\"/>\n  <meta content=\"Article\" property=\"og:type\"/>\n  <meta content=\"https://www.fda.gov/industry/structured-product-labeling-resources/dosage-forms\" property=\"og:url\"/>\n  <meta content=\"Dosage Forms\" property=\"og:title\"/>\n  <meta content=\"Thu, 02/03/2022 - 10:05\" property=\"og:updated_time\"/>\n  <meta content=\"FDA\" property=\"article:publisher\"/>\n  <meta content=\"Thu, 02/03/2022 - 09:02\" property=\"article:published_time\"/>\n  <meta content=\"Thu, 02/03/2022 - 10:05\" property=\"article:modified_time\"/>\n  <meta content=\"tWxlDhm4ANdksJZPj7TBmHgNoMqZCnecPp0Aa2vC9XA\" name=\"google-site-verification\"/>\n  <meta content=\"summary_large_image\" name=\"twitter:card\"/>\n  <meta content=\"@US_FDA\" name=\"twitter:site\"/>\n  <meta content=\"Dosage Forms\" name=\"twitter:title\"/>\n  <meta content=\"@US_FDA\" name=\"twitter:creator\"/>\n  <meta content=\"width\" name=\"MobileOptimized\"/>\n  <meta content=\"true\" name=\"HandheldFriendly\"/>\n  <meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n  <script type=\"application/ld+json\">\n   {\n    \"@context\": \"https://schema.org\",\n    \"@graph\": [\n        {\n            \"@type\": \"Article\",\n            \"headline\": \"Dosage Forms\",\n            \"name\": \"Dosage Forms\",\n            \"description\": \"This web page has a list of dosage form terms and National Cancer Institute Thesaurus concept codes associated with those term for use in Structured Product Labeling (SPL) documents submitted to FDA.\",\n            \"image\": {\n                \"@type\": \"ImageObject\",\n                \"representativeOfPage\": \"True\"\n            },\n            \"datePublished\": \"\\u003Ctime datetime=\\u00222022-02-03T09:02:47Z\\u0022\\u003EThu, 02/03/2022 - 09:02\\u003C/time\\u003E\",\n            \"dateModified\": \"\\u003Ctime datetime=\\u00222022-02-03T10:05:00Z\\u0022\\u003EThu, 02/03/2022 - 10:05\\u003C/time\\u003E\",\n            \"author\": {\n                \"@type\": \"Organization\",\n                \"name\": \"\\u003Ca href=\\u0022/taxonomy/term/819\\u0022 hreflang=\\u0022en\\u0022\\u003EOffice of the Commissioner\\u003C/a\\u003E\"\n            },\n            \"publisher\": {\n                \"@type\": \"Organization\",\n                \"name\": \"FDA\"\n            }\n        },\n        {\n            \"@type\": \"WebSite\"\n        }\n    ]\n}\n  </script>\n  <meta content=\"https://www.fda.gov/themes/custom/preview/img/FDA-Social-Graphic.png\" property=\"og:image\"/>\n  <meta content=\"https://www.fda.gov/themes/custom/preview/img/FDA-Social-Graphic.png\" name=\"twitter:image\"/>\n  <meta content=\"This web page has a list of dosage form terms and National Cancer Institute Thesaurus concept codes associated with those term for use in Structured Product Labeling (SPL) documents submitted to FDA.\" property=\"og:description\"/>\n  <meta content=\"This web page has a list of dosage form terms and National Cancer Institute Thesaurus concept codes associated with those term for use in Structured Product Labeling (SPL) documents submitted to FDA.\" property=\"twitter:description\"/>\n  <link href=\"/themes/custom/preview/favicon.ico\" rel=\"icon\" type=\"image/vnd.microsoft.icon\"/>\n  <link href=\"https://www.fda.gov/industry/structured-product-labeling-resources/dosage-forms\" hreflang=\"en\" rel=\"alternate\"/>\n  <link href=\"https://www.fda.gov/industry/structured-product-labeling-resources/dosage-forms\" rel=\"canonical\"/>\n  <link href=\"https://www.fda.gov/node/358928\" rel=\"shortlink\"/>\n  <script defer=\"\" src=\"/files/google_tag/production/google_tag.script.js?rt10fa\">\n  </script>\n  <title>\n   Dosage Forms | FDA\n  </title>\n  <link href=\"/files/css/css_VQK8mppKquBsweKvwlYQE65XHMoWqDIaAS_w8yNPtaw.css\" media=\"all\" rel=\"stylesheet\"/>\n  <link href=\"/files/css/css_wZl-oUwtZViT4j1MoWRni-RbKGdqgfm_QYwF8I2qvkA.css\" media=\"all\" rel=\"stylesheet\"/>\n  <script async=\"\" src=\"https://script.crazyegg.com/pages/scripts/0024/3700.js\">\n  </script>\n  <script id=\"_fed_an_ua_tag\" language=\"javascript\" src=\"https://dap.digitalgov.gov/Universal-Federated-Analytics-Min.js?agency=HHS&amp;subagency=FDA&amp;sdor=fda.gov&amp;dclink=true\">\n  </script>\n  <script>\n   window.dataLayer = window.dataLayer || [];function gtag(){dataLayer.push(arguments)};gtag(\"js\", new Date());gtag(\"config\", \"UA-22737364-1\", {\"groups\":\"default\",\"anonymize_ip\":true,\"allow_ad_personalization_signals\":false});\n  </script>\n </head>\n <body class=\"role-anonymous path-node page-node-type-article has-glyphicons\">\n  <div class=\"sr-only\" id=\"quicklinks\">\n   <ul>\n    <li>\n     <a class=\"sr-only sr-only-focusable\" href=\"#main-content\" tabindex=\"1\">\n      Skip to main content\n     </a>\n    </li>\n    <li>\n     <a class=\"sr-only sr-only-focusable\" href=\"#search-form\" tabindex=\"1\">\n      Skip to FDA Search\n     </a>\n    </li>\n    <li>\n     <a class=\"sr-only sr-only-focusable\" href=\"#section-nav\" tabindex=\"1\">\n      Skip to in this section menu\n     </a>\n    </li>\n    <li>\n     <a class=\"sr-only sr-only-focusable\" href=\"#footer-heading\" tabindex=\"1\">\n      Skip to footer links\n     </a>\n    </li>\n   </ul>\n  </div>\n  <noscript aria-hidden=\"true\">\n   <iframe height=\"0\" src=\"https://www.googletagmanager.com/ns.html?id=GTM-M95XGZW\" style=\"display:none;visibility:hidden\" width=\"0\">\n   </iframe>\n  </noscript>\n  <div class=\"dialog-off-canvas-main-canvas\" data-off-canvas-main-canvas=\"\">\n   <div class=\"main-container container-fluid\">\n    <div class=\"row\">\n     <header class=\"lcds-header container-fluid\" role=\"header\">\n      <div class=\"row us-masthead\">\n       <div class=\"usa-banner col-xs-12\">\n        <img alt=\"U.S. flag\" class=\"usa-banner__us-flag\" src=\"/themes/custom/preview/assets/images/US_Flag.png\"/>\n        <span>\n         An official website of the United States government\n        </span>\n        <a aria-controls=\"USABannerMenu\" aria-expanded=\"false\" class=\"collapsed\" data-target=\"#USABannerMenu\" data-toggle=\"collapse\" id=\"USMenuButton\">\n         Here’s how you know\n         <span class=\"toggle-indicator\">\n         </span>\n        </a>\n        <div aria-labelledby=\"USMenuButton\" class=\"col-xs-12 collapse usa-banner__menu\" id=\"USABannerMenu\">\n         <div aria-hidden=\"true\" class=\"row usa-banner-content usa-grid usa-accordion-content\" id=\"gov-banner\">\n          <div class=\"col-xs-12 col-sm-6 col-md-3\">\n           <img alt=\"Dot gov\" class=\"usa-banner-icon usa-media_block-img\" src=\"/themes/custom/preview/assets/images/icon-dot-gov.svg\" style=\"width:3em;\"/>\n           <div class=\"usa-media_block-body\">\n            <p>\n             <strong>\n              The .gov means it’s official.\n             </strong>\n             <br/>\n             Federal government websites often end in .gov or .mil. Before sharing sensitive information, make sure you're on a federal government site.\n            </p>\n           </div>\n          </div>\n          <div class=\"col-xs-12 col-sm-6 col-md-3\">\n           <img alt=\"SSL\" class=\"usa-banner-icon usa-media_block-img\" src=\"/themes/custom/preview/assets/images/icon-https.svg\" style=\"width:3em;\"/>\n           <div class=\"usa-media_block-body\">\n            <p>\n             <strong>\n              The site is secure.\n             </strong>\n             <br/>\n             The\n             <strong>\n              https://\n             </strong>\n             ensures that you are connecting to the official website and that any information you provide is encrypted and transmitted securely.\n            </p>\n           </div>\n          </div>\n         </div>\n        </div>\n       </div>\n      </div>\n      <div class=\"row fda-masthead\">\n       <div class=\"col-xs-4 col-md-8\">\n        <a href=\"/\" title=\"FDA Homepage\">\n         <h1 class=\"fda-masthead__fda-logo\">\n          U.S. Food and Drug Administration\n         </h1>\n        </a>\n       </div>\n       <div class=\"col-xs-8 col-md-4\">\n        <ul class=\"fda-masthead__item-list\">\n         <li>\n          <a class=\"btn btn-default btn-sm fda-masthead__btn-search\" id=\"btn-search\" title=\"\">\n           <span aria-hidden=\"true\" class=\"fa fa-search\">\n           </span>\n           <span class=\"fda-masthead__btn-label\">\n            Search\n           </span>\n          </a>\n         </li>\n         <li>\n          <a aria-expanded=\"true\" class=\"btn btn-default btn-sm fda-masthead__btn-menu collapsed\" data-toggle=\"collapse\" href=\"#primary-nav\" id=\"menu-btn\">\n           <span aria-hidden=\"true\" class=\"fa fa-bars\">\n           </span>\n           <span class=\"fda-masthead__btn-label\">\n            Menu\n           </span>\n          </a>\n         </li>\n        </ul>\n       </div>\n       <form accept-charset=\"UTF-8\" action=\"/search\" class=\"fda-masthead__search sr-only\" id=\"search-form\" method=\"GET\" name=\"searchForm\" role=\"search\">\n        <div class=\"search-popover\" id=\"search-popover\">\n         <div class=\"input-group pull-right\" id=\"search-group\">\n          <label class=\"sr-only\" for=\"search-query\">\n           Search FDA\n          </label>\n          <input aria-autocomplete=\"list\" aria-haspopup=\"true\" class=\"form-control search-input\" id=\"search-query\" name=\"s\" placeholder=\"Search FDA\" title=\"Enter the terms you wish to search for.\" type=\"text\"/>\n          <span class=\"input-group-btn\" id=\"input-group-btn\">\n           <button class=\"btn btn-danger search-btn\" id=\"search-btn\" title=\"Search\" type=\"submit\">\n            <span aria-hidden=\"true\" class=\"fa fa-search\">\n             <span class=\"sr-only\">\n              Submit search\n             </span>\n            </span>\n           </button>\n          </span>\n         </div>\n        </div>\n       </form>\n      </div>\n      <nav class=\"lcds-primary-nav row collapse\" id=\"primary-nav\">\n       <div class=\"col-md-5 col-lg-4\">\n        <section class=\"lcds-primary-nav__group lcds-primary-nav__group--bordered\">\n         <h2 class=\"lcds-primary-nav__group-heading\">\n          Featured\n         </h2>\n         <ul class=\"lcds-primary-nav__list lcds-primary-nav__list--featured\">\n          <li class=\"lcds-primary-nav__list-item\">\n           <a href=\"/about-fda/contact-fda\">\n            Contact FDA\n           </a>\n          </li>\n          <li class=\"lcds-primary-nav__list-item\">\n           <a href=\"/regulatory-information/search-fda-guidance-documents\">\n            FDA Guidance Documents\n           </a>\n          </li>\n          <li class=\"lcds-primary-nav__list-item\">\n           <a href=\"/safety/recalls-market-withdrawals-safety-alerts\">\n            Recalls, Market Withdrawals and Safety Alerts\n           </a>\n          </li>\n          <li class=\"lcds-primary-nav__list-item\">\n           <a href=\"/news-events/newsroom/press-announcements\">\n            Press Announcements\n           </a>\n          </li>\n          <li class=\"lcds-primary-nav__list-item\">\n           <a href=\"/inspections-compliance-enforcement-and-criminal-investigations/compliance-actions-and-activities/warning-letters\">\n            Warning Letters\n           </a>\n          </li>\n          <li class=\"lcds-primary-nav__list-item\">\n           <a href=\"/advisory-committees\">\n            Advisory Committees\n           </a>\n          </li>\n          <li class=\"lcds-primary-nav__list-item\">\n           <a href=\"/about-fda/en-espanol\">\n            En Español\n           </a>\n          </li>\n         </ul>\n        </section>\n       </div>\n       <div class=\"col-md-7 col-lg-8\">\n        <section class=\"lcds-primary-nav__group lcds-primary-nav__group--bordered\">\n         <h2 class=\"lcds-primary-nav__group-heading\">\n          Products\n         </h2>\n         <ul class=\"lcds-primary-nav__list\">\n          <li class=\"lcds-primary-nav__list-item\">\n           <a href=\"/food\">\n            Food\n           </a>\n          </li>\n          <li class=\"lcds-primary-nav__list-item\">\n           <a href=\"/drugs\">\n            Drugs\n           </a>\n          </li>\n          <li class=\"lcds-primary-nav__list-item\">\n           <a href=\"/medical-devices\">\n            Medical Devices\n           </a>\n          </li>\n          <li class=\"lcds-primary-nav__list-item\">\n           <a href=\"/radiation-emitting-products\">\n            Radiation-Emitting Products\n           </a>\n          </li>\n          <li class=\"lcds-primary-nav__list-item\">\n           <a href=\"/vaccines-blood-biologics\">\n            Vaccines, Blood, and Biologics\n           </a>\n          </li>\n          <li class=\"lcds-primary-nav__list-item\">\n           <a href=\"/animal-veterinary\">\n            Animal and Veterinary\n           </a>\n          </li>\n          <li class=\"lcds-primary-nav__list-item\">\n           <a href=\"/cosmetics\">\n            Cosmetics\n           </a>\n          </li>\n          <li class=\"lcds-primary-nav__list-item\">\n           <a href=\"/tobacco-products\">\n            Tobacco Products\n           </a>\n          </li>\n         </ul>\n        </section>\n        <section class=\"lcds-primary-nav__group lcds-primary-nav__group--bordered\">\n         <h2 class=\"lcds-primary-nav__group-heading\">\n          Topics\n         </h2>\n         <ul class=\"lcds-primary-nav__list\">\n          <li class=\"lcds-primary-nav__list-item\">\n           <a href=\"/about-fda\">\n            About FDA\n           </a>\n          </li>\n          <li class=\"lcds-primary-nav__list-item\">\n           <a href=\"/combination-products\">\n            Combination Products\n           </a>\n          </li>\n          <li class=\"lcds-primary-nav__list-item\">\n           <a href=\"/regulatory-information\">\n            Regulatory Information\n           </a>\n          </li>\n          <li class=\"lcds-primary-nav__list-item\">\n           <a href=\"/safety\">\n            Safety\n           </a>\n          </li>\n          <li class=\"lcds-primary-nav__list-item\">\n           <a href=\"/emergency-preparedness-and-response\">\n            Emergency Preparedness\n           </a>\n          </li>\n          <li class=\"lcds-primary-nav__list-item\">\n           <a href=\"/international-programs\">\n            International Programs\n           </a>\n          </li>\n          <li class=\"lcds-primary-nav__list-item\">\n           <a href=\"/news-events\">\n            News and Events\n           </a>\n          </li>\n          <li class=\"lcds-primary-nav__list-item\">\n           <a href=\"/training-and-continuing-education\">\n            Training and Continuing Education\n           </a>\n          </li>\n          <li class=\"lcds-primary-nav__list-item\">\n           <a href=\"/inspections-compliance-enforcement-and-criminal-investigations\">\n            Inspections and Compliance\n           </a>\n          </li>\n          <li class=\"lcds-primary-nav__list-item\">\n           <a href=\"/science-research\">\n            Science and Research\n           </a>\n          </li>\n         </ul>\n        </section>\n        <section class=\"lcds-primary-nav__group lcds-primary-nav__group--bordered\">\n         <h2 class=\"lcds-primary-nav__group-heading\">\n          Information For\n         </h2>\n         <ul class=\"lcds-primary-nav__list\">\n          <li class=\"lcds-primary-nav__list-item\">\n           <a href=\"/consumers\">\n            Consumers\n           </a>\n          </li>\n          <li class=\"lcds-primary-nav__list-item\">\n           <a href=\"/patients\">\n            Patients\n           </a>\n          </li>\n          <li class=\"lcds-primary-nav__list-item\">\n           <a href=\"/industry\">\n            Industry\n           </a>\n          </li>\n          <li class=\"lcds-primary-nav__list-item\">\n           <a href=\"/health-professionals\">\n            Health Professionals\n           </a>\n          </li>\n          <li class=\"lcds-primary-nav__list-item\">\n           <a href=\"/federal-state-local-tribal-and-territorial-officials\">\n            Federal, State and Local Officials\n           </a>\n          </li>\n         </ul>\n        </section>\n       </div>\n      </nav>\n     </header>\n     <div class=\"col-xs-12\">\n      <div class=\"hidden\" data-drupal-messages-fallback=\"\">\n      </div>\n     </div>\n     <section class=\"block block-ctools block-entity-viewnode clearfix\" data-block-plugin-id=\"entity_view:node\" id=\"block-entityviewcontent\">\n      <a class=\"lcds-button--expandable collapsed hidden-md hidden-lg\" data-toggle=\"collapse\" href=\"#section-nav\">\n       In this section\n       <span class=\"visible-sm-inline-block\">\n        :\n\n                Structured Product Labeling Resources\n       </span>\n      </a>\n      <nav class=\"lcds-card lcds-section-nav lcds-section-nav hidden-md hidden-lg collapse\" id=\"section-nav\">\n       <ul class=\"lcds-section-nav__list\">\n        <li>\n         <a class=\"lcds-section-nav__section-link lcds-section-nav__link lcds-section-nav__parent-link visible-xs-block visible-sm-block\" href=\"/industry/fda-data-standards-advisory-board/structured-product-labeling-resources\" title=\"Structured Product Labeling Resources\">\n          Structured Product Labeling Resources\n         </a>\n         <div class=\"views-element-container form-group\">\n          <div class=\"view view-in-this-section view-id-in_this_section view-display-id-block_5 js-view-dom-id-2cf21a564367354ef195b56aa81689e46f10f542498f1817b5f7bef7d0252658\">\n           <div>\n            <ul class=\"lcds-section-nav__section-link__active lcds-section-nav__list\">\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/risk-evaluation-and-mitigation-strategies-rems-spl-resources\">\n               Risk Evaluation and Mitigation Strategies (REMS) SPL Resources\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/business-entity-identifiers\">\n               Business Entity Identifiers\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/business-operation\">\n               Business Operation\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/business-operation-qualifier\">\n               Business Operation Qualifier\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/code-system-object-identifiers\">\n               Code System Object Identifiers\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/combination-product-types\">\n               Combination Product Types\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/contributing-factor-general\">\n               Contributing Factor - General\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/document-type-including-content-labeling-type\">\n               Document Type including Content of Labeling Type\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/dosage-forms\">\n               Dosage Forms\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/electronic-animal-drug-product-listing-directory\">\n               Electronic Animal Drug Product Listing Directory\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/equivalence-codes\">\n               Equivalence Codes\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/flavor\">\n               Flavor\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/geopolitical-entities-names-and-codes-genc\">\n               Geopolitical Entities, Names, and Codes (GENC)\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/indication-category\">\n               Indication Category\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/intent-use\">\n               Intent of Use\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/lab-test\">\n               Lab Test\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/license-disciplinary-action\">\n               License Disciplinary Action\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/licensed\">\n               Licensed\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/limitation-useissues\">\n               Limitation of Use/Issues\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/marketing-category\">\n               Marketing Category\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/marketing-status\">\n               Marketing Status\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/medical-condition\">\n               Medical Condition\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/ndcnhric-labeler-codes\">\n               NDC/NHRIC Labeler Codes\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/nsde\">\n               NSDE\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/package-type\">\n               Package Type\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/pharmacokinetic-effect\">\n               Pharmacokinetic Effect\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/pharmacologic-class\">\n               Pharmacologic Class\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/positron-emission-tomography-pet-drug-spl\">\n               Positron Emission Tomography (PET) Drug SPL\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/precondition-categories\">\n               Precondition Categories\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/race\">\n               Race\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/rems-approval\">\n               REMS Approval\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/rems-protocol\">\n               REMS Protocol\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/rems-requirements\">\n               REMS Requirements\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/rems-stakeholder\">\n               REMS Stakeholder\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/resources-spl-commercial-software-and-conversion-vendors-and-fda-regulated-company-self-generated\">\n               Resources for SPL Commercial Software and Conversion Vendors and FDA-Regulated Company Self-Generated SPL Software Developers\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/route-administration\">\n               Route of Administration\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/section-headings-loinc\">\n               Section Headings (LOINC)\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/sex\">\n               Sex\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/spl-color\">\n               SPL Color\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/spl-dea-schedule\">\n               SPL DEA Schedule\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/spl-lot-distribution-data-distribution-codes\">\n               SPL Lot Distribution Data - Distribution Codes\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/spl-shape\">\n               SPL Shape\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/spl-standard-training\">\n               SPL Standard Training\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/spl-xforms\">\n               SPL Xforms\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/time-units\">\n               Time Units\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/type-consequence\">\n               Type of Consequence\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/uniis-preferred-substance-names-and-their-identified-synonyms\">\n               UNIIs, Preferred Substance Names, and their Identified Synonyms\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/units-measure\">\n               Units of Measure\n              </a>\n             </li>\n             <li>\n              <a class=\"lcds-section-nav__link\" href=\"/industry/structured-product-labeling-resources/units-presentation\">\n               Units of Presentation\n              </a>\n             </li>\n            </ul>\n           </div>\n          </div>\n         </div>\n         <div class=\"views-element-container form-group\">\n          <div class=\"view view-in-this-section-sub view-id-in_this_section_sub view-display-id-block_2 js-view-dom-id-335ed711a47462688e70fc5baa76961c56138f181cbddd1216fba45fbfae0dc0\">\n          </div>\n         </div>\n        </li>\n       </ul>\n      </nav>\n     </section>\n     <section class=\"block block-ctools block-entity-viewnode clearfix\" data-block-plugin-id=\"entity_view:node\" id=\"block-entityviewcontent-15\">\n      <ol class=\"lcds-breadcrumb visible-md visible-lg\">\n       <li>\n        <a href=\"/\">\n         Home\n        </a>\n       </li>\n       <li>\n        <a href=\"/industry\">\n         For Industry\n        </a>\n       </li>\n       <li>\n        <a href=\"/industry/fda-data-standards-advisory-board\">\n         FDA Data Standards Advisory Board\n        </a>\n       </li>\n       <li>\n        <a href=\"/industry/fda-data-standards-advisory-board/structured-product-labeling-resources\">\n         Structured Product Labeling Resources\n        </a>\n       </li>\n       <li>\n        <a class=\"current-link\">\n         Dosage Forms\n        </a>\n       </li>\n      </ol>\n      <ol class=\"lcds-breadcrumb visible-sm visible-xs\">\n       <li>\n        <a href=\"/industry/fda-data-standards-advisory-board/structured-product-labeling-resources\" title=\"Structured Product Labeling Resources\">\n         Structured Product Labeling Resources\n        </a>\n       </li>\n      </ol>\n     </section>\n     <main>\n      <article class=\"article main-content container-fluid\" id=\"main-content\" role=\"article\">\n       <header class=\"row content-header\" role=\"heading\">\n        <section class=\"block block-ctools block-entity-viewnode clearfix\" data-block-plugin-id=\"entity_view:node\" id=\"block-entityviewcontent-2\">\n         <div class=\"col-sm-12 col-md-8 col-md-offset-2\">\n          <h1 class=\"content-title text-center\">\n           Dosage Forms\n          </h1>\n          <div class=\"lcds-toolbar lcds-toolbar--social\">\n           <ul class=\"lcds-share lcds-share--default\">\n            <li class=\"lcds-share__item\">\n             <a class=\"lcds-share__btn lcds-share--default__btn-facebook js-share\" href=\"https://www.facebook.com/sharer/sharer.php?u=https://www.fda.gov%2Findustry%2Fstructured-product-labeling-resources%2Fdosage-forms\" id=\"fb-share\" target=\"_blank\">\n              <span aria-hidden=\"true\" class=\"fa icon-facebook\">\n              </span>\n              Share\n             </a>\n            </li>\n            <li class=\"lcds-share__item\">\n             <a class=\"lcds-share__btn lcds-share--default__btn-twitter js-share\" href=\"https://twitter.com/intent/tweet/?text=Dosage%20Forms&amp;url=https://www.fda.gov%2Findustry%2Fstructured-product-labeling-resources%2Fdosage-forms\" id=\"twitter-share\" target=\"_blank\">\n              <span aria-hidden=\"true\" class=\"fa icon-twitter\">\n              </span>\n              Tweet\n             </a>\n            </li>\n            <li class=\"lcds-share__item hidden-xs\">\n             <a class=\"lcds-share__btn lcds-share--default__btn-linkedin js-share\" href=\"https://www.linkedin.com/shareArticle?mini=true&amp;url=https://www.fda.gov%2Findustry%2Fstructured-product-labeling-resources%2Fdosage-forms&amp;title=Dosage%20Forms&amp;source=FDA\" id=\"linkedin-share\" target=\"_blank\">\n              <span aria-hidden=\"true\" class=\"fa icon-linkedin\">\n              </span>\n              Linkedin\n             </a>\n            </li>\n            <li class=\"lcds-share__item\">\n             <a class=\"lcds-share__btn lcds-share--default__btn-mail\" href=\"mailto:?subject=Dosage%20Forms&amp;body=https://www.fda.gov%2Findustry%2Fstructured-product-labeling-resources%2Fdosage-forms\">\n              <span aria-hidden=\"true\" class=\"fa icon-envelope\">\n              </span>\n              Email\n             </a>\n            </li>\n            <li class=\"lcds-share__item hidden-xs\">\n             <a class=\"lcds-share__btn lcds-share--default__btn-print\" href=\"javascript:window.print();\" title=\"Print this page\">\n              <span aria-hidden=\"true\" class=\"fa icon-print\">\n              </span>\n              Print\n             </a>\n            </li>\n           </ul>\n           <div class=\"form-group\">\n           </div>\n          </div>\n         </div>\n        </section>\n       </header>\n       <div class=\"col-md-8 col-md-push-2\" role=\"main\">\n        <p>\n         NCI Thesaurus OID: 2.16.840.1.113883.3.26.1.1\n        </p>\n        <p>\n         NCI concept code for pharmaceutical dosage form: C42636\n        </p>\n        <p>\n        </p>\n        <table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" style=\"height: 2683px;\" width=\"95%\">\n         <tbody>\n          <tr>\n           <th scope=\"col\" style=\"height: 13px; text-align: left;\" valign=\"top\" width=\"400\">\n            <strong>\n             SPL Acceptable Term\n            </strong>\n           </th>\n           <th scope=\"col\" style=\"height: 13px; text-align: left;\" valign=\"top\" width=\"316\">\n            <strong>\n             Code\n            </strong>\n           </th>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"height: 21px; text-align: left;\" valign=\"top\">\n            AEROSOL\n           </td>\n           <td style=\"height: 21px;\" valign=\"top\" width=\"316\">\n            C42887\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            AEROSOL, FOAM\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42888\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            AEROSOL, METERED\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42960\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            AEROSOL, POWDER\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42971\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            AEROSOL, SPRAY\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42889\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            BAR, CHEWABLE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42892\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            BEAD\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42890\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            CAPSULE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C25158\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            CAPSULE, COATED\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42895\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            CAPSULE, COATED PELLETS\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42896\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            CAPSULE, COATED, EXTENDED RELEASE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42917\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            CAPSULE, DELAYED RELEASE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42902\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            CAPSULE, DELAYED RELEASE PELLETS\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42904\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            CAPSULE, EXTENDED RELEASE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42916\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            CAPSULE, FILM COATED, EXTENDED RELEASE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42928\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            CAPSULE, GELATIN COATED\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42936\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            CAPSULE, LIQUID FILLED\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42954\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            CELLULAR SHEET\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C100103\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            CHEWABLE GEL\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C134876\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            CLOTH\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C60884\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            CONCENTRATE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C60891\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            CREAM\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C28944\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            CREAM, AUGMENTED\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C60897\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            CRYSTAL\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42901\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            DISC\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C43525\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            DOUCHE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42679\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            DRESSING\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42763\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            DRUG-ELUTING CONTACT LENS\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C185352\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            ELIXIR\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42912\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            EMULSION\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42913\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            ENEMA\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42915\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            EXTRACT\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42929\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            FIBER, EXTENDED RELEASE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C60926\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            FILM\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42932\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            FILM, EXTENDED RELEASE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42920\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            FILM, SOLUBLE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42984\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            FOR SOLUTION\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C60927\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            FOR SUSPENSION\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C60928\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            FOR SUSPENSION, EXTENDED RELEASE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C60929\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            GAS\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42933\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            GEL\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42934\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            GEL, DENTIFRICE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42906\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            GEL, METERED\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C60930\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            GLOBULE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42937\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            GRANULE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42938\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            GRANULE, DELAYED RELEASE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42903\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            GRANULE, EFFERVESCENT\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42909\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            GRANULE, FOR SOLUTION\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42939\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            GRANULE, FOR SUSPENSION\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42940\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            GRANULE, FOR SUSPENSION, EXTENDED RELEASE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42921\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            GUM, CHEWING\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42894\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            IMPLANT\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42942\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            INHALANT\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42944\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            INJECTABLE FOAM\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C113106\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            INJECTABLE, LIPOSOMAL\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C60931\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            INJECTION\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42946\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            INJECTION, EMULSION\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42914\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            INJECTION, LIPID COMPLEX\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42950\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            INJECTION, POWDER, FOR SOLUTION\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42974\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            INJECTION, POWDER, FOR SUSPENSION\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42976\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            INJECTION, POWDER, FOR SUSPENSION, EXTENDED RELEASE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42977\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            INJECTION, POWDER, LYOPHILIZED, FOR LIPOSOMAL SUSPENSION\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42959\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            INJECTION, POWDER, LYOPHILIZED, FOR SOLUTION\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42957\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            INJECTION, POWDER, LYOPHILIZED, FOR SUSPENSION\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42958\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            INJECTION, POWDER, LYOPHILIZED, FOR SUSPENSION, EXTENDED RELEASE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42956\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            INJECTION, SOLUTION\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42945\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            INJECTION, SOLUTION, CONCENTRATE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42899\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            INJECTION, SUSPENSION\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42995\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            INJECTION, SUSPENSION, EXTENDED RELEASE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42926\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            INJECTION, SUSPENSION, LIPOSOMAL\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42951\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            INJECTION, SUSPENSION, SONICATED\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42988\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            INSERT\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C60933\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            INSERT, EXTENDED RELEASE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42922\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            INTRAUTERINE DEVICE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C47915\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            IRRIGANT\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42947\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            JELLY\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42948\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            KIT\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C47916\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            LINIMENT\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42949\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            LIPSTICK\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42952\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            LIQUID\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42953\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            LIQUID, EXTENDED RELEASE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C60934\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            LOTION\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C29167\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            LOTION, AUGMENTED\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C60957\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            LOTION/SHAMPOO\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C60958\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            LOZENGE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42955\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            MOUTHWASH\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C29269\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            NOT APPLICABLE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C48624\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            OIL\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42965\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            OINTMENT\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42966\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            OINTMENT, AUGMENTED\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C60984\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            PASTE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42967\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            PASTE, DENTIFRICE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42907\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            PASTILLE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C60985\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            PATCH\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42968\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            PATCH, EXTENDED RELEASE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42923\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            PATCH, EXTENDED RELEASE, ELECTRICALLY CONTROLLED\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42911\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            PELLET\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42969\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            PELLET, IMPLANTABLE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42943\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            PELLETS, COATED, EXTENDED RELEASE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42918\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            PILL\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C25394\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            PLASTER\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42970\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            POULTICE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C47913\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            POWDER\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42972\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            POWDER, DENTIFRICE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42908\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            POWDER, FOR SOLUTION\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42973\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            POWDER, FOR SUSPENSION\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42975\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            POWDER, METERED\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42961\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            RING\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C60988\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            RINSE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42979\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            SALVE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42980\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            SHAMPOO\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42981\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            SHAMPOO, SUSPENSION\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42982\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            SOAP\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42983\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            SOLUTION\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42986\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            SOLUTION, CONCENTRATE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42898\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            SOLUTION, FOR SLUSH\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42987\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            SOLUTION, GEL FORMING / DROPS\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C60994\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            SOLUTION, GEL FORMING, EXTENDED RELEASE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42935\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            SOLUTION/ DROPS\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C60992\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            SPONGE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C47912\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            SPRAY\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42989\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            SPRAY, METERED\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42962\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            SPRAY, SUSPENSION\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42990\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            STICK\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42991\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            STRIP\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C47914\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            SUPPOSITORY\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42993\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            SUPPOSITORY, EXTENDED RELEASE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42924\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            SUSPENSION\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42994\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            SUSPENSION, EXTENDED RELEASE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42925\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            SUSPENSION/ DROPS\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C60995\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            SWAB\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C47898\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            SYRUP\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42996\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            SYSTEM\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C17423\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            TABLET\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42998\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            TABLET, CHEWABLE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42893\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            TABLET, CHEWABLE, EXTENDED RELEASE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C124794\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            TABLET, COATED\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42897\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            TABLET, COATED PARTICLES\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C60997\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            TABLET, DELAYED RELEASE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42905\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            TABLET, DELAYED RELEASE PARTICLES\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42997\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            TABLET, EFFERVESCENT\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42910\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            TABLET, EXTENDED RELEASE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42927\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            TABLET, FILM COATED\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42931\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            TABLET, FILM COATED, EXTENDED RELEASE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42930\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            TABLET, FOR SOLUTION\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C61004\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            TABLET, FOR SUSPENSION\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C61005\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            TABLET, MULTILAYER\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42964\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            TABLET, MULTILAYER, EXTENDED RELEASE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42963\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            TABLET, ORALLY DISINTEGRATING\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42999\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            TABLET, ORALLY DISINTEGRATING, DELAYED RELEASE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C61006\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            TABLET, SOLUBLE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42985\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            TABLET, SUGAR COATED\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C42992\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            TABLET WITH SENSOR\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C147579\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            TAMPON\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C47892\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            TAPE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C47897\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            TINCTURE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C43000\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"text-align: left;\" valign=\"top\">\n            TROCHE\n           </td>\n           <td valign=\"top\" width=\"316\">\n            C43001\n           </td>\n          </tr>\n          <tr>\n           <td scope=\"row\" style=\"height: 13px; text-align: left;\" valign=\"top\">\n            WAFER\n           </td>\n           <td style=\"height: 13px;\" valign=\"top\" width=\"316\">\n            C43003\n           </td>\n          </tr>\n         </tbody>\n        </table>\n        <p>\n        </p>\n       </div>\n       <aside class=\"col-md-2 col-md-push-2\" role=\"complementary\">\n        <section class=\"block block-ctools block-entity-viewnode clearfix\" data-block-plugin-id=\"entity_view:node\" id=\"block-entityviewcontent-4\">\n         <div about=\"/industry/structured-product-labeling-resources/dosage-forms\" class=\"region region-\" role=\"article\">\n          <aside class=\"lcds-card lcds-card--border-top\" role=\"menu\">\n           <ul class=\"lcds-description-list\">\n            <div class=\"node-current-date\">\n             <li class=\"lcds-description-list__item\">\n              <div>\n               <h2 class=\"lcds-description-list__item-heading\">\n                Content current as of:\n               </h2>\n               <p class=\"lcds-description-list__item-text\">\n                <time datetime=\"2022-02-03T10:05:00Z\">\n                 02/03/2022\n                </time>\n               </p>\n              </div>\n             </li>\n            </div>\n            <li class=\"lcds-description-list__item\">\n             <div>\n             </div>\n            </li>\n           </ul>\n          </aside>\n         </div>\n        </section>\n       </aside>\n       <aside class=\"col-md-2 col-md-pull-10\" role=\"complementary\">\n        <section class=\"block block-ctools block-entity-viewnode clearfix\" data-block-plugin-id=\"entity_view:node\" id=\"block-entityviewcontent-3\">\n         <div about=\"/industry/structured-product-labeling-resources/dosage-forms\" class=\"region region-\" role=\"article\">\n          <nav class=\"lcds-card lcds-section-nav lcds-section-nav--side hidden-xs hidden-sm\" id=\"section-nav\">\n           <ul class=\"lcds-section-nav__list lcds-section-nav--side__list\">\n            <li>\n             <a class=\"lcds-section-nav__link lcds-section-nav--side__link lcds-section-nav__parent-link lcds-section-nav--side__parent-link\" href=\"/industry/fda-data-standards-advisory-board/structured-product-labeling-resources\">\n              Structured Product Labeling Resources\n             </a>\n             <div class=\"views-element-container form-group\">\n              <div class=\"view view-in-this-section view-id-in_this_section view-display-id-block_4 js-view-dom-id-f4e45e22b3b3ec96fee2374dd154bf5fb59f4016cdd6b6e9afac78399d5bda28\">\n               <div class=\"item-list\">\n                <ul class=\"lcds-section-nav__active lcds-section-nav__list lcds-section-nav--side__list\">\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/risk-evaluation-and-mitigation-strategies-rems-spl-resources\">\n                   REMS SPL Resources\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/business-entity-identifiers\">\n                   Business Entity Identifiers\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/business-operation\">\n                   Business Operation\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/business-operation-qualifier\">\n                   Business Operation Qualifier\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/code-system-object-identifiers\">\n                   Code System Object Identifiers\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/combination-product-types\">\n                   Combination Product Types\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/contributing-factor-general\">\n                   Contributing Factor - General\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/document-type-including-content-labeling-type\">\n                   Document Type including Content of Labeling Type\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/dosage-forms\">\n                   Dosage Forms\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/electronic-animal-drug-product-listing-directory\">\n                   Electronic Animal Drug Product Listing Directory\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/equivalence-codes\">\n                   Equivalence Codes\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/flavor\">\n                   Flavor\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/geopolitical-entities-names-and-codes-genc\">\n                   Geopolitical Entities, Names, and Codes (GENC)\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/indication-category\">\n                   Indication Category\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/intent-use\">\n                   Intent of Use\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/lab-test\">\n                   Lab Test\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/license-disciplinary-action\">\n                   License Disciplinary Action\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/licensed\">\n                   Licensed\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/limitation-useissues\">\n                   Limitation of Use/Issues\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/marketing-category\">\n                   Marketing Category\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/marketing-status\">\n                   Marketing Status\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/medical-condition\">\n                   Medical Condition\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/ndcnhric-labeler-codes\">\n                   NDC/NHRIC Labeler Codes\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/nsde\">\n                   NSDE\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/package-type\">\n                   Package Type\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/pharmacokinetic-effect\">\n                   Pharmacokinetic Effect\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/pharmacologic-class\">\n                   Pharmacologic Class\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/positron-emission-tomography-pet-drug-spl\">\n                   Positron Emission Tomography (PET) Drug SPL\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/precondition-categories\">\n                   Precondition Categories\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/race\">\n                   Race\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/rems-approval\">\n                   REMS Approval\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/rems-protocol\">\n                   REMS Protocol\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/rems-requirements\">\n                   REMS Requirements\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/rems-stakeholder\">\n                   REMS Stakeholder\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/resources-spl-commercial-software-and-conversion-vendors-and-fda-regulated-company-self-generated\">\n                   Resources for SPL Commercial Software and Conversion Vendors and FDA-Regulated Company Self-Generated SPL Software Developers\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/route-administration\">\n                   Route of Administration\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/section-headings-loinc\">\n                   Section Headings (LOINC)\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/sex\">\n                   Sex\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/spl-color\">\n                   SPL Color\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/spl-dea-schedule\">\n                   SPL DEA Schedule\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/spl-lot-distribution-data-distribution-codes\">\n                   SPL Lot Distribution Data - Distribution Codes\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/spl-shape\">\n                   SPL Shape\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/spl-standard-training\">\n                   SPL Standard Training\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/spl-xforms\">\n                   SPL Xforms\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/time-units\">\n                   Time Units\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/type-consequence\">\n                   Type of Consequence\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/uniis-preferred-substance-names-and-their-identified-synonyms\">\n                   UNIIs, Preferred Substance Names, and their Identified Synonyms\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/units-measure\">\n                   Units of Measure\n                  </a>\n                 </li>\n                 <li>\n                  <a class=\"lcds-section-nav__link lcds-section-nav--side__link\" href=\"/industry/structured-product-labeling-resources/units-presentation\">\n                   Units of Presentation\n                  </a>\n                 </li>\n                </ul>\n               </div>\n              </div>\n             </div>\n             <div class=\"views-element-container form-group\">\n              <div class=\"view view-in-this-section-sub view-id-in_this_section_sub view-display-id-block_1 js-view-dom-id-d419d9d275f7ccb0e40f34448099063062b85dbbc42f13f719f9b4c058d3b17a\">\n              </div>\n             </div>\n            </li>\n           </ul>\n          </nav>\n         </div>\n        </section>\n       </aside>\n      </article>\n     </main>\n    </div>\n   </div>\n   <div class=\"region region-subscribe\">\n    <section class=\"block block-ctools block-entity-viewnode clearfix\" data-block-plugin-id=\"entity_view:node\" id=\"block-entityviewcontent-5\">\n    </section>\n   </div>\n   <footer class=\"lcds-footer container-fluid\">\n    <div class=\"row lcds-footer__primary\">\n     <h2 class=\"sr-only\" id=\"footer-heading\">\n      Footer Links\n     </h2>\n     <nav class=\"text-center\">\n      <div class=\"col-sm-4\">\n       <ul class=\"nav\">\n        <li>\n         <a href=\"/about-fda/about-website/fdagov-archive\">\n          FDA Archive\n         </a>\n        </li>\n        <li>\n         <a href=\"/about-fda\">\n          About FDA\n         </a>\n        </li>\n        <li>\n         <a href=\"/about-fda/about-website/internet-accessibility\">\n          Accessibility\n         </a>\n        </li>\n       </ul>\n      </div>\n      <div class=\"col-sm-4\">\n       <ul class=\"nav\">\n        <li>\n         <a href=\"/about-fda/visitor-information\">\n          Visitor Information\n         </a>\n        </li>\n        <li>\n         <a href=\"/about-fda/about-website/website-policies\">\n          Website Policies / Privacy\n         </a>\n        </li>\n        <li>\n         <a href=\"/about-fda/jobs-and-training-fda/no-fear-act\">\n          No FEAR Act\n         </a>\n        </li>\n        <li>\n         <a href=\"https://www.hhs.gov/vulnerability-disclosure-policy/index.html\">\n          Vulnerability Disclosure Policy\n         </a>\n        </li>\n       </ul>\n      </div>\n      <div class=\"col-sm-4\">\n       <ul class=\"nav\">\n        <li>\n         <a href=\"/regulatory-information/freedom-information\" title=\"Freedom of Information Act\">\n          FOIA\n         </a>\n        </li>\n        <li>\n         <a href=\"https://www.hhs.gov/\" target=\"_blank\" title=\"Health and Human Services\">\n          HHS.gov\n         </a>\n        </li>\n        <li>\n         <a href=\"https://www.usa.gov/\" target=\"_blank\">\n          USA.gov\n         </a>\n        </li>\n       </ul>\n      </div>\n     </nav>\n    </div>\n    <div class=\"row lcds-footer__secondary\">\n     <div class=\"col-sm-12 col-md-6 col-lg-4 lcds-footer__social-links\">\n      <a class=\"btn btn-default btn-md\" href=\"/about-fda/contact-fda\">\n       Contact FDA\n      </a>\n      <a class=\"no-disclaimer\" href=\"https://www.facebook.com/FDA\" title=\"Follow FDA on Facebook\">\n       <span aria-hidden=\"true\" class=\"fa fa-facebook fa-2x\">\n        <span class=\"sr-only\">\n         Follow FDA on Facebook\n        </span>\n       </span>\n      </a>\n      <a class=\"no-disclaimer\" href=\"https://www.twitter.com/US_FDA\" title=\"Follow FDA on Twitter\">\n       <span aria-hidden=\"true\" class=\"fa fa-twitter fa-2x\">\n        <span class=\"sr-only\">\n         Follow FDA on Twitter\n        </span>\n       </span>\n      </a>\n      <a class=\"no-disclaimer\" href=\"https://instagram.com/FDA\" title=\"Follow FDA on Instagram\">\n       <span aria-hidden=\"true\" class=\"fa fa-instagram fa-2x\">\n        <span class=\"sr-only\">\n         Follow FDA on Instagram\n        </span>\n       </span>\n      </a>\n      <br class=\"visible-xs-inline\">\n       <a class=\"no-disclaimer\" href=\"https://www.linkedin.com/company/fda/\" title=\"Follow FDA on LinkedIn\">\n        <span aria-hidden=\"true\" class=\"fa fa-linkedin fa-2x\">\n         <span class=\"sr-only\">\n          Follow FDA on LinkedIn\n         </span>\n        </span>\n       </a>\n       <a class=\"no-disclaimer\" href=\"https://youtube.com/@US_FDA\" title=\"View FDA videos on YouTube\">\n        <span aria-hidden=\"true\" class=\"fa fa-youtube fa-2x\">\n         <span class=\"sr-only\">\n          View FDA videos on YouTube\n         </span>\n        </span>\n       </a>\n       <a href=\"/about-fda/contact-fda/subscribe-podcasts-and-news-feeds\" title=\"Subscribe to FDA RSS feeds\">\n        <span aria-hidden=\"true\" class=\"fa fa-rss fa-2x\">\n         <span class=\"sr-only\">\n          Subscribe to FDA RSS feeds\n         </span>\n        </span>\n       </a>\n      </br>\n     </div>\n     <a href=\"/\" title=\"FDA Homepage\">\n      <div class=\"visible-lg-block col-lg-4 text-center lcds-footer__logo\">\n       <span class=\"sr-only\">\n        FDA Homepage\n       </span>\n      </div>\n     </a>\n     <div class=\"col-sm-12 col-md-6 col-lg-4 text-center lcds-footer__contact-number\">\n      <span aria-hidden=\"true\" class=\"fa fa-phone\">\n      </span>\n      <span class=\"sr-only\">\n       Contact Number\n      </span>\n      1-888-INFO-FDA (1-888-463-6332)\n     </div>\n    </div>\n    <script type=\"text/javascript\">\n     (function(){var g=function(e,h,f,g){\n  this.get=function(a){for(var a=a+\"=\",c=document.cookie.split(\";\"),b=0,e=c.length;b<e;b++){for(var d=c[b];\" \"==d.charAt(0);)d=d.substring(1,d.length);if(0==d.indexOf(a))return d.substring(a.length,d.length)}return null};\n  this.set=function(a,c){var b=\"\",b=new Date;b.setTime(b.getTime()+6048E5);b=\"; expires=\"+b.toGMTString();document.cookie=a+\"=\"+c+b+\"; path=/; \"};\n  this.check=function(){var a=this.get(f);if(a)a=a.split(\":\");else if(100!=e)\"v\"==h&&(e=Math.random()>=e/100?0:100),a=[h,e,0],this.set(f,a.join(\":\"));else return!0;var c=a[1];if(100==c)return!0;switch(a[0]){case \"v\":return!1;case \"r\":return c=a[2]%Math.floor(100/c),a[2]++,this.set(f,a.join(\":\")),!c}return!0};\n  this.go=function(){if(this.check()){var a=document.createElement(\"script\");a.type=\"text/javascript\";a.src=g+ \"&t=\" + (new Date()).getTime();document.body&&document.body.appendChild(a)}};\n  this.start=function(){var a=this;window.addEventListener?window.addEventListener(\"load\",function(){a.go()},!1):window.attachEvent&&window.attachEvent(\"onload\",function(){a.go()})}};\n  try{(new g(100,\"r\",\"QSI_S_ZN_6FpQ8uiCQiPh6SN\",\"https://zn6fpq8uicqiph6sn-fdawebcx.gov1.siteintercept.qualtrics.com/SIE/?Q_ZID=ZN_6FpQ8uiCQiPh6SN\")).start()}catch(i){}})();\n    </script>\n    <div id=\"ZN_6FpQ8uiCQiPh6SN\">\n     <!--DO NOT REMOVE-CONTENTS PLACED HERE-->\n    </div>\n    <!--END WEBSITE FEEDBACK SNIPPET-->\n   </footer>\n   <a class=\"btn btn-primary btn-top\" href=\"\" id=\"btn-top\">\n    <span class=\"sr-only\">\n     Back to\n    </span>\n    Top\n   </a>\n  </div>\n  <script data-drupal-selector=\"drupal-settings-json\" type=\"application/json\">\n   {\"path\":{\"baseUrl\":\"\\/\",\"scriptPath\":null,\"pathPrefix\":\"\",\"currentPath\":\"node\\/358928\",\"currentPathIsAdmin\":false,\"isFront\":false,\"currentLanguage\":\"en\"},\"pluralDelimiter\":\"\\u0003\",\"suppressDeprecationErrors\":true,\"jquery\":{\"ui\":{\"datepicker\":{\"isRTL\":false,\"firstDay\":0}}},\"fda_ckeditor_enhancements\":{\"basePath\":\"modules\\/custom\\/fda_ckeditor_enhancements\"},\"google_analytics\":{\"account\":\"UA-22737364-1\",\"trackOutbound\":true,\"trackMailto\":true,\"trackDownload\":true,\"trackDownloadExtensions\":\"7z|aac|arc|arj|asf|asx|avi|bin|csv|doc(x|m)?|dot(x|m)?|exe|flv|gif|gz|gzip|hqx|jar|jpe?g|js|mp(2|3|4|e?g)|mov(ie)?|msi|msp|pdf|phps|png|ppt(x|m)?|pot(x|m)?|pps(x|m)?|ppam|sld(x|m)?|thmx|qtm?|ra(m|r)?|sea|sit|tar|tgz|torrent|txt|wav|wma|wmv|wpd|xls(x|m|b)?|xlt(x|m)|xlam|xml|z|zip\"},\"bootstrap\":{\"forms_has_error_value_toggle\":1,\"modal_animation\":1,\"modal_backdrop\":\"true\",\"modal_focus_input\":1,\"modal_keyboard\":1,\"modal_select_text\":1,\"modal_show\":1,\"modal_size\":\"\",\"popover_enabled\":1,\"popover_animation\":1,\"popover_auto_close\":1,\"popover_container\":\"body\",\"popover_content\":\"\",\"popover_delay\":\"0\",\"popover_html\":0,\"popover_placement\":\"right\",\"popover_selector\":\"\",\"popover_title\":\"\",\"popover_trigger\":\"click\"},\"ajax\":[],\"user\":{\"uid\":0,\"permissionsHash\":\"3aef67b4ac7d861d8624bf1f7ab2bc9cfc56d3c25b7d709dc15466dfa996dfb0\"}}\n  </script>\n  <script src=\"/files/js/js_Dci7uLWeq40FWcpIjiQjBlWDUvAHJXOZvUm0MMnj0C8.js\">\n  </script>\n </body>\n</html>\n\n\n\nThe following step was optional, but might be useful later, the web content could be saved as a file as shown below.\n\n# Create a file by passing the request content into write () method\n# and save the dosage form table as a file in binary format\nwith open(\"FDA_dosage_form\", \"wb\") as file:\n    file.write(data.content)\n\n\n\n\n\nTransform web-scraped data into dataframe\n\n\nUsing Pandas dataframe library\n\nPandas.append()\nThe original pandas.append() method was going to be deprecated in future versions of Pandas. This old method was shown as below:\n```{python}\n# Create an empty dataframe with columns named \"Dosage_form\" & \"Code\"\ndosage_form = pd.DataFrame(columns = [\"Dosage_form\", \"Code\"])\n\n# Create a loop to find all <tr> tags in the soup object (scraped html content)\nfor row in soup.find_all(\"tr\"): \n  # Set the columns to contain contents under <td> tags by searching all rows\n  col = row.find_all(\"td\") \n    # if columns are not an empty list, \n    # add the texts under columns in specified orders\n    if (col != []): \n    dosage = col[0].text \n    code = col[1].text \n\n# Append each text item into the dosage_form dataframe\ndosage_form = dosage_form.append({\"Dosage_form\":dosage, \"Code\":code}, ignore_index = True)\n\n# Show dataframe\ndosage_form\n```\nThis method might still work currently, however, the newer and recommended methods would be to use the pandas.concat() method as shown below.\n\n\nPandas.concat()\nFirst example:\n\n# Create an empty dictionary\ndict = []\n\n# Create a loop to iterate through html tags from the soup (scraped html content)\n# find all html tags that began with <tr>\nfor row in soup.find_all(\"tr\"):\n    # each column would hold the items under <td> tags\n    col = row.find_all(\"td\")\n    if (col != []): \n        # dosage form in column 1\n        dosage = col[0].text\n        # code in column 2\n        code = col[1].text\n        # Append each dosage form & code into the dictionary\n        dict.append({\"DosageForm\": dosage, \"dosage_form\": code})\n\n# Check if the loop was iterating through the html tags\n# and that it was appending each dosage form & code into the dictionary \n# Uncomment line below\n#print(dict)\n\n# Create an empty dataframe with the column names wanted\ndosage_form = pd.DataFrame(columns = [\"DosageForm\", \"dosage_form\"])\n\n# Concatenate the dosage_form dataframe with the dataframe converted from dict\ndf_new = pd.concat([dosage_form, pd.DataFrame.from_dict(dict)])\n\n# Print the combined dataframe df_new\ndf_new\n\n\n\n\n\n  \n    \n      \n      DosageForm\n      dosage_form\n    \n  \n  \n    \n      0\n      AEROSOL\n      C42887\n    \n    \n      1\n      AEROSOL, FOAM\n      C42888\n    \n    \n      2\n      AEROSOL, METERED\n      C42960\n    \n    \n      3\n      AEROSOL, POWDER\n      C42971\n    \n    \n      4\n      AEROSOL, SPRAY\n      C42889\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      153\n      TAMPON\n      C47892\n    \n    \n      154\n      TAPE\n      C47897\n    \n    \n      155\n      TINCTURE\n      C43000\n    \n    \n      156\n      TROCHE\n      C43001\n    \n    \n      157\n      WAFER\n      C43003\n    \n  \n\n158 rows × 2 columns\n\n\n\n\n\nPandas.from_dict()\nSecond example by using pd.from_dict() method, which might have less lines of code:\n\n# Create an empty dictionary\ndict = []\n\n# Create a loop to iterate through html tags from the soup (scraped html content)\n# find all html tags that began with <tr>\nfor row in soup.find_all(\"tr\"):\n    # each column would hold the items under <td> tags\n    col = row.find_all(\"td\")\n    if (col != []): \n        # dosage form in column 1\n        dosage = col[0].text\n        # code in column 2\n        code = col[1].text\n        # Append each dosage form & code into the dict\n        dict.append({\"DosageForm\": dosage, \"dosage_form\": code})\n\n# Check if the loop was working to iterate through the html tags\n# and that it was appending each dosage form & code into the dictionary \n# Uncomment line below\n#print(dict)\n\n# Convert the dictionary into a dataframe\ndf_new = pd.DataFrame.from_dict(dict)\n\n# Print the dataframe df_new\ndf_new\n\n\n\n\n\n  \n    \n      \n      DosageForm\n      dosage_form\n    \n  \n  \n    \n      0\n      AEROSOL\n      C42887\n    \n    \n      1\n      AEROSOL, FOAM\n      C42888\n    \n    \n      2\n      AEROSOL, METERED\n      C42960\n    \n    \n      3\n      AEROSOL, POWDER\n      C42971\n    \n    \n      4\n      AEROSOL, SPRAY\n      C42889\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      153\n      TAMPON\n      C47892\n    \n    \n      154\n      TAPE\n      C47897\n    \n    \n      155\n      TINCTURE\n      C43000\n    \n    \n      156\n      TROCHE\n      C43001\n    \n    \n      157\n      WAFER\n      C43003\n    \n  \n\n158 rows × 2 columns\n\n\n\n\n\n\nUsing Polars dataframe library\nPolars dataframe library also had a from_dict() method that could convert dictionary into a dataframe as shown below:\n\n# Create an empty dictionary\ndict = []\n\n# Create a loop to iterate through html tags from the soup (scraped html content)\n# find all html tags that began with <tr>\nfor row in soup.find_all(\"tr\"):\n    # each column would hold the items under <td> tags\n    col = row.find_all(\"td\")\n    if (col != []): \n        # dosage form in column 1\n        dosage = col[0].text\n        # code in column 2\n        code = col[1].text\n        # Append each dosage form & code into the dict\n        dict.append({\"DosageForm\": dosage, \"dosage_form\": code})\n\n# Check if the loop was iterating through the html tags\n# and that it was also appending each dosage form & code into the dictionary \n# Uncomment line below\n#print(dict)\n\n# Convert dictionary to dataframe\nnew_df = pl.from_dicts(dict)\nnew_df\n\n\n\n\nshape: (158, 2)\n\n\n\n\nDosageForm\n\n\ndosage_form\n\n\n\n\nstr\n\n\nstr\n\n\n\n\n\n\n\"AEROSOL\"\n\n\n\"C42887\"\n\n\n\n\n\"AEROSOL, FOAM\"\n\n\n\"C42888\"\n\n\n\n\n\"AEROSOL, METER...\n\n\n\"C42960\"\n\n\n\n\n\"AEROSOL, POWDE...\n\n\n\"C42971\"\n\n\n\n\n\"AEROSOL, SPRAY...\n\n\n\"C42889\"\n\n\n\n\n\"BAR, CHEWABLE\"\n\n\n\"C42892\"\n\n\n\n\n\"BEAD\"\n\n\n\"C42890\"\n\n\n\n\n\"CAPSULE\"\n\n\n\"C25158\"\n\n\n\n\n\"CAPSULE, COATE...\n\n\n\"C42895\"\n\n\n\n\n\"CAPSULE, COATE...\n\n\n\"C42896\"\n\n\n\n\n\"CAPSULE, COATE...\n\n\n\"C42917\"\n\n\n\n\n\"CAPSULE, DELAY...\n\n\n\"C42902\"\n\n\n\n\n...\n\n\n...\n\n\n\n\n\"TABLET, MULTIL...\n\n\n\"C42964\"\n\n\n\n\n\"TABLET, MULTIL...\n\n\n\"C42963\"\n\n\n\n\n\"TABLET, ORALLY...\n\n\n\"C42999\"\n\n\n\n\n\"TABLET, ORALLY...\n\n\n\"C61006\"\n\n\n\n\n\"TABLET, SOLUBL...\n\n\n\"C42985\"\n\n\n\n\n\"TABLET, SUGAR ...\n\n\n\"C42992\"\n\n\n\n\n\"TABLET WITH SE...\n\n\n\"C147579\"\n\n\n\n\n\"TAMPON\"\n\n\n\"C47892\"\n\n\n\n\n\"TAPE\"\n\n\n\"C47897\"\n\n\n\n\n\"TINCTURE\"\n\n\n\"C43000\"\n\n\n\n\n\"TROCHE\"\n\n\n\"C43001\"\n\n\n\n\n\"WAFER\"\n\n\n\"C43003\"\n\n\n\n\n\n\n\n\n\n\nPreparation of dataframe for data visualisation\nOnce we have the scraped dataframe ready, we could combine it with our original dataframe from the .csv file (the idea was basically doing dataframe join). Then the dosage form code column could be removed to make it easier to read.\n\n# Join the two dataframes together\ndf_final = df_med.join(new_df, on = \"dosage_form\")\n# Drop the column dosage_form which had code of each dosage form \ndf_final = df_final.drop(\"dosage_form\")\ndf_final\n\n\n\n\nshape: (83925, 5)\n\n\n\n\nsplshape_text\n\n\nsplcolor_text\n\n\nspl_strength\n\n\nspl_inactive_ing\n\n\nDosageForm\n\n\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\n\n\n\n\n\"CAPSULE\"\n\n\n\"PINK\"\n\n\n\"TEMAZEPAM 15 m...\n\n\n\"SILICON DIOXID...\n\n\n\"CAPSULE\"\n\n\n\n\n\"ROUND\"\n\n\n\"ORANGE\"\n\n\n\"IBUPROFEN 200 ...\n\n\n\"SILICON DIOXID...\n\n\n\"TABLET, FILM C...\n\n\n\n\n\"PENTAGON (5 SI...\n\n\n\"GREEN\"\n\n\n\"DEXAMETHASONE ...\n\n\n\"ANHYDROUS LACT...\n\n\n\"TABLET\"\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"Nickel Sulfate...\n\n\nnull\n\n\n\"TABLET\"\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"CLONAZEPAM 0.2...\n\n\n\"SORBITOL;ASPAR...\n\n\n\"TABLET, ORALLY...\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"SILDENAFIL CIT...\n\n\n\"ANHYDROUS DIBA...\n\n\n\"TABLET, FILM C...\n\n\n\n\n\"OVAL\"\n\n\n\"YELLOW\"\n\n\n\"RISPERIDONE 3 ...\n\n\n\"LACTOSE MONOHY...\n\n\n\"TABLET, FILM C...\n\n\n\n\n\"CAPSULE\"\n\n\n\"BLUE\"\n\n\n\"IBUPROFEN 200 ...\n\n\n\"FD&C BLUE NO. ...\n\n\n\"CAPSULE, LIQUI...\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"Iloperidone 12...\n\n\n\"silicon dioxid...\n\n\n\"TABLET\"\n\n\n\n\n\"CAPSULE\"\n\n\n\"YELLOW;WHITE\"\n\n\n\"FENOPROFEN CAL...\n\n\n\"CROSPOVIDONE;M...\n\n\n\"CAPSULE\"\n\n\n\n\n\"ROUND\"\n\n\n\"YELLOW\"\n\n\n\"BUTALBITAL 50 ...\n\n\n\"STARCH, CORN;C...\n\n\n\"TABLET\"\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"ESTRADIOL 0.5 ...\n\n\n\"COPOVIDONE K25...\n\n\n\"TABLET\"\n\n\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"MEMANTINE HYDR...\n\n\n\"SILICON DIOXID...\n\n\n\"TABLET\"\n\n\n\n\n\"CAPSULE\"\n\n\n\"ORANGE\"\n\n\n\"ACETAMINOPHEN ...\n\n\n\"BUTYLATED HYDR...\n\n\n\"CAPSULE, LIQUI...\n\n\n\n\n\"ROUND\"\n\n\n\"WHITE\"\n\n\n\"LAMOTRIGINE 25...\n\n\n\"MAGNESIUM CARB...\n\n\n\"TABLET, CHEWAB...\n\n\n\n\n\"OVAL\"\n\n\n\"BLUE\"\n\n\n\"ACETAMINOPHEN ...\n\n\n\"ACESULFAME POT...\n\n\n\"TABLET, COATED...\n\n\n\n\n\"OVAL\"\n\n\n\"WHITE\"\n\n\n\"AZITHROMYCIN D...\n\n\n\"CROSCARMELLOSE...\n\n\n\"TABLET, FILM C...\n\n\n\n\n\"OVAL\"\n\n\n\"BLUE\"\n\n\n\"IBUPROFEN 200 ...\n\n\n\"FD&C BLUE NO. ...\n\n\n\"CAPSULE, LIQUI...\n\n\n\n\n\"OVAL\"\n\n\n\"WHITE\"\n\n\n\"CETIRIZINE HYD...\n\n\n\"STARCH, CORN;H...\n\n\n\"TABLET\"\n\n\n\n\n\"OVAL\"\n\n\n\"BROWN\"\n\n\n\"OMEPRAZOLE 20 ...\n\n\n\"CARNAUBA WAX;F...\n\n\n\"TABLET, DELAYE...\n\n\n\n\n\"ROUND\"\n\n\n\"PINK;ORANGE;YE...\n\n\n\"CALCIUM CARBON...\n\n\n\"CITRIC ACID MO...\n\n\n\"TABLET, CHEWAB...\n\n\n\n\n\"OVAL\"\n\n\n\"GREEN\"\n\n\n\"ACETAMINOPHEN ...\n\n\n\"STARCH, CORN;D...\n\n\n\"TABLET, FILM C...\n\n\n\n\n\"CAPSULE\"\n\n\n\"BLUE\"\n\n\n\"Amlodipine bes...\n\n\n\"Cellulose, mic...\n\n\n\"CAPSULE\"\n\n\n\n\n\"ROUND\"\n\n\n\"ORANGE\"\n\n\n\"DARIFENACIN 15...\n\n\n\"ANHYDROUS DIBA...\n\n\n\"TABLET, EXTEND...\n\n\n\n\n\n\n\n\nHere, we could save the intended dataframe for data visualisation as a .csv file, so that further data wrangling and mining could be done later for part 2. This also avoided making request calls to the website again and again by extracting the scraped web information as a stand-alone file which could be imported when needed later on.\n\n# Save the inital cleaned dataframe as .csv file\n# for use in a new .ipynb file with Rust kernel\ndf_final.write_csv(\"pills.csv\", sep = \",\")"
  },
  {
    "objectID": "posts/Blog-Update/Update_on_portfolio.html",
    "href": "posts/Blog-Update/Update_on_portfolio.html",
    "title": "Update on portfolio",
    "section": "",
    "text": "So things have gone a little busier than usual behind the scene from last week till this week. As we know it, it’s always hard to plan when things are on the flow, especially in the current climate. So, a little about what I’m working on lately:\n\n\n\nPhoto by RetroSupply on Unsplash\n\n\n\nI’ve started working on an extension project to the rare disease work (recent Python project) by delving further into the natural history of rare diseases by using Orphanet’s data source (having fun working with xml files)\nWith the turn of events lately, I’m now also learning R programming language (which is something I was planning to do much later, but… to do this now is also fine as this’ll keep me on the ball) and surprisingly it is quite similar to Python in some ways but not at all as well\nTableau project most likely needs further work apart from what the dashboard is looking like at the moment (might be still a bit bare) but at the moment, my focus is on above two projects in the meantime. I’ll try to squeeze more time to work on this soon\n\nOther than that, I’m grateful that I can still work on things of great interests and the world is somehow still functioning in its best possible ways – onwards and upwards hopefully."
  },
  {
    "objectID": "posts/21_ML1-1_Small_mols_in_chembl_update/ML1-1-1_chembl_cpds_parquet_new.html",
    "href": "posts/21_ML1-1_Small_mols_in_chembl_update/ML1-1-1_chembl_cpds_parquet_new.html",
    "title": "Small molecules in ChEMBL database",
    "section": "",
    "text": "Why updating this post?\nThree reasons for this:\n\nChEMBL data downloaded straight from the ChEMBL database website is way too large to be uploaded to GitHub - this is one of my very early posts where ChEMBL is completely new to me at the time so I’ve downloaded the ChEMBL data without thinking too much, obviously there are other better and more reproducible ways to source ChEMBL data e.g. my more recent posts or through other ways in the literatures\nNote: GitHub blocks files larger than 100 MiB, which is in mebibytes and equivalent to 1,048,576 bytes or 1.04858 MB (reference) - my bad before as I’ve read “MiB” as “MB” from this GitHub doc!\nPolars seems to be a bit more integrated with scikit-learn now so I’m wondering if Polars dataframe library can be used with scikit-learn solely (i.e. not using Pandas at all)\nThis post is one of my earlier less mature posts (very embarrassing when I’m looking at it now…) so I just want to improve it a little at least\n\n\n\n\nPrevious post updates\nUpdate on 19th April 2024 - Polars is currently more integrated with scikit-learn from version 1.4 (since January 2024), see this link re. Polars output in set_output for Polars dataframe outputs in scikit-learn, and also a few other Polars enhancements from release version 1.4 changelog.\nUpdate on 16th August 2023 - some code updates only, please always refer to Polars API reference for most up-to-date code.\n\n\n\nBackground\nThis is the first part of the series of posts on building a logistic regression model by using scikit-learn with Polars dataframe library (note: the older version of this post also uses Pandas). Polars is a fast (or more commonly known as “blazingly fast”) dataframe library that is written completely in Rust with a very light Python binding that is available for use in Python or Rust programming language. Here I’ll be using Python throughout all posts in the series.\nThis post will only focus on getting the small molecules data ready from ChEMBL database via a straight website download (not recommended if you’re researching or doing virtual experiments that require a good level of data reproducibility, e.g. you’ll need the version of data etc., this is however only a demonstration so I’ll leave it as it is), and then convert the comma separated value (.csv) file into a parquet file (for better file compressions) in order to upload the data into GitHub.\n\n\n\nInstall and import Polars\n\n## To install Polars dataframe library (or install in virtual environments)\n#%pip install polars\n## Update Polars version\n#%pip install --upgrade polars\n\nimport polars as pl\npl.show_versions()\n\n--------Version info---------\nPolars:              1.9.0\nIndex type:          UInt32\nPlatform:            macOS-12.7.6-x86_64-i386-64bit\nPython:              3.11.0 (v3.11.0:deaf509e8f, Oct 24 2022, 14:43:23) [Clang 13.0.0 (clang-1300.0.29.30)]\n\n----Optional dependencies----\nadbc_driver_manager  \n\n\n<not installed>\naltair               \n\n\n5.4.1\ncloudpickle          \n\n\n<not installed>\nconnectorx           \n\n\n<not installed>\ndeltalake            \n\n\n<not installed>\nfastexcel            \n\n\n<not installed>\nfsspec               \n\n\n2024.6.1\ngevent               \n\n\n<not installed>\ngreat_tables         \n\n\n<not installed>\nmatplotlib           \n\n\n3.9.2\nnest_asyncio         \n\n\n1.6.0\nnumpy                \n\n\n1.26.4\nopenpyxl             \n\n\n<not installed>\npandas               \n\n\n2.1.4\npyarrow              \n\n\n17.0.0\npydantic             \n\n\n<not installed>\npyiceberg            \n\n\n<not installed>\nsqlalchemy           \n\n\n<not installed>\ntorch                \n\n\n<not installed>\nxlsx2csv             \n\n\n<not installed>\nxlsxwriter           \n\n\n<not installed>\n\n\n\n\n\nDownload dataset\nThe file being used here will be equivalent to a straight download from the home page of ChEMBL database, via clicking on the “Distinct compounds” (see the circled area in the image below). Options are available to download the files as .csv, .tsv or .sdf formats (located at the top right of the page).\n\n\n\nImage adapted from ChEMBL database website at version 31\n\n\nI’m reading the .csv file first to have an overall look at the data.\n\ndf = pl.read_csv(\"chembl_mols.csv\")\ndf.head()\n\n\n\nshape: (5, 1)ChEMBL ID\";\"Name\";\"Synonyms\";\"Type\";\"Max Phase\";\"Molecular Weight\";\"Targets\";\"Bioactivities\";\"AlogP\";\"Polar Surface Area\";\"HBA\";\"HBD\";\"#RO5 Violations\";\"#Rotatable Bonds\";\"Passes Ro3\";\"QED Weighted\";\"CX Acidic pKa\";\"CX Basic pKa\";\"CX LogP\";\"CX LogD\";\"Aromatic Rings\";\"Structure Type\";\"Inorganic Flag\";\"Heavy Atoms\";\"HBA (Lipinski)\";\"HBD (Lipinski)\";\"#RO5 Violations (Lipinski)\";\"Molecular Weight (Monoisotopic)\";\"Molecular Species\";\"Molecular Formula\";\"Smiles\";\"Inchi Keystr\"CHEMBL1206185;\";\";Small molecu…\"CHEMBL539070;\";\";Small molecul…\"CHEMBL3335528;\";\";Small molecu…\"CHEMBL2419030;\";\";Small molecu…\"CHEMBL4301448;\";\";Small molecu…\n\n\n\n\n\nSome data wrangling and converting a csv file into a parquet file\nA .csv file tends to be separated by delimiters e.g. commas, semicolons or tabs. To read it properly, we can add a delimiter term in the code to transform the dataframe into a more readable format.\nAnother thing being added below is to deal with null values early - by filling in “None” and “” values in the dataframe as “null” first. This will save some hassles later on (I’ve encountered this problem when trying to convert column data types so found out this may be the best way to resolve it).\n\ndf = pl.read_csv(\"chembl_mols.csv\", separator = \";\", null_values = [\"None\", \"\"])\ndf.head()\n#df\n\n\n\nshape: (5, 32)ChEMBL IDNameSynonymsTypeMax PhaseMolecular WeightTargetsBioactivitiesAlogPPolar Surface AreaHBAHBD#RO5 Violations#Rotatable BondsPasses Ro3QED WeightedCX Acidic pKaCX Basic pKaCX LogPCX LogDAromatic RingsStructure TypeInorganic FlagHeavy AtomsHBA (Lipinski)HBD (Lipinski)#RO5 Violations (Lipinski)Molecular Weight (Monoisotopic)Molecular SpeciesMolecular FormulaSmilesInchi Keystrstrstrstri64f64i64i64f64f64i64i64i64i64strf64f64f64f64f64i64stri64i64i64i64i64f64strstrstrstr\"CHEMBL1206185\"nullnull\"Small molecule\"0607.88nullnull9.4689.6252217\"N\"0.09-1.918.389.49.363\"MOL\"-142532607.279\"ACID\"\"C35H45NO4S2\"\"CCCCCCCCCCC#CC(N)c1ccccc1-c1cc…\"UFBLKYIDZFRLPR-UHFFFAOYSA-N\"\"CHEMBL539070\"nullnull\"Small molecule\"0286.79112.2873.066205\"N\"0.6313.843.642.572.572\"MOL\"-117530250.0888\"NEUTRAL\"\"C11H15ClN4OS\"\"CCCOc1ccccc1-c1nnc(NN)s1.Cl\"\"WPEWNRKLKLNLSO-UHFFFAOYSA-N\"\"CHEMBL3335528\"nullnull\"Small molecule\"0842.8260.18269.57185217\"N\"0.093.2null3.31-0.143\"MOL\"-1601952842.2633\"ACID\"\"C41H46O19\"\"COC(=O)[C@H](O[C@@H]1O[C@@H](C…\"KGUJQZWYZPYYRZ-LWEWUKDVSA-N\"\"CHEMBL2419030\"nullnull\"Small molecule\"0359.33443.9485.136103\"N\"0.66nullnull3.663.662\"MOL\"-124610359.0551\"NEUTRAL\"\"C14H12F3N3O3S\"\"O=c1nc(NC2CCCC2)sc2c([N+](=O)[…\"QGDMYSDFCXOKML-UHFFFAOYSA-N\"\"CHEMBL4301448\"nullnull\"Small molecule\"0465.55nullnull5.09105.2864110\"N\"0.15null12.144.412.04\"MOL\"-133751465.1635\"BASE\"\"C24H24FN5O2S\"\"N=C(N)NCCCOc1ccc(CNc2nc3ccc(Oc…\"RXTJPHLPHOZLFS-UHFFFAOYSA-N\"\n\n\nBelow is a series of data checks and cleaning that’ll reduce the original .csv file size (about 664.8 MB) into something more manageable. My goal is to get a parquet file under 104 MB which can then be uploaded to GitHub without using Git large file storage (this will be the last resort if this fails).\nI’m checking the “Type” column first.\n\ndf.group_by(\"Type\").len()\n\n\n\nshape: (11, 2)Typelenstru32\"Unknown\"18015null369155\"Cell\"47\"Gene\"77\"Oligonucleotide\"170……\"Antibody\"974\"Enzyme\"118\"Small molecule\"1920366\"Oligosaccharide\"92\"Unclassified\"4\n\n\nThe dataframe is further reduced in size by filtering the data for small molecules only, which are what I aim to look at.\n\ndf_sm = df.filter((pl.col(\"Type\") == \"Small molecule\"))\ndf_sm #1,920,366 entries\n\n\n\nshape: (1_920_366, 32)ChEMBL IDNameSynonymsTypeMax PhaseMolecular WeightTargetsBioactivitiesAlogPPolar Surface AreaHBAHBD#RO5 Violations#Rotatable BondsPasses Ro3QED WeightedCX Acidic pKaCX Basic pKaCX LogPCX LogDAromatic RingsStructure TypeInorganic FlagHeavy AtomsHBA (Lipinski)HBD (Lipinski)#RO5 Violations (Lipinski)Molecular Weight (Monoisotopic)Molecular SpeciesMolecular FormulaSmilesInchi Keystrstrstrstri64f64i64i64f64f64i64i64i64i64strf64f64f64f64f64i64stri64i64i64i64i64f64strstrstrstr\"CHEMBL1206185\"nullnull\"Small molecule\"0607.88nullnull9.4689.6252217\"N\"0.09-1.918.389.49.363\"MOL\"-142532607.279\"ACID\"\"C35H45NO4S2\"\"CCCCCCCCCCC#CC(N)c1ccccc1-c1cc…\"UFBLKYIDZFRLPR-UHFFFAOYSA-N\"\"CHEMBL539070\"nullnull\"Small molecule\"0286.79112.2873.066205\"N\"0.6313.843.642.572.572\"MOL\"-117530250.0888\"NEUTRAL\"\"C11H15ClN4OS\"\"CCCOc1ccccc1-c1nnc(NN)s1.Cl\"\"WPEWNRKLKLNLSO-UHFFFAOYSA-N\"\"CHEMBL3335528\"nullnull\"Small molecule\"0842.8260.18269.57185217\"N\"0.093.2null3.31-0.143\"MOL\"-1601952842.2633\"ACID\"\"C41H46O19\"\"COC(=O)[C@H](O[C@@H]1O[C@@H](C…\"KGUJQZWYZPYYRZ-LWEWUKDVSA-N\"\"CHEMBL2419030\"nullnull\"Small molecule\"0359.33443.9485.136103\"N\"0.66nullnull3.663.662\"MOL\"-124610359.0551\"NEUTRAL\"\"C14H12F3N3O3S\"\"O=c1nc(NC2CCCC2)sc2c([N+](=O)[…\"QGDMYSDFCXOKML-UHFFFAOYSA-N\"\"CHEMBL4301448\"nullnull\"Small molecule\"0465.55nullnull5.09105.2864110\"N\"0.15null12.144.412.04\"MOL\"-133751465.1635\"BASE\"\"C24H24FN5O2S\"\"N=C(N)NCCCOc1ccc(CNc2nc3ccc(Oc…\"RXTJPHLPHOZLFS-UHFFFAOYSA-N\"……………………………………………………………………………………\"CHEMBL2017916\"nullnull\"Small molecule\"0312.35332.8677.06104\"N\"0.88.133.492.172.13\"MOL\"-122610312.0681\"NEUTRAL\"\"C15H12N4O2S\"\"COc1ccc(-c2nnc(NC(=O)c3cccnc3)…\"XIZUJGDKNPVNQA-UHFFFAOYSA-N\"\"CHEMBL374652\"nullnull\"Small molecule\"0403.83115.9836.022214\"N\"0.4213.65null5.365.363\"MOL\"-126221403.0421\"NEUTRAL\"\"C18H14ClF4NOS\"\"CC(O)(CSc1ccc(F)cc1)c1cc2cc(Cl…\"CRPQTBRTHURKII-UHFFFAOYSA-N\"\"CHEMBL1416264\"nullnull\"Small molecule\"0380.41683.0685.077105\"N\"0.5413.853.862.472.474\"MOL\"-127710380.0856\"NEUTRAL\"\"C18H13FN6OS\"\"O=C(CSc1ccc2nnc(-c3cccnc3)n2n1…\"QVYIEKHEJKFNAT-UHFFFAOYSA-N\"\"CHEMBL213734\"nullnull\"Small molecule\"0288.26232.32101.75205\"N\"0.57.2null2.361.952\"MOL\"-121720288.0746\"NEUTRAL\"\"C14H12N2O5\"\"O=C(COc1ccccc1)Nc1ccc([N+](=O)…\"PZTWAHGBGTWVEB-UHFFFAOYSA-N\"\"CHEMBL1531634\"nullnull\"Small molecule\"0320.1619214.429.12104\"N\"0.67nullnull4.044.042\"MOL\"-119210319.0008\"NEUTRAL\"\"C15H11BrFNO\"\"O=C(/C=C/Nc1ccc(F)cc1)c1ccc(Br…\"DKPWCCDDKFLKEC-MDZDMXLPSA-N\"\n\n\nI’m looking at “Structure Type” column next.\n\ndf_sm.group_by(\"Structure Type\").len()\n\n\n\nshape: (4, 2)Structure Typelenstru32\"MOL\"1914876\"BOTH\"4\"NONE\"5485\"SEQ\"1\n\n\nThere are 5485 entries with “NONE” as “Structure Type” which means they have unknown compound structures or not recorded in either compound_structures table or protein_therapeutics table. These entries will be removed from df_sm first.\nNext, I’m filtering the df_sm dataset further by restricting the filters to only small molecules and excluding all “NONE” structure types.\n\ndf_sm = df.filter((pl.col(\"Type\") == \"Small molecule\") & (pl.col(\"Structure Type\") != \"NONE\"))\n\ndf_sm #1,914,881 entries\n\n\n\nshape: (1_914_881, 32)ChEMBL IDNameSynonymsTypeMax PhaseMolecular WeightTargetsBioactivitiesAlogPPolar Surface AreaHBAHBD#RO5 Violations#Rotatable BondsPasses Ro3QED WeightedCX Acidic pKaCX Basic pKaCX LogPCX LogDAromatic RingsStructure TypeInorganic FlagHeavy AtomsHBA (Lipinski)HBD (Lipinski)#RO5 Violations (Lipinski)Molecular Weight (Monoisotopic)Molecular SpeciesMolecular FormulaSmilesInchi Keystrstrstrstri64f64i64i64f64f64i64i64i64i64strf64f64f64f64f64i64stri64i64i64i64i64f64strstrstrstr\"CHEMBL1206185\"nullnull\"Small molecule\"0607.88nullnull9.4689.6252217\"N\"0.09-1.918.389.49.363\"MOL\"-142532607.279\"ACID\"\"C35H45NO4S2\"\"CCCCCCCCCCC#CC(N)c1ccccc1-c1cc…\"UFBLKYIDZFRLPR-UHFFFAOYSA-N\"\"CHEMBL539070\"nullnull\"Small molecule\"0286.79112.2873.066205\"N\"0.6313.843.642.572.572\"MOL\"-117530250.0888\"NEUTRAL\"\"C11H15ClN4OS\"\"CCCOc1ccccc1-c1nnc(NN)s1.Cl\"\"WPEWNRKLKLNLSO-UHFFFAOYSA-N\"\"CHEMBL3335528\"nullnull\"Small molecule\"0842.8260.18269.57185217\"N\"0.093.2null3.31-0.143\"MOL\"-1601952842.2633\"ACID\"\"C41H46O19\"\"COC(=O)[C@H](O[C@@H]1O[C@@H](C…\"KGUJQZWYZPYYRZ-LWEWUKDVSA-N\"\"CHEMBL2419030\"nullnull\"Small molecule\"0359.33443.9485.136103\"N\"0.66nullnull3.663.662\"MOL\"-124610359.0551\"NEUTRAL\"\"C14H12F3N3O3S\"\"O=c1nc(NC2CCCC2)sc2c([N+](=O)[…\"QGDMYSDFCXOKML-UHFFFAOYSA-N\"\"CHEMBL4301448\"nullnull\"Small molecule\"0465.55nullnull5.09105.2864110\"N\"0.15null12.144.412.04\"MOL\"-133751465.1635\"BASE\"\"C24H24FN5O2S\"\"N=C(N)NCCCOc1ccc(CNc2nc3ccc(Oc…\"RXTJPHLPHOZLFS-UHFFFAOYSA-N\"……………………………………………………………………………………\"CHEMBL2017916\"nullnull\"Small molecule\"0312.35332.8677.06104\"N\"0.88.133.492.172.13\"MOL\"-122610312.0681\"NEUTRAL\"\"C15H12N4O2S\"\"COc1ccc(-c2nnc(NC(=O)c3cccnc3)…\"XIZUJGDKNPVNQA-UHFFFAOYSA-N\"\"CHEMBL374652\"nullnull\"Small molecule\"0403.83115.9836.022214\"N\"0.4213.65null5.365.363\"MOL\"-126221403.0421\"NEUTRAL\"\"C18H14ClF4NOS\"\"CC(O)(CSc1ccc(F)cc1)c1cc2cc(Cl…\"CRPQTBRTHURKII-UHFFFAOYSA-N\"\"CHEMBL1416264\"nullnull\"Small molecule\"0380.41683.0685.077105\"N\"0.5413.853.862.472.474\"MOL\"-127710380.0856\"NEUTRAL\"\"C18H13FN6OS\"\"O=C(CSc1ccc2nnc(-c3cccnc3)n2n1…\"QVYIEKHEJKFNAT-UHFFFAOYSA-N\"\"CHEMBL213734\"nullnull\"Small molecule\"0288.26232.32101.75205\"N\"0.57.2null2.361.952\"MOL\"-121720288.0746\"NEUTRAL\"\"C14H12N2O5\"\"O=C(COc1ccccc1)Nc1ccc([N+](=O)…\"PZTWAHGBGTWVEB-UHFFFAOYSA-N\"\"CHEMBL1531634\"nullnull\"Small molecule\"0320.1619214.429.12104\"N\"0.67nullnull4.044.042\"MOL\"-119210319.0008\"NEUTRAL\"\"C15H11BrFNO\"\"O=C(/C=C/Nc1ccc(F)cc1)c1ccc(Br…\"DKPWCCDDKFLKEC-MDZDMXLPSA-N\"\n\n\n\n# Check \"NONE\" entries are removed/filtered\ndf_sm.group_by(\"Structure Type\").len()\n\n\n\nshape: (3, 2)Structure Typelenstru32\"SEQ\"1\"MOL\"1914876\"BOTH\"4\n\n\nI’ve tried filtering out data using “Inorganic flag” previously, however it turns out to be not so suitable - it’ll rule out a lot of preclinical compounds with max phase 0 or max phase > 1 compounds with no calculated physicochemical properties, which means there may not be enough training data to build a machine learning model. So I’m opting for the “Targets” column here by ruling out the ones with zero targets.\n\ndf_sm.group_by(\"Targets\").len()\n\n\n\nshape: (553, 2)Targetsleni64u3228986913702715365954081……86919527652134835151\n\n\n\ndf_sm = df.filter((pl.col(\"Type\") == \"Small molecule\") & (pl.col(\"Structure Type\") != \"NONE\") & (pl.col(\"Targets\") > 0 ))\n\ndf_sm #1,831,560 entries\n\n\n\nshape: (1_831_560, 32)ChEMBL IDNameSynonymsTypeMax PhaseMolecular WeightTargetsBioactivitiesAlogPPolar Surface AreaHBAHBD#RO5 Violations#Rotatable BondsPasses Ro3QED WeightedCX Acidic pKaCX Basic pKaCX LogPCX LogDAromatic RingsStructure TypeInorganic FlagHeavy AtomsHBA (Lipinski)HBD (Lipinski)#RO5 Violations (Lipinski)Molecular Weight (Monoisotopic)Molecular SpeciesMolecular FormulaSmilesInchi Keystrstrstrstri64f64i64i64f64f64i64i64i64i64strf64f64f64f64f64i64stri64i64i64i64i64f64strstrstrstr\"CHEMBL539070\"nullnull\"Small molecule\"0286.79112.2873.066205\"N\"0.6313.843.642.572.572\"MOL\"-117530250.0888\"NEUTRAL\"\"C11H15ClN4OS\"\"CCCOc1ccccc1-c1nnc(NN)s1.Cl\"\"WPEWNRKLKLNLSO-UHFFFAOYSA-N\"\"CHEMBL3335528\"nullnull\"Small molecule\"0842.8260.18269.57185217\"N\"0.093.2null3.31-0.143\"MOL\"-1601952842.2633\"ACID\"\"C41H46O19\"\"COC(=O)[C@H](O[C@@H]1O[C@@H](C…\"KGUJQZWYZPYYRZ-LWEWUKDVSA-N\"\"CHEMBL2419030\"nullnull\"Small molecule\"0359.33443.9485.136103\"N\"0.66nullnull3.663.662\"MOL\"-124610359.0551\"NEUTRAL\"\"C14H12F3N3O3S\"\"O=c1nc(NC2CCCC2)sc2c([N+](=O)[…\"QGDMYSDFCXOKML-UHFFFAOYSA-N\"\"CHEMBL3827271\"nullnull\"Small molecule\"0712.8511-2.84319.061011216\"N\"0.074.0810.49-6.88-8.950\"MOL\"-15019143712.4232\"ZWITTERION\"\"C31H56N10O9\"\"CC(C)C[C@@H]1NC(=O)[C@H](CCCNC…\"QJQNNLICZLLPMB-VUBDRERZSA-N\"\"CHEMBL3465961\"nullnull\"Small molecule\"0319.4216222.2250.54106\"N\"0.87null9.382.13-0.441\"MOL\"-123410319.206\"BASE\"\"C18H26FN3O\"\"CC(O)CN1CCC(CN(C)Cc2cc(C#N)ccc…\"FZEVYCHTADTXPM-UHFFFAOYSA-N\"……………………………………………………………………………………\"CHEMBL2017916\"nullnull\"Small molecule\"0312.35332.8677.06104\"N\"0.88.133.492.172.13\"MOL\"-122610312.0681\"NEUTRAL\"\"C15H12N4O2S\"\"COc1ccc(-c2nnc(NC(=O)c3cccnc3)…\"XIZUJGDKNPVNQA-UHFFFAOYSA-N\"\"CHEMBL374652\"nullnull\"Small molecule\"0403.83115.9836.022214\"N\"0.4213.65null5.365.363\"MOL\"-126221403.0421\"NEUTRAL\"\"C18H14ClF4NOS\"\"CC(O)(CSc1ccc(F)cc1)c1cc2cc(Cl…\"CRPQTBRTHURKII-UHFFFAOYSA-N\"\"CHEMBL1416264\"nullnull\"Small molecule\"0380.41683.0685.077105\"N\"0.5413.853.862.472.474\"MOL\"-127710380.0856\"NEUTRAL\"\"C18H13FN6OS\"\"O=C(CSc1ccc2nnc(-c3cccnc3)n2n1…\"QVYIEKHEJKFNAT-UHFFFAOYSA-N\"\"CHEMBL213734\"nullnull\"Small molecule\"0288.26232.32101.75205\"N\"0.57.2null2.361.952\"MOL\"-121720288.0746\"NEUTRAL\"\"C14H12N2O5\"\"O=C(COc1ccccc1)Nc1ccc([N+](=O)…\"PZTWAHGBGTWVEB-UHFFFAOYSA-N\"\"CHEMBL1531634\"nullnull\"Small molecule\"0320.1619214.429.12104\"N\"0.67nullnull4.044.042\"MOL\"-119210319.0008\"NEUTRAL\"\"C15H11BrFNO\"\"O=C(/C=C/Nc1ccc(F)cc1)c1ccc(Br…\"DKPWCCDDKFLKEC-MDZDMXLPSA-N\"\n\n\nThe next step is to save the dataframe as a parquet file.\nReference: Apache Parquet documentations\nI have tried two main different ways where one is using the write_parquet() by only adding file compression level parameter (the “without partition” way), and the other one using use_pyarrow & pyarrow_options to partition datasets. The changes in parquet file size are shown in the following two tables.\n```{python}\n# Without partitioning dataset\nfrom pathlib import Path\npath = Path.cwd() / \"chembl_sm_mols.parquet\"\ndf_sm.write_parquet(path, compression_level=22)\n```\n\nParquet file size changes without data partitions (note: original .csv file size is 664.8 MB)\n\n\n\n\n\n\n\n\nCompression level\nData restrictions\nFile size\nNumber of entries\n\n\n\n\n22\n\nNone\n\n127.3 MB\n2,331,700\n\n\n22\n\nSmall molecules only\n\n105.4 MB\n1,920,366\n\n\n22\n\nSmall molecules only\nExclude structure type with “NONE”\n\n105.1 MB\n1,914,881\n\n\n22\n\nSmall molecules only\nExclude structure type with “NONE”\nRemove compounds with no targets\n\n100.4 MB\n1,831,560\n\n\n\n```{python}\n# Partitioning dataset\npath = Path.cwd() / \"chembl_mols_type_part\"\ndf.write_parquet(\n    path,\n    #compression_level=20,\n    use_pyarrow=True,\n    pyarrow_options={\"partition_cols\": [\"Type\"]},\n)\n```\n\nParquet file size changes with data partitions (note: original .csv file size is 664.8 MB)\n\n\n\n\n\n\n\n\nCompression level\nData restrictions\nFile size\nNumber of entries\n\n\n\n\ndefault\nNone\n\nusing “Max Phase” as partition column\nmax phase 0 > 104 MB\nmax phases 1-4: each < 104 MB\n\n2,331,700\n\n\n15\nNone\n\nmax phase 0 > 104 MB\nmax phase 1-4: each < 104 MB\n\n2,331,700\n\n\n20\nNone\n\nsimilar sizes as mentioned above\n\n2,331,700\n\n\ndefault\nNone\n\nusing “Type” as partition column\n“Small molecule” file size = 135.2 MB\n\n2,331,700\n\n\n\nFinally, it appears that the one with three data restrictions at compression level of 22 has produced a file at 100.4 MB. I’m reading this file below into a dataframe to see if it’s working.\n\ndf_pa = pl.read_parquet(\"chembl_sm_mols.parquet\")\ndf_pa\n\n\n\nshape: (1_831_560, 32)ChEMBL IDNameSynonymsTypeMax PhaseMolecular WeightTargetsBioactivitiesAlogPPolar Surface AreaHBAHBD#RO5 Violations#Rotatable BondsPasses Ro3QED WeightedCX Acidic pKaCX Basic pKaCX LogPCX LogDAromatic RingsStructure TypeInorganic FlagHeavy AtomsHBA (Lipinski)HBD (Lipinski)#RO5 Violations (Lipinski)Molecular Weight (Monoisotopic)Molecular SpeciesMolecular FormulaSmilesInchi Keystrstrstrstri64f64i64i64f64f64i64i64i64i64strf64f64f64f64f64i64stri64i64i64i64i64f64strstrstrstr\"CHEMBL539070\"nullnull\"Small molecule\"0286.79112.2873.066205\"N\"0.6313.843.642.572.572\"MOL\"-117530250.0888\"NEUTRAL\"\"C11H15ClN4OS\"\"CCCOc1ccccc1-c1nnc(NN)s1.Cl\"\"WPEWNRKLKLNLSO-UHFFFAOYSA-N\"\"CHEMBL3335528\"nullnull\"Small molecule\"0842.8260.18269.57185217\"N\"0.093.2null3.31-0.143\"MOL\"-1601952842.2633\"ACID\"\"C41H46O19\"\"COC(=O)[C@H](O[C@@H]1O[C@@H](C…\"KGUJQZWYZPYYRZ-LWEWUKDVSA-N\"\"CHEMBL2419030\"nullnull\"Small molecule\"0359.33443.9485.136103\"N\"0.66nullnull3.663.662\"MOL\"-124610359.0551\"NEUTRAL\"\"C14H12F3N3O3S\"\"O=c1nc(NC2CCCC2)sc2c([N+](=O)[…\"QGDMYSDFCXOKML-UHFFFAOYSA-N\"\"CHEMBL3827271\"nullnull\"Small molecule\"0712.8511-2.84319.061011216\"N\"0.074.0810.49-6.88-8.950\"MOL\"-15019143712.4232\"ZWITTERION\"\"C31H56N10O9\"\"CC(C)C[C@@H]1NC(=O)[C@H](CCCNC…\"QJQNNLICZLLPMB-VUBDRERZSA-N\"\"CHEMBL3465961\"nullnull\"Small molecule\"0319.4216222.2250.54106\"N\"0.87null9.382.13-0.441\"MOL\"-123410319.206\"BASE\"\"C18H26FN3O\"\"CC(O)CN1CCC(CN(C)Cc2cc(C#N)ccc…\"FZEVYCHTADTXPM-UHFFFAOYSA-N\"……………………………………………………………………………………\"CHEMBL2017916\"nullnull\"Small molecule\"0312.35332.8677.06104\"N\"0.88.133.492.172.13\"MOL\"-122610312.0681\"NEUTRAL\"\"C15H12N4O2S\"\"COc1ccc(-c2nnc(NC(=O)c3cccnc3)…\"XIZUJGDKNPVNQA-UHFFFAOYSA-N\"\"CHEMBL374652\"nullnull\"Small molecule\"0403.83115.9836.022214\"N\"0.4213.65null5.365.363\"MOL\"-126221403.0421\"NEUTRAL\"\"C18H14ClF4NOS\"\"CC(O)(CSc1ccc(F)cc1)c1cc2cc(Cl…\"CRPQTBRTHURKII-UHFFFAOYSA-N\"\"CHEMBL1416264\"nullnull\"Small molecule\"0380.41683.0685.077105\"N\"0.5413.853.862.472.474\"MOL\"-127710380.0856\"NEUTRAL\"\"C18H13FN6OS\"\"O=C(CSc1ccc2nnc(-c3cccnc3)n2n1…\"QVYIEKHEJKFNAT-UHFFFAOYSA-N\"\"CHEMBL213734\"nullnull\"Small molecule\"0288.26232.32101.75205\"N\"0.57.2null2.361.952\"MOL\"-121720288.0746\"NEUTRAL\"\"C14H12N2O5\"\"O=C(COc1ccccc1)Nc1ccc([N+](=O)…\"PZTWAHGBGTWVEB-UHFFFAOYSA-N\"\"CHEMBL1531634\"nullnull\"Small molecule\"0320.1619214.429.12104\"N\"0.67nullnull4.044.042\"MOL\"-119210319.0008\"NEUTRAL\"\"C15H11BrFNO\"\"O=C(/C=C/Nc1ccc(F)cc1)c1ccc(Br…\"DKPWCCDDKFLKEC-MDZDMXLPSA-N\"\n\n\nSo it looks like it does. The next series of posts will be about trying to use Polars dataframe library all the way with scikit-learn.\nNote: the way I’ve compressed the original data file may not be the best as I’m losing some data along the way by restricting the number of data entries. There are definitely other better ways out there, please use this example with care."
  },
  {
    "objectID": "posts/21_ML1-1_Small_mols_in_chembl_update/ML1-1-3_chembl_cpds_ml_model.html",
    "href": "posts/21_ML1-1_Small_mols_in_chembl_update/ML1-1-3_chembl_cpds_ml_model.html",
    "title": "Small molecules in ChEMBL database",
    "section": "",
    "text": "Import libraries\nThis is the third post that follows on from the previous two about parquet file and data preprocessing, and it will need the following libraries to build and train a logistic regression (LR) model before using it to predict max phase outcome on a testing dataset by using scikit-learn.\n\n## using magic pip to install sklearn & altair (somehow venv keeps switching off in vscode...)\n# %pip install -U scikit-learn\n# %pip install altair\n\nimport sklearn\nprint(f\"scikit-learn version used is: {sklearn.__version__}\")\nfrom sklearn import preprocessing, set_config\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nimport polars as pl\nprint(f\"polars version used is: {pl.__version__}\")\nimport altair as alt\nprint(f\"altair version used is: {alt.__version__}\")\nimport pickle\nimport numpy as np\n\nscikit-learn version used is: 1.5.0\n\n\npolars version used is: 1.9.0\n\n\naltair version used is: 5.4.1\n\n\nThe same set of data saved in the previous post will be read here using polars dataframe library.\n\ndf = pl.read_csv(\"df_ml.csv\")\ndf\n\n\n\nshape: (5_670, 9)Max_PhasePolar Surface AreaHBAHBD#RO5 ViolationsQED WeightedCX LogPCX LogDHeavy Atomsi64f64i64i64i64f64f64f64i64066.814100.473.943.9432062.553100.933.383.3825073.865120.129.349.3440084.224200.762.01-0.1926040.464000.624.04.026………………………1128.038200.492.091.863410.00000.00.00.00174.026100.683.652.330194.834300.441.2-1.1812195.926100.91.661.6618\n\n\n\n\n\nLogistic regression with scikit-learn\nLR is one of the supervised methods in the statistical machine learning (ML) area. As the term “supervised” suggests, this type of ML is purely data-driven to allow computers to learn patterns from the input data with known outcomes in order to predict the same target outcomes for a different set of data that is previously unseen by the computer.\n\nDefine X and y variables\nThe dataset will be splitted into X (features) and y (target) variables first.\n\n# Define X variables\nX = df[\"#RO5 Violations\", \"Polar Surface Area\", \"HBA\", \"HBD\", \"QED Weighted\", \"CX LogP\", \"CX LogD\", \"Heavy Atoms\"]\nX\n\n\n\nshape: (5_670, 8)#RO5 ViolationsPolar Surface AreaHBAHBDQED WeightedCX LogPCX LogDHeavy Atomsi64f64i64i64f64f64f64i64066.81410.473.943.9432062.55310.933.383.3825273.86510.129.349.3440084.22420.762.01-0.1926040.46400.624.04.026……………………0128.03820.492.091.863400.0000.00.00.00074.02610.683.652.330094.83430.441.2-1.1812095.92610.91.661.6618\n\n\n\n# Define y variable\ny = df[\"Max_Phase\"]\ny\n\n\n\nshape: (5_670,)Max_Phasei6400000…11111\n\n\nNote: no need to use to_numpy() as there’s a transform step included when using pipeline to create a LR model (also StandardScaler() going to be used). This also applies if using fit_transform() or transform() when not using pipeline - see scikit-learn reference on “transform”.\n\n\n\nPrepare training and testing sets\nThen the data will be further splitted into separate training and testing sets.\n\n## Random number generator\n#rng = np.random.RandomState(0) - note: this may produce different result each time\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 50)\nprint('Training set:', X_train.shape, y_train.shape)\nprint('Testing set:', X_test.shape, y_test.shape)\n\nTraining set: (4536, 8) (4536,)\nTesting set: (1134, 8) (1134,)\n\n\n\n\n\nPipeline method\nSome benefits of using pipeline (scikit-learn reference):\n\nchaining preprocessing step with different transformers and estimators in one go where we only have to call fit and predict once on our data\navoiding data leakage from the testing set into the training set by making sure the same set of samples is used to train the transformers and predictors\navoiding missing out on the transform step (note: calling fit() on pipeline is equivalent to calling fit() on each estimator and transform() input data before the next step, plus StandardScaler() is going to be used in the pipeline as well - repeating myself here but this is just a gentle reminder…)\n\nThe example below uses Pipeline() to construct a pipeline that takes in a standard scaler to scale data and also a LR estimator, along with some parameters.\n\n## Pipeline:\n\n# Ensure prediction output can be read in polars df\nset_config(transform_output=\"polars\")\n\n# multi_class defaults to 'auto' which selects 'ovr' if the data is binary, or if solver='liblinear'\n# multi_class is deprecated in version 1.5 and will be removed in 1.7 \n# this post uses sklearn version 1.5.0\nparams_lr = {\n  # solver for small dataset\n  \"solver\": \"liblinear\",\n  \"random_state\": 50\n}\n\nLR = Pipeline(steps=[\n  # Preprocess/scale the dataset (transformer)\n  (\"StandardScaler\", StandardScaler()), # can add set_output() if preferred\n  # e.g. StandardScaler().set_output(transform=\"polars\")\n  # Create an instance of LR classifier (estimator)\n  (\"LogR\", LogisticRegression(**params_lr))\n  ])\n\n# can add set_output() if preferred e.g. LR.set_output(transform=\"polars\")\nLR.fit(X_train, y_train)\npred = LR.predict(X_test)\nLR.score(X_test, y_test)\n\n0.689594356261023\n\n\nDuring the pipeline building, I’ve figured out how to integrate set_output() in Polars, and noted that the best use case is to show the feature_names_in_ along with coef_ (scikit-learn reference). The first issue is that the feature names are being generated as “[x0, x1, x2…]”, which is not useful. One of the possible reasons could be because all the molecular features are not in strings (as they’re either i64 or f64), so the feature names are not shown - I’m actually unsure about this but this is just my guess.\nOne of the other ways I’ve tried is to use ColumnTransformer() within the pipeline (scikit-learn reference - code example folded below) but unfortunately it hasn’t worked as well as expected.\n\n\nCode\n# from sklearn.compose import ColumnTransformer\n# num_cols = [\"#RO5 Violations\", \"Polar Surface Area\", \"HBA\", \"HBD\", \"QED Weighted\", \"CX LogP\", \"CX LogD\", \"Heavy Atoms\"]\n# ct = ColumnTransformer(\n#     (\"numerical\", num_cols),\n#     verbose_feature_names_out=False,\n#   )\n# ct.set_output(transform=\"polars\")\n\n\nThe pipeline above is the final version that works to show molecular feature names with their corresponding coefficients in a polars dataframe output. There are 3 options to add either set_config(transform_output=\"polars\") or set_output(transform_output=\"polars\") with the pipeline code - only really needing one line (and not all 3 - it’ll still work but probably unnecessary to add extra code). I’ve marked all 3 options in the pipeline code above.\n\n\n\nMolecular features and coefficients\nNext, I’m calling out the LR model used above in the pipeline as we want to get the feature names used for training and predicting along with their corresponding coefficients, and generate a bar chart to show their relationship (reference on plotting directly in Polars using Altair).\n\nlog_reg = LR[-1]\nlog_reg\n\nLogisticRegression(random_state=50, solver='liblinear')In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  LogisticRegression?Documentation for LogisticRegressioniFittedLogisticRegression(random_state=50, solver='liblinear') \n\n\n\n# Save feature array as df\nlr_feat = pl.Series(log_reg.feature_names_in_).to_frame(\"Feature_names\")\n# Explode df due to a list series - e.g. array([[1, 2, 3...]]) and not array([1, 2, 3...])\nlr_coef = pl.Series(log_reg.coef_).to_frame(\"Coef\").explode(\"Coef\")\n# Concatenate dfs horizontally\ndf_feat = pl.concat([lr_feat, lr_coef], how=\"horizontal\")\n\n# Using altair to plot feature names vs. coefficients \ndf_feat.plot.bar(\n  x=\"Coef\", \n  # -x = sorting in descending order, x = ascending\n  y=alt.Y(\"Feature_names\").sort(\"-x\"), \n  #color=\"Feature_names\", #will create a legend if used\n  tooltip=\"Coef\",\n).configure_axis(\n  labelFontSize=15,\n  titleFontSize=15\n).configure_view(\n  continuousWidth=600,\n  discreteHeight=300\n)\n\n\n\n\n\n\n\n#RO5 Violations, CXLogP, HBA and HBD all have positive weights or coefficients, when the rest of the molecular features (CXLogD, heavy atoms, polar surface area and QED Weighted) all have the negative coefficients. This is likely the equivalent of using the feature_importances_ in random forest I’m guessing. I’ve sorted the order of coefficients from highest to lowest in the chart.\nAnother way to get features names is from the pipeline as well but requires a step saving dataframe column names separately as an NumPy array first (scikit-learn reference). The previous way seems to save a bit more time on coding as there’s no need to do this, and also you can retrieve the coefficients of the features at the same time.\n\n\nCode\n## note: df.columns = column names of physicochemical properties\n# feat_names = pl.Series(\"feat_names\", df.columns[1:])\n# LR[:-1].get_feature_names_out(feat_names)\n\n\n\n\n\nPredicted probabilities\nOne way to get predicted probabilities of the samples in each outcome class (either 0 - not approved or 1 - approved) is via predict_proba() in scikit-learn.\n\ny_mp_pre_proba = LR.predict_proba(X_test)\nprint(y_mp_pre_proba)\n\n[[0.45825999 0.54174001]\n [0.15229678 0.84770322]\n [0.38040658 0.61959342]\n ...\n [0.29652    0.70348   ]\n [0.83812298 0.16187702]\n [0.45729476 0.54270524]]\n\n\nThen we can convert the predicted probabilities into a polars dataframe, along with a statistics summary.\n\npl.DataFrame(y_mp_pre_proba).describe()\n\n\n\nshape: (9, 3)statisticcolumn_0column_1strf64f64\"count\"1134.01134.0\"null_count\"0.00.0\"mean\"0.4864420.513558\"std\"0.1996520.199652\"min\"0.004590.044198\"25%\"0.3414630.360326\"50%\"0.5068030.493416\"75%\"0.6396740.658537\"max\"0.9558020.99541\n\n\n\n\n\nPickle LR pipeline\nThis last part is really for saving the LR pipeline for the next post on evaluating the LR model. I’ve talked a bit more about the security aspect of pickling files in this old post in case anyone’s interested.\n\n# Pickle to save (serialise) the model in working directory (specify path if needed)\npickle.dump(LR, open(\"LR.pkl\", \"wb\")) # \"wb\" - write binary\n# Unpickle (de-serialise) the model\nLR2 = pickle.load(open(\"LR.pkl\", \"rb\")) # \"rb\" - read binary\n# Use the unpickled model object to make prediction\npred2 = LR2.predict(X_test)\n## Check unpickled model and original model are the same via Python's assertion method\n#assert np.sum(np.abs(pred2 - pred)) == 0\n## or alternatively use numpy's allclose()\nprint(np.allclose(pred, pred2)) # note: pred = LR.predict(X_test) from original LR pipeline\n\nTrue"
  },
  {
    "objectID": "posts/21_ML1-1_Small_mols_in_chembl_update/ML1-1-2_chembl_cpds_prep.html",
    "href": "posts/21_ML1-1_Small_mols_in_chembl_update/ML1-1-2_chembl_cpds_prep.html",
    "title": "Small molecules in ChEMBL database",
    "section": "",
    "text": "Import Polars and read parquet file\nThis second post will mostly be about doing some data preprocessing for the parquet file we’ve saved from the first post, trying to get the data in a reasonable state before moving onto the machine learning model building and training phase. The first step is to import Polars dataframe library and then read the parquet file as a dataframe.\n\nimport polars as pl\ndf_pa = pl.read_parquet(\"chembl_sm_mols.parquet\")\ndf_pa\n\n\n\nshape: (1_831_560, 32)ChEMBL IDNameSynonymsTypeMax PhaseMolecular WeightTargetsBioactivitiesAlogPPolar Surface AreaHBAHBD#RO5 Violations#Rotatable BondsPasses Ro3QED WeightedCX Acidic pKaCX Basic pKaCX LogPCX LogDAromatic RingsStructure TypeInorganic FlagHeavy AtomsHBA (Lipinski)HBD (Lipinski)#RO5 Violations (Lipinski)Molecular Weight (Monoisotopic)Molecular SpeciesMolecular FormulaSmilesInchi Keystrstrstrstri64f64i64i64f64f64i64i64i64i64strf64f64f64f64f64i64stri64i64i64i64i64f64strstrstrstr\"CHEMBL539070\"nullnull\"Small molecule\"0286.79112.2873.066205\"N\"0.6313.843.642.572.572\"MOL\"-117530250.0888\"NEUTRAL\"\"C11H15ClN4OS\"\"CCCOc1ccccc1-c1nnc(NN)s1.Cl\"\"WPEWNRKLKLNLSO-UHFFFAOYSA-N\"\"CHEMBL3335528\"nullnull\"Small molecule\"0842.8260.18269.57185217\"N\"0.093.2null3.31-0.143\"MOL\"-1601952842.2633\"ACID\"\"C41H46O19\"\"COC(=O)[C@H](O[C@@H]1O[C@@H](C…\"KGUJQZWYZPYYRZ-LWEWUKDVSA-N\"\"CHEMBL2419030\"nullnull\"Small molecule\"0359.33443.9485.136103\"N\"0.66nullnull3.663.662\"MOL\"-124610359.0551\"NEUTRAL\"\"C14H12F3N3O3S\"\"O=c1nc(NC2CCCC2)sc2c([N+](=O)[…\"QGDMYSDFCXOKML-UHFFFAOYSA-N\"\"CHEMBL3827271\"nullnull\"Small molecule\"0712.8511-2.84319.061011216\"N\"0.074.0810.49-6.88-8.950\"MOL\"-15019143712.4232\"ZWITTERION\"\"C31H56N10O9\"\"CC(C)C[C@@H]1NC(=O)[C@H](CCCNC…\"QJQNNLICZLLPMB-VUBDRERZSA-N\"\"CHEMBL3465961\"nullnull\"Small molecule\"0319.4216222.2250.54106\"N\"0.87null9.382.13-0.441\"MOL\"-123410319.206\"BASE\"\"C18H26FN3O\"\"CC(O)CN1CCC(CN(C)Cc2cc(C#N)ccc…\"FZEVYCHTADTXPM-UHFFFAOYSA-N\"……………………………………………………………………………………\"CHEMBL2017916\"nullnull\"Small molecule\"0312.35332.8677.06104\"N\"0.88.133.492.172.13\"MOL\"-122610312.0681\"NEUTRAL\"\"C15H12N4O2S\"\"COc1ccc(-c2nnc(NC(=O)c3cccnc3)…\"XIZUJGDKNPVNQA-UHFFFAOYSA-N\"\"CHEMBL374652\"nullnull\"Small molecule\"0403.83115.9836.022214\"N\"0.4213.65null5.365.363\"MOL\"-126221403.0421\"NEUTRAL\"\"C18H14ClF4NOS\"\"CC(O)(CSc1ccc(F)cc1)c1cc2cc(Cl…\"CRPQTBRTHURKII-UHFFFAOYSA-N\"\"CHEMBL1416264\"nullnull\"Small molecule\"0380.41683.0685.077105\"N\"0.5413.853.862.472.474\"MOL\"-127710380.0856\"NEUTRAL\"\"C18H13FN6OS\"\"O=C(CSc1ccc2nnc(-c3cccnc3)n2n1…\"QVYIEKHEJKFNAT-UHFFFAOYSA-N\"\"CHEMBL213734\"nullnull\"Small molecule\"0288.26232.32101.75205\"N\"0.57.2null2.361.952\"MOL\"-121720288.0746\"NEUTRAL\"\"C14H12N2O5\"\"O=C(COc1ccccc1)Nc1ccc([N+](=O)…\"PZTWAHGBGTWVEB-UHFFFAOYSA-N\"\"CHEMBL1531634\"nullnull\"Small molecule\"0320.1619214.429.12104\"N\"0.67nullnull4.044.042\"MOL\"-119210319.0008\"NEUTRAL\"\"C15H11BrFNO\"\"O=C(/C=C/Nc1ccc(F)cc1)c1ccc(Br…\"DKPWCCDDKFLKEC-MDZDMXLPSA-N\"\n\n\nI’m having a look at the max phase column first to see the distribution or counts of molecules in each max phase.\n\ndf_pa.group_by(\"Max Phase\").len()\n\n\n\nshape: (5, 2)Max Phaseleni64u3237730182634542870152021052\n\n\nI also want to find out what types of physicochemical properties are there in this dataset.\n\n# Print all column names and data types \nprint(df_pa.glimpse())\n\nRows: 1831560\nColumns: 32\n$ ChEMBL ID                       <str> 'CHEMBL539070', 'CHEMBL3335528', 'CHEMBL2419030', 'CHEMBL3827271', 'CHEMBL3465961', 'CHEMBL3824158', 'CHEMBL194112', 'CHEMBL2047226', 'CHEMBL1991010', 'CHEMBL195644'\n$ Name                            <str> None, None, None, None, None, None, None, None, None, None\n$ Synonyms                        <str> None, None, None, None, None, None, None, None, None, None\n$ Type                            <str> 'Small molecule', 'Small molecule', 'Small molecule', 'Small molecule', 'Small molecule', 'Small molecule', 'Small molecule', 'Small molecule', 'Small molecule', 'Small molecule'\n$ Max Phase                       <i64> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n$ Molecular Weight                <f64> 286.79, 842.8, 359.33, 712.85, 319.42, 422.48, 366.38, 452.4, 454.05, 375.47\n$ Targets                         <i64> 1, 2, 4, 1, 16, 2, 2, 4, 60, 2\n$ Bioactivities                   <i64> 1, 6, 4, 1, 22, 4, 3, 8, 60, 3\n$ AlogP                           <f64> 2.28, 0.18, 3.94, -2.84, 2.22, 5.09, 4.8, 4.93, 5.18, 4.95\n$ Polar Surface Area              <f64> 73.06, 269.57, 85.13, 319.06, 50.5, 109.54, 57.53, 53.08, 40.54, 70.42\n$ HBA                             <i64> 6, 18, 6, 10, 4, 6, 3, 5, 3, 4\n$ HBD                             <i64> 2, 5, 1, 11, 1, 2, 2, 2, 1, 2\n$ #RO5 Violations                 <i64> 0, 2, 0, 2, 0, 1, 0, 0, 1, 0\n$ #Rotatable Bonds                <i64> 5, 17, 3, 16, 6, 10, 1, 7, 8, 2\n$ Passes Ro3                      <str> 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N'\n$ QED Weighted                    <f64> 0.63, 0.09, 0.66, 0.07, 0.87, 0.31, 0.75, 0.53, 0.6, 0.73\n$ CX Acidic pKa                   <f64> 13.84, 3.2, None, 4.08, None, 4.59, 8.98, None, 13.88, 9.52\n$ CX Basic pKa                    <f64> 3.64, None, None, 10.49, 9.38, 7.99, None, 8.47, 8.48, 3.73\n$ CX LogP                         <f64> 2.57, 3.31, 3.66, -6.88, 2.13, 2.49, 4.84, 4.51, 6.34, 3.92\n$ CX LogD                         <f64> 2.57, -0.14, 3.66, -8.95, -0.44, 2.42, 4.83, 3.29, 5.22, 3.91\n$ Aromatic Rings                  <i64> 2, 3, 2, 0, 1, 2, 1, 3, 2, 2\n$ Structure Type                  <str> 'MOL', 'MOL', 'MOL', 'MOL', 'MOL', 'MOL', 'MOL', 'MOL', 'MOL', 'MOL'\n$ Inorganic Flag                  <i64> -1, -1, -1, -1, -1, -1, -1, -1, -1, -1\n$ Heavy Atoms                     <i64> 17, 60, 24, 50, 23, 31, 26, 29, 31, 28\n$ HBA (Lipinski)                  <i64> 5, 19, 6, 19, 4, 7, 3, 5, 3, 4\n$ HBD (Lipinski)                  <i64> 3, 5, 1, 14, 1, 2, 2, 2, 1, 2\n$ #RO5 Violations (Lipinski)      <i64> 0, 2, 0, 3, 0, 1, 0, 0, 1, 0\n$ Molecular Weight (Monoisotopic) <f64> 250.0888, 842.2633, 359.0551, 712.4232, 319.206, 422.1842, 366.1443, 451.1372, 417.2668, 375.1834\n$ Molecular Species               <str> 'NEUTRAL', 'ACID', 'NEUTRAL', 'ZWITTERION', 'BASE', 'ACID', 'NEUTRAL', 'NEUTRAL', 'NEUTRAL', 'NEUTRAL'\n$ Molecular Formula               <str> 'C11H15ClN4OS', 'C41H46O19', 'C14H12F3N3O3S', 'C31H56N10O9', 'C18H26FN3O', 'C24H26N2O5', 'C20H21F3O3', 'C23H26BrN5', 'C28H36ClNO2', 'C24H25NO3'\n$ Smiles                          <str> 'CCCOc1ccccc1-c1nnc(NN)s1.Cl', 'COC(=O)[C@H](O[C@@H]1O[C@@H](C)[C@@H](O)[C@@H](O)[C@@H]1O)[C@@H](O[C@@H]1O[C@H](CO)[C@H](OC(=O)c2ccccc2)[C@H](O[C@H](Cc2ccccc2)C(=O)O)[C@H]1OC(=O)c1ccccc1)C(=O)OC', 'O=c1nc(NC2CCCC2)sc2c([N+](=O)[O-])cc(C(F)(F)F)cc12', 'CC(C)C[C@@H]1NC(=O)[C@H](CCCNC(N)=O)NC(=O)[C@H](CCCCN)NC(=O)[C@H](CC(=O)O)NC(=O)[C@H](CCCCN)NC(=O)CCNC1=O', 'CC(O)CN1CCC(CN(C)Cc2cc(C#N)ccc2F)CC1', 'CCCCCCCNC(C1=C(O)C(=O)c2ccccc2C1=O)c1ccc([N+](=O)[O-])cc1', 'C[C@]12CCC3c4ccc(O)cc4CCC3C1CC(C(=O)C(F)(F)F)=C2O', 'Brc1ccc(CNc2ccnc(NC3CCN(Cc4ccccc4)CC3)n2)cc1', 'CCc1ccc(/C=C/C(=O)C2CN(CC)CCC2(O)/C=C/c2ccc(CC)cc2)cc1.Cl', 'C[C@]12CCC3c4ccc(O)cc4CCC3C1CC(C(=O)c1cccnc1)=C2O'\n$ Inchi Key                       <str> 'WPEWNRKLKLNLSO-UHFFFAOYSA-N', 'KGUJQZWYZPYYRZ-LWEWUKDVSA-N', 'QGDMYSDFCXOKML-UHFFFAOYSA-N', 'QJQNNLICZLLPMB-VUBDRERZSA-N', 'FZEVYCHTADTXPM-UHFFFAOYSA-N', 'AXOVDUYYBUYLPC-UHFFFAOYSA-N', 'FIBOSLUEJGPVMK-RYCRIANLSA-N', 'WOAVNWHCIXCOIZ-UHFFFAOYSA-N', 'XJDPAUYFONOZBC-DCPGAFKKSA-N', 'MOBPUUUBXAHZBM-KSAYNYSMSA-N'\n\nNone\n\n\n\n\nLooking at some of the physicochemical properties in the dataset\nI’ve gone through the ChEMBL_31 schema documentation and ChEMBL database website to find out the meanings for some of the column names. The explanations of the selected term are adapted from ChEMBL_31 schema documentation (available as “Release notes” on the website at the time), or if definitions for certain terms are not available, I resort to interpret them myself by going into “Dinstict compounds” section of the ChEMBL database.\nThe definitions for some of the listed physicochemical properties are:\nMax Phase - Maximum phase of development reached for the compound (where 4 = approved). Null is where max phase has not yet been assigned.\nBioactivities - Various biological assays used for the compounds e.g. IC50, GI50, potency tests etc.\nAlogP - Calculated partition coefficient\nHBA - Number of hydrogen bond acceptors\nHBD - Number of hydrogen bond donors\n#RO5 Violations - Number of violations of Lipinski’s rule-of-five, using HBA and HBD definitions\nPasses Ro3 - Indicating whether the compound passed the rule-of-three (MW < 300, logP < 3 etc)\nQED Weighted - Weighted quantitative estimate of drug likeness (Bickerton et al. 2012)\nInorganic flag - Indicating whether the molecule is inorganic (i.e., containing only metal atoms and <2 carbon atoms), where 1 = inorganic compound and 0 = non-inorganic compound (-1 meaning preclinical compound or not a drug)\nHeavy Atoms - Number of heavy (non-hydrogen) atoms\nCX Acidic pKa - The most acidic pKa calculated using ChemAxon v17.29.0\nCX Basic pKa - The most basic pKa calculated using ChemAxon v17.29.0\nCX LogP - The calculated octanol/water partition coefficient using ChemAxon v17.29.0\nCX LogD - The calculated octanol/water distribution coefficient at pH = 7.4 using ChemAxon v17.29.0\nStructure Type - based on compound_structures table, where SEQ indicates an entry in the protein_therapeutics table instead, NONE indicates an entry in neither tables, e.g. structure unknown\nInchi Key - the IUPAC international chemical identifier key\nThe older version of this post has had a code section for changing the data types of several columns. I’ve found out that this is no longer needed as I’ve taken care of this in the first post when I’ve specifically stated the null_values (e.g. “None” and ““) to be converted to”null” during pl.read_csv(). When the same dataframe df_pa is read here, you’ll notice that the data type for each column should be how it should be, matching the data inside each column.\n\n\n\n\nDealing with nulls\nI’m using null_count() to see the distributions of all null entries in the dataset.\n\n# Alternative code: df_pa.select(pl.all().null_count())\ndf_pa.null_count()\n\n\n\nshape: (1, 32)ChEMBL IDNameSynonymsTypeMax PhaseMolecular WeightTargetsBioactivitiesAlogPPolar Surface AreaHBAHBD#RO5 Violations#Rotatable BondsPasses Ro3QED WeightedCX Acidic pKaCX Basic pKaCX LogPCX LogDAromatic RingsStructure TypeInorganic FlagHeavy AtomsHBA (Lipinski)HBD (Lipinski)#RO5 Violations (Lipinski)Molecular Weight (Monoisotopic)Molecular SpeciesMolecular FormulaSmilesInchi Keyu32u32u32u32u32u32u32u32u32u32u32u32u32u32u32u32u32u32u32u32u32u32u32u32u32u32u32u32u32u32u32u320179594617531540000026426264262642626426264262642626426264267830386914422656026560264260026426264262642626426043392000\n\n\nThe following is basically several different ways to remove null values from the original dataset.\n\n## ---Drop all rows with null entries---\n#df_pa.drop_nulls()\n\n## Number of rows reduced to 2,645 - seems way too much...\n\n## ---Restricting drop nulls to only subsets of nulls in strings ---\n# import polars.selectors as cs\n# df_pa.drop_nulls(subset=cs.string())\n\n## Number of rows reduced to 17,735 - hmm... try other ways?\n\n## ---Drop a row if all values are null---\n# df_pa.filter(~pl.all_horizontal(pl.all().is_null()))\n\n## No change in number of rows - meaning no one row contains all null values\n\n## ---Restricting drop nulls to a specific column---\n# df_pa.drop_nulls(subset=\"CX LogP\")\n\n## Number of rows reduced to 1,873,678\n\nInitially, I’ve tried to remove all nulls first, then I realise that removing nulls above may not be the best way to prepare the data as all max phase 4 compounds are actually also removed completely! So what I’m going to do instead is to keep them by using fill_null() to replace all “null” as “0” (this’ll only apply to all the integers or floats in the data).\n\ndf_pa = df_pa.fill_null(0)\ndf_pa\n\n\n\nshape: (1_831_560, 32)ChEMBL IDNameSynonymsTypeMax PhaseMolecular WeightTargetsBioactivitiesAlogPPolar Surface AreaHBAHBD#RO5 Violations#Rotatable BondsPasses Ro3QED WeightedCX Acidic pKaCX Basic pKaCX LogPCX LogDAromatic RingsStructure TypeInorganic FlagHeavy AtomsHBA (Lipinski)HBD (Lipinski)#RO5 Violations (Lipinski)Molecular Weight (Monoisotopic)Molecular SpeciesMolecular FormulaSmilesInchi Keystrstrstrstri64f64i64i64f64f64i64i64i64i64strf64f64f64f64f64i64stri64i64i64i64i64f64strstrstrstr\"CHEMBL539070\"nullnull\"Small molecule\"0286.79112.2873.066205\"N\"0.6313.843.642.572.572\"MOL\"-117530250.0888\"NEUTRAL\"\"C11H15ClN4OS\"\"CCCOc1ccccc1-c1nnc(NN)s1.Cl\"\"WPEWNRKLKLNLSO-UHFFFAOYSA-N\"\"CHEMBL3335528\"nullnull\"Small molecule\"0842.8260.18269.57185217\"N\"0.093.20.03.31-0.143\"MOL\"-1601952842.2633\"ACID\"\"C41H46O19\"\"COC(=O)[C@H](O[C@@H]1O[C@@H](C…\"KGUJQZWYZPYYRZ-LWEWUKDVSA-N\"\"CHEMBL2419030\"nullnull\"Small molecule\"0359.33443.9485.136103\"N\"0.660.00.03.663.662\"MOL\"-124610359.0551\"NEUTRAL\"\"C14H12F3N3O3S\"\"O=c1nc(NC2CCCC2)sc2c([N+](=O)[…\"QGDMYSDFCXOKML-UHFFFAOYSA-N\"\"CHEMBL3827271\"nullnull\"Small molecule\"0712.8511-2.84319.061011216\"N\"0.074.0810.49-6.88-8.950\"MOL\"-15019143712.4232\"ZWITTERION\"\"C31H56N10O9\"\"CC(C)C[C@@H]1NC(=O)[C@H](CCCNC…\"QJQNNLICZLLPMB-VUBDRERZSA-N\"\"CHEMBL3465961\"nullnull\"Small molecule\"0319.4216222.2250.54106\"N\"0.870.09.382.13-0.441\"MOL\"-123410319.206\"BASE\"\"C18H26FN3O\"\"CC(O)CN1CCC(CN(C)Cc2cc(C#N)ccc…\"FZEVYCHTADTXPM-UHFFFAOYSA-N\"……………………………………………………………………………………\"CHEMBL2017916\"nullnull\"Small molecule\"0312.35332.8677.06104\"N\"0.88.133.492.172.13\"MOL\"-122610312.0681\"NEUTRAL\"\"C15H12N4O2S\"\"COc1ccc(-c2nnc(NC(=O)c3cccnc3)…\"XIZUJGDKNPVNQA-UHFFFAOYSA-N\"\"CHEMBL374652\"nullnull\"Small molecule\"0403.83115.9836.022214\"N\"0.4213.650.05.365.363\"MOL\"-126221403.0421\"NEUTRAL\"\"C18H14ClF4NOS\"\"CC(O)(CSc1ccc(F)cc1)c1cc2cc(Cl…\"CRPQTBRTHURKII-UHFFFAOYSA-N\"\"CHEMBL1416264\"nullnull\"Small molecule\"0380.41683.0685.077105\"N\"0.5413.853.862.472.474\"MOL\"-127710380.0856\"NEUTRAL\"\"C18H13FN6OS\"\"O=C(CSc1ccc2nnc(-c3cccnc3)n2n1…\"QVYIEKHEJKFNAT-UHFFFAOYSA-N\"\"CHEMBL213734\"nullnull\"Small molecule\"0288.26232.32101.75205\"N\"0.57.20.02.361.952\"MOL\"-121720288.0746\"NEUTRAL\"\"C14H12N2O5\"\"O=C(COc1ccccc1)Nc1ccc([N+](=O)…\"PZTWAHGBGTWVEB-UHFFFAOYSA-N\"\"CHEMBL1531634\"nullnull\"Small molecule\"0320.1619214.429.12104\"N\"0.670.00.04.044.042\"MOL\"-119210319.0008\"NEUTRAL\"\"C15H11BrFNO\"\"O=C(/C=C/Nc1ccc(F)cc1)c1ccc(Br…\"DKPWCCDDKFLKEC-MDZDMXLPSA-N\"\n\n\n\n# Summary statistics for df_dn dataset\ndf_pa.describe()\n\n\n\nshape: (9, 33)statisticChEMBL IDNameSynonymsTypeMax PhaseMolecular WeightTargetsBioactivitiesAlogPPolar Surface AreaHBAHBD#RO5 Violations#Rotatable BondsPasses Ro3QED WeightedCX Acidic pKaCX Basic pKaCX LogPCX LogDAromatic RingsStructure TypeInorganic FlagHeavy AtomsHBA (Lipinski)HBD (Lipinski)#RO5 Violations (Lipinski)Molecular Weight (Monoisotopic)Molecular SpeciesMolecular FormulaSmilesInchi Keystrstrstrstrstrf64f64f64f64f64f64f64f64f64f64strf64f64f64f64f64f64strf64f64f64f64f64f64strstrstrstr\"count\"\"1831560\"\"35614\"\"78406\"\"1831560\"1.83156e61.83156e61.83156e61.83156e61.83156e61.83156e61.83156e61.83156e61.83156e61.83156e6\"1805134\"1.83156e61.83156e61.83156e61.83156e61.83156e61.83156e6\"1831560\"1.83156e61.83156e61.83156e61.83156e61.83156e61.83156e6\"1788168\"\"1831560\"\"1831560\"\"1831560\"\"null_count\"\"0\"\"1795946\"\"1753154\"\"0\"0.00.00.00.00.00.00.00.00.00.0\"26426\"0.00.00.00.00.00.0\"0\"0.00.00.00.00.00.0\"43392\"\"0\"\"0\"\"0\"\"mean\"nullnullnullnull0.008967418.629226.4992449.7225753.45691280.6680315.188641.5494160.3983765.616697null0.541285.2699183.3894793.1569062.5411172.441586null-0.99546528.0011246.1872921.696130.443761414.111544nullnullnullnull\"std\"nullnullnullnull0.177118186.28752214.27359949.8290091.89750742.5875942.4455791.4801680.7108913.680179null0.2258595.3428313.6400442.1153812.4335131.247167null0.0675179.2397562.865681.7008080.780102184.202916nullnullnullnull\"min\"\"CHEMBL1\"\"(+) NEOMENTHOL\"\"'CLOPRA-''YELLOW'''|AHR-3070-C…\"Small molecule\"0.04.01.01.0-14.260.00.00.00.00.0\"N\"0.0-19.610.0-20.95-29.960.0\"MOL\"-1.00.00.00.00.04.0026\"ACID\"\"Ag+\"\"B.CC(=O)OC1CN2CCC1CC2\"\"AAAAEENPAALFRN-UHFFFAOYSA-N\"\"25%\"nullnullnullnull0.0326.421.02.02.3454.354.01.00.03.0null0.380.00.01.961.292.0null-1.022.04.01.00.0323.2209nullnullnullnull\"50%\"nullnullnullnull0.0393.493.04.03.4575.275.01.00.05.0null0.563.892.133.212.722.0null-1.027.06.01.00.0389.2355nullnullnullnull\"75%\"nullnullnullnull0.0471.736.09.04.5999.386.02.01.07.0null0.7310.616.584.434.023.0null-1.033.08.02.01.0467.1879nullnullnullnull\"max\"\"CHEMBL99999\"\"xerophilusin G\"\"zygosporamide\"\"Small molecule\"4.012546.321334.017911.022.57568.3932.025.04.067.0\"Y\"0.9514.061.924.8822.9930.0\"MOL\"1.079.035.031.04.08214.3786\"ZWITTERION\"\"Zn+2\"\"n1onc2c1NC1Nc3nonc3NC1N2\"\"ZZZZVQYIUQRCGN-UHFFFAOYSA-N\"\n\n\n\n\n\nLooking at max phase and QED weighted\nTo explore some of the physicochemical and molecular properties in the dataframe, “Max Phase” is one of the first few that I want to have a look. Each ChEMBL compound will have a max phase number from 0 to 4 (for this particular dataset only, you’ll notice that this can start from -1 in other ChEMBL datasets), where 4 means the compound is approved (e.g. a prescription medicine).\nWhile looking at max phases, I’m thinking the compounds with max phase 0 could be a testing set for prediction of their max phase outcomes, while the max phase 4 compounds could be the training set for building a machine learning (ML) model. There are of course some obvious and potential flaws of splitting a dataset like this, please treat this as an exercise for demonstration only.\nBelow I’m checking that I do have max phases of molecules spanning across the entire range of 0 to 4.\n\n## Alternative code\n# df_pa.group_by(\"Max Phase\", maintain_order = True).agg(pl.len())\ndf_pa.group_by(\"Max Phase\").len()\n\n\n\nshape: (5, 2)Max Phaseleni64u3201826345377342870152021052\n\n\nOne of the other parameters I’m interested in is “QED Weighted” (Bickerton et al. 2012). It’s a measure of druglikeness for small molecules based on the concept of desirability, which is based on a total of 8 different molecular properties. These molecular properties include molecular weight, ALogP, polar surface area, number of hydrogen bond acceptors, number of hydrogen bond donors, number of rotatable bonds, number of aromatic rings and structural alerts. It’s normally recorded as a number ranging from 0 to 1, where 0 is the least druglike and 1 being the most druglike.\n\n\n\nPrepare data prior to running ML model\nThe goal of this ML model is to answer this question - which physicochemical features may be useful to predict whether a compound may enter into max phase 4?\nA rough plan at this stage is:\n\nto filter out max phase 4 and 0 compounds from the df_pa dataset\nto use “Max Phase” as the target y variable for a logistic regression (LR) model because ultimately stakeholders are more likely to be interested in knowing which candidate compounds have the most likely chance to reach the final approved phase during a drug discovery project (please bear in mind that this ML model building is more like a demo only and may not reflect real-life scenarios…)\nto use “Polar Surface Area”, “HBA”, “HBD”, “#RO5 Violations”, “QED Weighted”, “CX LogP”, “CX LogD” and “Heavy atoms” as the training features for building the ML model (these molecular features are selected randomly and ideally I should include more… the first three are newly added in this updated version)\nto use max phase 0 compounds as the testing set since they are the ones not assigned with any max phase category yet\nto use max phase 4 compounds as the training set since they’ve reached the approved phase\nto build a confusion matrix in the end to see if the features selected may generate a somewhat reasonable model for predicting the outcomes of these small molecules\n\nDownsides of this plan are (there are many…):\n\nthe dataset used here may include some inorganic compounds (e.g. molecules containing metals)\nthe dataset is likely not very-chemically-diverse\nthere are only a small number of max phase 4 compounds for model training (especially comparing with the “much larger” amount of max phase 0 compounds present)\nLR may not be the best choice of ML model to start off with (I just wanted to find out how it works at the time and because I’m updating the post now so I’m trying to keep it the same…)\nother exploratory data analysis should be done really… e.g. how chemically diverse is the dataset?\nthis is only an exercise so will not be taking into account many other important aspects of drug discovery e.g. what disorders or illnesses are we targeting? (is it an experimentally validated and actually a suitable target?) and what have been done so far in the literatures? etc.\n\nFirstly, I’m filtering out all the max phase 0 compounds and also all the max phase 4 compounds then save them in separate dataframes.\n\n# Selecting all max phase 0 molecules with their training features\ndf_0 = df_pa.filter((pl.col(\"Max Phase\") == 0)).select([\n  \"ChEMBL ID\", \n  \"Max Phase\",\n  \"Polar Surface Area\",\n  \"HBA\",\n  \"HBD\",\n  \"#RO5 Violations\", \n  \"QED Weighted\", \n  \"CX LogP\", \n  \"CX LogD\", \n  \"Heavy Atoms\"\n  ])\ndf_0  #1,826,345 mols\n\n\n\nshape: (1_826_345, 10)ChEMBL IDMax PhasePolar Surface AreaHBAHBD#RO5 ViolationsQED WeightedCX LogPCX LogDHeavy Atomsstri64f64i64i64i64f64f64f64i64\"CHEMBL539070\"073.066200.632.572.5717\"CHEMBL3335528\"0269.5718520.093.31-0.1460\"CHEMBL2419030\"085.136100.663.663.6624\"CHEMBL3827271\"0319.06101120.07-6.88-8.9550\"CHEMBL3465961\"050.54100.872.13-0.4423…………………………\"CHEMBL2017916\"077.06100.82.172.122\"CHEMBL374652\"036.022210.425.365.3626\"CHEMBL1416264\"085.077100.542.472.4727\"CHEMBL213734\"0101.75200.52.361.9521\"CHEMBL1531634\"029.12100.674.044.0419\n\n\n\n# Selecting all max phase 4 molecules with their training features\ndf_4 = df_pa.filter((pl.col(\"Max Phase\") == 4)).select([\n      \"ChEMBL ID\", \n      \"Max Phase\",\n      \"Polar Surface Area\",\n      \"HBA\",\n      \"HBD\",\n      \"#RO5 Violations\", \n      \"QED Weighted\", \n      \"CX LogP\", \n      \"CX LogD\", \n      \"Heavy Atoms\"\n      ])\ndf_4  # 2,870 mols\n\n\n\nshape: (2_870, 10)ChEMBL IDMax PhasePolar Surface AreaHBAHBD#RO5 ViolationsQED WeightedCX LogPCX LogDHeavy Atomsstri64f64i64i64i64f64f64f64i64\"CHEMBL1200675\"412.472010.316.274.8929\"CHEMBL1200436\"446.533100.72.952.9522\"CHEMBL1096882\"4186.0710500.31-1.97-5.1224\"CHEMBL256997\"476.224100.83.920.6821\"CHEMBL2023898\"4174.648420.144.184.1654…………………………\"CHEMBL1619785\"4128.038200.492.091.8634\"CHEMBL4297142\"40.00000.00.00.00\"CHEMBL2364639\"474.026100.683.652.330\"CHEMBL1232131\"494.834300.441.2-1.1812\"CHEMBL3989949\"495.926100.91.661.6618\n\n\n\ndf_4.describe()\n\n\n\nshape: (9, 11)statisticChEMBL IDMax PhasePolar Surface AreaHBAHBD#RO5 ViolationsQED WeightedCX LogPCX LogDHeavy Atomsstrstrf64f64f64f64f64f64f64f64f64\"count\"\"2870\"2870.02870.02870.02870.02870.02870.02870.02870.02870.0\"null_count\"\"0\"0.00.00.00.00.00.00.00.00.0\"mean\"null4.074.9519274.5742161.7804880.3404180.549471.9665510.84159223.863066\"std\"null0.053.8759643.065891.7620480.7036260.2350632.618463.01539211.064927\"min\"\"CHEMBL1000\"4.00.00.00.00.00.0-10.11-17.920.0\"25%\"null4.037.612.01.00.00.390.34-0.6317.0\"50%\"null4.065.784.01.00.00.582.291.1223.0\"75%\"null4.0100.96.02.00.00.743.732.7530.0\"max\"\"CHEMBL99946\"4.0359.4220.015.04.00.9411.6211.6269.0\n\n\nI have to go back to the first post at this point to change the data restriction criteria for the parquet file as I’ve found out in this step above that if I restrict data via inorganic flags, then it’ll remove a lot of compounds with calculated physicochemical properties (because most of the ones in the data are preclinical compounds with inorganic flag of -1 or max phase 0 compounds; inorganic flag of 1 is inorganic ones and 0 should be the non-inorganic ones - I’ve updated its definition above too after re-checking the ChEMBL schema). For now, I’m restricting data via removing compounds with zero targets rather than via the inorganic flag, and this leaves us a set of max phase 4 compounds with their physicochemical properties calculated in ChEMBL (which is needed for training the model in the next post).\n\n\nRe-sampling via under-sampling - dealing with imbalanced dataset\nBecause of the presence of a large number of max phase 0 compounds (1,826,345 molecules) and the relatively smaller number of max phase 4 compounds (2,870 molecules) in the original dataset, I’m going to randomly sample 2800 small molecules from the max phase 0 group to balance out the ratio of max phase 0 versus max phase 4 compounds. This will allow us to have a similar amount of data in each group to avoid a very imbalanced dataset.\n\n\n\n\n\n\nNote\n\n\n\nFor an alternative and likely a better way to deal with imbalanced datasets, please see my later post that attempts to use a “generalized threshold shifting” method.\n\n\n\ndf_0 = df_0.sample(n = 2800, shuffle = True, seed = 0)\ndf_0\n\n\n\nshape: (2_800, 10)ChEMBL IDMax PhasePolar Surface AreaHBAHBD#RO5 ViolationsQED WeightedCX LogPCX LogDHeavy Atomsstri64f64i64i64i64f64f64f64i64\"CHEMBL1420527\"066.814100.473.943.9432\"CHEMBL1878707\"062.553100.933.383.3825\"CHEMBL3971884\"073.865120.129.349.3440\"CHEMBL3438846\"084.224200.762.01-0.1926\"CHEMBL1819378\"040.464000.624.04.026…………………………\"CHEMBL2145354\"084.675100.683.513.5130\"CHEMBL3926224\"087.155120.332.512.5138\"CHEMBL3448203\"086.374100.881.71.726\"CHEMBL1478078\"037.382000.742.92.920\"CHEMBL3105607\"064.995100.684.154.1528\n\n\nSince the plan is to use LR method for the ML model, the y variable I’m interested in is going to be a binary categorical variable - meaning it needs to be 0 (not approved) or 1 (approved). To do this, I’m going to add a new column with a new name of “Max_Phase” and replace “4” as “1” by dividing the whole column by 4 to reach this new label in the max phase 4 dataset.\nThen I’m changing the data type of “Max_Phase” from float to integer, so that the two different dataframes can be concatenated (which will only work if both are of the same data types).\n\ndf_4 = df_4.with_columns((pl.col(\"Max Phase\") / 4).alias(\"Max_Phase\")).cast({\"Max_Phase\": pl.Int64})\ndf_4\n\n\n\nshape: (2_870, 11)ChEMBL IDMax PhasePolar Surface AreaHBAHBD#RO5 ViolationsQED WeightedCX LogPCX LogDHeavy AtomsMax_Phasestri64f64i64i64i64f64f64f64i64i64\"CHEMBL1200675\"412.472010.316.274.89291\"CHEMBL1200436\"446.533100.72.952.95221\"CHEMBL1096882\"4186.0710500.31-1.97-5.12241\"CHEMBL256997\"476.224100.83.920.68211\"CHEMBL2023898\"4174.648420.144.184.16541……………………………\"CHEMBL1619785\"4128.038200.492.091.86341\"CHEMBL4297142\"40.00000.00.00.001\"CHEMBL2364639\"474.026100.683.652.3301\"CHEMBL1232131\"494.834300.441.2-1.18121\"CHEMBL3989949\"495.926100.91.661.66181\n\n\nI’m also going to create a new column with the same name of “Max_Phase” in the max phase 0 dataframe, so that the two dataframes can be combined.\n\ndf_0 = df_0.with_columns((pl.col(\"Max Phase\")).alias(\"Max_Phase\"))\ndf_0\n\n\n\nshape: (2_800, 11)ChEMBL IDMax PhasePolar Surface AreaHBAHBD#RO5 ViolationsQED WeightedCX LogPCX LogDHeavy AtomsMax_Phasestri64f64i64i64i64f64f64f64i64i64\"CHEMBL1420527\"066.814100.473.943.94320\"CHEMBL1878707\"062.553100.933.383.38250\"CHEMBL3971884\"073.865120.129.349.34400\"CHEMBL3438846\"084.224200.762.01-0.19260\"CHEMBL1819378\"040.464000.624.04.0260……………………………\"CHEMBL2145354\"084.675100.683.513.51300\"CHEMBL3926224\"087.155120.332.512.51380\"CHEMBL3448203\"086.374100.881.71.7260\"CHEMBL1478078\"037.382000.742.92.9200\"CHEMBL3105607\"064.995100.684.154.15280\n\n\nThen I’m combining df_0 (dataframe with max phase 0 compounds) and df_4 (dataframe with max phase 4 compounds).\n\ndf_concat = pl.concat([df_0, df_4])\ndf_concat\n\n\n\nshape: (5_670, 11)ChEMBL IDMax PhasePolar Surface AreaHBAHBD#RO5 ViolationsQED WeightedCX LogPCX LogDHeavy AtomsMax_Phasestri64f64i64i64i64f64f64f64i64i64\"CHEMBL1420527\"066.814100.473.943.94320\"CHEMBL1878707\"062.553100.933.383.38250\"CHEMBL3971884\"073.865120.129.349.34400\"CHEMBL3438846\"084.224200.762.01-0.19260\"CHEMBL1819378\"040.464000.624.04.0260……………………………\"CHEMBL1619785\"4128.038200.492.091.86341\"CHEMBL4297142\"40.00000.00.00.001\"CHEMBL2364639\"474.026100.683.652.3301\"CHEMBL1232131\"494.834300.441.2-1.18121\"CHEMBL3989949\"495.926100.91.661.66181\n\n\nThis df_concat dataset is checked to see if it has all compounds in max phases 0 and 4 only.\nNote: max phase 4 (approved) compounds are re-labelled as Max_Phase = 1.\n\ndf_concat.group_by(\"Max_Phase\").len()\n\n\n\nshape: (2, 2)Max_Phaseleni64u321287002800\n\n\nSo here we have the final version of the dataset, renamed to df_ml to avoid confusion from the previous dataframes, before entering into the ML phase.\n\ndf_ml = df_concat.select([\n  \"Max_Phase\", \n  \"Polar Surface Area\",\n  \"HBA\",\n  \"HBD\",\n  \"#RO5 Violations\", \n  \"QED Weighted\", \n  \"CX LogP\", \n  \"CX LogD\", \n  \"Heavy Atoms\"\n  ])\ndf_ml\n\n\n\nshape: (5_670, 9)Max_PhasePolar Surface AreaHBAHBD#RO5 ViolationsQED WeightedCX LogPCX LogDHeavy Atomsi64f64i64i64i64f64f64f64i64066.814100.473.943.9432062.553100.933.383.3825073.865120.129.349.3440084.224200.762.01-0.1926040.464000.624.04.026………………………1128.038200.492.091.863410.00000.00.00.00174.026100.683.652.330194.834300.441.2-1.1812195.926100.91.661.6618\n\n\nI’m just checking for any nulls in the final dataset (should be none as I’ve filled all nulls in one of the steps above).\n\ndf_ml.null_count()\n\n\n\nshape: (1, 9)Max_PhasePolar Surface AreaHBAHBD#RO5 ViolationsQED WeightedCX LogPCX LogDHeavy Atomsu32u32u32u32u32u32u32u32u32000000000\n\n\nAlso, I’m checking the data types in df_ml dataset to make sure they’re all integers or floats for scikit-learn algorithms to work.\n\n# also shown in the dataframe below the column names\ndf_ml.dtypes\n\n[Int64, Float64, Int64, Int64, Int64, Float64, Float64, Float64, Int64]\n\n\nThen finally I’m saving this tidied dataset as a separate .csv file for use in the next post.\n\ndf_ml.write_csv(\"df_ml.csv\", separator = \",\")\n\n\n\n\n\n\n\nReferences\n\nBickerton, G. Richard, Gaia V. Paolini, Jérémy Besnard, Sorel Muresan, and Andrew L. Hopkins. 2012. “Quantifying the Chemical Beauty of Drugs.” Nature Chemistry 4 (2): 90–98. https://doi.org/10.1038/nchem.1243."
  },
  {
    "objectID": "posts/21_ML1-1_Small_mols_in_chembl_update/ML1-1-4_chembl_cpds_evaluate.html",
    "href": "posts/21_ML1-1_Small_mols_in_chembl_update/ML1-1-4_chembl_cpds_evaluate.html",
    "title": "Small molecules in ChEMBL database",
    "section": "",
    "text": "Import libraries\nIn this fourth post and likely the last post of the logistic regression (LR) series, we’re still going to begin with importing all the libraries needed for the following work on model evaluations.\n\nimport sklearn\nprint(f\"scikit-learn version used is: {sklearn.__version__}\")\nfrom sklearn.model_selection import train_test_split\nimport polars as pl\nprint(f\"polars version used is: {pl.__version__}\")\nimport pickle\nimport matplotlib.pyplot as plt\nfrom sklearn import metrics\n# For model evaluations\nfrom sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, classification_report, RocCurveDisplay, roc_curve, log_loss\n\nscikit-learn version used is: 1.5.0\n\n\npolars version used is: 1.9.0\n\n\n\n\n\nImport logistic regression pipeline/model\nNext, we need to load the pickled file so we can evaluate the same LR pipeline used last time.\n\nLR = pickle.load(open(\"LR.pkl\", \"rb\"))\nLR\n\nPipeline(steps=[('StandardScaler', StandardScaler()),\n                ('LogR',\n                 LogisticRegression(random_state=50, solver='liblinear'))])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  Pipeline?Documentation for PipelineiFittedPipeline(steps=[('StandardScaler', StandardScaler()),\n                ('LogR',\n                 LogisticRegression(random_state=50, solver='liblinear'))])  StandardScaler?Documentation for StandardScalerStandardScaler()  LogisticRegression?Documentation for LogisticRegressionLogisticRegression(random_state=50, solver='liblinear') \n\n\n\n\n\nEvaluations of the logistic regression model\nThis part will involve using accuracy scores, confusion matrix, receiver operating characteristic (ROC) curve, classification report and log loss to evaluate the LR model. The main statistical principles and concepts being referred to here are mostly from this reference textbook (Bruce, Bruce, and Gedeck 2020), and a lot of native built-in functions from scikit-learn (Pedregosa et al. 2011) are used to generate the results.\n\nAccuracy scores\nThe easiest one to understand will be accuracy score, which can be calculated using predicted y outcome and actual or true y outcome in scikit-learn as shown below.\n\n## Read in data & split into training & testing sets\ndf = pl.read_csv(\"df_ml.csv\")\nX = df[\"#RO5 Violations\", \"Polar Surface Area\", \"HBA\", \"HBD\", \"QED Weighted\", \"CX LogP\", \"CX LogD\", \"Heavy Atoms\"]\ny = df[\"Max_Phase\"]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 50)\nLR.fit(X_train, y_train)\ny_mp = LR.predict(X_test)\naccuracy_score(y_mp, y_test)\n\n## getting a warning message after accuracy score generated earlier \n# \"UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\" \n# - resolved, missed the fitting step first (my bad) before predict()\n\n0.689594356261023\n\n\nThe accuracy score is 0.69 (after rounding up) which means that there are around 70% of the cases or compounds classified correctly by using the LR classifier. This score is also the same as the one shown from the previous post using score() instead of accuracy_score().\nAccuracy score gives an idea about how close the predicted samples are to the true values. One caveat to note is that for imbalanced dataset, accuracy score might not be very informative and other evaluation metrics will be needed as well.\n\n\n\nConfusion matrix\nA confusion matrix is built below based on the model in order to visualise the counts of correct and incorrect predictions. Previous code used to plot confusion matrix is shown below:\n\n\nCode\n## Function to print and plot confusion matrix\n## The function code below was adapted from the IBM data science course I've taken previously\n\n# # to create iterators for efficient looping\n# import itertools\n# import numpy as np\n\n# def plot_confusion_matrix(# Sets a cm object (cm = confusion matrix)\n#                           cm, \n#                           # Sets classes of '1s' (Successes) & '0s' (Non-successes) for the cm\n#                           classes,\n#                           # If setting normalize = true, reports in ratios instead of counts\n#                           normalize,\n#                           title = 'Confusion matrix',\n#                           # Choose colour of the cm (using colourmap recognised by matplotlib)\n#                           cmap = plt.cm.Reds):\n    \n    # if normalize:\n    #     cm = cm.astype('float') / cm.sum(axis = 1)[:, np.newaxis]\n    #     print(\"Normalized confusion matrix\")\n    # else:\n    #     print('Confusion matrix, without normalization')\n\n    # print(cm)\n\n    # # Plot the confusion matrix \n    # plt.imshow(cm, interpolation = 'nearest', cmap = cmap)\n    # plt.title(title)\n    # plt.colorbar()\n    # tick_marks = np.arange(len(classes))\n    # plt.xticks(tick_marks, classes, rotation = 45)\n    # plt.yticks(tick_marks, classes)\n\n    # # Floats to be round up to two decimal places if using normalize = True\n    # # or else use integers\n    # fmt = '.2f' if normalize else 'd'\n    # # Sets threshold of 0.5\n    # thresh = cm.max() / 2.\n    # # Iterate through the results and differentiate between two text colours \n    # # by using the threshold as a cut-off\n    # for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n    #     plt.text(j, i, format(cm[i, j], fmt),\n    #              horizontalalignment = \"center\",\n    #              color = \"white\" if cm[i, j] > thresh else \"black\")\n\n    # plt.tight_layout()\n    # plt.ylabel('True label')\n    # plt.xlabel('Predicted label')\n\n# # Compute confusion matrix\n# matrix = confusion_matrix(y_test, y_mp, labels = [0,1])\n# np.set_printoptions(precision = 2)\n\n# # Plot confusion matrix without normalisation\n# plt.figure()\n# plot_confusion_matrix(matrix, \n#                       # Define classes of outcomes\n#                       classes = ['Max_Phase = 0','Max_Phase = 1'], \n#                       # Set normalize = True if wanting ratios instead\n#                       normalize = False, \n#                       title = \"Confusion matrix without normalisation\"\n#                      )\n\n\nThere is actually an alternative and probably a better way (that uses less code) to plot confusion matrix using scikit-learn’s code as shown here:\n\nConfusionMatrixDisplay.from_estimator(LR, X_test, y_test)\nplt.show()\n\n\n\n\nA common rule of thumb for confusion matrix is that all predicted outcomes are columns and all the true outcomes are rows. However, there might be exceptions where this would be the other way round.\nFour different categories can be seen in the confusion matrix:\n\nTrue positive - Predicted Max_Phase = 1 & True Max_Phase = 1 (391) - interested in this\nTrue negative - Predicted Max_Phase = 0 & True Max_Phase = 0 (391)\nFalse positive - Predicted Max_Phase = 1 & True Max_Phase = 0 (167)\nFalse negative - Predicted Max_Phase = 0 & True Max_Phase = 1 (185)\n\n\n\n\nReceiver operating characteristic (ROC) curve\nMy old post about random forest classifier has already explained what an area under the ROC curve is (I’m just going to quote myself…):\n\nArea under the ROC curve: reference - the area under a curve plot between sensitivity or recall (percent of all 1s classified correctly by a classifier or true positive rate) and specificity (percent of all 0s classified correctly by a classifier, or equivalent to 1 - false positive rate or true negative rate) (Bruce, Bruce, and Gedeck 2020). It is useful for evaluating the performance of a classification model via comparing the true positive rate and false positive rate which are influenced by shifting the decision threshold. Area under the ROC is usually represented as a number ranging from 0 to 1 (1 being a perfect classifier, 0.5 or below meaning a poor, ineffective classifier)\n\nIn this case, we can also apply ROC curve to the LR model and its predicted outcomes.\n\n# get the predicted probabilities of outcome = 1 (approved drugs)\ny_mp_probs = LR.predict_proba(X_test)[:, 1]\nRocCurveDisplay.from_predictions(y_test, y_mp_probs, plot_chance_level = True)\n\n<sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x12cfd02d0>\n\n\n\n\n\n\n\n\nClassification report\n\nprint(classification_report(y_test, y_mp))\n\n              precision    recall  f1-score   support\n\n           0       0.68      0.70      0.69       558\n           1       0.70      0.68      0.69       576\n\n    accuracy                           0.69      1134\n   macro avg       0.69      0.69      0.69      1134\nweighted avg       0.69      0.69      0.69      1134\n\n\n\nPrecision is a measure of the accuracy of a predicted outcome, where a class label has been predicted by the classifier. In this case, we can see that for class label 1, the precision is 0.70, which corresponds to the true positive result of 391 out of 558 samples (= 0.70, for true predicted Max_Phase = 1 column). It is defined by:\n\\[\n\\text{Precision} = \\frac{\\Sigma\\ True\\ Positive}{(\\Sigma\\ True\\ Positive + \\Sigma\\ False\\ Positive)}\n\\]\nRecall, also known as sensitivity (especially widely used in biostatistics and medical diagnostic fields), is a measure of the strength of the classifier to predict a positive outcome. In simple words, it measures the true positive rate. In this example, there is a total of 391 out of 576 samples (which = 0.68, for true Max_Phase = 1 row). It is defined by:\n\\[\n\\text{Recall} = \\frac{\\Sigma\\ True\\ Positive}{(\\Sigma\\ True\\ Positive + \\Sigma\\ False\\ Negative)}\n\\]\nThe precision and recall metrics are also calculated and shown for row 0 in the classification report.\nf1-score, or also known as balanced F-score or F-measure, denoted the harmonic average of both precision and recall metrics. This metric will also give another indication about whether this model performed well on outcome predictions. Its range is normally from 0 (worst precision and recall) to 1 (perfect precision and recall). For this particular classifier, f1-score was at 0.69 (for class label = 1). It is defined as:\n\\[\n\\text{F1-score} = \\frac{2 \\times (Precision \\times Recall)}{(Precision + Recall)}\n\\]\nSupport is the total number of true samples in each class label (reading row-wise from the confusion matrix). The main purpose of showing this metric is to help clarifying whether the model has had a reasonably balanced dataset for each class (and also helped to check the precision and recall values if needed).\n\n\n\nLog loss\nLog loss can be used as another metric to show how good the classifier is at making the predictions. The further apart the predicted probability is from the true value, the larger the log loss, which is also ranging from 0 to 1. Ideally, the smaller the log loss the better the model will be. Here, we have a log loss of 0.61 (after rounding up) for this particular model.\n\nlog_loss(y_test, y_mp_probs)\n\n0.6097696128595831\n\n\n\n\n\n\nThoughts\nSo here I’ve completed a very basic LR classifier model for ChEMBL small molecules dataset. This is certainly not the most optimal machine learning model as I’ve only wanted to show how a baseline LR model can be built. This post update has added a molecular features versus coefficients plot (in the previous post) which shows the different weightings of the features used to train the dataset, ideally I should include more to provide a better overview of how the physicochemical properties will influence the prediction outcomes, but potentially this plot sort of answers the main goal of the post - which molecular properties might influence max phase outcomes. This last post here is really to show all the different evaluation metrics for the LR model, and I’ve added a ROC curve this time.\nTo further improve this model, I could possibly try hyperparameter tuning although I’ve come across comments from others in the past that it might not improve LR model that much once it’s done. Originally I do have two other posts following on from the first one (which is currently splitted into four smaller posts), and one of them is about hyperparameter tuning. My possible plan at the moment is to maybe update these other two posts further down the line and I may decide to condense or remove them if it’s not really going to make much difference or impact, I’ll see…\n\n\n\nAcknowledgements\nHuge thanks to our online open-source communities, libraries, and also all the references used in this series of posts.\n\n\n\nOnline references\nI’ve listed below all the online references used throughout this project. All the other journal paper or text book references used should be cited in the post already or listed below.\n\nscikit-learn\nStack Overflow\nPolars references:\n\nPolars - User Guide - https://docs.pola.rs/\nPolars API reference - https://pola-rs.github.io/polars/py-polars/html/index.html#\nPolars GitHub repository - https://github.com/pola-rs/polars\n\n\n\n\n\n\n\nReferences\n\nBruce, Peter, Andrew Bruce, and Peter Gedeck. 2020. Practical Statistics for Data Scientists. https://www.oreilly.com/library/view/practical-statistics-for/9781492072935/.\n\n\nPedregosa, Fabian, Gaël Varoquaux, Alexandre Gramfort, Vincent Michel, Bertrand Thirion, Olivier Grisel, Mathieu Blondel, et al. 2011. “Scikit-Learn: Machine Learning in Python.” Journal of Machine Learning Research 12 (85): 2825–30. http://jmlr.org/papers/v12/pedregosa11a.html."
  },
  {
    "objectID": "posts/20_Cyp3a4_2d6_inh/1_CYP450_drugs.html",
    "href": "posts/20_Cyp3a4_2d6_inh/1_CYP450_drugs.html",
    "title": "Cytochrome P450 and small drug molecules",
    "section": "",
    "text": "Outline\nThe main goal for this post is to have a preliminary look into two of the most common groups of cytochrome P450 (CYP) inhibitors with an initial aim to look for any maximum common substructures (MCS) in these compounds if present or applicable.\nTL;DR - Many pharmaceuticals have different types of rings found in their chemical structures (Taylor, MacCoss, and Lawson 2014), so it is unsurprising that the MCSes found here are mainly rings. To further explore the underlying mechanisms of actions (e.g. putative or active binding sites) of these CYP inhibitors, the structures of CYPs should be examined at the same time ideally.\nBelow is a general outline of the post:\n\nSmall introduction on drug toxicology and metabolism regarding CYPs\n\nciting data sources for drug structural alerts in ChEMBL\na thought on another drug metabolism data source\n\nData extraction using chembl_downloader\nData import and preprocessing\nQuick check on structural validities\nFurther look into duplicated structures and stereochemistries\n\nquinidine\nitraconazole\n\nMaximum common substructures\n\nCYP3A4 inhibitors\nCYP2D6 inhibitors\nSome other interesting code re. MCS\n\nSome small findings and possible future work\nAcknowledgements\n\n\n\n\nSome introductions\nI initially want to work on something about drug toxicology without setting any goals or intentions on how this post will end (bit like a free-style post) and currently I feel it will be more to do with metabolism, which is also directly linked to drug toxicity, an important area not to ignore during any therapeutic drug discovery and developmental work.\nThis post is sort of inspired by a recent commentary that talks about “avoidome” and DMPK-related proteins to avoid (Fraser and Murcko 2024). I also happen to encounter two other blog posts (a post from D. Lowe, and another one from P. Kenny) that have provided reviews on this commentary recently with interesting view points.\nIn a very rough sense, three main areas have been looked at (not exhaustive) with the aim to create safer therapeutic drugs:\n\nStructural alerts on compound substructures that are known to cause adverse drug effects or pan-assay interference compounds (PAINs)\nMany have looked into structural alerts (an example repo: rd_filters). ChEMBL database has already had a cheminformatic utils web service developed that provides structural alert computations for compounds. There are most likely much more efforts than these ones.\nToxicophores in relation to human ether-a-go-go-related gene (hERG) potassium channel (related to structural alerts as well)\nhERG potassium channel is also another frequently-looked-at aspect for drug toxicology due to its known effect leading to cardiac QT prolongations or more commonly known as arrhythmias (Curran et al. 1995).\nCYP enzymes with the well-known ones as CYP3A4, 2D6, 1A2, 2C9 and 2C19\nCYP450 enzymes play a key role in the metabolism and toxicology parts of the ADMET process of drugs. When a drug behaves like a cytochrome inhibitor, it inhibits the activity of a particular cytochrome enzyme e.g. CYP3A4 leading to a reduction of clearance of a particular therapeutic drug e.g. a CYP3A4 substrate such as apixaban, thus increasing its plasma concentration in vivo causing a higher chance of adverse effect (which in the context of apixaban, this means the poor person taking the apixaban may get excessive bleeding…).\n\nOther useful categories involve drug-induced skin sensitisations and liver injuries and more.\nMy very inital naive thought is that if we can at least cover some of the drug toxicology part during drug design and discovery process, this may be able to save some resources along the way (obviously it won’t be this simple…). The main thing here is that it may still be useful and interesting to look into the relationship between CYP450 and small drug molecules - to see if there are anything worth further explorations. This post will start with the two largest groups of CYP inhibitors, so focussing on CYP3A4 and 2D6 first.\nWhile my focus is only on a very small cohort of small molecules relating to only two CYPs, it is also worth noting that there are actually more CYPs present as well, for example, CYP1A1, 2A6, 2B6, 2C8, 2E1, 2J2, 3A5 (note: amlodipine is a moderate CYP3A5 inhibitor and will be looked at below), 3A7 and 4F2 (Guengerich 2020). The cited paper here also provides quite a comprehensive background on the history of CYP450 and their relevance to toxicities in drugs, so I won’t repeat them here.\n\n\nMore on structural alerts\nI am only really curious about the data sources used to build these ChEMBL structural alerts, so below are some of my notes on these sources.\nFrom ChEMBL 20, only 6 filters are present, as shown by this ChEMBL blogpost - it may appear that this blog post cites all 8 filters but in fact it only has 6. I’ve attempted to find out the sources of these ChEMBL structural alert sets, here they are:\n\nPfizer LINT filters\nGlaxo Wellcome hard filters\nBMS HTS Deck Filters\nNIH MLSMR Excluded Functionality Filters (the old link provided in the old ChEMBL blog post is no longer available, this is found via KNIME’s REOS Tagger webpage)\nUniversity of Dundee NTD Screening Library Filters (also known as “Brenk filter” in RDKit)\nPAINS filters\n\nFrom ChEMBL 20 to 23, there are 8 filters in total (agreed with rd_filters’ README.md that there aren’t many documentations about this in ChEMBL, as I’ve tried also), the sources of the two additional ones are as follow:\n\nInpharmatica - unable to find direct source initially but this is later confirmed as private communications between ChEMBL and Inpharmatica Ltd. in the earlier days - an older ChEMBL presentation on ChEMBL 09 mentions about this, and this is also further elaborated by this paper (Gaulton et al. 2016)\nSureChEMBL (old link provided by the paper (Gaulton et al. 2016) also no longer exists)\n\nRDKit (section on “Filtering unwanted substructures”) also has another NIH filter based on two other references (Jadhav et al. 2010) and (Doveston et al. 2015). At one point I’m so confused with this NIH filter here and the NIH MLSMR one above… they are actually different as different papers are cited.\nRDKit also uses the above 8 filters mentioned in ChEMBL in its FilterCatalogs class currently. Brenk filter seems to be the same as the CHEMBL_Dundee one since both of them have quoted the same journal paper as reference. It’s also got a ZINC one I think. Before I get very carried away, I’ll stop searching for every structural alerts papers here as there are many in the literatures.\n\n\n\nMore on CYPs and ADMET\nA bit of a sidetrack for this part (feel free to skip) as I come across a new paper online recently about using deep learning model for ADMET prediction which uses data from Therapeutics data commons (TDC). So while working on this relevant topic of CYP and ADMET (only the metabolism and toxicology parts), I just want to dig a bit deeper to see what sort of data are used by TDC.\nThe TDC ADME dataset, specifically the metabolism one on all five CYP isoenzymes (CYP2C19, 2D6, 3A4, 1A2 and 2C9), are all derived from a 2009 paper by Veith et al.. A closer look at this paper only seems to mention:\n\n…we tested 17,143 samples at between seven and fifteen concentrations for all five CYP isozymes. The samples consisted of 8,019 compounds from the MLSMR including compounds chosen for diversity and rule-of-five compliance, 16 synthetic tractability, and availability; 6,144 compounds from a set of biofocused libraries which included 1,114 FDA-approved drugs; and 2,980 compounds from combinatorial libraries containing privileged structures targeted at GPCRs and kinases, and libraries of purified natural products or related structures…\n\nIf I go to its original journal paper site (the link provided was a NCBI one), there is only one additional Excel file with a long list of chemical scaffolds showing different CYP activities (no other supplementary information I can spot there). The only likely lists of compounds tested are shown in its figures 6 and 7 in the paper, where figure 7 is more relevant for drug-drug interactions. I then realise the proportions of FDA-approved drugs used and the rest of the molecules tested in this paper are also not very balanced (thinking along the line of approved drugs and non-approved drugs), and notice that what they are saying in its discussion about how they are not noticing the usual prominent activities of CYP3A4 and 2D6 in the compounds they’ve tested:\n\n…It has been suggested that CYP 3A4 is the most prominent P450 isozyme in drug metabolism and hepatic distribution (Fig. 2b),25, 26 but the drugs in our collection do not appear to have been optimized away from this activity. There has also been speculation that CYP 2D6 isozyme plays a prominent role in drug metabolism,27 but no difference in activity was observed between diversity compounds and approved drugs for this isozyme…\n\nI wonder if this may be due to the imbalanced set of compounds used e.g. number of FDA-approved drug (smaller) vs. number of other compounds from other libraries (larger)…\nI’ve also visited FDA’s website to look at how the CYP stories are compiled (FDA link). The in vitro inhibitors and clinical index inhibitors are not completely the same across all the CYPs. There are some overlappings in CYP3A4/5 and 2D6 for sure but definitely not exactly the same across all the documented CYPs in this FDA webpage.\nSo back to this new paper on predicting ADMET… how likely will it be useful in real-life hit/lead ADMET optimisation projects in drug discovery settings if the data source only involves a larger portion of non-approved drugs versus a smaller portion of actual FDA-approved drugs?… It just shows that there are a lot of things to think about in the DMPK/ADMET areas within drug discovery pipelines, as ultimately this is crucial to see if a candidate molecule will proceed or not (i.e. causing toxicity or not and whether it’s tolerable side effects or adverse or even life-threatening ones instead).\n\n\n\n\nExtracting data\nFirst step here is to import the following software packages in order to retrieve and work with ChEMBL data (again).\n\nimport pandas as pd\nimport chembl_downloader\nfrom chembl_downloader import latest\nfrom rdkit import Chem\nfrom rdkit.Chem import Draw, AllChem\n# For maximum common substructures & labelling stereocentres\nfrom rdkit.Chem import rdFMCS, rdCIPLabeler\nfrom rdkit.Chem.Draw import IPythonConsole\nIPythonConsole.drawOptions.addAtomIndices = False\n# Change to false to remove stereochem labels\nIPythonConsole.drawOptions.addStereoAnnotation = True\nIPythonConsole.ipython_useSVG=True\n\n\n# Latest version of ChEMBL\nlatest_version = latest()\nprint(f\"The latest ChEMBL version is: {latest_version}\")\n\nThe latest ChEMBL version is: 34\n\n\nI’m using SQL via chembl_downloader to download approved drugs with their ChEMBL ID and equivalent canonical SMILES. All of the CYP3A4 and 2D6 inhibitors extracted from ChEMBL are based on the Flockhart table of drug interactions (Flockhart et al. 2021).\nNote: Three other categories of medicines are not going to be looked at for now, which are the weak inhibitors, ones with in vitro evidence only and ones that are still pending reviews.\nA bit about retrieving data here, the following may not be the best way to get the data, but I’ve somehow incorporated chembl_downloader into my own small piece of function code (see Python script named as “cyp_drugs.py” in the repo) to retrieve SMILES of approved drugs (other public databases may also work very well equally, but I’m used to using ChEMBL now as it’s easy to read and navigate).\nAnother possible way is to use get_target_sql() within chembl_downloader, e.g. using a specific CYP enzyme as the protein target to retrieve data, but it appears that there are no clear data marked to indicate the potency of CYP inhibition or induction (i.e. weak, moderate or strong) in the ChEMBL database (an example link for CYP2D6 in ChEMBL). The Flockhart table has clearly annotated each approved drug with journal paper citations so I decide to stick with the previous method.\n\n## Main issue previously is with sql string - too many quotation marks!\n# e.g. WHERE molecule_dictionary.pref_name = '('KETOCONAZOLE', 'FLUCONAZOLE')'': near \"KETOCONAZOLE\": syntax error\n# Resolved issue by adding string methods e.g. strip() and replace() to sql query string\n\nfrom cyp_drugs import chembl_drugs\n\n# Get a list of strong cyp3a4 inhibitors\n# For the story on why I also added a weird spelling of \"itraconzole\", please see below.\n# and save as a tsv file\ndf_3a4_strong_inh = chembl_drugs(\n    \"CERITINIB\", \"CLARITHROMYCIN\", \"DELAVIRIDINE\", \"IDELALISIB\", \"INDINAVIR\", \"ITRACONAZOLE\", \"ITRACONZOLE\", \"KETOCONAZOLE\", \"MIBEFRADIL\", \"NEFAZODONE\", \"NELFINAVIR\", \"RIBOCICLIB\", \"RITONAVIR\", \"SAQUINAVIR\", \"TELAPREVIR\", \"TELITHROMYCIN\", \"TUCATINIB\", \"VORICONAZOLE\",\n    #file_name=\"strong_3a4_inh\"\n    )\ndf_3a4_strong_inh.head()\n\n\n\n\n\n  \n    \n      \n      chembl_id\n      pref_name\n      max_phase\n      canonical_smiles\n    \n  \n  \n    \n      0\n      CHEMBL2403108\n      CERITINIB\n      4.0\n      Cc1cc(Nc2ncc(Cl)c(Nc3ccccc3S(=O)(=O)C(C)C)n2)c...\n    \n    \n      1\n      CHEMBL1741\n      CLARITHROMYCIN\n      4.0\n      CC[C@H]1OC(=O)[C@H](C)[C@@H](O[C@H]2C[C@@](C)(...\n    \n    \n      2\n      CHEMBL2216870\n      IDELALISIB\n      4.0\n      CC[C@H](Nc1ncnc2[nH]cnc12)c1nc2cccc(F)c2c(=O)n...\n    \n    \n      3\n      CHEMBL115\n      INDINAVIR\n      4.0\n      CC(C)(C)NC(=O)[C@@H]1CN(Cc2cccnc2)CCN1C[C@@H](...\n    \n    \n      4\n      CHEMBL22587\n      ITRACONAZOLE\n      NaN\n      CCC(C)n1ncn(-c2ccc(N3CCN(c4ccc(OC[C@H]5CO[C@](...\n    \n  \n\n\n\n\n\n## Get a list of moderate cyp3a4 inhibitors\n# skipping grapefruit juice as it's not quite an approved drug...\n# note: amlodipine inhibits cyp3a5\ndf_3a4_mod_inh = chembl_drugs(\n    \"AMLODIPINE\", \"APREPITANT\", \"CIPROFLOXACIN\", \"CRIZOTINIB\", \"DILTIAZEM\", \"ERYTHROMYCIN\", \"FLUCONAZOLE\", \"IMATINIB\", \"LETERMOVIR\", \"NETUPITANT\", \"VERAPAMIL\", #file_name=\"mod_3a4_inh\"\n    )\ndf_3a4_mod_inh.head()\n\n\n\n\n\n  \n    \n      \n      chembl_id\n      pref_name\n      max_phase\n      canonical_smiles\n    \n  \n  \n    \n      0\n      CHEMBL1491\n      AMLODIPINE\n      4\n      CCOC(=O)C1=C(COCCN)NC(C)=C(C(=O)OC)C1c1ccccc1Cl\n    \n    \n      1\n      CHEMBL1471\n      APREPITANT\n      4\n      C[C@@H](O[C@H]1OCCN(Cc2n[nH]c(=O)[nH]2)[C@H]1c...\n    \n    \n      2\n      CHEMBL8\n      CIPROFLOXACIN\n      4\n      O=C(O)c1cn(C2CC2)c2cc(N3CCNCC3)c(F)cc2c1=O\n    \n    \n      3\n      CHEMBL601719\n      CRIZOTINIB\n      4\n      C[C@@H](Oc1cc(-c2cnn(C3CCNCC3)c2)cnc1N)c1c(Cl)...\n    \n    \n      4\n      CHEMBL23\n      DILTIAZEM\n      4\n      COc1ccc([C@@H]2Sc3ccccc3N(CCN(C)C)C(=O)[C@@H]2...\n    \n  \n\n\n\n\n\n# Get a list of strong cyp2d6 inhibitors\ndf_2d6_strong_inh = chembl_drugs(\n    \"BUPROPION\", \"FLUOXETINE\", \"PAROXETINE\", \"QUINIDINE\", \n    #file_name=\"strong_2d6_inh\"\n    )\ndf_2d6_strong_inh\n\n\n\n\n\n  \n    \n      \n      chembl_id\n      pref_name\n      max_phase\n      canonical_smiles\n    \n  \n  \n    \n      0\n      CHEMBL894\n      BUPROPION\n      4.0\n      CC(NC(C)(C)C)C(=O)c1cccc(Cl)c1\n    \n    \n      1\n      CHEMBL41\n      FLUOXETINE\n      4.0\n      CNCCC(Oc1ccc(C(F)(F)F)cc1)c1ccccc1\n    \n    \n      2\n      CHEMBL490\n      PAROXETINE\n      4.0\n      Fc1ccc([C@@H]2CCNC[C@H]2COc2ccc3c(c2)OCO3)cc1\n    \n    \n      3\n      CHEMBL21578\n      QUINIDINE\n      NaN\n      C=C[C@H]1CN2CCC1C[C@@H]2[C@@H](O)c1ccnc2ccc(OC...\n    \n    \n      4\n      CHEMBL1294\n      QUINIDINE\n      4.0\n      C=C[C@H]1CN2CC[C@H]1C[C@@H]2[C@@H](O)c1ccnc2cc...\n    \n  \n\n\n\n\n\n# Get a list of moderate cyp2d6 inhibitors\ndf_2d6_mod_inh = chembl_drugs(\n    \"ABIRATERONE\", \"CINACALCET\", \"CLOBAZAM\", \"DOXEPIN\", \"DULOXETINE\", \"HALOFANTRINE\", \"LORCASERIN\", \"MOCLOBEMIDE\", \"ROLAPITANT\", \"TERBINAFINE\", \n    #file_name=\"mod_2d6_inh\"\n    )\ndf_2d6_mod_inh.head()\n\n\n\n\n\n  \n    \n      \n      chembl_id\n      pref_name\n      max_phase\n      canonical_smiles\n    \n  \n  \n    \n      0\n      CHEMBL254328\n      ABIRATERONE\n      4\n      C[C@]12CC[C@H](O)CC1=CC[C@@H]1[C@@H]2CC[C@]2(C...\n    \n    \n      1\n      CHEMBL1201284\n      CINACALCET\n      4\n      C[C@@H](NCCCc1cccc(C(F)(F)F)c1)c1cccc2ccccc12\n    \n    \n      2\n      CHEMBL70418\n      CLOBAZAM\n      4\n      CN1C(=O)CC(=O)N(c2ccccc2)c2cc(Cl)ccc21\n    \n    \n      3\n      CHEMBL1628227\n      DOXEPIN\n      4\n      CN(C)CCC=C1c2ccccc2COc2ccccc21\n    \n    \n      4\n      CHEMBL1175\n      DULOXETINE\n      4\n      CNCC[C@H](Oc1cccc2ccccc12)c1cccs1\n    \n  \n\n\n\n\nInitially, four categories of approved drugs are retrieved - the strong and moderate CYP3A4 inhibitors, and also the strong and moderate CYP2D6 inhibitors. CYP3A4 inhibitors are the largest cohort of all the cytochrome inhibitors known so far (based on clinical documentations).\n\n\n\nImport and preprocess data\n\n## When using pandas 2.2.2, numpy 2.0.0 and rdkit 2024.3.1 \n# (all latest major versions at the time of writing, \n# note: rdkit has a latest minor release as 2024.03.4, which includes a patch for numpy 2.0)\n# Seems to work as a new df is generated but with error messages shown\n\n## Eventually using downgraded versions of pandas and numpy instead \n# pandas 2.1.4, numpy 1.26.4 & rdkit 2024.3.1 work with no error messages generated\n\n# preprocess canonical smiles \nfrom mol_prep import preprocess\n\n# cyp3a4 strong inhibitors\ndf_3a4_s_inh = df_3a4_strong_inh.copy()\ndf_3a4_s_inh_p = df_3a4_s_inh.apply(preprocess, axis=1)\ndf_3a4_s_inh_p.head(3)\n\n\n\n\n\n  \n    \n      \n      chembl_id\n      pref_name\n      max_phase\n      canonical_smiles\n      rdkit_mol\n      standard_smiles\n      selfies\n      inchi\n      inchikey\n    \n  \n  \n    \n      0\n      CHEMBL2403108\n      CERITINIB\n      4.0\n      Cc1cc(Nc2ncc(Cl)c(Nc3ccccc3S(=O)(=O)C(C)C)n2)c...\n      <rdkit.Chem.rdchem.Mol object at 0x135da19a0>\n      Cc1cc(Nc2ncc(Cl)c(Nc3ccccc3S(=O)(=O)C(C)C)n2)c...\n      [C][C][=C][C][Branch2][Ring2][=Branch1][N][C][...\n      InChI=1S/C28H36ClN5O3S/c1-17(2)37-25-15-21(20-...\n      VERWOWGGCGHDQE-UHFFFAOYSA-N\n    \n    \n      1\n      CHEMBL1741\n      CLARITHROMYCIN\n      4.0\n      CC[C@H]1OC(=O)[C@H](C)[C@@H](O[C@H]2C[C@@](C)(...\n      <rdkit.Chem.rdchem.Mol object at 0x135da1b60>\n      CC[C@H]1OC(=O)[C@H](C)[C@@H](O[C@H]2C[C@@](C)(...\n      [C][C][C@H1][O][C][=Branch1][C][=O][C@H1][Bran...\n      InChI=1S/C38H69NO13/c1-15-26-38(10,45)31(42)21...\n      AGOYDEPGAOXOCK-KCBOHYOISA-N\n    \n    \n      2\n      CHEMBL2216870\n      IDELALISIB\n      4.0\n      CC[C@H](Nc1ncnc2[nH]cnc12)c1nc2cccc(F)c2c(=O)n...\n      <rdkit.Chem.rdchem.Mol object at 0x135da1a80>\n      CC[C@H](Nc1ncnc2[nH]cnc12)c1nc2cccc(F)c2c(=O)n...\n      [C][C][C@H1][Branch1][#C][N][C][=N][C][=N][C][...\n      InChI=1S/C22H18FN7O/c1-2-15(28-20-18-19(25-11-...\n      IFSDAJWBUCMOAH-HNNXBMFYSA-N\n    \n  \n\n\n\n\n\n# cyp3a4 moderate inhibitors\ndf_3a4_m_inh = df_3a4_mod_inh.copy()\ndf_3a4_m_inh_p = df_3a4_m_inh.apply(preprocess, axis=1)\ndf_3a4_m_inh_p.head(3)\n\n\n\n\n\n  \n    \n      \n      chembl_id\n      pref_name\n      max_phase\n      canonical_smiles\n      rdkit_mol\n      standard_smiles\n      selfies\n      inchi\n      inchikey\n    \n  \n  \n    \n      0\n      CHEMBL1491\n      AMLODIPINE\n      4\n      CCOC(=O)C1=C(COCCN)NC(C)=C(C(=O)OC)C1c1ccccc1Cl\n      <rdkit.Chem.rdchem.Mol object at 0x135da3990>\n      CCOC(=O)C1=C(COCCN)NC(C)=C(C(=O)OC)C1c1ccccc1Cl\n      [C][C][O][C][=Branch1][C][=O][C][=C][Branch1][...\n      InChI=1S/C20H25ClN2O5/c1-4-28-20(25)18-15(11-2...\n      HTIQEAQVCYTUBX-UHFFFAOYSA-N\n    \n    \n      1\n      CHEMBL1471\n      APREPITANT\n      4\n      C[C@@H](O[C@H]1OCCN(Cc2n[nH]c(=O)[nH]2)[C@H]1c...\n      <rdkit.Chem.rdchem.Mol object at 0x135da2ce0>\n      C[C@@H](O[C@H]1OCCN(Cc2n[nH]c(=O)[nH]2)[C@H]1c...\n      [C][C@@H1][Branch2][Ring2][C][O][C@H1][O][C][C...\n      InChI=1S/C23H21F7N4O3/c1-12(14-8-15(22(25,26)2...\n      ATALOFNDEOCMKK-OITMNORJSA-N\n    \n    \n      2\n      CHEMBL8\n      CIPROFLOXACIN\n      4\n      O=C(O)c1cn(C2CC2)c2cc(N3CCNCC3)c(F)cc2c1=O\n      <rdkit.Chem.rdchem.Mol object at 0x135da2ff0>\n      O=C(O)c1cn(C2CC2)c2cc(N3CCNCC3)c(F)cc2c1=O\n      [O][=C][Branch1][C][O][C][=C][N][Branch1][=Bra...\n      InChI=1S/C17H18FN3O3/c18-13-7-11-14(8-15(13)20...\n      MYSWGUAQZAJSOK-UHFFFAOYSA-N\n    \n  \n\n\n\n\n\n# cyp2d6 strong inhibitors\ndf_2d6_s_inh = df_2d6_strong_inh.copy()\ndf_2d6_s_inh_p = df_2d6_s_inh.apply(preprocess, axis=1)\ndf_2d6_s_inh_p.head(3)\n\n\n\n\n\n  \n    \n      \n      chembl_id\n      pref_name\n      max_phase\n      canonical_smiles\n      rdkit_mol\n      standard_smiles\n      selfies\n      inchi\n      inchikey\n    \n  \n  \n    \n      0\n      CHEMBL894\n      BUPROPION\n      4.0\n      CC(NC(C)(C)C)C(=O)c1cccc(Cl)c1\n      <rdkit.Chem.rdchem.Mol object at 0x135da3530>\n      CC(NC(C)(C)C)C(=O)c1cccc(Cl)c1\n      [C][C][Branch1][#Branch2][N][C][Branch1][C][C]...\n      InChI=1S/C13H18ClNO/c1-9(15-13(2,3)4)12(16)10-...\n      SNPPWIUOZRMYNY-UHFFFAOYSA-N\n    \n    \n      1\n      CHEMBL41\n      FLUOXETINE\n      4.0\n      CNCCC(Oc1ccc(C(F)(F)F)cc1)c1ccccc1\n      <rdkit.Chem.rdchem.Mol object at 0x135da3290>\n      CNCCC(Oc1ccc(C(F)(F)F)cc1)c1ccccc1\n      [C][N][C][C][C][Branch2][Ring1][Ring2][O][C][=...\n      InChI=1S/C17H18F3NO/c1-21-12-11-16(13-5-3-2-4-...\n      RTHCYVBBDHJXIQ-UHFFFAOYSA-N\n    \n    \n      2\n      CHEMBL490\n      PAROXETINE\n      4.0\n      Fc1ccc([C@@H]2CCNC[C@H]2COc2ccc3c(c2)OCO3)cc1\n      <rdkit.Chem.rdchem.Mol object at 0x135da3bc0>\n      Fc1ccc([C@@H]2CCNC[C@H]2COc2ccc3c(c2)OCO3)cc1\n      [F][C][=C][C][=C][Branch2][Ring1][#Branch2][C@...\n      InChI=1S/C19H20FNO3/c20-15-3-1-13(2-4-15)17-7-...\n      AHOUBRCZNHFOSL-YOEHRIQHSA-N\n    \n  \n\n\n\n\n\n#cyp2d6 moderate inhibitors\ndf_2d6_m_inh = df_2d6_mod_inh.copy()\ndf_2d6_m_inh_p = df_2d6_m_inh.apply(preprocess, axis=1)\ndf_2d6_m_inh_p.head(3)\n\n\n\n\n\n  \n    \n      \n      chembl_id\n      pref_name\n      max_phase\n      canonical_smiles\n      rdkit_mol\n      standard_smiles\n      selfies\n      inchi\n      inchikey\n    \n  \n  \n    \n      0\n      CHEMBL254328\n      ABIRATERONE\n      4\n      C[C@]12CC[C@H](O)CC1=CC[C@@H]1[C@@H]2CC[C@]2(C...\n      <rdkit.Chem.rdchem.Mol object at 0x135dd0270>\n      C[C@]12CC[C@H](O)CC1=CC[C@@H]1[C@@H]2CC[C@]2(C...\n      [C][C@][C][C][C@H1][Branch1][C][O][C][C][Ring1...\n      InChI=1S/C24H31NO/c1-23-11-9-18(26)14-17(23)5-...\n      GZOSMCIZMLWJML-VJLLXTKPSA-N\n    \n    \n      1\n      CHEMBL1201284\n      CINACALCET\n      4\n      C[C@@H](NCCCc1cccc(C(F)(F)F)c1)c1cccc2ccccc12\n      <rdkit.Chem.rdchem.Mol object at 0x135da3e60>\n      C[C@@H](NCCCc1cccc(C(F)(F)F)c1)c1cccc2ccccc12\n      [C][C@@H1][Branch2][Ring1][#Branch1][N][C][C][...\n      InChI=1S/C22H22F3N/c1-16(20-13-5-10-18-9-2-3-1...\n      VDHAWDNDOKGFTD-MRXNPFEDSA-N\n    \n    \n      2\n      CHEMBL70418\n      CLOBAZAM\n      4\n      CN1C(=O)CC(=O)N(c2ccccc2)c2cc(Cl)ccc21\n      <rdkit.Chem.rdchem.Mol object at 0x135da3b50>\n      CN1C(=O)CC(=O)N(c2ccccc2)c2cc(Cl)ccc21\n      [C][N][C][=Branch1][C][=O][C][C][=Branch1][C][...\n      InChI=1S/C16H13ClN2O2/c1-18-13-8-7-11(17)9-14(...\n      CXOXHMZGEKVPMT-UHFFFAOYSA-N\n    \n  \n\n\n\n\n\n\n\nImages of structures\nHere what I’m trying to do is to check structural validities of all the drug molecules, and one of the easiest things to do is to look at their chemical structures directly.\n\n# moderate cyp2d6 inhibitors\nDraw.MolsToGridImage(\n    df_2d6_m_inh_p[\"rdkit_mol\"], \n    molsPerRow=3, \n    subImgSize=(400, 300), \n    legends=list(df_2d6_m_inh_p[\"pref_name\"])\n    )\n\n\n\n\n\n# strong cyp2d6 inhibitors\nDraw.MolsToGridImage(\n    df_2d6_s_inh_p[\"rdkit_mol\"], \n    molsPerRow=3, \n    subImgSize=(400, 300), \n    legends=list(df_2d6_s_inh_p[\"pref_name\"])\n    )\n\n\n\n\n\n\nDuplicated structures and stereochemistries\nThis is a small detour while checking structural validities due to the presence of two duplicated molecules, and since these two molecules consist of stereocentres, I’m just going to have a look at their stereochemistries.\n\n\n\nquinidine\nThere are different stereochemistries spotted in the two quinidines shown below.\n\n# Stereochem in RDKit\n# Older approach - AssignStereochemistry() -> this is used in datamol's standardize_mol(), \n# which is used in my small mol_prep.py script\n# Newer approach - FindPotentialStereo()\n\n\n# Get 2D image of quinidine at row 3\ndf_2d6_s_inh_p.loc[3, \"rdkit_mol\"]\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Get 2D image of quinidine at row 4\ndf_2d6_s_inh_p.loc[4, \"rdkit_mol\"]\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Get SMILES for quinidine at row 3\ndf_2d6_s_inh_p.loc[3, \"canonical_smiles\"]\n\n'C=C[C@H]1CN2CCC1C[C@@H]2[C@@H](O)c1ccnc2ccc(OC)cc12'\n\n\n\n# Get SMILES for quinidine at row 4\ndf_2d6_s_inh_p.loc[4, \"canonical_smiles\"]\n\n'C=C[C@H]1CN2CC[C@H]1C[C@@H]2[C@@H](O)c1ccnc2ccc(OC)cc12'\n\n\n\n# quinidine at index row 3\nquinidine_3 = Chem.MolFromSmiles('C=C[C@H]1CN2CCC1C[C@@H]2[C@@H](O)c1ccnc2ccc(OC)cc12')\nrdCIPLabeler.AssignCIPLabels(quinidine_3)\nquinidine_3\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRef: Stereochemical or CIP (Cahn–Ingold–Prelog) labeller in RDKit\n\n# quinidine index row 4\nquinidine_4 = Chem.MolFromSmiles('C=C[C@H]1CN2CC[C@H]1C[C@@H]2[C@@H](O)c1ccnc2ccc(OC)cc12')\nrdCIPLabeler.AssignCIPLabels(quinidine_4)\nquinidine_4\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuinidine has 4 defined atom stereocentre count as per PubChem compound summary (as one of possible references for cross-checking) - this is based on the calculation for CHEMBL1294, which is the same as the quinidine spotted at index row 4. So I’m dropping the quinidine at index row 3 for now.\n\n# Note: old index is unchanged for now (re-index later if needed)\ndf_2d6_s_inh_p = df_2d6_s_inh_p.drop(labels = 3)\ndf_2d6_s_inh_p\n\n\n\n\n\n  \n    \n      \n      chembl_id\n      pref_name\n      max_phase\n      canonical_smiles\n      rdkit_mol\n      standard_smiles\n      selfies\n      inchi\n      inchikey\n    \n  \n  \n    \n      0\n      CHEMBL894\n      BUPROPION\n      4.0\n      CC(NC(C)(C)C)C(=O)c1cccc(Cl)c1\n      <rdkit.Chem.rdchem.Mol object at 0x135da3530>\n      CC(NC(C)(C)C)C(=O)c1cccc(Cl)c1\n      [C][C][Branch1][#Branch2][N][C][Branch1][C][C]...\n      InChI=1S/C13H18ClNO/c1-9(15-13(2,3)4)12(16)10-...\n      SNPPWIUOZRMYNY-UHFFFAOYSA-N\n    \n    \n      1\n      CHEMBL41\n      FLUOXETINE\n      4.0\n      CNCCC(Oc1ccc(C(F)(F)F)cc1)c1ccccc1\n      <rdkit.Chem.rdchem.Mol object at 0x135da3290>\n      CNCCC(Oc1ccc(C(F)(F)F)cc1)c1ccccc1\n      [C][N][C][C][C][Branch2][Ring1][Ring2][O][C][=...\n      InChI=1S/C17H18F3NO/c1-21-12-11-16(13-5-3-2-4-...\n      RTHCYVBBDHJXIQ-UHFFFAOYSA-N\n    \n    \n      2\n      CHEMBL490\n      PAROXETINE\n      4.0\n      Fc1ccc([C@@H]2CCNC[C@H]2COc2ccc3c(c2)OCO3)cc1\n      <rdkit.Chem.rdchem.Mol object at 0x135da3bc0>\n      Fc1ccc([C@@H]2CCNC[C@H]2COc2ccc3c(c2)OCO3)cc1\n      [F][C][=C][C][=C][Branch2][Ring1][#Branch2][C@...\n      InChI=1S/C19H20FNO3/c20-15-3-1-13(2-4-15)17-7-...\n      AHOUBRCZNHFOSL-YOEHRIQHSA-N\n    \n    \n      4\n      CHEMBL1294\n      QUINIDINE\n      4.0\n      C=C[C@H]1CN2CC[C@H]1C[C@@H]2[C@@H](O)c1ccnc2cc...\n      <rdkit.Chem.rdchem.Mol object at 0x135da2d50>\n      C=C[C@H]1CN2CC[C@H]1C[C@@H]2[C@@H](O)c1ccnc2cc...\n      [C][=C][C@H1][C][N][C][C][C@H1][Ring1][=Branch...\n      InChI=1S/C20H24N2O2/c1-3-13-12-22-9-7-14(13)10...\n      LOUPRKONTZGTKE-LHHVKLHASA-N\n    \n  \n\n\n\n\n\n\n\nitraconazole\nTwo itraconazoles are also found with different stereochemistries.\n\n# Get SMILES of itraconazole at index row 4\ndf_3a4_s_inh_p.loc[4, \"canonical_smiles\"]\n\n'CCC(C)n1ncn(-c2ccc(N3CCN(c4ccc(OC[C@H]5CO[C@](Cn6cncn6)(c6ccc(Cl)cc6Cl)O5)cc4)CC3)cc2)c1=O'\n\n\n\n# Get SMILES of itraconazole at index row 5\ndf_3a4_s_inh_p.loc[5, \"canonical_smiles\"]\n\n'CCC(C)n1ncn(-c2ccc(N3CCN(c4ccc(OCC5COC(Cn6cncn6)(c6ccc(Cl)cc6Cl)O5)cc4)CC3)cc2)c1=O'\n\n\n\nitracon_4 = Chem.MolFromSmiles(\"CCC(C)n1ncn(-c2ccc(N3CCN(c4ccc(OC[C@H]5CO[C@](Cn6cncn6)(c6ccc(Cl)cc6Cl)O5)cc4)CC3)cc2)c1=O\")\nrdCIPLabeler.AssignCIPLabels(itracon_4)\nitracon_4\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nitracon_5 = Chem.MolFromSmiles(\"CCC(C)n1ncn(-c2ccc(N3CCN(c4ccc(OCC5COC(Cn6cncn6)(c6ccc(Cl)cc6Cl)O5)cc4)CC3)cc2)c1=O\")\nrdCIPLabeler.AssignCIPLabels(itracon_5)\nitracon_5\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClearly, even if the SMILES of these two itraconzoles are not converted into RDKit molecules, we can probably tell one of them has stereochemistries and the other one is without due to the presence of “@” in the SMILES string for the one at index row 4. The output images show exactly that - one with chiral centres, where the other one doesn’t have any.\nPubChem calculations have however generated different result for itraconazole. It seems it only has one defined atom stereocentre count and two undefined stereocentre counts (PubChem reference).\nI’ve also noted that the two itraconzoles obtained from ChEMBL have different ChEMBL ID numbers (ChEMBL IDs: CHEMBL22587 and CHEMBL64391) to the one calculated in PubChem (ChEMBL ID: CHEMBL224725). So below I’ve looked into CHEMBL224725 first.\nThen I realise that if I search for “itraconazole” directly in ChEMBL, only four entries will appear with ChEMBL IDs of CHEMBL64391, CHEMBL22587, CHEMBL882 and CHEMBL5090785, and there is no ChEMBL224725. This is all due to a small spelling error (which is most likely a typo by accident) of itraconazole - being spelled as “itraconzole”, which is also carried over into PubChem as well. I have checked again to make sure both “itraconzole” and the usual itraconazole are referring to the same chemical structure. Below are some screenshots showing the typo.  \nSo to add this likely-mis-spelled “itraconzole” into the dataframe, I literally just add it into the SQL query above when obtaining drug information through chembl_downloader.\n\n# SMILES of new addition - \"itraconzole\"\ndf_3a4_s_inh_p.loc[6, \"canonical_smiles\"]\n\n'CCC(C)n1ncn(-c2ccc(N3CCN(c4ccc(OC[C@H]5COC(Cn6cncn6)(c6ccc(F)cc6F)O5)cc4)CC3)cc2)c1=O'\n\n\n\n# Labelling stereocentres of new addition - \"itraconzole\"\nitracon_6 = Chem.MolFromSmiles(\"CCC(C)n1ncn(-c2ccc(N3CCN(c4ccc(OC[C@H]5COC(Cn6cncn6)(c6ccc(F)cc6F)O5)cc4)CC3)cc2)c1=O\")\nrdCIPLabeler.AssignCIPLabels(itracon_6)\nitracon_6\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThere is only one stereocentre for “itraconzole”, which will match the CHEMBL224725 entry for “itraconzole” in PubChem. Without looking into other cross-referencing sources, and if only sticking with PubChem for now, I’ve then gone back to check all 3 (stereochemically-)different versions of itraconazole and found that the RDKit stereochemical calculations of these 3 itraconazoles have all basically matched their equivalent PubChem computations for atom sterecentre counts.\nCHEMBL22587 - PubChem CID 55283 - 2 defined, 1 undefined atom stereocentre count\n\nitracon_4\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCHEMBL64391 - PubChem CID 3793 - 0 defined, 3 undefined atom stereocentre count\n\nitracon_5\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCHEMBL224725 - PubChem CID 44428219 - 1 defined, 2 undefined atom stereocentre count\n\nitracon_6\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDataframe df_3a4_s_inh_p (the preprocessed strong CYP3A4 inhibitors) containing 3 different itraconazoles is then updated below to remove two of the triplicated entries.\n\n# Preprocessed df of strong cyp3a4 inhibitors\ndf_3a4_s_inh_p.head(10)\n\n\n\n\n\n  \n    \n      \n      chembl_id\n      pref_name\n      max_phase\n      canonical_smiles\n      rdkit_mol\n      standard_smiles\n      selfies\n      inchi\n      inchikey\n    \n  \n  \n    \n      0\n      CHEMBL2403108\n      CERITINIB\n      4.0\n      Cc1cc(Nc2ncc(Cl)c(Nc3ccccc3S(=O)(=O)C(C)C)n2)c...\n      <rdkit.Chem.rdchem.Mol object at 0x135da19a0>\n      Cc1cc(Nc2ncc(Cl)c(Nc3ccccc3S(=O)(=O)C(C)C)n2)c...\n      [C][C][=C][C][Branch2][Ring2][=Branch1][N][C][...\n      InChI=1S/C28H36ClN5O3S/c1-17(2)37-25-15-21(20-...\n      VERWOWGGCGHDQE-UHFFFAOYSA-N\n    \n    \n      1\n      CHEMBL1741\n      CLARITHROMYCIN\n      4.0\n      CC[C@H]1OC(=O)[C@H](C)[C@@H](O[C@H]2C[C@@](C)(...\n      <rdkit.Chem.rdchem.Mol object at 0x135da1b60>\n      CC[C@H]1OC(=O)[C@H](C)[C@@H](O[C@H]2C[C@@](C)(...\n      [C][C][C@H1][O][C][=Branch1][C][=O][C@H1][Bran...\n      InChI=1S/C38H69NO13/c1-15-26-38(10,45)31(42)21...\n      AGOYDEPGAOXOCK-KCBOHYOISA-N\n    \n    \n      2\n      CHEMBL2216870\n      IDELALISIB\n      4.0\n      CC[C@H](Nc1ncnc2[nH]cnc12)c1nc2cccc(F)c2c(=O)n...\n      <rdkit.Chem.rdchem.Mol object at 0x135da1a80>\n      CC[C@H](Nc1ncnc2[nH]cnc12)c1nc2cccc(F)c2c(=O)n...\n      [C][C][C@H1][Branch1][#C][N][C][=N][C][=N][C][...\n      InChI=1S/C22H18FN7O/c1-2-15(28-20-18-19(25-11-...\n      IFSDAJWBUCMOAH-HNNXBMFYSA-N\n    \n    \n      3\n      CHEMBL115\n      INDINAVIR\n      4.0\n      CC(C)(C)NC(=O)[C@@H]1CN(Cc2cccnc2)CCN1C[C@@H](...\n      <rdkit.Chem.rdchem.Mol object at 0x135da1ee0>\n      CC(C)(C)NC(=O)[C@@H]1CN(Cc2cccnc2)CCN1C[C@@H](...\n      [C][C][Branch1][C][C][Branch1][C][C][N][C][=Br...\n      InChI=1S/C36H47N5O4/c1-36(2,3)39-35(45)31-24-4...\n      CBVCZFGXHXORBI-PXQQMZJSSA-N\n    \n    \n      4\n      CHEMBL22587\n      ITRACONAZOLE\n      NaN\n      CCC(C)n1ncn(-c2ccc(N3CCN(c4ccc(OC[C@H]5CO[C@](...\n      <rdkit.Chem.rdchem.Mol object at 0x135da1cb0>\n      CCC(C)n1ncn(-c2ccc(N3CCN(c4ccc(OC[C@H]5CO[C@](...\n      [C][C][C][Branch1][C][C][N][N][=C][N][Branch2]...\n      InChI=1S/C35H38Cl2N8O4/c1-3-25(2)45-34(46)44(2...\n      VHVPQPYKVGDNFY-ZPGVKDDISA-N\n    \n    \n      5\n      CHEMBL64391\n      ITRACONAZOLE\n      4.0\n      CCC(C)n1ncn(-c2ccc(N3CCN(c4ccc(OCC5COC(Cn6cncn...\n      <rdkit.Chem.rdchem.Mol object at 0x135da1d90>\n      CCC(C)n1ncn(-c2ccc(N3CCN(c4ccc(OCC5COC(Cn6cncn...\n      [C][C][C][Branch1][C][C][N][N][=C][N][Branch2]...\n      InChI=1S/C35H38Cl2N8O4/c1-3-25(2)45-34(46)44(2...\n      VHVPQPYKVGDNFY-UHFFFAOYSA-N\n    \n    \n      6\n      CHEMBL224725\n      ITRACONZOLE\n      NaN\n      CCC(C)n1ncn(-c2ccc(N3CCN(c4ccc(OC[C@H]5COC(Cn6...\n      <rdkit.Chem.rdchem.Mol object at 0x135da1f50>\n      CCC(C)n1ncn(-c2ccc(N3CCN(c4ccc(OC[C@H]5COC(Cn6...\n      [C][C][C][Branch1][C][C][N][N][=C][N][Branch2]...\n      InChI=1S/C35H38F2N8O4/c1-3-25(2)45-34(46)44(24...\n      HUADITLKOCMHSB-RPOYNCMSSA-N\n    \n    \n      7\n      CHEMBL157101\n      KETOCONAZOLE\n      4.0\n      CC(=O)N1CCN(c2ccc(OCC3COC(Cn4ccnc4)(c4ccc(Cl)c...\n      <rdkit.Chem.rdchem.Mol object at 0x135da2030>\n      CC(=O)N1CCN(c2ccc(OCC3COC(Cn4ccnc4)(c4ccc(Cl)c...\n      [C][C][=Branch1][C][=O][N][C][C][N][Branch2][R...\n      InChI=1S/C26H28Cl2N4O4/c1-19(33)31-10-12-32(13...\n      XMAYWYJOQHXEEK-UHFFFAOYSA-N\n    \n    \n      8\n      CHEMBL45816\n      MIBEFRADIL\n      4.0\n      COCC(=O)O[C@]1(CCN(C)CCCc2nc3ccccc3[nH]2)CCc2c...\n      <rdkit.Chem.rdchem.Mol object at 0x135da1e70>\n      COCC(=O)O[C@]1(CCN(C)CCCc2nc3ccccc3[nH]2)CCc2c...\n      [C][O][C][C][=Branch1][C][=O][O][C@][Branch2][...\n      InChI=1S/C29H38FN3O3/c1-20(2)28-23-12-11-22(30...\n      HBNPJJILLOYFJU-VMPREFPWSA-N\n    \n    \n      9\n      CHEMBL623\n      NEFAZODONE\n      4.0\n      CCc1nn(CCCN2CCN(c3cccc(Cl)c3)CC2)c(=O)n1CCOc1c...\n      <rdkit.Chem.rdchem.Mol object at 0x135da20a0>\n      CCc1nn(CCCN2CCN(c3cccc(Cl)c3)CC2)c(=O)n1CCOc1c...\n      [C][C][C][=N][N][Branch2][Ring1][=Branch2][C][...\n      InChI=1S/C25H32ClN5O2/c1-2-24-27-31(25(32)30(2...\n      VRBKIVRKKCLPHA-UHFFFAOYSA-N\n    \n  \n\n\n\n\nI’m keeping the one with max phase marked as 4.0 (due to the other two having “NaN” with no relevant medical or therapeutic indications data documented in PubChem).\n\n# Note old index unchanged (re-index later if needed)\n# Dropping itraconazole at index rows 4 & 6\ndf_3a4_s_inh_p = df_3a4_s_inh_p.drop(labels = [4, 6])\ndf_3a4_s_inh_p.head(10)\n\n\n\n\n\n  \n    \n      \n      chembl_id\n      pref_name\n      max_phase\n      canonical_smiles\n      rdkit_mol\n      standard_smiles\n      selfies\n      inchi\n      inchikey\n    \n  \n  \n    \n      0\n      CHEMBL2403108\n      CERITINIB\n      4.0\n      Cc1cc(Nc2ncc(Cl)c(Nc3ccccc3S(=O)(=O)C(C)C)n2)c...\n      <rdkit.Chem.rdchem.Mol object at 0x135da19a0>\n      Cc1cc(Nc2ncc(Cl)c(Nc3ccccc3S(=O)(=O)C(C)C)n2)c...\n      [C][C][=C][C][Branch2][Ring2][=Branch1][N][C][...\n      InChI=1S/C28H36ClN5O3S/c1-17(2)37-25-15-21(20-...\n      VERWOWGGCGHDQE-UHFFFAOYSA-N\n    \n    \n      1\n      CHEMBL1741\n      CLARITHROMYCIN\n      4.0\n      CC[C@H]1OC(=O)[C@H](C)[C@@H](O[C@H]2C[C@@](C)(...\n      <rdkit.Chem.rdchem.Mol object at 0x135da1b60>\n      CC[C@H]1OC(=O)[C@H](C)[C@@H](O[C@H]2C[C@@](C)(...\n      [C][C][C@H1][O][C][=Branch1][C][=O][C@H1][Bran...\n      InChI=1S/C38H69NO13/c1-15-26-38(10,45)31(42)21...\n      AGOYDEPGAOXOCK-KCBOHYOISA-N\n    \n    \n      2\n      CHEMBL2216870\n      IDELALISIB\n      4.0\n      CC[C@H](Nc1ncnc2[nH]cnc12)c1nc2cccc(F)c2c(=O)n...\n      <rdkit.Chem.rdchem.Mol object at 0x135da1a80>\n      CC[C@H](Nc1ncnc2[nH]cnc12)c1nc2cccc(F)c2c(=O)n...\n      [C][C][C@H1][Branch1][#C][N][C][=N][C][=N][C][...\n      InChI=1S/C22H18FN7O/c1-2-15(28-20-18-19(25-11-...\n      IFSDAJWBUCMOAH-HNNXBMFYSA-N\n    \n    \n      3\n      CHEMBL115\n      INDINAVIR\n      4.0\n      CC(C)(C)NC(=O)[C@@H]1CN(Cc2cccnc2)CCN1C[C@@H](...\n      <rdkit.Chem.rdchem.Mol object at 0x135da1ee0>\n      CC(C)(C)NC(=O)[C@@H]1CN(Cc2cccnc2)CCN1C[C@@H](...\n      [C][C][Branch1][C][C][Branch1][C][C][N][C][=Br...\n      InChI=1S/C36H47N5O4/c1-36(2,3)39-35(45)31-24-4...\n      CBVCZFGXHXORBI-PXQQMZJSSA-N\n    \n    \n      5\n      CHEMBL64391\n      ITRACONAZOLE\n      4.0\n      CCC(C)n1ncn(-c2ccc(N3CCN(c4ccc(OCC5COC(Cn6cncn...\n      <rdkit.Chem.rdchem.Mol object at 0x135da1d90>\n      CCC(C)n1ncn(-c2ccc(N3CCN(c4ccc(OCC5COC(Cn6cncn...\n      [C][C][C][Branch1][C][C][N][N][=C][N][Branch2]...\n      InChI=1S/C35H38Cl2N8O4/c1-3-25(2)45-34(46)44(2...\n      VHVPQPYKVGDNFY-UHFFFAOYSA-N\n    \n    \n      7\n      CHEMBL157101\n      KETOCONAZOLE\n      4.0\n      CC(=O)N1CCN(c2ccc(OCC3COC(Cn4ccnc4)(c4ccc(Cl)c...\n      <rdkit.Chem.rdchem.Mol object at 0x135da2030>\n      CC(=O)N1CCN(c2ccc(OCC3COC(Cn4ccnc4)(c4ccc(Cl)c...\n      [C][C][=Branch1][C][=O][N][C][C][N][Branch2][R...\n      InChI=1S/C26H28Cl2N4O4/c1-19(33)31-10-12-32(13...\n      XMAYWYJOQHXEEK-UHFFFAOYSA-N\n    \n    \n      8\n      CHEMBL45816\n      MIBEFRADIL\n      4.0\n      COCC(=O)O[C@]1(CCN(C)CCCc2nc3ccccc3[nH]2)CCc2c...\n      <rdkit.Chem.rdchem.Mol object at 0x135da1e70>\n      COCC(=O)O[C@]1(CCN(C)CCCc2nc3ccccc3[nH]2)CCc2c...\n      [C][O][C][C][=Branch1][C][=O][O][C@][Branch2][...\n      InChI=1S/C29H38FN3O3/c1-20(2)28-23-12-11-22(30...\n      HBNPJJILLOYFJU-VMPREFPWSA-N\n    \n    \n      9\n      CHEMBL623\n      NEFAZODONE\n      4.0\n      CCc1nn(CCCN2CCN(c3cccc(Cl)c3)CC2)c(=O)n1CCOc1c...\n      <rdkit.Chem.rdchem.Mol object at 0x135da20a0>\n      CCc1nn(CCCN2CCN(c3cccc(Cl)c3)CC2)c(=O)n1CCOc1c...\n      [C][C][C][=N][N][Branch2][Ring1][=Branch2][C][...\n      InChI=1S/C25H32ClN5O2/c1-2-24-27-31(25(32)30(2...\n      VRBKIVRKKCLPHA-UHFFFAOYSA-N\n    \n    \n      10\n      CHEMBL584\n      NELFINAVIR\n      4.0\n      Cc1c(O)cccc1C(=O)N[C@@H](CSc1ccccc1)[C@H](O)CN...\n      <rdkit.Chem.rdchem.Mol object at 0x135da2180>\n      Cc1c(O)cccc1C(=O)N[C@@H](CSc1ccccc1)[C@H](O)CN...\n      [C][C][=C][Branch1][C][O][C][=C][C][=C][Ring1]...\n      InChI=1S/C32H45N3O4S/c1-21-25(15-10-16-28(21)3...\n      QAGYKUNXZHXKMR-HKWSIXNMSA-N\n    \n    \n      11\n      CHEMBL3545110\n      RIBOCICLIB\n      4.0\n      CN(C)C(=O)c1cc2cnc(Nc3ccc(N4CCNCC4)cn3)nc2n1C1...\n      <rdkit.Chem.rdchem.Mol object at 0x135da22d0>\n      CN(C)C(=O)c1cc2cnc(Nc3ccc(N4CCNCC4)cn3)nc2n1C1...\n      [C][N][Branch1][C][C][C][=Branch1][C][=O][C][=...\n      InChI=1S/C23H30N8O/c1-29(2)22(32)19-13-16-14-2...\n      RHXHGRAEPCAFML-UHFFFAOYSA-N\n    \n  \n\n\n\n\nAfter cleaning up the duplicated structures, below are the full sets of strong and moderate CYP3A4 inhibitors for structural checking.\n\n# strong cyp3a4 inhibitors\nDraw.MolsToGridImage(\n    df_3a4_s_inh_p[\"rdkit_mol\"], \n    molsPerRow=3, \n    subImgSize=(400, 300), \n    legends=list(df_3a4_s_inh_p[\"pref_name\"]))\n\n\n\n\n\n# moderate cyp3a4 inhibitors\nDraw.MolsToGridImage(\n    df_3a4_m_inh_p[\"rdkit_mol\"], \n    molsPerRow=3, \n    subImgSize=(400, 300), \n    legends=list(df_3a4_m_inh_p[\"pref_name\"])\n    )\n\n\n\n\n\n\n\n\nMaximum common substructures\nMCS is something I’m interested in trying out so below are some examples of finding MCS in these CYP inhibitors. Please note that MCS may not be the most suitable strategy to look at these CYP inhibitors, I’m only using it to become a bit more familiar with it so that I can better understand MCS.\nSome information regarding MCS in RDKit:\n\nFindMCS is for 2 or more molecules and returns single-fragment MCS - based on FMCS algorithm (Dalke and Hastings 2013)\nRascalMCES (maximum common edge substructures) is for 2 molecules only and returns multi-fragment MCES. A RDKit blog post by Dave Cosgrove talks about this in more details\n\nSome code examples to refer to:\n\nA RDKit code example may be a good starting point to learn about MCS\nTeachOpenCADD’s MCS talktorial - a nice tutorial-like piece that introduces MCS and explains about the FMCS algorithm\n“Customising MCS mapping in rdkit” - a more detailed post providing some code examples for atom matching\n\n\n\nStrong CYP3A4 inhibitors\nI’m starting with the strong CYP3A4 inhibitors first.\n\n# Get list of RDKit mols\nmols_s3a4 = list(df_3a4_s_inh_p[\"rdkit_mol\"])\n\n# Find MCS in mols\ns3a4_mcs = rdFMCS.FindMCS(mols_s3a4)\n\n# Get images of highlighted MCS for strong CYP3A4 inhibitors\nDraw.MolsToGridImage(\n    mols_s3a4, \n    subImgSize=(400, 300), \n    molsPerRow=2, \n    legends = list(df_3a4_s_inh_p[\"pref_name\"]), \n    highlightAtomLists=[m.GetSubstructMatch(s3a4_mcs.queryMol) for m in mols_s3a4]\n    )\n\n\n\n\nYou can get the number of atoms and bonds and also SMARTS string for the MCS like this below.\n\ns3a4_mcs.numAtoms, s3a4_mcs.numBonds\n\n(7, 6)\n\n\n\ns3a4_mcs.smartsString\n\n'[#6](-,:[#6](:,-[#7]:,-[#6]):,-[#6])-,:[#6]-,:[#6]'\n\n\nOne way to customise MCS is via reducing molecule threshold to relax the MCS rule as suggested by the TeachOpenCADD reference above.\n\ns3a4_mcs_80 = rdFMCS.FindMCS(mols_s3a4, threshold=0.8)\n\nDraw.MolsToGridImage(\n    mols_s3a4, \n    subImgSize=(400, 300), \n    molsPerRow=2, \n    legends = list(df_3a4_s_inh_p[\"pref_name\"]), \n    highlightAtomLists=[m.GetSubstructMatch(s3a4_mcs_80.queryMol) for m in mols_s3a4]\n    )\n\n\n\n\n\n# Without changing threshold\ns3a4_mcs1 = Chem.MolFromSmarts(s3a4_mcs.smartsString)\n\n# Lowered MCS threshold to 80% of mols\ns3a4_mcs2 = Chem.MolFromSmarts(s3a4_mcs_80.smartsString)\n\nDraw.MolsToGridImage([s3a4_mcs1, s3a4_mcs2], legends=[\"MCS1\", \"MCS2 with threshold = 0.8\"])\n\n\n\n\nHere the MCS differs between different MCS thresholds - when the threshold is not changed, it shows a partial contour of a ring structure, whereas the lowered threshold shows more of an alkyl chain structure.\n\n\n\nModerate CYP3A4 inhibitors\nThis is then followed by the moderate inhibitors for CYP3A4.\n\n# Get list of RDKit mols\nmols_m3a4 = list(df_3a4_m_inh_p[\"rdkit_mol\"])\n\n# Find MCS in mols\nm3a4_mcs = rdFMCS.FindMCS(mols_m3a4)\n\n# Get images of highlighted MCS for moderate CYP3A4 inhibitors\nDraw.MolsToGridImage(\n    mols_m3a4, \n    subImgSize=(400, 300), \n    molsPerRow=2, \n    legends = list(df_3a4_s_inh_p[\"pref_name\"]), \n    highlightAtomLists=[m.GetSubstructMatch(m3a4_mcs.queryMol) for m in mols_m3a4]\n    )\n\n\n\n\nAromatic (and macrolide) rings are highlighted in the MCS for this group.\n\n\n\nAll CYP3A4 inhibitors\nThe moderate CYP3A4 inhibitors are then added next in order to see if MCS changes when looking at all of the CYP3A4 inhibitors.\n\n# Concatenate dfs for moderate & strong CYP3A4 inhibitors\ndf_3a4_all = pd.concat([df_3a4_s_inh_p, df_3a4_m_inh_p])\n# index un-changed for now\nprint(df_3a4_all.shape)\ndf_3a4_all.head(3)\n\n(27, 9)\n\n\n\n\n\n\n  \n    \n      \n      chembl_id\n      pref_name\n      max_phase\n      canonical_smiles\n      rdkit_mol\n      standard_smiles\n      selfies\n      inchi\n      inchikey\n    \n  \n  \n    \n      0\n      CHEMBL2403108\n      CERITINIB\n      4.0\n      Cc1cc(Nc2ncc(Cl)c(Nc3ccccc3S(=O)(=O)C(C)C)n2)c...\n      <rdkit.Chem.rdchem.Mol object at 0x135da19a0>\n      Cc1cc(Nc2ncc(Cl)c(Nc3ccccc3S(=O)(=O)C(C)C)n2)c...\n      [C][C][=C][C][Branch2][Ring2][=Branch1][N][C][...\n      InChI=1S/C28H36ClN5O3S/c1-17(2)37-25-15-21(20-...\n      VERWOWGGCGHDQE-UHFFFAOYSA-N\n    \n    \n      1\n      CHEMBL1741\n      CLARITHROMYCIN\n      4.0\n      CC[C@H]1OC(=O)[C@H](C)[C@@H](O[C@H]2C[C@@](C)(...\n      <rdkit.Chem.rdchem.Mol object at 0x135da1b60>\n      CC[C@H]1OC(=O)[C@H](C)[C@@H](O[C@H]2C[C@@](C)(...\n      [C][C][C@H1][O][C][=Branch1][C][=O][C@H1][Bran...\n      InChI=1S/C38H69NO13/c1-15-26-38(10,45)31(42)21...\n      AGOYDEPGAOXOCK-KCBOHYOISA-N\n    \n    \n      2\n      CHEMBL2216870\n      IDELALISIB\n      4.0\n      CC[C@H](Nc1ncnc2[nH]cnc12)c1nc2cccc(F)c2c(=O)n...\n      <rdkit.Chem.rdchem.Mol object at 0x135da1a80>\n      CC[C@H](Nc1ncnc2[nH]cnc12)c1nc2cccc(F)c2c(=O)n...\n      [C][C][C@H1][Branch1][#C][N][C][=N][C][=N][C][...\n      InChI=1S/C22H18FN7O/c1-2-15(28-20-18-19(25-11-...\n      IFSDAJWBUCMOAH-HNNXBMFYSA-N\n    \n  \n\n\n\n\n\nmols_3a4_all = list(df_3a4_all[\"rdkit_mol\"])\n\n# Find MCS for all CYP3A4 inhibitors\nall_3a4_mcs = rdFMCS.FindMCS(mols_3a4_all)\n\n# All CYP3A4 inhibitors\nDraw.MolsToGridImage(\n    mols_3a4_all, \n    subImgSize=(400, 300), \n    molsPerRow=2, \n    legends = list(df_3a4_all[\"pref_name\"]),\n    highlightAtomLists=[m.GetSubstructMatch(all_3a4_mcs.queryMol) for m in mols_3a4_all]\n    )\n\n\n\n\nIt appears the MCS for most of them involves (partial) rings (e.g. cycloalkane, aromatic and macrolide ones). This result is basically not very different from when we’ve looked at the the CYP3A4 inhibitors separately in their moderate and strong potencies. The next thing I want to try is to add in the ring bonds matching.\n\n# matching ring bonds\nall_3a4_mcs_ring = rdFMCS.FindMCS(mols_3a4_all, ringMatchesRingOnly=True)\n\nDraw.MolsToGridImage(\n    mols_3a4_all, \n    subImgSize=(400, 300), \n    molsPerRow=2, \n    legends = list(df_3a4_all[\"pref_name\"]), \n    highlightAtomLists=[m.GetSubstructMatch(all_3a4_mcs_ring.queryMol) for m in mols_3a4_all]\n    )\n\n\n\n\nThe ring bond matching also shows a very similar result here as it only restricts the MCS matching to ring bonds only.\n\nSome other interesting code re. MCS\nOne of the code examples I’d like to try next, in order to see if it makes any differences from above, is the code snippets shared by a RDKit post from Paolo Tosco - “New MCS features in 2023.09.1” - the “Custom Python AtomCompare and BondCompare classes” section.\nSome notes from me:\n\nAtomCompare & BondCompare - looking at elements/bond orders/aromaticities in ring systems or\ncustom subclasses in AtomCompare & BondCompare - looking at elements/bond orders/aromaticities in non-ring systems\n\ni.e. customise parameters using rdFMCS.MCSParameters()\nI’ll also attempt to add some code comments below to explain how the code works (anyone’s welcomed to report any issues or changes for this part).\n\nRing systems\nHere, I’m trying the AtomCompare & BondCompare along with RingMatchesRingOnly and CompleteRingsOnly first.\n\n\nCode\n## Customise MCS parameters\n# Initiate a MCSParameter object\nparams = rdFMCS.MCSParameters()\n# Define atom typer to be used to compare elements within rdFMCS.AtomCompare class\nparams.AtomTyper = rdFMCS.AtomCompare.CompareElements\n# Define bond typer to be used to compare bond orders within rdFMCS.BondCompare class\nparams.BondTyper = rdFMCS.BondCompare.CompareOrder\n# RingMatchesRingOnly - ring atoms to match other ring atoms only\n# CompleteRingsOnly - match full rings only\nparams.BondCompareParameters.RingMatchesRingOnly = True\nparams.BondCompareParameters.CompleteRingsOnly = False\n\nall_3a4_ringMCS = rdFMCS.FindMCS(mols_3a4_all, params)\n\nDraw.MolsToGridImage(\n    mols_3a4_all, \n    subImgSize=(400, 300), \n    molsPerRow=3, \n    legends = list(df_3a4_all[\"pref_name\"]), \n    highlightAtomLists=[m.GetSubstructMatch(all_3a4_ringMCS.queryMol) for m in mols_3a4_all]\n    )\n\n\n\n\n\nSome MCS characteristics noted after trying this:\n\nWhen both BondCompareParameters are set to true, no rings are highlighted (apart from ethyl chains being highlighted in every molecule)\nWhen turning off CompleteRingsOnly, this allows partial rings to be shown in highlighted MCS\nA similar output is generated when using ringMatchesRingOnly = True in FindMCS() earlier for all CYP3A4 inhibitors\n\n\nNon-ring systems\nThe class code below is also borrowed from the RDKit blog post, which explains why it’s done as a custom “class” code and not a “function” one.\n\n\nCode\n# I've had to think harder about the what the class code are doing below, \n# especially the differences between comparing bond orders and ring atoms... \n# I can only describe it as both a restrictive (matching non-ring bonds only) \n# and lenient (but still comparing ring atoms) process in order to cover the non-ring parts (?)\n\n# Compare bond orders outside ring systems using rdFMCS.MCSBondCompare\n# Using class code that will call a function object\nclass CompareOrderOutsideRings(rdFMCS.MCSBondCompare):\n\n    def __call__(self, p, mol1, bond1, mol2, bond2):\n\n        # Get bonds 1 and 2 based on bond indices for mols 1 and 2\n        b1 = mol1.GetBondWithIdx(bond1)\n        b2 = mol2.GetBondWithIdx(bond2)\n        # If bonds 1 and 2 are both in ring or if their bond types are the same\n        if (b1.IsInRing() and b2.IsInRing()) or (b1.GetBondType() == b2.GetBondType()):\n            # If using stereo matching parameter and not checking bond stereo descriptors,\n            # return bonds that are not using stereo matching parameter\n            if (p.MatchStereo and not self.CheckBondStereo(p, mol1, bond1, mol2, bond2)):\n                return False\n            # If using ring bonds-matching-ring bonds parameter \n            # return mols/bonds that are part of a ring only\n            if p.RingMatchesRingOnly:\n                return self.CheckBondRingMatch(p, mol1, bond1, mol2, bond2)\n            return True\n        # Only match bonds that are not part of ring systems\n        return False\n\n# Compare atom elements outside ring systems using rdFMCS.MCSAtomCompare\nclass CompareElementsOutsideRings(rdFMCS.MCSAtomCompare):\n\n    def __call__(self, p, mol1, atom1, mol2, atom2):\n\n        # Get atoms 1 and 2 based on atom indices for mols 1 and 2\n        a1 = mol1.GetAtomWithIdx(atom1)\n        a2 = mol2.GetAtomWithIdx(atom2)\n        # If atomic numbers for both atoms are different and the atoms are not in ring systems,\n        # return atoms that instead have the same atomic numbers and in rings systems\n        if (a1.GetAtomicNum() != a2.GetAtomicNum()) and not (a1.IsInRing() and a2.IsInRing()):\n            return False\n        # If using matching atom chirality parameter and not checking both atoms have a chiral tag,\n        # return atoms that are not using the matching atom chirality parameter\n        if (p.MatchChiralTag and not self.CheckAtomChirality(p, mol1, atom1, mol2, atom2)):\n            return False\n        # If using ring bonds-matching-ring bonds parameter,\n        # return mols/atoms that are part of a ring only\n        if p.RingMatchesRingOnly:\n            return self.CheckAtomRingMatch(p, mol1, atom1, mol2, atom2)\n        # Only match ring atoms against ring atoms \n        return True\n\nparams_or = rdFMCS.MCSParameters()\nparams_or.AtomTyper = CompareElementsOutsideRings()\nparams_or.BondTyper = CompareOrderOutsideRings()\nparams_or.BondCompareParameters.RingMatchesRingOnly = True\nparams_or.BondCompareParameters.CompleteRingsOnly = True\n\nall_3a4_orMCS = rdFMCS.FindMCS(mols_3a4_all, params_or)\n\nDraw.MolsToGridImage(\n    mols_3a4_all, \n    subImgSize=(500, 400), \n    molsPerRow=3, \n    legends = list(df_3a4_all[\"pref_name\"]), \n    highlightAtomLists=[m.GetSubstructMatch(all_3a4_orMCS.queryMol) for m in mols_3a4_all]\n    )\n\n\n\n\n\nBy using the suggested class code above, the MCS has indeed become larger, where a full ring is highlighted as the MCS.\nA second code example from iwatobipen is to highlight molecular differences, which is different from highlighting only the MCSes. Alternative URL link and more examples can be accessed via RDKit Cookbook. Possible use cases of this code may be when dealing with a large set of analogues with changes in R-groups or during large compound screening and search (just as a few examples only). The main thing I can see from the code is that it begins with finding MCS for the input molecules, then uses SMARTS strings of the MCS in order to find atoms not within the MCS (using GetSubstructMatch() part) then highlights that part of the molecules.\n\n\n\nAll CYP2D6 inhibitors\nBecause of how the MCSes have turned out for CYP3A4 inhibitors above, I think I should just look at CYP2D6 inhibitors as a whole here. First thing is to combine the dataframes between the moderate and strong inhibitor groups.\n\n# Concatenate dfs \ndf_2d6_all = pd.concat([df_2d6_s_inh_p, df_2d6_m_inh_p])\n# index un-changed for now\nprint(df_2d6_all.shape)\ndf_2d6_all.head()\n\n(14, 9)\n\n\n\n\n\n\n  \n    \n      \n      chembl_id\n      pref_name\n      max_phase\n      canonical_smiles\n      rdkit_mol\n      standard_smiles\n      selfies\n      inchi\n      inchikey\n    \n  \n  \n    \n      0\n      CHEMBL894\n      BUPROPION\n      4.0\n      CC(NC(C)(C)C)C(=O)c1cccc(Cl)c1\n      <rdkit.Chem.rdchem.Mol object at 0x135da3530>\n      CC(NC(C)(C)C)C(=O)c1cccc(Cl)c1\n      [C][C][Branch1][#Branch2][N][C][Branch1][C][C]...\n      InChI=1S/C13H18ClNO/c1-9(15-13(2,3)4)12(16)10-...\n      SNPPWIUOZRMYNY-UHFFFAOYSA-N\n    \n    \n      1\n      CHEMBL41\n      FLUOXETINE\n      4.0\n      CNCCC(Oc1ccc(C(F)(F)F)cc1)c1ccccc1\n      <rdkit.Chem.rdchem.Mol object at 0x135da3290>\n      CNCCC(Oc1ccc(C(F)(F)F)cc1)c1ccccc1\n      [C][N][C][C][C][Branch2][Ring1][Ring2][O][C][=...\n      InChI=1S/C17H18F3NO/c1-21-12-11-16(13-5-3-2-4-...\n      RTHCYVBBDHJXIQ-UHFFFAOYSA-N\n    \n    \n      2\n      CHEMBL490\n      PAROXETINE\n      4.0\n      Fc1ccc([C@@H]2CCNC[C@H]2COc2ccc3c(c2)OCO3)cc1\n      <rdkit.Chem.rdchem.Mol object at 0x135da3bc0>\n      Fc1ccc([C@@H]2CCNC[C@H]2COc2ccc3c(c2)OCO3)cc1\n      [F][C][=C][C][=C][Branch2][Ring1][#Branch2][C@...\n      InChI=1S/C19H20FNO3/c20-15-3-1-13(2-4-15)17-7-...\n      AHOUBRCZNHFOSL-YOEHRIQHSA-N\n    \n    \n      4\n      CHEMBL1294\n      QUINIDINE\n      4.0\n      C=C[C@H]1CN2CC[C@H]1C[C@@H]2[C@@H](O)c1ccnc2cc...\n      <rdkit.Chem.rdchem.Mol object at 0x135da2d50>\n      C=C[C@H]1CN2CC[C@H]1C[C@@H]2[C@@H](O)c1ccnc2cc...\n      [C][=C][C@H1][C][N][C][C][C@H1][Ring1][=Branch...\n      InChI=1S/C20H24N2O2/c1-3-13-12-22-9-7-14(13)10...\n      LOUPRKONTZGTKE-LHHVKLHASA-N\n    \n    \n      0\n      CHEMBL254328\n      ABIRATERONE\n      4.0\n      C[C@]12CC[C@H](O)CC1=CC[C@@H]1[C@@H]2CC[C@]2(C...\n      <rdkit.Chem.rdchem.Mol object at 0x135dd0270>\n      C[C@]12CC[C@H](O)CC1=CC[C@@H]1[C@@H]2CC[C@]2(C...\n      [C][C@][C][C][C@H1][Branch1][C][O][C][C][Ring1...\n      InChI=1S/C24H31NO/c1-23-11-9-18(26)14-17(23)5-...\n      GZOSMCIZMLWJML-VJLLXTKPSA-N\n    \n  \n\n\n\n\n\nmols_all_2d6 = list(df_2d6_all[\"rdkit_mol\"])\n\n# Find MCS for all CYP2D6 inhibitors\nall_2d6_mcs = rdFMCS.FindMCS(mols_all_2d6)\n\n# Get images of highlighted MCS for all CYP2D6 inhibitors\nDraw.MolsToGridImage(\n    mols_all_2d6, \n    subImgSize=(400, 300), \n    molsPerRow=2, \n    legends = list(df_2d6_all[\"pref_name\"]), \n    highlightAtomLists=[m.GetSubstructMatch(all_2d6_mcs.queryMol) for m in mols_all_2d6]\n    )\n\n\n\n\nAgain, only a phenyl ring is highlighted as the MCS so this is not informative at all.\n\n\n\n\nSome findings and future work\nBelow are some of my small findings and thoughts.\n\nAs mentioned at the very top in the outline section, rings (heterocycles, aromatic or fused ones) are everywhere in the MCSes for CYP3A4 and CYP2D6 inhibitors, and they are very common in known approved drugs\nLooking at CYP structures in relation to these inhibitors may be more meaningful and also may reveal more insights about possible binding sites or mechanisms of actions of CYP inhibitions for these compounds. This may also be further explored in parallel to the actual drug targets of these CYP inhibitors e.g. binding site on CYP isoenzyme versus binding site on drug target protein as there are different classes of drugs within these CYP inhibitors. For example, some of CYP2D6 inhibitors are drugs acting on central nervous system (about 9 out of 14 drugs) - e.g. bupropion, fluoxetine, paroxetine, clobazam, doxepin, duloxetine, locaserin, moclobemide and rolapitant. For the CYP3A4 inhibitors, they are in several different therapeutic classes e.g. antivirals, antifungals, antibacterials, kinase inhibitors etc.\nIt may be a bit more interesting to compare the MCSes between CYP3A4 and CYP2D6 substrates (adding in other substrates for other CYPs)\nFuture posts may involve looking at CYP substrates using different cheminformatics strategies or doing molecular docking within a notebook setting (has this been done before?)\nCYP inducers are a different story as they tend to increase drug metabolisms via CYP inductions, which are more likely to do with losing therapeutic effects than gaining adverse effects, so they may be looked at further down the line\nMCS may not be absolutely useful in every scenario as I think it aims to look for the most maximum common substructures within a set of molecules, so not every molecule will be able to have a MCS shown (e.g. in a very diverse chemical set), other similarity searching techniques should probably be used instead if needed\n\n\n\n\nAcknowledgements\nThanks to every contributor, developer or authors of every software package used in this post, and also the online communities behind them. Before I forget, the thanks would also be extended to the authors of the journal papers cited in this post. Lastly, special thanks to Noel O’Boyle for being very patient with reading my awfully-long old draft earlier and pointed out some useful things to note and change (I kind of got lost when writing the draft… due to it being a “free-style post”, I should avoid doing this again).\n\n\n\n\n\nReferences\n\nCurran, Mark E, Igor Splawski, Katherine W Timothy, G.Michael Vincen, Eric D Green, and Mark T Keating. 1995. “A Molecular Basis for Cardiac Arrhythmia: HERG Mutations Cause Long QT Syndrome.” Cell 80 (5): 795–803. https://doi.org/10.1016/0092-8674(95)90358-5.\n\n\nDalke, Andrew, and Janna Hastings. 2013. “FMCS: A Novel Algorithm for the Multiple MCS Problem.” Journal of Cheminformatics 5 (S1). https://doi.org/10.1186/1758-2946-5-s1-o6.\n\n\nDoveston, Richard G., Paolo Tosatti, Mark Dow, Daniel J. Foley, Ho Yin Li, Amanda J. Campbell, David House, Ian Churcher, Stephen P. Marsden, and Adam Nelson. 2015. “A Unified Lead-Oriented Synthesis of over Fifty Molecular Scaffolds.” Organic & Biomolecular Chemistry 13 (3): 859–65. https://doi.org/10.1039/c4ob02287d.\n\n\nFlockhart, DA., D. Thacker, C. McDonald, and Z. Desta. 2021. “The Flockhart Cytochrome P450 Drug-Drug Interaction Table.” https://drug-interactions.medicine.iu.edu/.\n\n\nFraser, James S., and Mark A. Murcko. 2024. “Structure Is Beauty, but Not Always Truth.” Cell 187 (3): 517–20. https://doi.org/10.1016/j.cell.2024.01.003.\n\n\nGaulton, Anna, Anne Hersey, Michał Nowotka, A. Patrícia Bento, Jon Chambers, David Mendez, Prudence Mutowo, et al. 2016. “The ChEMBL database in 2017.” Nucleic Acids Research 45 (D1): D945–54. https://doi.org/10.1093/nar/gkw1074.\n\n\nGuengerich, F. Peter. 2020. “A History of the Roles of Cytochrome P450 Enzymes in the Toxicity of Drugs.” Toxicological Research 37 (1): 1–23. https://doi.org/10.1007/s43188-020-00056-z.\n\n\nJadhav, Ajit, Rafaela S. Ferreira, Carleen Klumpp, Bryan T. Mott, Christopher P. Austin, James Inglese, Craig J. Thomas, David J. Maloney, Brian K. Shoichet, and Anton Simeonov. 2010. “Quantitative Analyses of Aggregation, Autofluorescence, and Reactivity Artifacts in a Screen for Inhibitors of a Thiol Protease.” Journal of Medicinal Chemistry 53 (1): 37–51. https://doi.org/10.1021/jm901070c.\n\n\nTaylor, Richard D., Malcolm MacCoss, and Alastair D. G. Lawson. 2014. “Rings in Drugs.” Journal of Medicinal Chemistry 57 (14): 5845–59. https://doi.org/10.1021/jm4017625."
  },
  {
    "objectID": "posts/07_Molecular_similarities_in_COVID-19_antivirals/Mol_sim_covid.html",
    "href": "posts/07_Molecular_similarities_in_COVID-19_antivirals/Mol_sim_covid.html",
    "title": "Molecular similarities in selected COVID-19 antivirals",
    "section": "",
    "text": "Why this post?\nWell, I’ve always had a thought sitting at the back of my mind about working on a chemistry-related data project. It was partly due to the research saga detailed in another blog post. About two months ago, I thought I will never be able to get anything decent (e.g. first-author paper) published out of my PhD, so I was thinking of going down the route of working on health data science, which was where I could tie in my pharmacist background. Miraculously, the paper actually got published last month, which meant I might have more career options now…\nThe funny thing was that before I knew this paper was coming, I’ve already made up my mind about working on at least one piece of chemistry-related work before leaving it behind completely. Therefore, this was how I got myself started on this post, a small piece of cheminformatics work on molecular similarity for selected COVID-19 antivirals, as taking my first baby step in this field.\n\n\nHeads up\nThis work was coded entirely in Python3 and saved as .ipynb file initially in Jupyter Notebook. It was later converted into .qmd file via CLI1, which was run without problems in RStudio IDE. One thing to note was that all 2D chemical structures or similarity maps did not physically show up in RStudio IDE after code executions, but after file rendering, all of them appeared accordingly in the published version.\n\n\n\n\nPhoto by D koi on Unsplash\n\n\n\n\n\n\nThe COVID-19 antivirals\nWithout going into too much pharmacodynamic profiles for these antivirals, as that could easily be another blog post, I’ll provide only brief overviews on how these medicines were used mainly in the New Zealand context (may vary for different countries).\n\nnirmatrelvir & ritonavir\nOne of the oral COVID-19 antivirals, marketed as Paxlovid, was indicated for mild to moderate symptoms, or at risk of severe disease. For effectiveness, it needed to be taken within 5 days of symptom onset, otherwise it might not work as expected. As a side note, ritonavir was added like an enhancer agent for nirmatrelvir, due to its known ability to inhibit CYP3A2-mediated metabolism of nirmatrelvir, therefore, by having it also inside the oral tablet, it would ensure that the plasma concentration of nirmatrelvir would be kept at an optimal therapeutic level in vivo, vital for the antiviral effect. One of the well-known downsides for this medicine was that it could cause drug interactions with several other commonly used medications such as dabigatran, or potent CYP3A inducers such as carbamazepine as one of the examples (for full drug interaction profiles, please consult local guidelines). Renal functions was also another important factor to consider when dosing.\n\n\nmolnupiravir\nThis was the other oral COVID-19 antiviral, also indicated for mild to moderate symptoms or at risk of severe disease, and also if the option of nirmatrelvir with ritonavir was unsuitable. It was often selected as an oral alternative to nirmatrelvir with ritonavir to avoid drug interactions. It also needed to be taken within 5 days of symptom onset to reach optimal effect.\n\n\nremdesivir\nThis was administered via intravenous infusion for selected adult or paediatric patients (depends on local guidelines) when they were hospitalised and at risk of developing severe disease. Current consideration for its use would be within 7 days of symptom onset. It was classed as a section 29 medicine, which meant it was unapproved, but could be prescribed on a case-by-case basis by qualified medical practitioners.\n\n\nbaricitinib\nThis was also another unapproved, section 29 medicine, indicated for use in hospitalised patients on a case-by-case basis. It was indicated for moderate to severe disease with renally-adjusted dose via oral or nasogastric route.\n\n\n\n\nSource of dataset\nThe URLs to obtain canonical simplified molecular input line entry systems (SMILES) of all 5 molecules are listed below (there are several different ways to obtain SMILES for molecules, I’ve decided to use PubChem in this case):\n\nPubChem [Internet]. Bethesda (MD): National Library of Medicine (US), National Center for Biotechnology Information; 2004-. PubChem Compound Summary for CID 155903259, Nirmatrelvir; [cited 2022 Nov. 13]. Available from: https://pubchem.ncbi.nlm.nih.gov/compound/Nirmatrelvir\nPubChem [Internet]. Bethesda (MD): National Library of Medicine (US), National Center for Biotechnology Information; 2004-. PubChem Compound Summary for CID 392622, Ritonavir; [cited 2022 Nov. 13]. Available from: https://pubchem.ncbi.nlm.nih.gov/compound/Ritonavir\nPubChem [Internet]. Bethesda (MD): National Library of Medicine (US), National Center for Biotechnology Information; 2004-. PubChem Compound Summary for CID 145996610, EIDD-2801; [cited 2022 Nov. 13]. Available from: https://pubchem.ncbi.nlm.nih.gov/compound/eidd-2801\nPubChem [Internet]. Bethesda (MD): National Library of Medicine (US), National Center for Biotechnology Information; 2004-. PubChem Compound Summary for CID 121304016, Remdesivir; [cited 2022 Nov. 13]. Available from: https://pubchem.ncbi.nlm.nih.gov/compound/Remdesivir\nPubChem [Internet]. Bethesda (MD): National Library of Medicine (US), National Center for Biotechnology Information; 2004-. PubChem Compound Summary for CID 44205240, Baricitinib; [cited 2022 Nov. 13]. Available from: https://pubchem.ncbi.nlm.nih.gov/compound/Baricitinib\n\n\n\n\nInstall modules/libraries\nInstall relevant libraries if needed.\n\n# Uncomment and install the following libraries if required \n#!pip install rdkit-pypi pandas mols2grid matplotlib\n\nImport libraries needed as shown below.\n\n# RDKit chemistry\nfrom rdkit import Chem\n# RDKit drawing\nfrom rdkit.Chem.Draw import IPythonConsole\nfrom rdkit.Chem import Draw\n# RDKit fingerprint generator\nfrom rdkit.Chem import rdFingerprintGenerator\n# RDKit functionality for basic data structures\nfrom rdkit.Chem import DataStructs\n# Settings to improve quality of structures\nfrom rdkit.Chem import rdDepictor\n# SVG = scalable vector graphics, set to false if wanting PNGs instead\nIPythonConsole.ipython_useSVG = True\nrdDepictor.SetPreferCoordGen(True)\n# Add ability to add a molecule to a dataframe\nfrom rdkit.Chem import PandasTools\n# mols2grid library provides convenient way to display molecules in a grid\nimport mols2grid\n# for dataframe manipulations\nimport pandas as pd\n# for plotting graphs\nimport matplotlib.pyplot as plt\n\n\n\n\nGenerate RDKit molecules based on SMILES\nBefore any actual molecular manipulation work could begin, the SMILES of all 5 molecules were downloaded from the source URLs. I’ve downloaded all 5 molecules’ SMILES and saved them as separate .sdf files (selected 2D structure option).\nSo I started off with nirmatrelvir with its canonical SMILES retrieved from PubChem. To display a molecule as a 2D chemical structure graphically, an open-source cheminformatics toolkit library, RDKit, was used.\n\n# Generate a RDKit molecule representing nirmatrelvir\nnmt = Chem.MolFromSmiles(\"CC1(C2C1C(N(C2)C(=O)C(C(C)(C)C)NC(=O)C(F)(F)F)C(=O)NC(CC3CCNC3=O)C#N)C\")\nnmt\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Create a RDKit molecule for ritonavir using canonical SMILES\nrit = Chem.MolFromSmiles(\"CC(C)C1=NC(=CS1)CN(C)C(=O)NC(C(C)C)C(=O)NC(CC2=CC=CC=C2)CC(C(CC3=CC=CC=C3)NC(=O)OCC4=CN=CS4)O\")\nrit\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Create a RDKit molecule for molnupiravir using canonical SMILES\nmol = Chem.MolFromSmiles(\"CC(C)C(=O)OCC1C(C(C(O1)N2C=CC(=NC2=O)NO)O)O\")\nmol\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Create a RDKit molecule for remdesivir by using canonical SMILES\nrem = Chem.MolFromSmiles(\"CCC(CC)COC(=O)C(C)NP(=O)(OCC1C(C(C(O1)(C#N)C2=CC=C3N2N=CN=C3N)O)O)OC4=CC=CC=C4\")\nrem\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Create a RDKit molecule for baricitinib by using canonical SMILES\nbar = Chem.MolFromSmiles(\"CCS(=O)(=O)N1CC(C1)(CC#N)N2C=C(C=N2)C3=C4C=CNC4=NC=N3\")\nbar\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDisplay 2D molecules in grid view\nTo display all 5 molecules in a grid view, I’ve saved all separate .sdf files into one .sdf file (e.g. covid_antivirals.sdf). A quick way to do this was via CLI by using one line of code: cat *.sdf > file_name.sdf (replace “file_name” as the actual file name wanted). One thing to be aware of was to make sure which working directory this was saved to, as it needed to be in the same directory as the .qmd file for it to work.\n\n# Save all 5 COVID-19 antivirals as a list in a cpds object\ncpds = [x for x in Chem.SDMolSupplier(\"covid_antivirals.sdf\")]\ncpds\n\n[<rdkit.Chem.rdchem.Mol at 0x12bdf9b60>,\n <rdkit.Chem.rdchem.Mol at 0x12bdf9cb0>,\n <rdkit.Chem.rdchem.Mol at 0x12bdf9d20>,\n <rdkit.Chem.rdchem.Mol at 0x12bdf9d90>,\n <rdkit.Chem.rdchem.Mol at 0x12bdf9e00>]\n\n\nWell, this flexible grid view with function to select molecules would be much more useful if there were several thousands of molecules downloaded. I was just basically trialling this as a practice, which turned out quite nicely.\n\n# Display all compounds in a flexible grid view with selection function\nmols2grid.display(cpds)\n\n\n\n\n\n\n\n\n\nThen I thought about adding drug names to each molecule, rather than listing their IUPAC3 names, for the sake of easier reading and viewing. One of the ways to do this was to add legend with the drug names in the same order.\n\n# Display compounds in grid view with drug names shown\nDraw.MolsToGridImage(cpds, \n                     molsPerRow = 3, \n                     legends = (\"baricitinib\", \"molnupiravir\", \"nirmatrelvir\", \"remdesivir\", \"ritonavir\"), \n                     subImgSize=(300, 300), \n                     useSVG = True\n                    )\n\n\n\n\n\n\n\nSimilarity maps\nNow this part was interesting to me and I’ve spent at least a day or two to just try and understand the fundamentals behind this functionality in RDKit. One of the biggest help for me to fully understand this was this paper: Riniker, S.; Landrum, G. A. “Similarity Maps - A Visualization Strategy for Molecular Fingerprints and Machine-Learning Methods” J. Cheminf. 5:43 (2013). It explained the full methodology behind generating similarity map between compounds using molecular fingerprints.\n\n# Build similarity maps between molecules\n# Import additional libraries needed\nfrom rdkit.Chem.Draw import SimilarityMaps\nimport io\nfrom PIL import Image\n\nThe following step was important to ensure a good image of the map was produced for the molecules, by creating a function for “show_png” first, which was used later.\n\n# Binary i/o keeps data as bytes in an in-memory buffer\n# A function that creates a bytes object as an image\ndef show_png(data):\n    bio = io.BytesIO(data)\n    img = Image.open(bio)\n    return img\n\nI’ve randomly set nirmatrelvir as the reference compound. The other 4 molecules were set as test or probe molecules to be compared with the reference compound. So here I’ve compared nirmatrelvir with ritonavir first.\n\n# Create a Draw2D object \"a\" and specify size of 2D image\na = Draw.MolDraw2DCairo(500, 500)\n# Produces a similarity map for nirmatrelvir and ritonavir\n# Specify which compounds to compare (reference and probe) for the similarity map\nfig, maxweight = SimilarityMaps.GetSimilarityMapForFingerprint(nmt, rit, \n                                                               # creates a lambda function (anonymous function) for use within SimilarityMaps, \n                                                               # then select fingerprint type e.g. Morgan fingerprint\n                                                               # types of Morgan fingerprint: bit vector (bv, default) & count vector (count)\n                                                               lambda b, c: SimilarityMaps.GetMorganFingerprint(b, c, radius = 2, fpType = 'bv'),\n                                                               draw2d = a)\n\n# Finish drawing Draw2D object \"a\"                                                                                       \na.FinishDrawing()\n# Display similarity map                                                             \nshow_png(a.GetDrawingText())\n\n\n\n\nTo quickly explain how to look at the contour or topographical map in different colours for the molecule:\n\nGreen shades represented a positive difference or where the similarity decreased when the bits4 were removed\nPink shades showed negative difference or where the similarity increased when the bits were removed\nGrey shades meant there was no change\n\nAnother parameter that might allow us to interpret more easily was to obtain the maximum weight (also known as “maxweight” in the code) for the structure comparison between two molecules. Maximum weight could be understood as maximum difference between the reference and probe molecules. By default, maximum weight was capped at 1.0. This function was already built in above code, so to find out the maximum weight or difference for nirmatrelvir and ritonavir, simply just use the print() function.\n\n# Max weight between nirmatrelvir and ritonavir \nprint(maxweight)\n\n0.03389096421417358\n\n\nI’ve then saved this particular maxweight result with a different label name (to clearly show which molecules were being compared), for later use.\n\nmol2_rit_maxw_mol1 = maxweight\nmol2_rit_maxw_mol1\n\n0.03389096421417358\n\n\nTo further explain and understand the parameter of maximum weight, this paper by Riniker and Landrum have included a full calculation styled as pseudocode in Python. I have attempted to summarise them in words, along with the code (adapted from the paper), as below:\n```{python}\n# 1. Calculate the fingerprint for reference molecule\nref_fp = calculate_fingerprint (ref_mol)\n\n# 2. Calculate the fingerprint for test molecule\nthis_fp = calculate_fingerprint (this_mol)\n\n# 3. Create an empty weights list\nweights = []\n\n# 4. Calculate original similarity for ref mol & test mol based on Dice similarity\norig_simil = dice_similarity(ref_fp, this_fp)\n\n# 5. Loop over the different atoms present in the test mol\nfor atom in this_mol.get_atoms:\n\n# 5. (cont.) Generate a new fingerprint by calculating new fingerprints without each of the atom for the test mol\n    new_fp = calculate_fingerprint_without_atom(this_mol, atom)\n    \n# 5. (cont.) Calculate new similarity for the ref fingerprint & new fingerprint based on Dice similarity\n    new_simil = dice_similarity(ref_fp, new_fp)\n    \n# 6. The atomic weight will be calculated as the difference between the original similarity and the new similarity\nweight = original_simil - new_simil\n\n# 7. The atomic weight obtained for each loop iteration (for each atom present) will be added up to contribute to the final atomic weight\nweights.append(weight)\n\n# Note: maximum absolute weight is normalised and capped at 1.0\n```\nNext one was between nirmatrelvir and molnupiravir. I’ve renamed “maxweight” to “mol3_mol_maxw_mol1” to reflect this parameter was measured between 3rd molecule (molnupiravir) and 1st molecule (nirmatrelvir).\n\n# 2. Comparing nirmatrelvir and molnupiravir\na = Draw.MolDraw2DCairo(400, 400)\n# Produces a similarity map for molecules selected\n# Specify which compounds to compare (reference and probe) for the similarity map\nfig, mol3_mol_maxw_mol1 = SimilarityMaps.GetSimilarityMapForFingerprint(nmt, mol, \n                                                               # creates a lambda function (anonymous function) for use within SimilarityMaps, \n                                                               # then select fingerprint type e.g. Morgan fingerprint\n                                                               # types of Morgan fingerprint: bit vector (bv, default) & count vector (count)\n                                                               lambda b, c: SimilarityMaps.GetMorganFingerprint(b, c, radius = 2, fpType = 'bv'),\n                                                               draw2d = a)\n\n# Finish drawing Draw2D object \"a\"                                                                                       \na.FinishDrawing()\n# Display similarity map                                                             \nshow_png(a.GetDrawingText())\n\n\n\n\nThe maximum weight between nirmatrelvir and molnupiravir was shown as below.\n\nprint(mol3_mol_maxw_mol1)\n\n0.026617250673854453\n\n\nSimilarity map was then generated for nirmatrelvir and remdesivir.\n\n# 3. Comparing nirmatrelvir and remdesivir\na = Draw.MolDraw2DCairo(400, 400)\n# Produces a similarity map for molecules selected\n# Specify which compounds to compare (reference and probe) for the similarity map\nfig, mol4_rem_maxw_mol1 = SimilarityMaps.GetSimilarityMapForFingerprint(nmt, rem, \n                                                               # creates a lambda function (anonymous function) for use within SimilarityMaps, \n                                                               # then select fingerprint type e.g. Morgan fingerprint\n                                                               # types of Morgan fingerprint: bit vector (bv, default) & count vector (count)\n                                                               lambda b, c: SimilarityMaps.GetMorganFingerprint(b, c, radius = 2, fpType = 'bv'),\n                                                               draw2d = a)\n\n# Finish drawing Draw2D object \"a\"                                                                                       \na.FinishDrawing()\n# Display similarity map                                                             \nshow_png(a.GetDrawingText())\n\n\n\n\nTheir maximum weight was found as below.\n\nprint(mol4_rem_maxw_mol1)\n\n0.021674876847290636\n\n\nLastly, the comparison was made between nirmatrelvir and baricitinib.\n\n# 4. Comparing nirmatrelvir and baricitinib\na = Draw.MolDraw2DCairo(400, 400)\n# Produces a similarity map for molecules selected\n# Specify which compounds to compare (reference and probe) for the similarity map\nfig, mol5_bar_maxw_mol1 = SimilarityMaps.GetSimilarityMapForFingerprint(nmt, bar, \n                                                               # creates a lambda function (anonymous function) for use within SimilarityMaps, \n                                                               # then select fingerprint type e.g. Morgan fingerprint\n                                                               # types of Morgan fingerprint: bit vector (bv, default) & count vector (count)\n                                                               lambda b, c: SimilarityMaps.GetMorganFingerprint(b, c, radius = 2, fpType = 'bv'),\n                                                               draw2d = a)\n\n# Finish drawing Draw2D object \"a\"                                                                                       \na.FinishDrawing()\n# Display similarity map                                                             \nshow_png(a.GetDrawingText())\n\n\n\n\nThe maximum weight was found as below.\n\nprint(mol5_bar_maxw_mol1)\n\n0.026242075777679508\n\n\nShort summary:\n\nNirmatrelvir vs. remdesivir had the smallest maximum weight or difference out of all 5 compounds\nNirmatrelvir vs. ritonavir had the biggest maximum weight or difference out of all compounds, the second biggest one would be between nirmatrelvir and molnupiravir\n\n\n\n\nFingerprint generator\nAfter using the similarity maps, I found more things to trial in RDKit, and this one was a fingerprint generator. I’ve decided to use the same 5 molecules as before, and see if I could get similar results.\n\n# Re-label molecules for later use\nmol1 = nmt\nmol2 = rit\nmol3 = mol\nmol4 = rem\nmol5 = bar\n\n# Combine all 5 molecules into a list\nmols = [mol1, mol2, mol3, mol4, mol5]\n\nBelow was the set of code used to generate a fingerprint between compounds. I’ve changed the radius to 2 to align with the similarity map test above.\n\n# Create an object fp to generate fingerprint\n# Default radius of molecule = 3 \nfp = rdFingerprintGenerator.GetMorganGenerator(radius = 2)\n# Get fingerprints of all molecules in the list\nfp1 = [fp.GetFingerprint(x) for x in mols]\nfp1\n\n[<rdkit.DataStructs.cDataStructs.ExplicitBitVect at 0x12bfb7140>,\n <rdkit.DataStructs.cDataStructs.ExplicitBitVect at 0x12bfb71b0>,\n <rdkit.DataStructs.cDataStructs.ExplicitBitVect at 0x12bfb7220>,\n <rdkit.DataStructs.cDataStructs.ExplicitBitVect at 0x12bfb7290>,\n <rdkit.DataStructs.cDataStructs.ExplicitBitVect at 0x12bfb7300>]\n\n\nA loop was created to iterate through all 5 antivirals to compare their molecular similarities by using Tanimoto coefficient (TC)5. Particularly, each molecule was compared to the other 4 molecules, with results printed as shown below.\n\nfor i in range(len(fp1)):\n    for a in range(i):\n        tc = DataStructs.TanimotoSimilarity(fp1[i], fp1[a])\n        print(f'mol{i+1}-mol{a+1}: Tanimoto coefficient {tc}')\n\nmol2-mol1: Tanimoto coefficient 0.08461538461538462\nmol3-mol1: Tanimoto coefficient 0.10891089108910891\nmol3-mol2: Tanimoto coefficient 0.14953271028037382\nmol4-mol1: Tanimoto coefficient 0.10687022900763359\nmol4-mol2: Tanimoto coefficient 0.1386861313868613\nmol4-mol3: Tanimoto coefficient 0.19811320754716982\nmol5-mol1: Tanimoto coefficient 0.11214953271028037\nmol5-mol2: Tanimoto coefficient 0.09243697478991597\nmol5-mol3: Tanimoto coefficient 0.10989010989010989\nmol5-mol4: Tanimoto coefficient 0.15517241379310345\n\n\nI then saved each TC separately between nirmatrelvir and other 4 molecules. This was to create another list of these TCs for data visualisation later.\n\n# Tanimoto coefficient between nirmatrelvir (mol1) & ritonavir (mol2)\ntc_mol1_mol2 = DataStructs.TanimotoSimilarity(fp1[0], fp1[1])\n\n# Tanimoto coefficient between nirmatrelvir (mol1) & molnupiravir (mol3)\ntc_mol1_mol3 = DataStructs.TanimotoSimilarity(fp1[0], fp1[2])\n\n# Tanimoto coefficient between nirmatrelvir (mol1) & remdesivir (mol4)\ntc_mol1_mol4 = DataStructs.TanimotoSimilarity(fp1[0], fp1[3])\n\n# Tanimoto coefficient between nirmatrelvir (mol1) & baricitinib (mol5)\ntc_mol1_mol5 = DataStructs.TanimotoSimilarity(fp1[0], fp1[4])\n\nA new list was created to save all TCs for nirmatrelvir versus other 4 molecules.\n\ntc_mols = [tc_mol1_mol2, tc_mol1_mol3, tc_mol1_mol4, tc_mol1_mol5]\ntc_mols\n\n[0.08461538461538462,\n 0.10891089108910891,\n 0.10687022900763359,\n 0.11214953271028037]\n\n\nI thought to include following code to ensure I wasn’t losing track on which molecule was which by having them displayed as 2D structures with labels.\n\n# Display compounds to help with recognising which antivirals are being compared\nDraw.MolsToGridImage(mols, \n                     molsPerRow = 3, \n                     legends = (\"mol1 = nirmatrelvir\", \"mol2 = ritonavir\", \"mol3 = molnupiravir\", \"mol4 = remdesivir\", \"mol5 = baricitinib\"), \n                     subImgSize=(300, 300), \n                     useSVG = True\n                    )\n\n\n\n\nAnother list was generated to save all maximum weights between nirmatrelvir and the rest of the molecules.\n\nmaxw_diff = [mol2_rit_maxw_mol1, mol3_mol_maxw_mol1, mol4_rem_maxw_mol1, mol5_bar_maxw_mol1]\nmaxw_diff\n\n[0.03389096421417358,\n 0.026617250673854453,\n 0.021674876847290636,\n 0.026242075777679508]\n\n\nA new dataframe was also created to include maximum weights and TCs of all 5 molecules.\n\ndf_ms = pd.DataFrame(list(zip(maxw_diff, tc_mols)),\n                     index = ['nmt_v_rit', 'nmt_v_mol', 'nmt_v_rem', 'nmt_v_bar'],\n                     columns = ['Maxweight', 'T_coeff']\n                    )\ndf_ms\n\n\n\n\n\n  \n    \n      \n      Maxweight\n      T_coeff\n    \n  \n  \n    \n      nmt_v_rit\n      0.033891\n      0.084615\n    \n    \n      nmt_v_mol\n      0.026617\n      0.108911\n    \n    \n      nmt_v_rem\n      0.021675\n      0.106870\n    \n    \n      nmt_v_bar\n      0.026242\n      0.112150\n    \n  \n\n\n\n\nTo produce a bar graph representing these parameters, I realised I would probably need to change the index into a column instead.\n\ndf_ms.reset_index(inplace = True)\ndf_ms_new = df_ms.rename(columns = {'index': 'Molecules'})\ndf_ms_new\n\n\n\n\n\n  \n    \n      \n      Molecules\n      Maxweight\n      T_coeff\n    \n  \n  \n    \n      0\n      nmt_v_rit\n      0.033891\n      0.084615\n    \n    \n      1\n      nmt_v_mol\n      0.026617\n      0.108911\n    \n    \n      2\n      nmt_v_rem\n      0.021675\n      0.106870\n    \n    \n      3\n      nmt_v_bar\n      0.026242\n      0.112150\n    \n  \n\n\n\n\n\n\n\nData visualisation and some findings\nA side-by-side bar graph showing two different molecular similarity parameters - maximum weights from similarity map and TCs calculated from Morgan fingerprints - was plotted based on the dataframe created above. It showed similar trend between these two molecular similarity tests for these known COVID-19 antivirals. In that, nirmatrelvir versus ritonavir showed the largest molecular difference out of all 5 compounds with the highest maximum weight. This was reflected in the lowest TC as the shortest orange bar, which implied a low similarity between the two molecules. Interestingly, between nirmatrelvir and remdesivir, it appeared the maximum weight was lowest of all 5 molecules, but the TC did not quite reflect that (being lower than that for nirmatrelvir versus molnupiravir and baricitinib).\n\n# Set the overall font size to make all labels on graph easier to read\nplt.rcParams.update({'font.size': 10})\n\n# Used nirmatrelvir as reference compound (mol1) and compared it with 4 other antivirals\n# If wanting stacked bar graph:\n#df_ms_new.plot(x = 'Molecules', \n               #kind = 'bar', \n               #width = 0.3, \n               #stacked = True, \n               #title = 'Molecular similarities between 5 known COVID-19 antivirals'\n               #)\n#plt.show()\n\n# Side-by-side bar graph\ndf_ms_new.plot(x = 'Molecules', \n               y = ['Maxweight', 'T_coeff'], \n               kind = 'bar', \n               figsize = (7, 7)\n               )\n# Add title\nplt.title(label = 'Molecular similarities between 5 known COVID-19 antivirals')\n\n# Add caption for graph re. abbreviations of all the molecules compared \n# Import textwrap module\nimport textwrap\nt = \"nmt = nirmatrelvir, \"\\\n    \"rit = ritonavir, \"\\\n    \"mol = molnupiravir, \"\\\n    \"rem = remdesivir, \"\\\n    \"bar = baricitinib\"\nb = textwrap.fill(t, width = 58)\nx = 'Molecules'\ny = ['Maxweight', 'T_coeff']\nplt.text(len(x) / 2, 0, b, ha = 'left', va = 'bottom')\n\nText(4.5, 0, 'nmt = nirmatrelvir, rit = ritonavir, mol = molnupiravir,\\nrem = remdesivir, bar = baricitinib')\n\n\n\n\n\n\nOne possibility for this difference could be that the maximum weight parameter in the similarity map test was based on Dice similarity (if referring back to the pseudocode for how to calculate atomic weight), but for the other fingerprint generator test, Tanimoto similarity (also known as Jaccard coefficient) was used instead. These two similarity coefficients were actually calculated differently, with their equivalent equations shown below.\n\nTanimoto similarity/coefficient\nTC was the ratio of the number of chemical features common to two molecules (e.g. molecule a and molecule b) to the total number of chemical features in the two molecules. The following equation summarised this.\n\\[\n\\text{Tanimoto coefficient} = \\frac{(a \\cap b)}{(a + b - (a \\cap b))}\n\\]\n\n\nDice similarity/coefficient\nOn the other hand, Dice coefficient described the number of features in common for molecules a and b, relative to the average size of the total number of chemical features present in the two molecules. The weighting factor of 0.5 was shown in the denominator (or can be 2 in the numerator). The coefficient also ranges from zero to 1. The following showed the equation of Dice similarity.\n\\[\n\\text{Dice coefficient} = \\frac{(a \\cap b)}{0.5\\times(a + b)}\n\\]\n\n\n\n\nAcknowledgement\nThe code used in this post were heavily inspired by and adapted from the following blogs and website shown below. I’ve learnt a lot from them, and would like to thank the existence of these blogs and website, which are helping readers like me to learn in an open-source manner. I particularly like the clear and concise writing style from P. Walter’s Practical Cheminformatics blog which is easy to follow. Iwatobipen’s is life worth living? blog has shown a very diverse range of cheminformatics tools available for use, and I’m constantly surprised by how many there are from this blog and also the generous sharing of all the code.\n\nP. Walter’s blog\nIwatobipen’s blog\nRDKit documentation by G. Landrum\n\n\n\n\nFinal words\nI have read quite a few blog posts from P. Walter and Iwatobipen, and have enjoyed them but never quite got around to write one myself, so finally I did it! Although this post itself was not written in a grand scale, and I would warmly welcome comments for improvements or corrections, I hope to project what I did here in the future, e.g. to apply them to a much larger set of compounds. My very draft thought now is to perhaps trial using ChEMBL database, which is a well-known open-source cheminformatics library.\nAs a little prelude to what other work I’m planning to do, I’ve managed to start learning Rust as well. There is a back story about why I’ve started learning Rust, which I’ll leave as a probable new post in the future if I feel it fits the context of the post. From what I’ve tried so far, only at seedling stage, it’s going to be an even steeper learning curve than Python and R, but I feel it’s going to benefit whatever I’m planning to do consciously or unconsciously in the future.\n\n\n\n\n\nFootnotes\n\n\nCommand line interface↩︎\nCytochrome P450 enzymes of 3A subfamily↩︎\nInternational Union of Pure and Applied Chemistry↩︎\nBits in a bit vector or counts in a count vector are converted from structural features in chemical structures to formulate molecular fingerprints, which subsequently allows a more efficient way to compare chemical structures computationally↩︎\nRanged from zero (lowest similarity) to 1.0 (highest similarity), more on this in the next section↩︎"
  },
  {
    "objectID": "posts/04_Natural_history_of_rare_diseases_–_malformation_syndrome/Natural_history_rare_diseases_mal_syn.html",
    "href": "posts/04_Natural_history_of_rare_diseases_–_malformation_syndrome/Natural_history_rare_diseases_mal_syn.html",
    "title": "Natural history of rare diseases - malformation syndrome",
    "section": "",
    "text": "Introduction\nSo my current interests are still in rare diseases from Orphanet website so the next focus is on natural history of rare diseases, specifically I’d like to focus on malformation syndrome1 for now. There are so much more data available on Orphanet, which I’d really like to look further into such as phenotypes associated with different rare diseases, so this is likely the next one I’ll be working on.\n\n\n\nPhoto by Sangharsh Lohakare on Unsplash\n\n\n\n\nProject link\nThe .ipynb file can be found in my GitHub repository of Portfolio-projects at this URL: https://github.com/jhylin/Portfolio-projects or go to this link, which will take you to the Jupyter notebook for this work to show the differences in life spans for different rare diseases under this particular disorder type.\n\n\nSummary\n\nTurner syndrome and Prune belly syndrome are the only two disorders of the malformation syndrome type that have an average age of onset at antenatal period, with an average age of death in the elderly years\nThis means these two rare disorders have had relatively long life spans out of all the rare diseases present in the dataset\nOppositely, there are far more rare disorders, such as Noonan syndrome, Trisomy 13, Hydraencephaly and more, with early childhood deaths while having the same antenatal onsets as Turner syndrome and Prune belly syndrome\n\n\n\n\n\n\nFootnotes\n\n\nThis project was last committed on 27th June 2022 on GitHub so I’ve set it as the published date, prior to the blog move. This work is under CC BY-SA 4.0 International License for anyone interested in exploring the topic further.↩︎"
  },
  {
    "objectID": "posts/19_ML2-3_Boosted_trees/1_adaboost_xgb.html",
    "href": "posts/19_ML2-3_Boosted_trees/1_adaboost_xgb.html",
    "title": "Boosted trees",
    "section": "",
    "text": "Some introductions\nI’ve somehow promised myself to do a tree series on machine learning and glad I’ve made it to the boosted trees part (it took a while…). This is also likely my last post on this topic for now as there are other things I want to explore in the near future. Hopefully this is somewhat useful for anyone who’s new to this.\n\n\nAdaBoost\nAdaptive Boost or AdaBoost has originated from Robert E. Schapire in 1990 (Schapire 1990), (Raschka, Liu, and Mirjalili 2022), and was further introduced in 1996 by Robert Schapire and Yoav Freund at a conference which also led to a publication (Freund and Schapire 1997).\nAs quoted from scikit-learn, an AdaBoost algorithm is doing this:\n\n…fit a sequence of weak learners (i.e., models that are only slightly better than random guessing, such as small decision trees) on repeatedly modified versions of the data.\n\n\n\n\n\n\n\nNote\n\n\n\nWeak learner means an ensemble of very simple base classifiers such as decision tree stumps (Raschka, Liu, and Mirjalili 2022)\n\n\nDuring the process of running the algorithm, increased weights are given to the incorrectly predicted samples at each iteration, and less weights are given to the correctly predicted ones. This then forces the AdaBoost models to focus more on the less accurately predicted samples with the aim to improve ensemble performance. The predictions from these iterations are combined to produce a final prediction via a weighted majority vote style, which is a well-known signature of tree models. Overall, AdaBoost algorithm can be used for classification or regression problems. The main difference between bagging and boosting is that boosting only uses random subsets of training samples drawn from the training dataset without any replacements (Raschka, Liu, and Mirjalili 2022). One caveat to note is that AdaBoost tend to overfit training data (high variance).\nParameters to tune:\n\nn_estimators - number of weak learners\nlearning_rate - contributions of weak learners in the final combination\nmax_depth - depth of trees\nmin_samples_split - minimum required number of samples to consider a split\n\n\n\n\nGradient boosted trees\nEssentially a similar concept is behind gradient boosted trees where a series of weak learners is trained in order to create a stronger ensemble of models (Raschka, Liu, and Mirjalili 2022). However, some differences between these two types of boosted trees (e.g. AdaBoost and XGBoost) should be noted, and rather than describing them in a paragraph, I’ve summarised them in a table below.\n\n\n\n\n\n\nAdaBoost\nXGBoost\n\n\n\n\ntrains weak learners based on errors from previous decision tree stump\ntrains weak learners that are deeper than decision tree stumps with a max depth of 3 to 6 (or max number of leaf nodes from 8 to 64)\n\n\nuses prediction errors to calculate sample weights and classifier weights\nuses prediction errors directly to produce the target variable to fit the next tree\n\n\nuses individual weighting terms for each tree\nuses a global learning rate for each tree\n\n\n\nDifferences between XGBoost and AdaBoost (Raschka, Liu, and Mirjalili 2022) \n\nXGBoost or extreme gradient boosting (Chen and Guestrin 2016) is one of the most commonly used open-source packages, originally developed at the University of Washington by T. Chen and C. Guestrin, that uses stochastic gradient boosting to build an ensemble of predictive models.\nXGBoost documentation - https://xgboost.readthedocs.io/en/stable/index.html\nMain parameters to tune as suggested by (Bruce, Bruce, and Gedeck 2020):\n\nsubsample - controls fraction of observations that should be sampled at each iteration or a subsample ratio of the training instance (as per XGBoost’s scikit-learn API). This is similar to how a random forest operates but without the sample replacement part\neta (in XGBoost) or learning_rate (in scikit-learn wrapper interface for XGBoost) - a shrinkage factor applied to alpha (a factor derived from weighted errors) in the boosting algorithm or it simply may be more easily understood as the boosting learning rate used to prevent overfitting\n\nThere are of course a whole bunch of other XGBoost parameters that can be tuned, and in order to keep this post at a reasonable reading length, I won’t go through every single one of them, but see this link as an example parameter set for XGBClassifier().\nIn scikit-learn, there are also two types of gradient boosted tree methods, GradientBoostingClassifer() and HistGradientBoostingClassifier(), in its sklearn.ensemble module (note: equivalent regressor class also available). One way to choose between them is to check sample size first. GradientBoostingClassifer() class is likely better when there is only a small sample size (e.g. when number of sample is less than 10,000), while HistGradientBoostingClassifier() class is likely better when your sample size is at least 10,000+ or more. The HistGradientBoostingClassifier() is a histogram-based gradient boosting classification tree that is mainly inpired by LightGBM.\n\n\n\n\nA demo\nIn the example below, I’m only using AdaBoost classifier and XGBoost classifier for now. Please note that the dataset used here is very small and the example is likely not going to reflect real-life use case completely (use with care).\n\n\nImport libraries\n\nimport sys\nimport pandas as pd\nimport numpy as np\nimport chembl_downloader\nimport rdkit\nfrom rdkit import Chem\nimport pickle\n\n# Import Scikit_mol\n## Check and clean SMILES\nfrom scikit_mol.utilities import CheckSmilesSanitazion\n## Standardise molecules\nfrom scikit_mol.standardizer import Standardizer\n## Import fingerprints & descriptors\nfrom scikit_mol.fingerprints import MorganFingerprintTransformer\nfrom scikit_mol.descriptors import MolecularDescriptorTransformer\n## Import smi2mol transformer\nfrom scikit_mol.conversions import SmilesToMolTransformer\n\n# Import scikit-learn\nimport sklearn\nfrom sklearn.model_selection import train_test_split, GridSearchCV\n## Data scaler (variance scaling)\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\n\n# Import xgboost classifier\nimport xgboost\nfrom xgboost import XGBClassifier\n\nprint(f\"xgboost version used: {xgboost.__version__}\")\nprint(f\"scikit-learn version used: {sklearn.__version__}\")\nprint(f\"rdkit version used: {rdkit.__version__}\")\n\nxgboost version used: 2.0.3\nscikit-learn version used: 1.5.0\nrdkit version used: 2024.09.4\n\n\n\n# Show Python version used \nprint(sys.version)\n\n3.12.7 (main, Oct 16 2024, 09:10:10) [Clang 18.1.8 ]\n\n\n\n\n\nData source\nData source is based on ChEMBL database version 33 (as shown by the file name below, “chembl_d_ache_33”), which was downloaded previously from last post (on random forest classifier) by using chembl_downloader.\n\nfrom pathlib import Path\n\n# Pick any directory, but make sure it's relative to your home directory\ndirectory = Path.home().joinpath(\".data\", \"blog\")\n# Create the directory if it doesn't exist\ndirectory.mkdir(exist_ok=True, parents=True)\n\n# Create a file path that corresponds to the previously cached ChEMBL data \npath = directory.joinpath(f\"chembl_d_ache_33.tsv\")\n\n# alternative way to download latest ChEMBL version\n# please see post link - https://jhylin.github.io/Data_in_life_blog/posts/17_ML2-2_Random_forest/2_random_forest_classifier.html#data-retrieval-using-chembl_downloader for details\n# note: need to specify late_version = latest() first\n# path = directory.joinpath(f\"chembl_d_ache_{latest_version}.tsv\")\n\nif path.is_file():\n    # If the file already exists, load it\n    df_ache = pd.read_csv(path, sep=',')\nelse:\n    # If the file doesn't already exist, make the query then cache it\n    df_ache = chembl_downloader.query(sql)\n    df_ache.to_csv(path, sep=\",\", index=False)\n\n\nprint(df_ache.shape)\ndf_ache.head()\n\n(7144, 9)\n\n\n\n\n\n\n  \n    \n      \n      assay_chembl_id\n      target_type\n      tax_id\n      chembl_id\n      canonical_smiles\n      molecule_chembl_id\n      max_phase\n      standard_type\n      pchembl_value\n    \n  \n  \n    \n      0\n      CHEMBL1909212\n      SINGLE PROTEIN\n      9606\n      CHEMBL220\n      CC/C(=C(/CC)c1ccc(O)cc1)c1ccc(O)cc1\n      CHEMBL411\n      4.0\n      IC50\n      4.59\n    \n    \n      1\n      CHEMBL1003053\n      SINGLE PROTEIN\n      9606\n      CHEMBL220\n      COc1c2occc2cc2ccc(=O)oc12\n      CHEMBL416\n      4.0\n      IC50\n      4.27\n    \n    \n      2\n      CHEMBL2406149\n      SINGLE PROTEIN\n      9606\n      CHEMBL220\n      COc1c2occc2cc2ccc(=O)oc12\n      CHEMBL416\n      4.0\n      IC50\n      6.12\n    \n    \n      3\n      CHEMBL1909212\n      SINGLE PROTEIN\n      9606\n      CHEMBL220\n      CC1(COc2ccc(CC3SC(=O)NC3=O)cc2)CCCCC1\n      CHEMBL7002\n      -1.0\n      IC50\n      4.82\n    \n    \n      4\n      CHEMBL3071788\n      SINGLE PROTEIN\n      9606\n      CHEMBL220\n      O=c1cc(-c2ccc(O)cc2)oc2cc(O)cc(O)c12\n      CHEMBL28\n      NaN\n      IC50\n      7.92\n    \n  \n\n\n\n\nExploring max phases of compounds in the dataset.\n\ndf_ache.value_counts(\"max_phase\", dropna=False)\n\nmax_phase\n NaN    6410\n 4.0     618\n-1.0      69\n 2.0      29\n 3.0      10\n 1.0       7\n 0.5       1\nName: count, dtype: int64\n\n\n\n\n\n\nDatasets\nThe definition of “NaN” assigned to max_phase indicates that compounds labelled as “NaN” or “null” have no evidence of showing they’ve reached clinical trials yet, but I’m still keeping them in the dataset (this can also be excluded depending on project goals).\nA max_phase of -1 is assigned to molecules with unknown clinical phase status (ChEMBL reference), for which I’ll drop for this particular experiment.\n\n# Fill \"NaNs\" as \"0\" first\ndf_ache.fillna({\"max_phase\": 0}, inplace=True)\n\n\n# Select only mols with max_phase of 0 and above\ndf_ache = df_ache[(df_ache[\"max_phase\"] >= 0)]\n\n\ndf_ache[\"max_phase\"].describe()\n\ncount    7075.000000\nmean        0.362898\nstd         1.138520\nmin         0.000000\n25%         0.000000\n50%         0.000000\n75%         0.000000\nmax         4.000000\nName: max_phase, dtype: float64\n\n\n\ndf_ache.value_counts(\"max_phase\", dropna=False)\n\nmax_phase\n0.0    6410\n4.0     618\n2.0      29\n3.0      10\n1.0       7\n0.5       1\nName: count, dtype: int64\n\n\n\n# Convert max_phase from float to int for the ease of reading predicted outcomes,\n# otherwise it'll look like \"4., 2., 4., ...\"\ndf_ache = df_ache.astype({\"max_phase\": int, \"canonical_smiles\": \"string\"})\n\n\ndf_ache.dtypes\n\nassay_chembl_id               object\ntarget_type                   object\ntax_id                         int64\nchembl_id                     object\ncanonical_smiles      string[python]\nmolecule_chembl_id            object\nmax_phase                      int64\nstandard_type                 object\npchembl_value                float64\ndtype: object\n\n\nPlease note: the only molecule with max_phase of “0.5” was converted into “0” after I’ve converted the datatype of max_phase from float to integer (I’ve left it deliberately like this since this is only a demonstration on using scikit_learn’s pipeline along with Scikit-mol (Bjerrum et al. 2023), but in reality this should be handled with care i.e. don’t discard it as different max phase values have different meanings!). Therefore the following max_phase value count will have 6411 molecules with max_phase “0”, rather than the previous number of 6410.\n\ndf_ache.value_counts(\"max_phase\", dropna=False)\n\nmax_phase\n0    6411\n4     618\n2      29\n3      10\n1       7\nName: count, dtype: int64\n\n\n\n\n\nModel building using scikit-learn’s pipeline\nBinary classification has been used in my previous posts, e.g. target as max_phase 4 (re-labelled as “1”) with training set of max_phase “null” re-labelled as “0” with their different RDKit molecular features. This time I’ll be using multi-class classification to predict a training set of molecules containing max_phase of 0, 1, 2, 3 and 4.\n\n\nDefine X and y variables\n\n# A sanity check and view on the original dataset \ndf_ache\n\n\n\n\n\n  \n    \n      \n      assay_chembl_id\n      target_type\n      tax_id\n      chembl_id\n      canonical_smiles\n      molecule_chembl_id\n      max_phase\n      standard_type\n      pchembl_value\n    \n  \n  \n    \n      0\n      CHEMBL1909212\n      SINGLE PROTEIN\n      9606\n      CHEMBL220\n      CC/C(=C(/CC)c1ccc(O)cc1)c1ccc(O)cc1\n      CHEMBL411\n      4\n      IC50\n      4.59\n    \n    \n      1\n      CHEMBL1003053\n      SINGLE PROTEIN\n      9606\n      CHEMBL220\n      COc1c2occc2cc2ccc(=O)oc12\n      CHEMBL416\n      4\n      IC50\n      4.27\n    \n    \n      2\n      CHEMBL2406149\n      SINGLE PROTEIN\n      9606\n      CHEMBL220\n      COc1c2occc2cc2ccc(=O)oc12\n      CHEMBL416\n      4\n      IC50\n      6.12\n    \n    \n      4\n      CHEMBL3071788\n      SINGLE PROTEIN\n      9606\n      CHEMBL220\n      O=c1cc(-c2ccc(O)cc2)oc2cc(O)cc(O)c12\n      CHEMBL28\n      0\n      IC50\n      7.92\n    \n    \n      5\n      CHEMBL1119333\n      SINGLE PROTEIN\n      9606\n      CHEMBL220\n      CNCCC(Oc1ccc(C(F)(F)F)cc1)c1ccccc1\n      CHEMBL41\n      4\n      IC50\n      6.89\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      7139\n      CHEMBL5216374\n      SINGLE PROTEIN\n      9606\n      CHEMBL220\n      CCC(C)(C)NCC(O)c1cc(O)cc(OC(=O)N(C)C)c1\n      CHEMBL5220560\n      0\n      IC50\n      4.70\n    \n    \n      7140\n      CHEMBL5216425\n      SINGLE PROTEIN\n      9606\n      CHEMBL220\n      CC(C)(C)OC(=O)Nc1ccc(O)c(C(=O)NCCCN2CCCCC2)c1\n      CHEMBL5220695\n      0\n      Ki\n      6.92\n    \n    \n      7141\n      CHEMBL5216408\n      SINGLE PROTEIN\n      9606\n      CHEMBL220\n      O=C1CCOc2cc(OCCCCCSC(=S)N3CCCCC3)ccc21\n      CHEMBL5220742\n      0\n      IC50\n      7.00\n    \n    \n      7142\n      CHEMBL5218078\n      SINGLE PROTEIN\n      9606\n      CHEMBL220\n      Cn1ccc2cc(-c3cnc4ccc(C(=O)N5CCCCC5)cc4n3)ccc2c1=O\n      CHEMBL5220884\n      0\n      IC50\n      5.27\n    \n    \n      7143\n      CHEMBL5216374\n      SINGLE PROTEIN\n      9606\n      CHEMBL220\n      COC(=O)c1cc2c(OC(=O)N(C)C)cccc2[n+]([11CH3])c1\n      CHEMBL5220983\n      0\n      IC50\n      7.70\n    \n  \n\n7075 rows × 9 columns\n\n\n\n\nX = df_ache.canonical_smiles\ny = df_ache.max_phase\n\n\nX.shape\n\n(7075,)\n\n\n\ny.shape\n\n(7075,)\n\n\n\nprint(X)\n\n0                     CC/C(=C(/CC)c1ccc(O)cc1)c1ccc(O)cc1\n1                               COc1c2occc2cc2ccc(=O)oc12\n2                               COc1c2occc2cc2ccc(=O)oc12\n4                    O=c1cc(-c2ccc(O)cc2)oc2cc(O)cc(O)c12\n5                      CNCCC(Oc1ccc(C(F)(F)F)cc1)c1ccccc1\n                              ...                        \n7139              CCC(C)(C)NCC(O)c1cc(O)cc(OC(=O)N(C)C)c1\n7140        CC(C)(C)OC(=O)Nc1ccc(O)c(C(=O)NCCCN2CCCCC2)c1\n7141               O=C1CCOc2cc(OCCCCCSC(=S)N3CCCCC3)ccc21\n7142    Cn1ccc2cc(-c3cnc4ccc(C(=O)N5CCCCC5)cc4n3)ccc2c1=O\n7143       COC(=O)c1cc2c(OC(=O)N(C)C)cccc2[n+]([11CH3])c1\nName: canonical_smiles, Length: 7075, dtype: string\n\n\n\nprint(y)\n\n0       4\n1       4\n2       4\n4       0\n5       4\n       ..\n7139    0\n7140    0\n7141    0\n7142    0\n7143    0\nName: max_phase, Length: 7075, dtype: int64\n\n\n\n\n\nSanitise SMILES\nUpdate on 30th Jan 2025 - A new safe inference mode feature has been introduced in Scikit-mol recently which will be able to handle invalid SMILES, please visit this demonstration notebook for details (thanks to Esben Jannik Bjerrum for mentioning this in the comment below).\nThis post is going to focus on Scikit-mol which has a manual way to handle SMILES errors, as shown in the code below. Another useful way to deal with SMILES errors is Molpipeline’s SMILES error handling, with an example shown in one of its notebooks. The main difference from what I can see, even though I haven’t got to use it yet, is that Molpipeline takes into account of all the invalid SMILES by giving each invalid SMILES a “NaN” label in the pipeline process - this maintains the matrix shape and good for tracking down the problematic SMILES (molecules).\n\nchecksmi = CheckSmilesSanitazion()\n# Checking on SMILES (X) \nX_valid, X_errors = checksmi.sanitize(X)\n\nIdeally, X_valid & y_valid will be used for further work, meaning all the invalids or errors will be removed from the training set.\n\nchecksmi.errors\n\n\n\n\n\n  \n    \n      \n      SMILES\n    \n  \n  \n  \n\n\n\n\nNo SMILES errors are shown.\n\nX_errors\n\n[]\n\n\nNo outputs are there (no errors detected).\n\nprint(X_valid)\n\n['CC/C(=C(/CC)c1ccc(O)cc1)c1ccc(O)cc1', 'COc1c2occc2cc2ccc(=O)oc12', 'COc1c2occc2cc2ccc(=O)oc12', 'O=c1cc(-c2ccc(O)cc2)oc2cc(O)cc(O)c12', 'CNCCC(Oc1ccc(C(F)(F)F)cc1)c1ccccc1', 'CCN(CC)CCCC(C)Nc1c2ccc(Cl)cc2nc2ccc(OC)cc12', 'O=c1c(O)c(-c2ccc(O)c(O)c2)oc2cc(O)cc(O)c12', 'O=C1C=CC(=O)C=C1', 'CCc1c2c(nc3ccc(OC(=O)N4CCC(N5CCCCC5)CC4)cc13)-c1cc3c(c(=O)n1C2)COC(=O)[C@]3(O)CC', 'CCc1c2c(nc3ccc(OC(=O)N4CCC(N5CCCCC5)CC4)cc13)-c1cc3c(c(=O)n1C2)COC(=O)[C@]3(O)CC', 'O=C(c1ccc(OCCN2CCCCC2)cc1)c1c(-c2ccc(O)cc2)sc2cc(O)ccc12', 'Oc1c(Cl)cc(Cl)c(Cl)c1Cc1c(O)c(Cl)cc(Cl)c1Cl', 'Clc1ccc(COC(Cn2ccnc2)c2ccc(Cl)cc2Cl)c(Cl)c1', 'CNC(=O)Oc1ccc2c(c1)OC[C@@H]1CCN(C)[C@H]21', 'CNC(=O)Oc1ccc2c(c1)OC[C@@H]1CCN(C)[C@H]21', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'Nc1c2c(nc3ccccc13)CCCC2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2', 'CNC(=O)Oc1ccc2c(c1)OC[C@@H]1CC[N+](C)(C)[C@H]21', 'CNC(=O)Oc1cccc2c1OC[C@@H]1CCN(C)[C@H]21', 'CNC(=O)Oc1cccc2c1OC[C@@H]1CCN(C)[C@H]21', 'CNC(=O)Oc1cccc2c1OC[C@@H]1CCN(C)[C@H]21', 'CNC(=O)Oc1ccc2c(c1)[C@@H]1[C@@H](CCN1C)CO2', 'CN1CC[C@H]2COc3c(O)cccc3[C@H]21', 'COc1ccc2cc3[n+](cc2c1OC)CCc1cc2c(cc1-3)OCO2.[Cl-]', 'COc1ccc2cc3[n+](cc2c1OC)CCc1cc2c(cc1-3)OCO2.[Cl-]', 'COc1ccc2cc3[n+](cc2c1OC)CCc1cc2c(cc1-3)OCO2.[Cl-]', 'COc1ccc2cc3[n+](cc2c1OC)CCc1cc2c(cc1-3)OCO2.[Cl-]', 'COc1ccccc1CN(C)CCCCCC(=O)N(C)CCCCCCCCN(C)C(=O)CCCCCN(C)Cc1ccccc1OC', 'COc1ccccc1CN(C)CCCCCC(=O)N(C)CCCCCCCCN(C)C(=O)CCCCCN(C)Cc1ccccc1OC', 'COc1ccccc1CN(C)CCCCCC(=O)N(C)CCCCCCCCN(C)C(=O)CCCCCN(C)Cc1ccccc1OC', 'COc1ccccc1CN(C)CCCCCC(=O)N(C)CCCCCCCCN(C)C(=O)CCCCCN(C)Cc1ccccc1OC', 'COc1ccccc1CN(C)CCCCCC(=O)N(C)CCCCCCCCN(C)C(=O)CCCCCN(C)Cc1ccccc1OC', 'COc1ccccc1CN(C)CCCCCC(=O)N(C)CCCCCCCCN(C)C(=O)CCCCCN(C)Cc1ccccc1OC', 'COc1ccccc1CN(C)CCCCCC(=O)N(C)CCCCCCCCN(C)C(=O)CCCCCN(C)Cc1ccccc1OC', 'COc1ccccc1CN(C)CCCCCC(=O)N(C)CCCCCCCCN(C)C(=O)CCCCCN(C)Cc1ccccc1OC', 'COc1ccccc1CN(C)CCCCCC(=O)N(C)CCCCCCCCN(C)C(=O)CCCCCN(C)Cc1ccccc1OC', 'COc1ccccc1CN(C)CCCCCC(=O)N(C)CCCCCCCCN(C)C(=O)CCCCCN(C)Cc1ccccc1OC', 'COc1ccccc1CN(C)CCCCCC(=O)N(C)CCCCCCCCN(C)C(=O)CCCCCN(C)Cc1ccccc1OC', 'COc1ccccc1CN(C)CCCCCC(=O)N(C)CCCCCCCCN(C)C(=O)CCCCCN(C)Cc1ccccc1OC', 'COc1ccccc1CN(C)CCCCCC(=O)N(C)CCCCCCCCN(C)C(=O)CCCCCN(C)Cc1ccccc1OC', 'c1ccc2c(c1)[nH]c1ccncc12', 'COc1ccc2c(c[n+](C)c3c4cc5c(cc4ccc23)OCO5)c1OC', 'CN(C)Cc1ccc(CSCc2ccc(-c3ccc(CSCc4ccc(CN(C)C)o4)cc3)cc2)o1', 'CN(C)Cc1ccc(CSCCNc2cc(NCCSCc3ccc(CN(C)C)o3)c([N+](=O)[O-])cc2[N+](=O)[O-])o1', 'CN(C)Cc1ccc(CSCCCCCCCCCSCc2ccc(CN(C)C)o2)o1', 'CN(C)Cc1ccc(CSCCCCCCCCCCSCc2ccc(CN(C)C)o2)o1', 'CN(C)Cc1ccc(CSCc2ccc(CSCc3ccc(CN(C)C)o3)cc2)o1', 'CN(C)Cc1ccc(CSCc2cccc(CSCc3ccc(CN(C)C)o3)c2)o1', 'CN(C)Cc1ccc(CSCc2ccccc2CSCc2ccc(CN(C)C)o2)o1', 'CN(C)Cc1ccc(CSCCCCCCSCc2ccc(CN(C)C)o2)o1', 'CN(C)Cc1ccc(CSCCCCCCCCSCc2ccc(CN(C)C)o2)o1', 'CN(C)Cc1ccc(CSCCNC(=NC#N)NCCSCc2ccc(CN(C)C)o2)o1', 'CN(C)Cc1ccc(CSCCN/C=C(/NCCSCc2ccc(CN(C)C)o2)[N+](=O)[O-])o1', 'CN(C)Cc1ccc(CSCc2ccc(CN(C)C)o2)o1', 'CN(C)Cc1ccc(CSCCSCc2ccc(CN(C)C)o2)o1', 'CN(C)Cc1ccc(CSCCCCSCc2ccc(CN(C)C)o2)o1', 'CN(C)Cc1ccc(CSCCCCCCCSCc2ccc(CN(C)C)o2)o1', 'CN(C)Cc1ccc(CSCCCCCSCc2ccc(CN(C)C)o2)o1', 'CN(C)Cc1ccc(CSCCNC(=O)CSCc2ccc(CN(C)C)o2)o1', 'CN(C)Cc1ccc(CSCCCSCc2ccc(CN(C)C)o2)o1', 'CN(C)Cc1ccc(CSCCNC(=O)NCCSCc2ccc(CN(C)C)o2)o1', 'COc1ccc(C)cc1OC', 'COc1ccc(C)cc1OC', 'CCN(CC)CCNC(=O)c1c(C)[nH]c(/C=C2\\\\C(=O)Nc3ccc(F)cc32)c1C', 'Clc1ccccc1C(c1ccccc1)(c1ccccc1)n1ccnc1', 'CN(C)C(=O)Oc1cccc([N+](C)(C)C)c1', 'CN(C)CCCC1(c2ccc(F)cc2)OCc2cc(C#N)ccc21', 'O=C(c1ccc(OCCCc2c[nH]cn2)cc1)C1CC1', 'O=C(c1ccc(OCCCc2c[nH]cn2)cc1)C1CC1', 'c1ccc2c(NCCc3ccc(OCCCN4CCCCC4)cc3)c3c(nc2c1)CCCC3', 'Cn1c(=O)c2c(ncn2C)n(C)c1=O', 'Cc1ccccc1', 'Cc1ccccc1', 'Cc1ccc(O)cc1', 'Cc1ccc(O)cc1', 'COc1ccccc1CNCCCCCCNCCSSCCNCCCCCCNCc1ccccc1OC', 'COc1ccccc1CNCCCCCCNCCSSCCNCCCCCCNCc1ccccc1OC', 'COc1ccccc1CNCCCCCCNCCSSCCNCCCCCCNCc1ccccc1OC', 'COc1ccc(Cc2nccc3cc(OC)c(OC)cc23)cc1OC', 'CN1C[C@H](CNC(=O)OCc2ccccc2)C[C@@H]2c3cccc4c3c(cn4C)C[C@H]21', 'CCN(CC)CCS/C(=N\\\\O)c1nc(C)no1', 'CCN(CC)CCS/C(=N\\\\O)c1nc(-c2ccccc2)no1', 'CCc1nn(CCCN2CCN(c3cccc(Cl)c3)CC2)c(=O)n1CCOc1ccccc1', 'CC(=O)CCCCn1c(=O)c2c(ncn2C)n(C)c1=O', 'CCN(C)C(=O)Oc1cccc([C@H](C)N(C)C)c1', 'CCN(C)C(=O)Oc1cccc([C@H](C)N(C)C)c1', 'CCN(C)C(=O)Oc1cccc([C@H](C)N(C)C)c1', 'CCN(C)C(=O)Oc1cccc([C@H](C)N(C)C)c1', 'CCN(C)C(=O)Oc1cccc([C@H](C)N(C)C)c1', 'CCN(C)C(=O)Oc1cccc([C@H](C)N(C)C)c1', 'CCN(C)C(=O)Oc1cccc([C@H](C)N(C)C)c1', 'CCN(C)C(=O)Oc1cccc([C@H](C)N(C)C)c1', 'CCN(C)C(=O)Oc1cccc([C@H](C)N(C)C)c1', 'CCN(C)C(=O)Oc1cccc([C@H](C)N(C)C)c1', 'CCN(C)C(=O)Oc1cccc([C@H](C)N(C)C)c1', 'CCN(C)C(=O)Oc1cccc([C@H](C)N(C)C)c1', 'CCN(C)C(=O)Oc1cccc([C@H](C)N(C)C)c1', 'CCN(C)C(=O)Oc1cccc([C@H](C)N(C)C)c1', 'CCN(C)C(=O)Oc1cccc([C@H](C)N(C)C)c1', 'CCN(C)C(=O)Oc1cccc([C@H](C)N(C)C)c1', 'CCN(C)C(=O)Oc1cccc([C@H](C)N(C)C)c1', 'CCN(C)C(=O)Oc1cccc([C@H](C)N(C)C)c1', 'CCN(C)C(=O)Oc1cccc([C@H](C)N(C)C)c1', 'CCN(C)C(=O)Oc1cccc([C@H](C)N(C)C)c1', 'CCN(C)C(=O)Oc1cccc([C@H](C)N(C)C)c1', 'CCN(C)C(=O)Oc1cccc([C@H](C)N(C)C)c1', 'CCN(C)C(=O)Oc1cccc([C@H](C)N(C)C)c1', 'CCN(C)C(=O)Oc1cccc([C@H](C)N(C)C)c1', 'CCN(C)C(=O)Oc1cccc([C@H](C)N(C)C)c1', 'CCN(C)C(=O)Oc1cccc([C@H](C)N(C)C)c1', 'CCN(C)C(=O)Oc1cccc([C@H](C)N(C)C)c1', 'CCN(C)C(=O)Oc1cccc([C@H](C)N(C)C)c1', 'CCN(C)C(=O)Oc1cccc([C@H](C)N(C)C)c1', 'CCN(C)C(=O)Oc1cccc([C@H](C)N(C)C)c1', 'CCN(C)C(=O)Oc1cccc([C@H](C)N(C)C)c1', 'CCN(C)C(=O)Oc1cccc([C@H](C)N(C)C)c1', 'CCN(C)C(=O)Oc1cccc([C@H](C)N(C)C)c1', 'CCN(C)C(=O)Oc1cccc([C@H](C)N(C)C)c1', 'CCN(C)C(=O)Oc1cccc([C@H](C)N(C)C)c1', 'CCN(C)C(=O)Oc1cccc([C@H](C)N(C)C)c1', 'CCN(C)C(=O)Oc1cccc([C@H](C)N(C)C)c1', 'CCN(C)C(=O)Oc1cccc([C@H](C)N(C)C)c1', 'CCN(C)C(=O)Oc1cccc([C@H](C)N(C)C)c1', 'CCN(C)C(=O)Oc1cccc([C@H](C)N(C)C)c1', 'CCN(C)C(=O)Oc1cccc([C@H](C)N(C)C)c1', 'CCN(C)C(=O)Oc1cccc([C@H](C)N(C)C)c1', 'CCN(C)C(=O)Oc1cccc([C@H](C)N(C)C)c1', 'CCN(C)C(=O)Oc1cccc([C@H](C)N(C)C)c1', 'CCN(C)C(=O)Oc1cccc([C@H](C)N(C)C)c1', 'CCN(C)C(=O)Oc1cccc([C@H](C)N(C)C)c1', 'CCN(C)C(=O)Oc1cccc([C@H](C)N(C)C)c1', 'CCN(CC)CCNC(=O)c1ccc(N)cc1', 'CCN(CC)CCNC(=O)c1ccc(N)cc1', 'CCN(CC)CCNC(=O)c1ccc(N)cc1', 'CCN(CC)CCNC(=O)c1ccc(N)cc1', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'CC(C)OC(=O)C(C)(C)Oc1ccc(C(=O)c2ccc(Cl)cc2)cc1', 'c1ccc(CN2CCC(CCNc3ccc(-c4ccccc4)nn3)CC2)cc1', 'c1ccc(-c2ccc(NCCCCN3CCc4ccccc4C3)nn2)cc1', 'c1ccc(-c2ccc(NCCN3CCCCC3)nn2)cc1', 'C[C@]12CC[C@H](O)[C@@](C)(CO)C1C[C@H](O)[C@@]1(C)Oc3cc(-c4ccncc4)oc(=O)c3C(=O)C21', 'Cc1cc(-c2ccccc2)nnc1NCCN1CCOCC1', 'COc1ccc(-c2cc3c(c(=O)o2)C(=O)C2[C@@]4(C)CC[C@H](O)[C@@](C)(CO)C4C[C@H](O)[C@@]2(C)O3)cc1OC', 'C[C@]12CC[C@H](O)[C@@](C)(CO)C1C[C@H](O)[C@@]1(C)Oc3cc(-c4cccnc4)oc(=O)c3C(=O)C21', 'C[C@]12CC[C@H](O)[C@@](C)(CO)C1C[C@H](O)[C@@]1(C)Oc3cc(-c4ccccc4)oc(=O)c3C(=O)C21', 'COc1cc(-c2cc3c(c(=O)o2)C[C@]2(O)[C@@]4(C)C(=O)C=CC(C)(C)[C@]4(O)CC[C@@]2(C)O3)cc(OC)c1OC', 'COc1cc(-c2cc3c(c(=O)o2)C[C@]2(O)[C@@]4(C)C(=O)C=CC(C)(C)[C@]4(O)CC[C@@]2(C)O3)cc(OC)c1OC', 'COc1cc(-c2cc3c(c(=O)o2)C[C@]2(O)[C@@]4(C)C(=O)C=CC(C)(C)[C@]4(O)CC[C@@]2(C)O3)cc(OC)c1OC', 'COc1cc(-c2cc3c(c(=O)o2)C[C@]2(O)[C@@]4(C)C(=O)C=CC(C)(C)[C@]4(O)CC[C@@]2(C)O3)cc(OC)c1OC', 'C[C@]12CC[C@H](O)[C@@](C)(CO)C1C[C@H](O)[C@@]1(C)Oc3cc(-c4ccc(Cl)nc4)oc(=O)c3C(=O)C21', 'COc1cc2nc(N(C)CCCNC(=O)C3CCCO3)nc(N)c2cc1OC', 'COc1ccc(-c2cc3c(c(=O)o2)C[C@]2(O)[C@@]4(C)C(=O)C=CC(C)(C)[C@]4(O)CC[C@@]2(C)O3)cc1OC', 'COc1ccc(-c2cc3c(c(=O)o2)C[C@]2(O)[C@@]4(C)C(=O)C=CC(C)(C)[C@]4(O)CC[C@@]2(C)O3)cc1OC', 'COc1ccc(-c2cc3c(c(=O)o2)C[C@]2(O)[C@@]4(C)C(=O)C=CC(C)(C)[C@]4(O)CC[C@@]2(C)O3)cc1OC', 'COc1ccc(-c2cc3c(c(=O)o2)C[C@]2(O)[C@@]4(C)C(=O)C=CC(C)(C)[C@]4(O)CC[C@@]2(C)O3)cc1OC', 'COc1ccc(-c2cc3c(c(=O)o2)C[C@]2(O)[C@@]4(C)C(=O)C=CC(C)(C)[C@]4(O)CC[C@@]2(C)O3)cc1OC', 'COc1ccc(-c2cc3c(c(=O)o2)C[C@]2(O)[C@@]4(C)C(=O)C=CC(C)(C)[C@]4(O)CC[C@@]2(C)O3)cc1', 'COc1ccc(-c2cc3c(c(=O)o2)C[C@]2(O)[C@@]4(C)C(=O)C=CC(C)(C)[C@]4(O)CC[C@@]2(C)O3)cc1', 'COc1ccc(-c2cc3c(c(=O)o2)C(=O)C2[C@@]4(C)CC[C@H](O)[C@@](C)(CO)C4C[C@H](O)[C@@]2(C)O3)cc1', 'Cc1cccc(C)c1', 'Cc1cccc(C)c1', 'CN(CCn1cc[n+](C)c1/C=N/O)S(C)(=O)=O.[Cl-]', 'C[n+]1ccn(COCCS(C)(=O)=O)c1/C=N/O.[Cl-]', 'C[n+]1ccn(COCC(C)(C)[N+](=O)[O-])c1/C=N/O.[Cl-]', 'C[n+]1ccccc1/C=N/O.[Cl-]', 'C[n+]1ccccc1/C=N/O.[Cl-]', 'C[n+]1ccccc1/C=N/O.[Cl-]', 'C[n+]1ccccc1/C=N/O.[Cl-]', 'C[n+]1ccccc1/C=N/O.[Cl-]', 'C[n+]1ccccc1/C=N/O.[Cl-]', 'C[n+]1ccccc1/C=N/O.[Cl-]', 'C[n+]1ccccc1/C=N/O.[Cl-]', 'C[n+]1ccccc1/C=N/O.[Cl-]', 'C[n+]1ccccc1/C=N/O.[Cl-]', 'C[n+]1ccccc1/C=N/O.[Cl-]', 'C[n+]1ccccc1/C=N/O.[Cl-]', 'C[n+]1ccccc1/C=N/O.[Cl-]', 'COc1ccccc1CNCCCCCCNCCCCCCCCNCCCCCCNCc1ccccc1OC', 'COc1ccccc1CNCCCCCCNCCCCCCCCNCCCCCCNCc1ccccc1OC', 'COc1ccccc1CNCCCCCCNCCCCCCCCNCCCCCCNCc1ccccc1OC', 'O=c1c(O)c(-c2ccc(O)c(O)c2)oc2cc(O)ccc12', 'Cc1ccc(C)cc1', 'Cc1ccc(C)cc1', 'c1ccc2c(c1)cc1ccc3cccc4ccc2c1c34', 'Cn1cc[n+](COCCCc2ccccc2)c1/C=N/O.[Cl-]', 'NC(=O)c1cc[n+](COC[n+]2ccccc2/C=N/O)cc1.[Cl-].[Cl-]', 'NC(=O)c1cc[n+](COC[n+]2ccccc2/C=N/O)cc1.[Cl-].[Cl-]', 'NC(=O)c1cc[n+](COC[n+]2ccccc2/C=N/O)cc1.[Cl-].[Cl-]', 'NC(=O)c1cc[n+](COC[n+]2ccccc2/C=N/O)cc1.[Cl-].[Cl-]', 'NC(=O)c1cc[n+](COC[n+]2ccccc2/C=N/O)cc1.[Cl-].[Cl-]', 'NC(=O)c1cc[n+](COC[n+]2ccccc2/C=N/O)cc1.[Cl-].[Cl-]', 'NC(=O)c1cc[n+](COC[n+]2ccccc2/C=N/O)cc1.[Cl-].[Cl-]', 'NC(=O)c1cc[n+](COC[n+]2ccccc2/C=N/O)cc1.[Cl-].[Cl-]', 'CCN1CC[C@@]2(C)c3cc(OC(=O)NC(C)(C)C)ccc3CC12', 'CCCCCCCNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(Cc3ccccc3)C1C2', 'CCCCCCCNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(CCC)C1C2', 'CC(C)OC[n+]1ccn(C)c1/C=N/O.[Cl-]', 'CCN1CC[C@@]2(C)c3cc(OC(=O)Nc4ccccc4)ccc3CC12', 'CCCCCCNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(CC)C1C2', 'CCCCCCNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(CC)C1C2', 'CCCCCCNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(CC)C1C2', 'CCCCCCCNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(CC)C1C2', 'CCCCCCCNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(CC)C1C2', 'CCCCCCCNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(CC)C1C2', 'CCCCCCNC(=O)Oc1ccc2c(c1)[C@@H]1CCN(CCC)C1C2', 'CCCCCCNC(=O)Oc1ccc2c(c1)[C@@H]1CCN(CCC)C1C2', 'CCCCNC(=O)Oc1ccc2c(c1)[C@@H]1CCN(CC)C1C2', 'CCCCCCNC(=O)Oc1ccc2c(c1)[C@@H]1CCN(CC)C1C2', 'CCN1CC[C@@]2(C)c3cc(OC(=O)NCc4ccccc4)ccc3CC12', 'CCN1CC[C@@]2(C)c3cc(OC(=O)N[C@@H](C)c4ccccc4)ccc3CC12', 'CCCCCCCNC(=O)Oc1ccc2c(c1)[C@@H]1CCN(CCC)C1C2', 'CCN1CC[C@H]2c3cc(OC(=O)NC)ccc3CC21', 'CCCNC(=O)Oc1ccc2c(c1)[C@@H]1CCN(CC)C1C2', 'Cn1cc[n+](COCc2cccc3ccccc23)c1/C=N/O.[Cl-]', 'Cn1cc[n+](COCc2ccccc2)c1/C=N/O.[Cl-]', 'CCCCOC[n+]1ccn(C)c1/C=N/O.[Cl-]', 'Cn1cc[n+](COCC(C)(C)C)c1/C=N/O.[Cl-]', 'CCCNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(CC)C1C2', 'CCCCNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(CC)C1C2', 'CCCCCCCNC(=O)Oc1ccc2c(c1)[C@@H]1CCN(CC)C1C2', 'CCN1CC[C@@]2(C)c3cc(OC(=O)NC)ccc3CC12', 'CCCCCCNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)C1C2', 'CCCCCCCNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)C1C2', 'O=c1c(O)c(-c2ccc(O)cc2)oc2cc(O)cc(O)c12', 'CC(OC[n+]1ccn(C)c1/C=N/O)C(C)(C)C.[Cl-]', 'CCCCCCCCOC[n+]1ccn(C)c1/C=N/O.[Cl-]', 'O=c1cc(-c2ccc(O)c(O)c2)oc2cc(O)cc(O)c12', 'c1ccc2c(NCCCCCCCNc3c4c(nc5ccccc35)CCCC4)c3c(nc2c1)CCCC3', 'c1ccc2c(NCCCCCCCNc3c4c(nc5ccccc35)CCCC4)c3c(nc2c1)CCCC3', 'c1ccc2c(NCCCCCCCNc3c4c(nc5ccccc35)CCCC4)c3c(nc2c1)CCCC3', 'c1ccc2c(NCCCCCCCNc3c4c(nc5ccccc35)CCCC4)c3c(nc2c1)CCCC3', 'c1ccc2c(NCCCCCCCNc3c4c(nc5ccccc35)CCCC4)c3c(nc2c1)CCCC3', 'c1ccc2c(NCCCCCCCNc3c4c(nc5ccccc35)CCCC4)c3c(nc2c1)CCCC3', 'c1ccc2c(NCCCCCCCNc3c4c(nc5ccccc35)CCCC4)c3c(nc2c1)CCCC3', 'c1ccc2c(NCCCCCCCNc3c4c(nc5ccccc35)CCCC4)c3c(nc2c1)CCCC3', 'Clc1cccc(Cl)c1CO/N=C/c1cc[n+](CCCc2ccccc2)cc1', 'CC12CC3CC(C)(C1)CC(N)(C3)C2', 'Clc1ccc(COC(Cn2ccnc2)c2ccc(Cl)cc2Cl)cc1', 'CN(C)C(=O)Oc1ccc[n+](C)c1.[Br-]', 'CN(C)C(=O)Oc1ccc[n+](C)c1.[Br-]', 'CN(C)C(=O)Oc1ccc[n+](C)c1.[Br-]', 'CN(C)C(=O)Oc1ccc[n+](C)c1.[Br-]', 'Cc1ccc2cc3c(ccc4ccccc43)c3c2c1CC3', 'c1ccc2nc3ccccc3cc2c1', 'CNC(=O)Oc1ccc2c(c1)c(C)cn2Nc1ccncc1F', 'COc1ccc2cc3[n+](cc2c1OC)CCc1cc2c(cc1-3)OCO2', 'COc1ccc2cc3[n+](cc2c1OC)CCc1cc2c(cc1-3)OCO2', 'Cc1ccccc1C', 'Cc1ccccc1C', 'Nc1cc(-c2ccccc2)nc2ccccc12', 'O=c1c2ccccc2[se]n1-c1ccccc1', 'C#CCN[C@@H]1CCc2ccccc21', 'O=C1C(=O)c2cc([N+](=O)[O-])ccc2-c2ccccc21', 'O=C1C=Cc2ccccc2C1=O', 'CN(C)C(=O)Oc1cccc([N+](C)(C)C)c1.[Br-]', 'CN(C)C(=O)Oc1cccc([N+](C)(C)C)c1.[Br-]', 'CN(C)C(=O)Oc1cccc([N+](C)(C)C)c1.[Br-]', 'CN(C)C(=O)Oc1cccc([N+](C)(C)C)c1.[Br-]', 'CN(C)C(=O)Oc1cccc([N+](C)(C)C)c1.[Br-]', 'CN(C)C(=O)Oc1cccc([N+](C)(C)C)c1.[Br-]', 'CN(C)C(=O)Oc1cccc([N+](C)(C)C)c1.[Br-]', 'CN(C)C(=O)Oc1cccc([N+](C)(C)C)c1.[Br-]', 'CN(C)C(=O)Oc1cccc([N+](C)(C)C)c1.[Br-]', 'CN(C)C(=O)Oc1cccc([N+](C)(C)C)c1.[Br-]', 'CN(C)C(=O)Oc1cccc([N+](C)(C)C)c1.[Br-]', 'CN1CC[C@@]2(C)c3cc(OC(=O)Nc4ccccc4)ccc3N(C)C12', 'CN1CC[C@@]2(C)c3cc(OC(=O)Nc4ccccc4)ccc3N(C)C12', 'CN1CC[C@@]2(C)c3cc(OC(=O)Nc4ccccc4)ccc3N(C)C12', 'CN1CC[C@@]2(C)c3cc(OC(=O)Nc4ccccc4)ccc3N(C)C12', 'CN1CC[C@@]2(C)c3cc(OC(=O)Nc4ccccc4)ccc3N(C)C12', 'CN1CC[C@@]2(C)c3cc(OC(=O)Nc4ccccc4)ccc3N(C)C12', 'CN1CC[C@@]2(C)c3cc(OC(=O)Nc4ccccc4)ccc3N(C)C12', 'Cc1ccccc1NC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)C1N2C', 'Cc1ccccc1NC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)C1N2C', 'Cc1ccccc1NC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)C1N2C', 'CC(C)c1ccc(NC(=O)Oc2ccc3c(c2)[C@]2(C)CCN(C)C2N3C)cc1', 'CC(C)c1ccc(NC(=O)Oc2ccc3c(c2)[C@]2(C)CCN(C)C2N3C)cc1', 'CC(C)c1ccc(NC(=O)Oc2ccc3c(c2)[C@]2(C)CCN(C)C2N3C)cc1', 'CC(C)c1ccc(NC(=O)Oc2ccc3c(c2)[C@]2(C)CCN(C)C2N3Cc2ccccc2)cc1', 'CC(C)c1ccc(NC(=O)Oc2ccc3c(c2)[C@]2(C)CCN(C)C2N3)cc1', 'CC(C)c1ccc(NC(=O)Oc2ccc3c(c2)[C@]2(C)CCNC2N3)cc1', 'CC(C)c1ccc(NC(=O)Oc2ccc3c(c2)[C@]2(C)CCNC2N3)cc1', 'Cc1ccccc1NC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(CCc3ccccc3)C1N2C', 'Cc1ccccc1NC(=O)Oc1ccc2c(c1)[C@]1(C)CCNC1N2C', 'Cc1ccccc1NC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)C1N2Cc1ccccc1', 'CC(C)c1ccc(NC(=O)Oc2ccc3c(c2)[C@]2(C)CCNC2N3C)cc1', 'Cc1ccccc1NC(=O)Oc1ccc2c(c1)[C@]1(C)CCNC1N2', 'Cc1ccccc1NC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(Cc3ccccc3)C1N2Cc1ccccc1', 'Cc1ccccc1NC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)C1N2', 'O=C(c1ccccc1)N(CCC1CCN(Cc2ccccc2)CC1)c1ccccc1', 'CN(CCC1CCN(Cc2ccccc2)CC1)C(=O)c1ccccc1', 'O=C(NCCC1CCN(Cc2ccccc2)CC1)c1ccccc1', 'C/C=C1\\\\C2C=C(C(F)(F)F)CC1(N)c1ccc(O)nc1C2', 'CC1=CC2Cc3nc(O)ccc3C(N)(C1)/C2=C/C(F)(F)F', 'Cc1ccc(N)cc1', 'Cc1ccc(N)cc1', 'NC12CC(C(F)(F)F)=CC(Cc3nc(O)ccc31)/C2=C\\\\C(F)(F)F', 'CC[N+](C)(C)c1cccc(O)c1.[Br-]', 'CC[N+](C)(C)c1cccc(O)c1.[Br-]', 'CC[N+](C)(C)c1cccc(O)c1.[Br-]', 'CC[N+](C)(C)c1cccc(O)c1.[Br-]', 'C=CC[N+](C)(C)c1ccccc1O.[Br-]', 'C=CC[N+](C)(C)c1ccccc1OC.[Br-]', 'C=CC[N+](C)(C)c1cccc(O)c1.[Br-]', 'COc1ccc(C(=O)COc2ccc([N+](C)(C)C)cc2)cc1OC.[Br-]', 'COc1ccc(C(=O)COc2cccc([N+](C)(C)Cc3ccccc3)c2)cc1OC.[Br-]', 'COc1ccc(C(=O)COc2cccc([N+](C)(C)C)c2)cc1OC.[Br-]', 'C=CCC[N+](C)(C)c1ccccc1O.[Br-]', 'COc1ccc(C(=O)CCc2cccc([N+](C)(C)Cc3ccccc3)c2)cc1OC.[Br-]', 'C=CC[N+](C)(C)c1ccc(OCC(=O)c2ccc(OC)c(OC)c2)cc1.[Br-]', 'COc1ccc(C(=O)COc2ccc([N+](C)(C)Cc3ccccc3)cc2)cc1OC.[Br-]', 'COc1ccc(C(=O)CCc2ccc([N+](C)(C)Cc3ccccc3)cc2)cc1OC.[Br-]', 'COc1ccc(C(=O)CCc2ccc([N+](C)(C)C)cc2)cc1OC.[Br-]', 'C=CC[N+](C)(C)c1cccc(OC(C)=O)c1.[Br-]', 'CCCCCCCNC(=O)Oc1ccc2c(c1)C1(C)CCN(CC)C2C1', 'Nc1ccc2nc3c(c(N)c2c1)CCCC3', 'Nc1ccc2nc3c(c(N)c2c1)CCCC3', 'Nc1ccc2nc3c(c(N)c2c1)CCCC3', 'COc1ccc2c(N)c3c(nc2c1)CCCC3', 'COc1ccc2c(N)c3c(nc2c1)CCCC3', 'COc1ccc2c(N)c3c(nc2c1)CCCC3', 'COc1ccc2c(N)c3c(nc2c1)CCCC3', 'COc1ccc2c(c1)Cc1c-2nc2ccccc2c1N', 'CCCN1CCCC(c2cccc(OC(=O)NC(C)C)c2)C1', 'COc1cccc2c1Cc1c-2nc2ccccc2c1N', 'Nc1c2c(nc3cc(F)ccc13)-c1ccccc1C2', 'Nc1c2c(nc3cc(Cl)ccc13)-c1ccccc1C2', 'Nc1ccc2c(N)c3c(nc2c1)-c1ccccc1C3', 'Nc1ccc2nc3c(c(N)c2c1)Cc1ccccc1-3', 'Nc1c2c(nc3ccccc13)-c1ccccc1C2', 'Nc1c2c(nc3ccccc13)-c1ccccc1C2', 'Nc1c2c(nc3ccccc13)-c1ccccc1C2', 'O=[N+]([O-])c1ccc2c(NCc3ccccc3)c3c(nc2c1)CCCC3', 'O=[N+]([O-])c1ccc2c(NCc3ccccc3)c3c(nc2c1)CCCC3', 'CCCCCCCNc1c2c(nc3cc(F)ccc13)CCCC2', 'CCCCCCCNc1c2c(nc3cc(F)ccc13)CCCC2', 'CCCCCCCNc1c2c(nc3cc(F)ccc13)CCCC2', 'CCCCCCCNc1c2c(nc3cc(OC)ccc13)CCCC2', 'CCCCCCCNc1c2c(nc3cc(OC)ccc13)CCCC2', 'CCCCCCCNc1c2c(nc3cc(OC)ccc13)CCCC2', 'CCCCCCCNc1c2c(nc3cc([N+](=O)[O-])ccc13)CCCC2', 'CCCCCCCNc1c2c(nc3cc([N+](=O)[O-])ccc13)CCCC2', 'CCCCCCCNc1c2c(nc3cc([N+](=O)[O-])ccc13)CCCC2', 'CCCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'CCCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'CCCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'CCCCCCNC(=O)Oc1ccc2c(c1)C1CCN(CC)C2C1', 'CCCCCCNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(CC)[C@@H]1C2', 'CCCCCCNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(CC)[C@@H]1C2', 'CCCCCCNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(CC)[C@@H]1C2', 'CCCCCCCNc1c2c(nc3cc(C)ccc13)CCCC2', 'CCCCCCCNc1c2c(nc3cc(C)ccc13)CCCC2', 'CCCCCCCNc1c2c(nc3cc(C)ccc13)CCCC2', 'CCN1CCC2CC1c1ccc(OC(=O)NC)cc12', 'CCCCNC(=O)Oc1ccc2c(c1)C1CCN(CC)C2C1', 'CCCCCCNC(=O)Oc1ccc2c(c1)C1CCN(C)C2C1', 'CCCCCCCNC(=O)Oc1ccc2c(c1)C1CCN(CC)C2C1', 'Cc1ccc2c(NCc3ccccc3)c3c(nc2c1)CCCC3', 'Cc1ccc2c(NCc3ccccc3)c3c(nc2c1)CCCC3', 'CCCCCCCNC(=O)Oc1ccc2c(c1)C1CCN(C)C2C1', 'CCCCCCNC(=O)Oc1ccc2c(c1)C1(C)CCN(CC)C2C1', 'Nc1c2c(nc3cc([N+](=O)[O-])ccc13)CCCC2', 'Nc1c2c(nc3cc([N+](=O)[O-])ccc13)CCCC2', 'Nc1c2c(nc3cc([N+](=O)[O-])ccc13)CCCC2', 'Nc1c2c(nc3cc([N+](=O)[O-])ccc13)CCCC2', 'O=[N+]([O-])c1ccc2nc3c(c(NCc4ccccc4)c2c1)CCCC3', 'O=[N+]([O-])c1ccc2nc3c(c(NCc4ccccc4)c2c1)CCCC3', 'Clc1ccc2c(NCc3ccccc3)c3c(nc2c1)CCCC3', 'Clc1ccc2c(NCc3ccccc3)c3c(nc2c1)CCCC3', 'Cc1ccc2nc3c(c(NCc4ccccc4)c2c1)CCCC3', 'Cc1ccc2nc3c(c(NCc4ccccc4)c2c1)CCCC3', 'Nc1c2c(nc3ccc(Cl)cc13)CCCC2', 'Nc1c2c(nc3ccc(Cl)cc13)CCCC2', 'Nc1c2c(nc3ccc(Cl)cc13)CCCC2', 'Nc1c2c(nc3ccc(Cl)cc13)CCCC2', 'Nc1c2c(nc3ccc(Cl)cc13)CCCC2', 'Nc1c2c(nc3ccc(Cl)cc13)CCCC2', 'Nc1c2c(nc3ccc(Cl)cc13)CCCC2', 'Cc1ccc2nc3c(c(N)c2c1)CCCC3', 'Cc1ccc2nc3c(c(N)c2c1)CCCC3', 'Cc1ccc2nc3c(c(N)c2c1)CCCC3', 'Cc1ccc2nc3c(c(N)c2c1)CCCC3', 'Nc1c2c(nc3ccccc13)-c1ccc(F)cc1C2', 'Cc1cccc2c1Cc1c-2nc2ccccc2c1N', 'COc1cc2nc3c(c(N)c2cc1OC)CCCC3', 'COc1cc2nc3c(c(N)c2cc1OC)CCCC3', 'COc1cc2nc3c(c(N)c2cc1OC)CCCC3', 'COc1cc2nc3c(c(N)c2cc1OC)CCCC3', 'Nc1c2c(nc3cc(Cl)c(Cl)cc13)CCCC2', 'Nc1c2c(nc3cc(Cl)c(Cl)cc13)CCCC2', 'Nc1c2c(nc3cc(Cl)c(Cl)cc13)CCCC2', 'Nc1c2c(nc3cc(Cl)c(Cl)cc13)CCCC2', 'Nc1c2c(nc3cc(F)ccc13)CCCC2', 'Nc1c2c(nc3cc(F)ccc13)CCCC2', 'Nc1c2c(nc3cc(F)ccc13)CCCC2', 'Nc1c2c(nc3cc(F)ccc13)CCCC2', 'Nc1c2c(nc3cc([N+](=O)[O-])ccc13)-c1ccccc1C2', 'COc1ccc2c(c1)-c1nc3ccccc3c(N)c1C2', 'CCCCCCCNc1c2c(nc3ccc(C)cc13)CCCC2', 'CCCCCCCNc1c2c(nc3ccc(C)cc13)CCCC2', 'CCCCCCCNc1c2c(nc3ccc(C)cc13)CCCC2', 'Nc1c2c(nc3cc(Br)ccc13)CCCC2', 'Nc1c2c(nc3ccccc13)-c1ccc(Cl)cc1C2', 'Cc1ccc2c(N)c3c(nc2c1)CCCC3', 'Cc1ccc2c(N)c3c(nc2c1)CCCC3', 'Cc1ccc2c(N)c3c(nc2c1)CCCC3', 'Cc1ccc2c(N)c3c(nc2c1)CCCC3', 'Nc1c2c(nc3cc(Cl)ccc13)CCCC2', 'Nc1c2c(nc3cc(Cl)ccc13)CCCC2', 'Nc1c2c(nc3cc(Cl)ccc13)CCCC2', 'Nc1c2c(nc3cc(Cl)ccc13)CCCC2', 'Nc1c2c(nc3cc(Cl)ccc13)CCCC2', 'Nc1c2c(nc3cc(Cl)ccc13)CCCC2', 'Nc1c2c(nc3cc(Cl)ccc13)CCCC2', 'Nc1c2c(nc3cc(Cl)ccc13)CCCC2', 'Nc1c2c(nc3cc(Cl)ccc13)CCCC2', 'Nc1c2c(nc3cc(Cl)ccc13)CCCC2', 'Nc1c2c(nc3cc(Cl)ccc13)CCCC2', 'Nc1c2c(nc3cc(Cl)ccc13)CCCC2', 'Nc1c2c(nc3cc(Cl)ccc13)CCCC2', 'Nc1c2c(nc3cc(Cl)ccc13)CCCC2', 'Nc1c2c(nc3cc(Cl)ccc13)CCCC2', 'Nc1c2c(nc3cc(Cl)ccc13)CCCC2', 'Nc1c2c(nc3cc(Cl)ccc13)CCCC2', 'Nc1c2c(nc3cc(Cl)ccc13)CCCC2', 'Nc1c2c(nc3cc(Cl)ccc13)CCCC2', 'Nc1c2c(nc3ccc([N+](=O)[O-])cc13)CCCC2', 'Nc1c2c(nc3ccc([N+](=O)[O-])cc13)CCCC2', 'Nc1c2c(nc3ccc([N+](=O)[O-])cc13)CCCC2', 'Nc1c2c(nc3ccc([N+](=O)[O-])cc13)CCCC2', 'Cc1ccc2c(c1)-c1nc3ccccc3c(N)c1C2', 'COc1ccccc1CNCCCCCCNCCCCCCNCCCCCCNCc1ccccc1OC', 'CN(C)c1ccc(C(=C2C=CC(=[N+](C)C)C=C2)c2ccc(N(C)C)cc2)cc1.[Cl-]', 'CN1CC[C@@]2(C)c3cc(OC(=O)NCCN4CCOCC4)ccc3N(C)[C@@H]12', 'CN1CC[C@@]2(C)c3cc(OC(=O)NCCCCCCCN4CCOCC4)ccc3N(C)[C@@H]12', 'CN1CC[C@@]2(C)c3cc(OC(=O)NCCCCCCCCCN4CCOCC4)ccc3N(C)[C@@H]12', 'CN1CC[C@@]2(C)c3cc(OC(=O)NCCCCCCN4CCOCC4)ccc3N(C)[C@@H]12', 'CN1CC[C@@]2(C)c3cc(OC(=O)NCCCN4CCOCC4)ccc3N(C)[C@@H]12', 'CN1CC[C@@]2(C)c3cc(OC(=O)NCCCCCCCCCCCN4CCOCC4)ccc3N(C)[C@@H]12', 'CN1CC[C@@]2(C)c3cc(OC(=O)NCCCCCCCCCCN4CCOCC4)ccc3N(C)[C@@H]12', 'CN1CC[C@@]2(C)c3cc(OC(=O)NCCCCCCCCN4CCOCC4)ccc3N(C)[C@@H]12', 'CN1CC[C@@]2(C)c3cc(OC(=O)NCCCCCN4CCOCC4)ccc3N(C)[C@@H]12', 'CN1CC[C@@]2(C)c3cc(OC(=O)NCCCCN4CCOCC4)ccc3N(C)[C@@H]12', 'CN1CC[C@@]2(C)c3cc(OC(=O)NCCCCCCCCCCCCN4CCOCC4)ccc3N(C)[C@@H]12', 'O=c1c(O)c(-c2cc(O)c(O)c(O)c2)oc2cc(O)cc(O)c12', 'O=c1c(O)c(-c2cc(O)c(O)c(O)c2)oc2cc(O)cc(O)c12', 'CN(Cc1ccc(C(C)(C)C)cc1)Cc1cccc2ccccc12', 'CCCCCCCCc1noc(/C(=N/O)SCCN(CC)CC)n1', 'CCN(CC)CCS/C(=N\\\\O)c1nc(Cc2ccccc2)no1', 'COc1cc2ccc(=O)oc2cc1O', 'CC(C)(C)c1ccc(C(=O)CCCN2CCC(OC(c3ccccc3)c3ccccc3)CC2)cc1', 'Fc1ccc2c(NCCCCCCCNc3c4c(nc5cc(F)ccc35)CCCC4)c3c(nc2c1)CCCC3', 'c1ccc2c(NCCCCCCCCNc3c4c(nc5ccccc35)CCCC4)c3c(nc2c1)CCCC3', 'c1cnc2nc3c(c(NCCCCCCCCNc4c5c(nc6ncccc46)CCCC5)c2c1)CCCC3', 'COc1ccc(CN2CCC(CCC(=O)c3ccc4c(c3)CCN4)CC2)cc1', 'COc1ccccc1CN1CCC(CCC(=O)c2ccc3c(c2)CCN3)CC1', 'CCCCCN1CCc2cc(C(=O)CCC3CCN(Cc4ccccc4)CC3)ccc21', 'CN1CCc2cc(C(=O)CCC3CCN(Cc4ccccc4)CC3)ccc21', 'c1ccc2c(NCCCCCCCCNc3c4c(nc5ccccc35)CCC4)c3c(nc2c1)CCC3', 'c1ccc2c(NCCCCCCCNc3c4c(nc5ccccc35)CCC4)c3c(nc2c1)CCC3', 'c1ccc2c(NCCCCCCCCNc3c4c(nc5ccccc35)CCCCC4)c3c(nc2c1)CCCCC3', 'c1cnc2nc3c(c(NCCCCCCCNc4c5c(nc6ncccc46)CCCC5)c2c1)CCCC3', 'c1ccc2c(NCCCCCCCNc3c4c(nc5ccccc35)CCCCC4)c3c(nc2c1)CCCCC3', 'c1cnc2nc3c(c(NCCCCCCNc4c5c(nc6ncccc46)CCCC5)c2c1)CCCC3', 'Clc1ccc2c(NCCCCCCNc3c4c(nc5cc(Cl)ccc35)CCCC4)c3c(nc2c1)CCCC3', 'c1ccc2c(NCCCCCCNc3c4c(nc5ccccc35)CCC4)c3c(nc2c1)CCC3', 'Clc1ccc2c(NCCCCCCCCNc3c4c(nc5cc(Cl)ccc35)CCCC4)c3c(nc2c1)CCCC3', 'Fc1ccc2c(NCCCCCCNc3c4c(nc5cc(F)ccc35)CCCC4)c3c(nc2c1)CCCC3', 'c1ccc2c(NCCCCCCNc3c4c(nc5ccccc35)CCCC4)c3c(nc2c1)CCCC3', 'Clc1ccc2c(NCCCCCCCNc3c4c(nc5cc(Cl)ccc35)CCCC4)c3c(nc2c1)CCCC3', 'O=C(CCC1CCN(Cc2cccc(F)c2)CC1)c1ccc2c(c1)CCN2', 'O=C(CCC1CCN(Cc2ccccc2)CC1)c1ccc2c(c1)CCN2', 'O=C(CCC1CCN(Cc2ccccc2)CC1)c1ccc2c(c1)CCN2', 'Fc1ccc2c(NCCCCCCCCNc3c4c(nc5cc(F)ccc35)CCCC4)c3c(nc2c1)CCCC3', 'COc1cc2cc(-c3ccc(CN(C)Cc4ccccc4)cc3)c(=O)oc2cc1OC', 'COc1cc2cc(-c3ccc(CN(C)Cc4ccccc4)cc3)c(=O)oc2cc1OC', 'COc1cc2cc(-c3ccc(CN(C)Cc4ccccc4)cc3)c(=O)oc2cc1OC', 'COc1cc2cc(-c3ccc(CN(C)Cc4ccccc4)cc3)c(=O)oc2cc1OC', 'COc1cc2cc(-c3ccc(CN(C)Cc4ccccc4)cc3)c(=O)oc2cc1OC', 'COc1cc2cc(-c3ccc(CN(C)Cc4ccccc4)cc3)c(=O)oc2cc1OC', 'COc1cc2cc(-c3ccc(CN(C)Cc4ccccc4)cc3)c(=O)oc2cc1OC', 'COc1cc2cc(-c3ccc(CN(C)Cc4ccccc4)cc3)c(=O)oc2cc1OC', 'COc1cc2cc(-c3ccc(CN(C)Cc4ccccc4)cc3)c(=O)oc2cc1OC', 'COc1cc2cc(-c3ccc(CN(C)Cc4ccccc4)cc3)c(=O)oc2cc1OC', 'O=C(CCC1CCN(Cc2ccccc2F)CC1)c1ccc2c(c1)CCN2', 'O=C(CCC1CCN(Cc2ccccc2Cl)CC1)c1ccc2c(c1)CCN2', 'O=C(CCC1CCN(Cc2ccc(Cl)cc2)CC1)c1ccc2c(c1)CCN2', 'CN1CCCc2ccc(C(=O)CCC3CCN(Cc4ccccc4)CC3)cc21', 'O=C(CCC1CCN(Cc2cccc(Cl)c2)CC1)c1ccc2c(c1)CCN2', 'O=C(CCC1CCN(Cc2ccc(F)cc2)CC1)c1ccc2c(c1)CCN2', 'O=C(CCC1CCN(Cc2ccccc2)CC1)c1ccc2c(c1)N(Cc1ccccc1)CC2', 'O=C(CCC1CCN(Cc2ccccc2)CC1)c1ccc2c(c1)NCC2', 'O=C(CCC1CCN(Cc2cccc([N+](=O)[O-])c2)CC1)c1ccc2c(c1)CCN2', 'Cc1cccc(CN2CCC(CCC(=O)c3ccc4c(c3)CCN4)CC2)c1', 'O=C(CCC1CCN(Cc2ccccc2)CC1)c1ccc2c(c1)NCCCCC2', 'O=C(CCC1CCN(Cc2cccc([N+](=O)[O-])c2)CC1)c1ccc2c(c1)NCCCC2', 'Cc1cccc(CN2CCC(CCC(=O)c3ccc4c(c3)NCCCC4)CC2)c1', 'O=C(CCC1CCN(Cc2cccc(Cl)c2)CC1)c1ccc2c(c1)NCCCC2', 'O=C(CCC1CCN(Cc2ccc(F)cc2)CC1)c1ccc2c(c1)NCCCC2', 'O=C(CCC1CCN(Cc2cccc(F)c2)CC1)c1ccc2c(c1)NCCCC2', 'CCN1CCc2cc(C(=O)CCC3CCN(Cc4ccccc4)CC3)ccc21', 'O=C(CCC1CCN(Cc2ccccc2)CC1)c1ccc2c(c1)CCCCN2', 'CCCN1CCc2cc(C(=O)CCC3CCN(Cc4ccccc4)CC3)ccc21', 'CCCCN1CCc2cc(C(=O)CCC3CCN(Cc4ccccc4)CC3)ccc21', 'COc1cccc(CN2CCC(CCC(=O)c3ccc4c(c3)CCN4)CC2)c1', 'O=C(CCC1CCN(Cc2ccccc2)CC1)c1ccc2c(c1)NCCC2', 'O=C(CCC1CCN(Cc2ccccc2)CC1)c1ccc2c(c1)NCCC2', 'O=C(CCC1CCN(Cc2ccccc2F)CC1)c1ccc2c(c1)NCCCC2', 'COc1ccc(CN2CCC(CCC(=O)c3ccc4c(c3)NCCCC4)CC2)cc1', 'COc1cccc(CN2CCC(CCC(=O)c3ccc4c(c3)NCCCC4)CC2)c1', 'COc1ccccc1CN1CCC(CCC(=O)c2ccc3c(c2)NCCCC3)CC1', 'O=C(CCC1CCN(Cc2ccccc2)CC1)c1ccc2c(c1)N(Cc1ccccc1)CCCC2', 'CCCN1CCCCc2ccc(C(=O)CCC3CCN(Cc4ccccc4)CC3)cc21', 'CCN1CCCCc2ccc(C(=O)CCC3CCN(Cc4ccccc4)CC3)cc21', 'CN1CCCCc2ccc(C(=O)CCC3CCN(Cc4ccccc4)CC3)cc21', 'O=c1c(O)c(-c2ccccc2)oc2cc(O)cc(O)c12', 'O=c1c(O)c(-c2ccccc2)oc2cc(O)cc(O)c12', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCNC1N2C', 'CN1CC[C@@]2(C)c3cc(OC(=O)NC(C)(C)C)ccc3N(C)[C@@H]12', 'CN1CC[C@@]2(C)c3cc(OC(=O)NC(C)(C)C)ccc3N(C)[C@@H]12', 'CC(C)OP(=O)(F)OC(C)C', 'CC(C)OP(=O)(F)OC(C)C', 'CC(C)OP(=O)(F)OC(C)C', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(Cc3ccccc3)C1N2C', 'CN1CC[C@@]2(C)c3cc(OC(=O)Nc4ccccc4)ccc3N(C)[C@@H]12', 'CN1CC[C@@]2(C)c3cc(OC(=O)Nc4ccccc4)ccc3N(C)[C@@H]12', 'CN1CC[C@@]2(C)c3cc(OC(=O)Nc4ccccc4)ccc3N(C)[C@@H]12', 'CN1CC[C@@]2(C)c3cc(OC(=O)Nc4ccccc4)ccc3N(C)[C@@H]12', 'CN1CC[C@@]2(C)c3cc(OC(=O)Nc4ccccc4)ccc3N(C)[C@@H]12', 'CN1CC[C@@]2(C)c3cc(OC(=O)Nc4ccccc4)ccc3N(C)[C@@H]12', 'CN1CC[C@@]2(C)c3cc(OC(=O)Nc4ccccc4)ccc3N(C)[C@@H]12', 'CN(C)C(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'CN(C)C(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'CN(C)C(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'CCCCCCCCNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'CCCCCCCCNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(Cc3ccccc3)[C@@H]1N2C', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(Cc3ccccc3)[C@@H]1N2C', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(Cc3ccccc3)[C@@H]1N2C', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN[C@@H]1N2C', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN[C@@H]1N2C', 'C=CCN1CC[C@@]2(C)c3cc(OC(=O)NC)ccc3N(C)[C@@H]12', 'C=CCN1CC[C@@]2(C)c3cc(OC(=O)NC)ccc3N(C)[C@@H]12', 'COc1ccc(NC(=O)Oc2ccc3c(c2)[C@]2(C)CCN(C)[C@@H]2N3C)cc1', 'COc1ccc(NC(=O)Oc2ccc3c(c2)[C@]2(C)CCN(C)[C@@H]2N3C)cc1', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(CCc3ccccc3)[C@@H]1N2C', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(CCc3ccccc3)[C@@H]1N2C', 'CNC(=O)Oc1ccc2c(c1)[C@@]1(C)CCNC1N2', 'C[C@]12CCNC1Nc1ccc(OC(=O)Nc3ccccc3)cc12', 'CNC(=O)Oc1ccc2c(c1)[C@@]1(C)CCN(C)C1N2C', 'CNC(=O)Oc1ccc2c(c1)[C@@]1(C)CCN(C)C1N2C', 'CN1CC[C@]2(C)c3cc(OC(=O)Nc4ccccc4)ccc3N(C)C12', 'CN1CC[C@]2(C)c3cc(OC(=O)Nc4ccccc4)ccc3N(C)C12', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(Cc3ccccc3)C1N2Cc1ccccc1', 'CN1CC[C@@]2(C)c3cc(OC(=O)Nc4ccccc4)ccc3NC12', 'CN1CC[C@@]2(C)c3cc(OC(=O)Nc4ccccc4)ccc3NC12', 'CNC(=O)Oc1ccc2c(c1)[C@@]1(C)CCN(Cc3ccccc3)C1N2Cc1ccccc1', 'CN1c2ccc(OC(=O)Nc3ccccc3)cc2[C@]2(C)CCNC12', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)C1N2Cc1ccccc1', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)C1N2Cc1ccccc1', 'C[C@@]12CCN(Cc3ccccc3)C1N(Cc1ccccc1)c1ccc(OC(=O)Nc3ccccc3)cc12', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCNC1N2', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)C1N2', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)C1N2', 'C[C@@]12CCNC1Nc1ccc(OC(=O)Nc3ccccc3)cc12', 'CCCCN1CCC(CCC(=O)c2cc(Cl)c(N)cc2OC)CC1', 'CCCCN1CCC(CCC(=O)c2cc(Cl)c(N)cc2OC)CC1', 'COCC[N+]1(C)CCC(CCC(=O)c2cc3cc(OC)c(OC)cc3s2)CC1.[Br-]', 'COc1cc2cc(CC3CC[N+](C)(Cc4ccccc4)CC3)sc2cc1OC.[Br-]', 'COc1cc2cc(C(O)C3CC[N+](C)(Cc4ccccc4)CC3)sc2cc1OC.[Br-]', 'COc1cc2cc(C(=O)CC3=CC[N+](C)(Cc4ccccc4)CC3)sc2cc1OC.[Br-]', 'COc1cc2cc(C(=O)CC3(O)CC[N+](C)(Cc4ccccc4)CC3)sc2cc1OC.[Br-]', 'COc1cc2cc(C(=O)CC3(O)CC[N+](C)(Cc4ccccc4)CC3)sc2cc1OC.[Br-]', 'COc1cc2cc(C(=O)CCC3CC[N+](C)(Cc4ccc([N+](=O)[O-])o4)CC3)sc2cc1OC.[Br-]', 'COC(=O)C[N+]1(C)CCC(CCC(=O)c2cc3cc(OC)c(OC)cc3s2)CC1.[Br-]', 'COc1cc2cc(C=C3CC[N+](C)(Cc4ccccc4)CC3)sc2cc1OC.[Br-]', 'COc1cc2c(cc1OC)C(=O)C(Cc1cc[n+](Cc3ccccc3)cc1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CC[N+](C)(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CC[N+](C)(Cc3ccccc3)CC1)C2', 'C[N+]1(Cc2ccccc2)CCC(CCC(=O)c2ccc3c(c2)NCCCC3)CC1', 'COc1cc2c(cc1OC)C(=O)[C@@H]([C@@H](O)C1CC[N+](C)(Cc3ccccc3)CC1)C2', 'Cc1cc(C(=O)CCC2CC[N+](C)(Cc3ccccc3)CC2)nn1-c1ccccc1', 'Cc1cc(C(=O)CCC2CC[N+](C)(Cc3ccccc3)CC2)nn1-c1ccccc1', 'Cc1cc(C(=O)CCC2CC[N+](C)(Cc3ccccc3)CC2)nn1-c1ccccc1', 'Cc1cc(C(=O)CCC2CC[N+](C)(Cc3ccccc3)CC2)nn1-c1ccccc1', 'COc1cc2cc(C(=O)C=C3CC[N+](C)(Cc4ccccc4)CC3)sc2cc1OC.[Br-]', 'COc1cc2cc(C(=O)C=C3CC[N+](C)(Cc4ccccc4)CC3)sc2cc1OC.[Br-]', 'COc1cc2cc(C(=O)CCc3cc[n+](CC4CCC4)cc3)sc2cc1OC.[Br-]', 'COc1cc2cc(C(=O)CCc3cc[n+](CC4CCC4)cc3)sc2cc1OC.[Br-]', 'COc1cc2cc(C(=O)CC(O)C3CC[N+](C)(Cc4ccccc4)CC3)sc2cc1OC.[Br-]', 'COc1cc2cc(C(=O)CC(O)C3CC[N+](C)(Cc4ccccc4)CC3)sc2cc1OC.[Br-]', 'COc1cc2cc(C(=O)CC(O)C3CC[N+](C)(Cc4ccccc4)CC3)sc2cc1OC.[Br-]', 'COc1cc2cc(C(=O)CC(O)C3CC[N+](C)(Cc4ccccc4)CC3)sc2cc1OC.[Br-]', 'COc1cc2cc(C(=O)CC(O)C3CC[N+](C)(Cc4ccccc4)CC3)sc2cc1OC.[Br-]', 'COc1cc2cc(C(=O)CC(OC)C3CC[N+](C)(Cc4ccccc4)CC3)sc2cc1OC.[Br-]', 'COc1cc2cc(C(=O)CC(OC)C3CC[N+](C)(Cc4ccccc4)CC3)sc2cc1OC.[Br-]', 'C=CC[n+]1ccc(CCC(=O)c2cc3cc(OC)c(OC)cc3s2)cc1.[Br-]', 'COc1cc2cc(C(=O)CCc3cc[n+](CC4CC4)cc3)sc2cc1OC.[Br-]', 'CCC[n+]1ccc(CCC(=O)c2cc3cc(OC)c(OC)cc3s2)cc1.[Br-]', 'CC[n+]1ccc(CCC(=O)c2cc3cc(OC)c(OC)cc3s2)cc1.[Br-]', 'COc1cc2cc(C(=O)CCC3CC[N+](C)(Cc4ccccc4)CC3)n(C)c2cc1OC', 'COc1cc2cc(C(=O)CCC3CC[N+](C)(Cc4ccccc4)CC3)n(C)c2cc1OC', 'COc1cc2cc(C(=O)CCC3CC[N+](C)(Cc4ccccc4)CC3)n(C)c2cc1OC', 'COc1cc2cc(C(=O)CCC3CC[N+](C)(Cc4ccccc4)CC3)n(C)c2cc1OC', 'COc1cc2cc(C(=O)CCc3cc[n+](C)cc3)sc2cc1OC.[Br-]', 'COc1cc2cc(C(=O)CCc3cc[n+](C)cc3)sc2cc1OC.[Br-]', 'COc1cc2c(cc1OC)C(=O)C(C(O)C1CC[N+](C)(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)[C@@H]([C@H](O)C1CC[N+](C)(Cc3ccccc3)CC1)C2', 'C[N+]1(Cc2ccccc2)CCC(CCC(=O)c2ccc3c(c2)OCCO3)CC1', 'C[N+]1(Cc2ccccc2)CCC(CCC(=O)c2ccc3c(c2)OCCO3)CC1', 'C[N+]1(Cc2ccccc2)CCC(CCC(=O)c2ccc3c(c2)OCCO3)CC1', 'COc1cc2cc(C(=O)CCCCC3CC[N+](C)(Cc4ccccc4)CC3)sc2cc1OC.[Br-]', 'COc1cc2cc(C(=O)CC(O)CCC3CC[N+](C)(Cc4ccccc4)CC3)sc2cc1OC.[Br-]', 'COc1cc2cc(C(=O)CC(O)CCC3CC[N+](C)(Cc4ccccc4)CC3)sc2cc1OC.[Br-]', 'COc1cc2c(cc1OC)C(=O)/C(=C/c1cc[n+](Cc3ccccc3)cc1)C2', 'COc1ccc2c3c1OC1C[C@@H](O)C=C[C@@]31CC[N+](C)(C)C2', 'COc1cc2c(cc1OC)C(=O)C(C(O)c1cc[n+](Cc3ccccc3)cc1)C2', 'COc1cc2cc(C(=O)CCC3CC[N+](C)(Cc4ccccc4)CC3)sc2cc1OC.[Br-]', 'COc1cc2cc(C(=O)CCC3CC[N+](C)(Cc4ccccc4)CC3)sc2cc1OC.[Br-]', 'COc1cc2c(cc1OC)C(=O)C(C(O)C1CC[N+](Cc3ccccc3)(Cc3ccccc3)CC1)C2', 'COc1cc2cc(C(=O)CCc3cc[n+](Cc4ccsc4)cc3)sc2cc1OC', 'COc1cc2cc(C(=O)CCc3cc[n+](Cc4ccsc4)cc3)sc2cc1OC', 'COC(=O)c1ccc(C[n+]2ccc(CCC(=O)c3cc4cc(OC)c(OC)cc4s3)cc2)cc1', 'COC(=O)c1ccc(C[n+]2ccc(CCC(=O)c3cc4cc(OC)c(OC)cc4s3)cc2)cc1', 'COc1cc2cc(C(=O)CCc3cc[n+](Cc4ccc(F)cc4)cc3)sc2cc1OC', 'COc1cc2cc(C(=O)CCc3cc[n+](Cc4ccc(F)cc4)cc3)sc2cc1OC', 'COc1cc2cc(C(=O)CCC3CC[N+](C)(CC(=O)OC(C)(C)C)CC3)sc2cc1OC.[Br-]', 'COc1cc2cc(C(=O)CCC3CC[N+](C)(CCOc4ccccc4)CC3)sc2cc1OC.[Br-]', 'C[N+]1(Cc2ccccc2)CCC(CCC(=O)c2ccc3c(c2)OCO3)CC1', 'C[N+]1(Cc2ccccc2)CCC(CCC(=O)c2ccc3c(c2)OCO3)CC1', 'C[N+]1(Cc2ccccc2)CCC(CCC(=O)c2ccc3c(c2)OCO3)CC1', 'C[N+]1(Cc2ccccc2)CCC(CCC(=O)c2ccc3c(c2)OCO3)CC1', 'COc1ccc2cc(C(=O)CCC3CC[N+](C)(Cc4ccccc4)CC3)ccc2c1', 'COc1ccc2cc(C(=O)CCC3CC[N+](C)(Cc4ccccc4)CC3)ccc2c1', 'COc1ccc2cc(C(=O)CCC3CC[N+](C)(Cc4ccccc4)CC3)ccc2c1', 'COc1ccc2cc(C(=O)CCC3CC[N+](C)(Cc4ccccc4)CC3)ccc2c1', 'COc1cc2cc(C(=O)CCC3CC[N+](C)(Cc4ccccc4)CC3)sc2cc1OC', 'COc1cc2cc(C(=O)CCC3CC[N+](C)(Cc4ccccc4)CC3)sc2cc1OC', 'C[N+]1(Cc2ccccc2)CCC(CCC(=O)c2ccc3c(c2)CCCCO3)CC1', 'C[N+]1(Cc2ccccc2)CCC(CCC(=O)c2ccc3c(c2)CCCCO3)CC1', 'C[N+]1(Cc2ccccc2)CCC(CCC(=O)c2ccc3c(c2)CCCCO3)CC1', 'COc1cc2cc(C(=O)CCc3cc[n+](Cc4ccccc4)cc3)sc2cc1OC', 'COc1cc2cc(C(=O)CCc3cc[n+](Cc4ccccc4)cc3)sc2cc1OC', 'C[N@+]1(Cc2ccccc2)CC[C@H](CCC(=O)c2ccc3c(c2)CCO3)CC1', 'C[N+]1(Cc2ccccc2)CCC(CCC(=O)c2ccc3c(c2)CCO3)CC1', 'C[N+]1(Cc2ccccc2)CCC(CCC(=O)c2ccc3c(c2)CCO3)CC1', 'CCOCC[n+]1ccc(CCC(=O)c2cc3cc(OC)c(OC)cc3s2)cc1', 'COCC[n+]1ccc(CCC(=O)c2cc3cc(OC)c(OC)cc3s2)cc1', 'COCC[n+]1ccc(CCC(=O)c2cc3cc(OC)c(OC)cc3s2)cc1', 'COc1cc2cc(C(=O)CCC3CC[N+](C)(CC4CCCCO4)CC3)sc2cc1OC.[Br-]', 'Nc1c2c(nc3ccccc13)-c1ccccc1CC2', 'Nc1c2c(nc3ccccc13)-c1ccccc1CC2', 'Nc1c2c(nc3ccccc13)-c1ccccc1CS2', 'CC(C)(C)c1cccc(C(=O)C(F)(F)F)c1', 'CC(C)(C)c1cccc(C(=O)C(F)(F)F)c1', 'CCCc1cc(=NCCC2CCN(Cc3ccccc3)CC2)[nH]nc1-c1ccccc1', 'CCc1cc(=NCCC2CCN(Cc3ccccc3)CC2)[nH]nc1-c1ccccc1', 'c1ccc(CN2CCC(CCN=c3[nH]nc(-c4ccccc4)c4ccccc34)CC2)cc1', 'CC(C)c1cc(-c2ccccc2)n[nH]c1=NCCC1CCN(Cc2ccccc2)CC1', 'Cc1cc(=NCCC2CCN(Cc3ccccc3)CC2)[nH]nc1-c1ccccc1', 'Cc1cc(-c2ccccc2)n[nH]c1=NCCC1CCN(Cc2ccccc2)CC1', 'Cc1ccc2onc(CCC3CCN(Cc4ccccc4)CC3)c2c1', 'Cc1ccc2onc(CCC3CCN(Cc4ccccc4)CC3)c2c1', 'Cc1ccc2onc(CCC3CCN(Cc4ccccc4)CC3)c2c1', 'Cc1ccc2onc(CCC3CCN(Cc4ccccc4)CC3)c2c1', 'Cc1ccc2onc(CCC3CCN(Cc4ccccc4)CC3)c2c1', 'Cc1ccc2onc(CCC3CCN(Cc4ccccc4)CC3)c2c1', 'Nc1ccc2c(CCC3CCN(Cc4ccccc4)CC3)noc2c1', 'Nc1ccc2c(CCC3CCN(Cc4ccccc4)CC3)noc2c1', 'Nc1ccc2c(CCC3CCN(Cc4ccccc4)CC3)noc2c1', 'Nc1ccc2c(CCC3CCN(Cc4ccccc4)CC3)noc2c1', 'Nc1ccc2c(CCC3CCN(Cc4ccccc4)CC3)noc2c1', 'Nc1ccc2c(CCC3CCN(Cc4ccccc4)CC3)noc2c1', 'Oc1ccc2c(CCC3CCN(Cc4ccccc4)CC3)noc2c1', 'Oc1ccc2c(CCC3CCN(Cc4ccccc4)CC3)noc2c1', 'Oc1ccc2c(CCC3CCN(Cc4ccccc4)CC3)noc2c1', 'Oc1ccc2c(CCC3CCN(Cc4ccccc4)CC3)noc2c1', 'Oc1ccc2c(CCC3CCN(Cc4ccccc4)CC3)noc2c1', 'Oc1ccc2c(CCC3CCN(Cc4ccccc4)CC3)noc2c1', 'N#Cc1ccc2c(CCC3CCN(Cc4ccccc4)CC3)noc2c1', 'N#Cc1ccc2c(CCC3CCN(Cc4ccccc4)CC3)noc2c1', 'N#Cc1ccc2c(CCC3CCN(Cc4ccccc4)CC3)noc2c1', 'N#Cc1ccc2c(CCC3CCN(Cc4ccccc4)CC3)noc2c1', 'N#Cc1ccc2c(CCC3CCN(Cc4ccccc4)CC3)noc2c1', 'Brc1ccc2c(CCC3CCN(Cc4ccccc4)CC3)noc2c1', 'Brc1ccc2c(CCC3CCN(Cc4ccccc4)CC3)noc2c1', 'Brc1ccc2c(CCC3CCN(Cc4ccccc4)CC3)noc2c1', 'Brc1ccc2c(CCC3CCN(Cc4ccccc4)CC3)noc2c1', 'Brc1ccc2c(CCC3CCN(Cc4ccccc4)CC3)noc2c1', 'Brc1ccc2c(CCC3CCN(Cc4ccccc4)CC3)noc2c1', 'c1ccc(CN2CCC(CCc3n[nH]c4ccccc34)CC2)cc1', 'c1ccc(CN2CCC(CCc3n[nH]c4ccccc34)CC2)cc1', 'c1ccc(CN2CCC(CCc3n[nH]c4ccccc34)CC2)cc1', 'c1ccc(CN2CCC(CCc3n[nH]c4ccccc34)CC2)cc1', 'c1ccc(CN2CCC(CCc3n[nH]c4ccccc34)CC2)cc1', 'c1ccc(CN2CCC(CCc3ncnc4ccccc34)CC2)cc1', 'c1ccc(CN2CCC(CCc3ncnc4ccccc34)CC2)cc1', 'c1ccc(CN2CCC(CCc3ncnc4ccccc34)CC2)cc1', 'c1ccc(CN2CCC(CCc3ncnc4ccccc34)CC2)cc1', 'O=S(=O)(Nc1ccc2c(CCC3CCN(Cc4ccccc4)CC3)noc2c1)c1ccccc1', 'O=S(=O)(Nc1ccc2c(CCC3CCN(Cc4ccccc4)CC3)noc2c1)c1ccccc1', 'O=S(=O)(Nc1ccc2c(CCC3CCN(Cc4ccccc4)CC3)noc2c1)c1ccccc1', 'O=S(=O)(Nc1ccc2c(CCC3CCN(Cc4ccccc4)CC3)noc2c1)c1ccccc1', 'O=S(=O)(Nc1ccc2c(CCC3CCN(Cc4ccccc4)CC3)noc2c1)c1ccccc1', 'O=C(Nc1ccc2c(CCC3CCN(Cc4ccccc4)CC3)noc2c1)c1ccccc1', 'O=C(Nc1ccc2c(CCC3CCN(Cc4ccccc4)CC3)noc2c1)c1ccccc1', 'O=C(Nc1ccc2c(CCC3CCN(Cc4ccccc4)CC3)noc2c1)c1ccccc1', 'O=C(Nc1ccc2c(CCC3CCN(Cc4ccccc4)CC3)noc2c1)c1ccccc1', 'O=C(Nc1ccc2c(CCC3CCN(Cc4ccccc4)CC3)noc2c1)c1ccccc1', 'O=C(Nc1ccc2c(CCC3CCN(Cc4ccccc4)CC3)noc2c1)c1ccccc1', 'C(=C\\\\C1CCN(Cc2ccccc2)CC1)\\\\c1noc2ccccc12', 'c1ccc(CN2CCC(CCc3nccc4ccccc34)CC2)cc1', 'c1ccc(CN2CCC(CCc3nccc4ccccc34)CC2)cc1', 'c1ccc(CN2CCC(CCc3nccc4ccccc34)CC2)cc1', 'c1ccc(CN2CCC(CCc3nccc4ccccc34)CC2)cc1', 'c1ccc(CN2CCC(CCc3nccc4ccccc34)CC2)cc1', 'c1ccc(CN2CCC(CCc3nccc4ccccc34)CC2)cc1', 'c1ccc(CN2CCC(CCc3noc4cc(N5CCOCC5)ccc34)CC2)cc1', 'c1ccc(CN2CCC(CCc3noc4cc(N5CCOCC5)ccc34)CC2)cc1', 'c1ccc(CN2CCC(CCc3noc4cc(N5CCOCC5)ccc34)CC2)cc1', 'c1ccc(CN2CCC(CCc3noc4cc(N5CCOCC5)ccc34)CC2)cc1', 'c1ccc(CN2CCC(CCc3noc4cc(N5CCOCC5)ccc34)CC2)cc1', 'COc1ccc2c(CCC3CCN(Cc4ccccc4)CC3)noc2c1', 'COc1ccc2c(CCC3CCN(Cc4ccccc4)CC3)noc2c1', 'COc1ccc2c(CCC3CCN(Cc4ccccc4)CC3)noc2c1', 'COc1ccc2c(CCC3CCN(Cc4ccccc4)CC3)noc2c1', 'COc1ccc2c(CCC3CCN(Cc4ccccc4)CC3)noc2c1', 'COc1ccc2c(CCC3CCN(Cc4ccccc4)CC3)noc2c1', 'CC(=O)Nc1ccc2c(CCC3CCN(Cc4ccccc4)CC3)noc2c1', 'CC(=O)Nc1ccc2c(CCC3CCN(Cc4ccccc4)CC3)noc2c1', 'CC(=O)Nc1ccc2c(CCC3CCN(Cc4ccccc4)CC3)noc2c1', 'CC(=O)Nc1ccc2c(CCC3CCN(Cc4ccccc4)CC3)noc2c1', 'CC(=O)Nc1ccc2c(CCC3CCN(Cc4ccccc4)CC3)noc2c1', 'CC(=O)Nc1ccc2c(CCC3CCN(Cc4ccccc4)CC3)noc2c1', 'c1ccc(CN2CCC(CCc3noc4ccccc34)CC2)cc1', 'c1ccc(CN2CCC(CCc3noc4ccccc34)CC2)cc1', 'c1ccc(CN2CCC(CCc3noc4ccccc34)CC2)cc1', 'c1ccc(CN2CCC(CCc3noc4ccccc34)CC2)cc1', 'c1ccc(CN2CCC(CCc3noc4ccccc34)CC2)cc1', 'c1ccc(CN2CCC(CCc3noc4ccccc34)CC2)cc1', 'c1ccc(CN2CCC(CCc3noc4ccccc34)CC2)cc1', 'c1ccc(CN2CCC(CCc3noc4ccccc34)CC2)cc1', 'COc1cccc2c(CCC3CCN(Cc4ccccc4)CC3)noc12', 'COc1cccc2c(CCC3CCN(Cc4ccccc4)CC3)noc12', 'COc1cccc2c(CCC3CCN(Cc4ccccc4)CC3)noc12', 'COc1cccc2c(CCC3CCN(Cc4ccccc4)CC3)noc12', 'COc1cccc2c(CCC3CCN(Cc4ccccc4)CC3)noc12', 'COc1cccc2c(CCC3CCN(Cc4ccccc4)CC3)noc12', 'COc1ccc2onc(CCC3CCN(Cc4ccccc4)CC3)c2c1', 'COc1ccc2onc(CCC3CCN(Cc4ccccc4)CC3)c2c1', 'COc1ccc2onc(CCC3CCN(Cc4ccccc4)CC3)c2c1', 'COc1ccc2onc(CCC3CCN(Cc4ccccc4)CC3)c2c1', 'COc1ccc2onc(CCC3CCN(Cc4ccccc4)CC3)c2c1', 'COc1ccc2onc(CCC3CCN(Cc4ccccc4)CC3)c2c1', 'Cc1cc2onc(CCC3CCN(Cc4ccccc4)CC3)c2cc1C', 'Cc1cc2onc(CCC3CCN(Cc4ccccc4)CC3)c2cc1C', 'Cc1cc2onc(CCC3CCN(Cc4ccccc4)CC3)c2cc1C', 'Cc1cc2onc(CCC3CCN(Cc4ccccc4)CC3)c2cc1C', 'c1ccc(CN2CCC(CCc3nsc4ccccc34)CC2)cc1', 'c1ccc(CN2CCC(CCc3nsc4ccccc34)CC2)cc1', 'c1ccc(CN2CCC(CCc3nsc4ccccc34)CC2)cc1', 'c1ccc(CN2CCC(CCc3nsc4ccccc34)CC2)cc1', 'c1ccc(CN2CCC(CCc3nsc4ccccc34)CC2)cc1', 'c1ccc(CN2CCC(CCNc3noc4ccccc34)CC2)cc1', 'c1ccc(CN2CCC(CCNc3noc4ccccc34)CC2)cc1', 'c1ccc(CN2CCC(CCNc3noc4ccccc34)CC2)cc1', 'c1ccc(CN2CCC(CCNc3noc4ccccc34)CC2)cc1', 'c1ccc(CN2CCC(CCNc3noc4ccccc34)CC2)cc1', 'c1ccc(CN2CCC(CNc3noc4ccccc34)CC2)cc1', 'c1ccc(CN2CCC(CNc3noc4ccccc34)CC2)cc1', 'c1ccc(CN2CCC(CNc3noc4ccccc34)CC2)cc1', 'c1ccc(CN2CCC(CNc3noc4ccccc34)CC2)cc1', 'c1ccc(CN2CCC(CNc3noc4ccccc34)CC2)cc1', 'c1ccc(CN2CCC(CNc3noc4ccccc34)CC2)cc1', 'c1ccc(CN2CCC(COc3noc4ccccc34)CC2)cc1', 'c1ccc(CN2CCC(COc3noc4ccccc34)CC2)cc1', 'c1ccc(CN2CCC(COc3noc4ccccc34)CC2)cc1', 'c1ccc(CN2CCC(COc3noc4ccccc34)CC2)cc1', 'c1ccc(CN2CCC(COc3noc4ccccc34)CC2)cc1', 'NC(=O)c1ccc2c(CCC3CCN(Cc4ccccc4)CC3)noc2c1', 'NC(=O)c1ccc2c(CCC3CCN(Cc4ccccc4)CC3)noc2c1', 'NC(=O)c1ccc2c(CCC3CCN(Cc4ccccc4)CC3)noc2c1', 'NC(=O)c1ccc2c(CCC3CCN(Cc4ccccc4)CC3)noc2c1', 'NC(=O)c1ccc2c(CCC3CCN(Cc4ccccc4)CC3)noc2c1', 'NC(=O)c1ccc2c(CCC3CCN(Cc4ccccc4)CC3)noc2c1', 'NC(=O)c1ccc2c(CCC3CCN(Cc4ccccc4)CC3)noc2c1', 'c1ccc(CN2CCC(CCCc3noc4ccccc34)CC2)cc1', 'c1ccc(CN2CCC(CCCc3noc4ccccc34)CC2)cc1', 'c1ccc(CN2CCC(CCCc3noc4ccccc34)CC2)cc1', 'c1ccc(CN2CCC(CCCc3noc4ccccc34)CC2)cc1', 'c1ccc(CN2CCC(CCCc3noc4ccccc34)CC2)cc1', 'O=C(OC1Cc2c(O)cc(O)cc2OC1c1ccc(O)c(O)c1)c1cc(O)c(O)c(O)c1', 'O=C1Cc2cc3onc(CCC4CCN(Cc5ccccc5)CC4)c3cc2N1', 'O=C1Cc2cc3onc(CCC4CCN(Cc5ccccc5)CC4)c3cc2N1', 'O=C1Cc2cc3onc(CCC4CCN(Cc5ccccc5)CC4)c3cc2N1', 'O=C1Cc2cc3onc(CCC4CCN(Cc5ccccc5)CC4)c3cc2N1', 'O=C1Cc2cc3onc(CCC4CCN(Cc5ccccc5)CC4)c3cc2N1', 'CN1C(=O)Cc2cc3c(CCC4CCN(Cc5ccccc5)CC4)noc3cc21.CS(=O)(=O)O', 'O=C1Cc2c(ccc3c(CCC4CCN(Cc5ccccc5)CC4)noc23)N1', 'O=C1Cc2c(ccc3c(CCC4CCN(Cc5ccccc5)CC4)noc23)N1', 'O=C1Cc2c(ccc3c(CCC4CCN(Cc5ccccc5)CC4)noc23)N1', 'O=C1Cc2c(ccc3c(CCC4CCN(Cc5ccccc5)CC4)noc23)N1', 'O=C1Cc2c(ccc3c(CCC4CCN(Cc5ccccc5)CC4)noc23)N1', 'CC(=O)Nc1ccc2c(CCC3CCN(Cc4ccccc4)CC3)noc2c1.O=C(O)/C=C/C(=O)O', 'O=C1CCc2cc3c(CCC4CCN(Cc5ccccc5)CC4)noc3cc2N1', 'O=C1CCc2cc3c(CCC4CCN(Cc5ccccc5)CC4)noc3cc2N1', 'O=C1CCc2cc3c(CCC4CCN(Cc5ccccc5)CC4)noc3cc2N1', 'O=C1CCc2cc3c(CCC4CCN(Cc5ccccc5)CC4)noc3cc2N1', 'O=C1CCc2cc3c(CCC4CCN(Cc5ccccc5)CC4)noc3cc2N1', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)C1N2C=O', 'CN1CC[C@]2(C)c3cc(OC(=O)Nc4ccccc4)ccc3NC12', 'CN1CC[C@@]2(C)c3cc(OC(=O)Nc4ccccc4)ccc3N(Cc3ccccc3)C12', 'CN1CC[C@@]2(C)c3cc(OC(=O)Nc4ccccc4)ccc3N(C=O)C12', 'CN1CC[C@]2(C)c3cc(OC(=O)Nc4ccccc4)ccc3N(Cc3ccccc3)C12', 'CNC(=O)Oc1ccc2c(c1)[C@@]1(C)CCN(C)C1N2Cc1ccccc1', 'CNC(=O)Oc1ccc2c(c1)[C@@]1(C)CCN(C)C1N2', 'CN(CCOCCNC(=O)Nc1ccc([N+](=O)[O-])cc1)Cc1ccccc1', 'CN(CCOCCNC(=S)NC(=O)c1ccc(-c2ccccc2)cc1)Cc1ccccc1', 'CN(CCOCCNC(=S)NC(=O)c1ccc(Cl)c(Cl)c1)Cc1ccccc1', 'CN(CCOCCNC(=S)Nc1ccc(OC(F)(F)F)cc1)Cc1ccccc1', 'CN(CCOCCNC(=S)Nc1cccc2ccccc12)Cc1ccccc1', 'CN(CCOCCNC(=S)NC1CCCCC1)Cc1ccccc1', 'CN(CCOCCNC(=S)Nc1ccc(Cl)cc1)Cc1ccccc1', 'COc1ccc(NC(=S)NCCOCCN(C)Cc2cccc([N+](=O)[O-])c2)cc1OC', 'CN(CCOCCNC(=S)NC(=O)c1cccc([N+](=O)[O-])c1)Cc1ccccc1', 'CCN(CCOCCNC(=O)NCc1ccccc1)CC1CCCCC1', 'CN(CCOCCNC(=S)NC(=O)c1ccc(Cl)cc1)Cc1ccccc1', 'COc1ccc(C(=O)NC(=S)NCCOCCN(C)Cc2ccccc2)cc1', 'Cc1ccc(C(=O)NC(=S)NCCOCCN(C)Cc2ccccc2)cc1', 'CN(CCOCCNC(=S)NC(=O)c1ccc2ccccc2c1)Cc1ccccc1', 'CN(CCOCCNC(=S)NC(=O)c1ccccc1)Cc1ccccc1', 'CN(CCOCCNC(=S)NC(=O)c1ccccc1)C1CCCCC1', 'CN(CCOCCCNC(=S)NC(=O)c1ccccc1)Cc1ccccc1', 'CC(C)CCSC(=O)OCC[N+](C)(C)C.[Cl-]', 'CC(C)CCSC(=O)OCC[N+](C)(C)C.[Cl-]', 'CCCCCCSC(=O)OCC[N+](C)(C)C.[Cl-]', 'CCCCCCSC(=O)OCC[N+](C)(C)C.[Cl-]', 'CCC(C)(C)SC(=O)OCC[N+](C)(C)C.[Cl-]', 'Nc1c2c(nc3ccccc13)CCC(O)C2', 'Nc1c2c(nc3ccccc13)CCC(O)C2', 'Nc1c2c(nc3ccccc13)CC(O)CC2', 'Nc1c2c(nc3ccccc13)CC(O)CC2', 'Nc1c2c(nc3ccccc13)C(O)CCC2', 'Nc1c2c(nc3ccccc13)C(O)CCC2', 'CCCCCSC(=O)OCC[N+](C)(C)C.[Cl-]', 'CCCCCSC(=O)OCC[N+](C)(C)C.[Cl-]', 'CCCCCSC(=O)OCC[N+](C)(C)C.[Cl-]', 'CCCCCSC(=O)OCC[N+](C)(C)C.[Cl-]', 'CCCCCCCSC(=O)OCC[N+](C)(C)C.[Cl-]', 'CCCCCCCSC(=O)OCC[N+](C)(C)C.[Cl-]', 'CCCCCCCSC(=O)OCC[N+](C)(C)C.[Cl-]', 'CC[N+](C)(C)c1cccc(O)c1.[Cl-]', 'CC[N+](C)(C)c1cccc(O)c1.[Cl-]', 'CC[N+](C)(C)c1cccc(O)c1.[Cl-]', 'CC[N+](C)(C)c1cccc(O)c1.[Cl-]', 'CC[N+](C)(C)c1cccc(O)c1.[Cl-]', 'CC[N+](C)(C)c1cccc(O)c1.[Cl-]', 'CC[N+](C)(C)c1cccc(O)c1.[Cl-]', 'CC[N+](C)(C)c1cccc(O)c1.[Cl-]', 'CC[N+](C)(C)c1cccc(O)c1.[Cl-]', 'CC[N+](C)(C)c1cccc(O)c1.[Cl-]', 'CC[N+](C)(C)c1cccc(O)c1.[Cl-]', 'CC[N+](C)(C)c1cccc(O)c1.[Cl-]', 'CCc1ccccc1SC(=O)OCC[N+](C)(C)C.[Cl-]', 'CCc1ccc(SC(=O)OCC[N+](C)(C)C)cc1.[Cl-]', '[Br-].[Br-].c1ccc2c[n+](CCCCCCCCCCC[n+]3ccc4ccccc4c3)ccc2c1', '[Br-].[Br-].c1cc[n+](CCCCCCCCC[n+]2ccccc2)cc1', '[Br-].[Br-].c1ccc2c(c1)ccc[n+]2CCCCCCCCCCCC[n+]1cccc2ccccc21', '[Br-].[Br-].c1ccc2c[n+](CCCCCCCCC[n+]3ccc4ccccc4c3)ccc2c1', '[Br-].[Br-].c1ccc2c(c1)ccc[n+]2CCCCCCCCCCC[n+]1cccc2ccccc21', 'C[N+](C)(C)CCCCCCCCCC[N+](C)(C)C.[Br-].[Br-]', '[Br-].[Br-].c1ccc2c(c1)ccc[n+]2CCCCCCCCC[n+]1cccc2ccccc21', '[Br-].[Br-].c1cc[n+](CCCCCCCCCCC[n+]2ccccc2)cc1', '[Br-].[Br-].c1cc[n+](CCCCCCCCCCC[n+]2ccccc2)cc1', '[Br-].[Br-].c1cc[n+](CCCCCCCCCCC[n+]2ccccc2)cc1', 'CN(C)Cc1ccc(CSCCNc2cc(Oc3ccc([N+](=O)[O-])cc3)c([N+](=O)[O-])cc2[N+](=O)[O-])o1', 'CN(C)Cc1ccc(CSCCNc2cc(Nc3ncccc3[N+](=O)[O-])c([N+](=O)[O-])cc2[N+](=O)[O-])o1', 'CN(C)Cc1ccc(CSCCNc2cc(N)c([N+](=O)[O-])cc2[N+](=O)[O-])o1', 'CN(C)Cc1ccc(CSCCNc2cc(Nc3ccccc3C#N)c([N+](=O)[O-])cc2[N+](=O)[O-])o1', 'CCCNc1cc(NCCSCc2ccc(CN(C)C)o2)c([N+](=O)[O-])cc1[N+](=O)[O-]', 'CNc1cc(NCCSCc2ccc(CN(C)C)o2)c([N+](=O)[O-])cc1[N+](=O)[O-]', 'CCCCCNc1cc(NCCSCc2ccc(CN(C)C)o2)c([N+](=O)[O-])cc1[N+](=O)[O-]', 'CN(C)Cc1ccc(CSCCNc2cc(Nc3ccc(F)cc3)c([N+](=O)[O-])cc2[N+](=O)[O-])o1', 'CN(C)Cc1ccc(CSCCNc2cc(NCc3ccccn3)c([N+](=O)[O-])cc2[N+](=O)[O-])o1', 'CN(C)Cc1ccc(CSCCNc2cc(NCCCN3CCOCC3)c([N+](=O)[O-])cc2[N+](=O)[O-])o1', 'CN(C)Cc1ccc(CSCCNc2cc(NCc3ccccc3)c([N+](=O)[O-])cc2[N+](=O)[O-])o1', 'CN(C)Cc1ccc(CSCCNc2cc(NCc3cccnc3)c([N+](=O)[O-])cc2[N+](=O)[O-])o1', 'CN(C)CCNc1cc(NCCSCc2ccc(CN(C)C)o2)c([N+](=O)[O-])cc1[N+](=O)[O-]', 'CN(C)Cc1ccc(CSCCNc2cc(Nc3ccccc3)c([N+](=O)[O-])cc2[N+](=O)[O-])o1', 'CC(C)=NNc1cc(NCCSCc2ccc(CN(C)C)o2)c([N+](=O)[O-])cc1[N+](=O)[O-]', 'CN(C)Cc1ccc(CSCCNc2cc(NN)c([N+](=O)[O-])cc2[N+](=O)[O-])o1', 'CN(C)Cc1ccc(CSCCNc2nnccc2[N+](=O)[O-])o1', 'CN(C)Cc1ccc(CSCCNc2ccc([N+](=O)[O-])cc2[N+](=O)[O-])o1', 'CN(C)Cc1ccc(CSCCNc2cc(F)c([N+](=O)[O-])cc2[N+](=O)[O-])o1', 'CN(C)Cc1ccc(CSCCNc2ccc(F)cc2[N+](=O)[O-])o1', 'CN(C)Cc1ccc(CSCCNc2cccc(F)c2C#N)o1', 'O=C1c2ccccc2C(=O)N1CCC1CCN(Cc2ccccc2)CC1', 'O=C1c2ccc([N+](=O)[O-])cc2C(=O)N1CC1CCN(Cc2ccccc2)CC1', 'O=C1c2ccc([N+](=O)[O-])cc2C(=O)N1CCC1CCN(Cc2ccccc2)CC1', 'O=C1c2ccc([N+](=O)[O-])cc2C(=O)N1C1CCN(Cc2ccccc2)CC1', 'Cc1c(C(C)C)c(=O)on1C(=O)N1CCC[C@H](C)C1', 'Cc1c(C)c2ccc(OCc3cccc(Cl)c3)cc2oc1=O', 'CC1=CC2Cc3nc4cccc(F)c4c(N)c3C(C1)C2', 'COc1cc(N)c(Cl)cc1C(=O)NC1CCN(Cc2ccccc2)CC1', 'COc1ccccc1CN1CCCCCC(=O)N(C)CCCCCCCCN(C)C(=O)CCCCCN(Cc2ccccc2OC)Cc2ccc(cc2)-c2ccc(cc2)C1', 'CCCCCCCCCN(Cc1ccccc1OC)C(=O)CCCCCNCc1ccc(-c2ccc(-c3ccc(CNCCCCCC(=O)NCc4ccccc4OC)cc3)cc2)cc1', 'COc1ccccc1CN(CCCCCCCCN(Cc1ccccc1OC)C(=O)CCCCCN)C(=O)CCCCCN', 'COc1ccccc1CN1CCCCCCCCN(Cc2ccccc2OC)C(=O)CCCCCNCc2ccc(cc2)-c2ccc(cc2)CNCCCCCC1=O', 'COc1ccccc1CN1CCCCCCCCN(Cc2ccccc2OC)C(=O)CCCCCNCc2cccc(c2)Cc2cccc(c2)CNCCCCCC1=O', 'COc1ccccc1CN1CCCCCCCCN(Cc2ccccc2OC)C(=O)CCCCCNCc2ccc(cc2)CNCCCCCC1=O', 'CCCCC1=NC2(CCCC2)C(=O)N1Cc1ccc(-c2ccccc2C#N)cc1', 'CCCCC1=NC2(CCCC2)C(=O)N1Cc1ccc(-c2ccccc2C(=O)OC(C)(C)C)cc1', 'CCCCC1=NC2(CCCC2)C(=O)N1Cc1ccc(-c2ccccc2C(=O)OC)cc1', 'Cc1cccc([N+](=O)[O-])c1', 'Cc1cccc([N+](=O)[O-])c1', 'Nc1c2c(nc3ccccc13)CCCCCC2', 'Nc1c2c(nc3ccccc13)CCCCC2', 'COc1ccc2c(c1)CCCc1c-2nc2ccccc2c1N', 'CCCCC1(O)c2nc3ccccc3c(N)c2CC1C', 'CCCCC1=C(C)Cc2c1nc1ccccc1c2N', 'CC1=C(C)c2nc3ccccc3c(N)c2C1', 'Nc1c2c(nc3ccccc13)-c1ccccc1NCC2', 'Nc1c2c(nc3ccccc13)CCCc1ccccc1-2', 'COc1ccc2c(c1)CCc1c-2nc2ccccc2c1N', 'NC(=O)c1cc[n+](CCCC[n+]2ccc(/C=N/O)cc2)cc1.[Br-].[Br-]', 'Nc1c2c(nc3ccccc13)C1CCC2C1', 'Nc1c2c(nc3ccccc13)C1CCC2C1', 'Nc1c2c(nc3ccccc13)C1CCC2C1', 'Nc1c2c(nc3ccccc13)CCC2', 'CCCCCCCCCCCCCCCC[n+]1ccccc1.[Br-]', 'CC(C)c1ccc(NC(=O)Oc2ccc3c(c2)[C@]2(C)CCN(C)[C@@H]2N3C)cc1.O=C(O)C(O)C(O)C(=O)O', 'CCc1ccccc1NC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C.O=C(O)C(O)C(O)C(=O)O', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C.O=C(O)c1ccccc1O', 'Cc1ccccc1NC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)O[C@@H]1N2C', 'CN1CC[C@@]2(C)c3cc(OC(=O)Nc4ccccc4)ccc3N(C)[C@@H]12.O=C(O)C(O)C(O)C(=O)O', 'CN1CC[C@@]2(C)c3cc(OC(=O)Nc4ccccc4)ccc3N(C)[C@H]2O1', 'Cc1ccccc1NC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C.O=C(O)C(O)C(O)C(=O)O', 'C[N+](C)(C)CCCCCCCCCC[N+](C)(C)C', 'NC(=O)O', 'CNC(=O)Oc1cccc(CN(C)CCCOc2ccc3c(=O)c4ccccc4oc3c2)c1', 'CNC(=O)Oc1cccc(CN(C)CCCOc2ccc3c(=O)c4ccccc4oc3c2)c1', 'CNC(=O)Oc1cccc(CN(C)CCCOc2ccc3c(=O)c4ccccc4oc3c2)c1', 'CNC(=O)Oc1cccc(CN(C)CCCOc2ccc3c(=O)c4ccccc4oc3c2)c1', 'CNC(=O)Oc1cccc(CN(C)CCCOc2ccc3c(=O)c4ccccc4oc3c2)c1', 'CNC(=O)Oc1cccc(CN(C)CCCOc2ccc3c(=O)c4ccccc4oc3c2)c1', 'CNC(=O)Oc1cccc(CN(C)CCCOc2ccc3c(=O)c4ccccc4oc3c2)c1', 'CNC(=O)Oc1cccc(CN(C)CCCCCCOc2ccc3c(=O)c4ccccc4oc3c2)c1', 'CNC(=O)Oc1cccc(CN(C)CCCCCCOc2ccc3c(=O)c4ccccc4oc3c2)c1', 'CN(CCCOc1ccc2c(=O)c3ccccc3oc2c1)Cc1cccc(OC(=O)NCCCCCCCCN2CCOCC2)c1', 'CN(CCCOc1ccc2c(=O)c3ccccc3oc2c1)Cc1cccc(OC(=O)NCCCCCCCCN2CCOCC2)c1', 'CN(CCCOc1ccc2c(=O)c3ccccc3oc2c1)Cc1cccc(OC(=O)NCCCCCCCN2CCOCC2)c1', 'CN(CCCOc1ccc2c(=O)c3ccccc3oc2c1)Cc1cccc(OC(=O)NCCCCCCCN2CCOCC2)c1', 'CN(CCCOc1ccc2c(=O)c3ccccc3oc2c1)Cc1cccc(OC(=O)NCCCCCCN2CCOCC2)c1', 'CN(CCCOc1ccc2c(=O)c3ccccc3oc2c1)Cc1cccc(OC(=O)NCCCCCCN2CCOCC2)c1', 'CNC(=O)Oc1cccc(CN(C)CCCOc2ccc(-c3ccccc3)cc2)c1', 'CNC(=O)Oc1cccc(CN(C)CCCOc2ccc(-c3ccccc3)cc2)c1', 'CN(CCCOc1ccc2c(=O)c3ccccc3oc2c1)Cc1cccc(OC(=O)NCCCCCCCCCN2CCOCC2)c1', 'CN(CCCOc1ccc2c(=O)c3ccccc3oc2c1)Cc1cccc(OC(=O)NCCCCCCCCCN2CCOCC2)c1', 'CN(CCCOc1ccc2c(=O)c3ccccc3oc2c1)Cc1cccc(OC(=O)NCCCCCCCCCN2CCOCC2)c1', 'CN(CCCOc1ccc2c(=O)c3ccccc3oc2c1)Cc1cccc(OC(=O)NCCCCCCCCCN2CCOCC2)c1', 'CC(=O)N(CCC1CCN(Cc2ccccc2)CC1)c1ccccc1', 'O=C(c1ccncc1)N(CCC1CCN(Cc2ccccc2)CC1)c1ccccc1', 'O=C(c1ccc([N+](=O)[O-])cc1)N(CCC1CCN(Cc2ccccc2)CC1)c1ccccc1', 'O=C1c2ccc([N+](=O)[O-])cc2C(=O)N1CCC1CCN(Cc2ccc(Cl)cc2)CC1', 'CC(=O)N(C)CCC1CCN(Cc2ccccc2)CC1', 'CC(=O)N(CCC1CCN(Cc2ccccc2)CC1)c1ccc(F)cc1', 'O=C1c2ccccc2CN1CCC1CCN(Cc2ccccc2)CC1', 'COc1cccc(N(CCC2CCN(Cc3ccccc3)CC2)C(C)=O)c1', 'C(=C/C1CCN(Cc2ccccc2)CC1)\\\\c1noc2ccccc12', 'C(=C/C1CCN(Cc2ccccc2)CC1)\\\\c1noc2ccccc12', 'C(=C/C1CCN(Cc2ccccc2)CC1)\\\\c1noc2ccccc12', 'OC1CCN(Cc2ccc(OCCCN3CCCCC3)cc2)CC1', 'COc1ccc2c3c([nH]c2c1)C(C)=NCC3', 'c1cc(OCCCN2CCCCC2)ccc1CN1CCCCC1', 'CCCCCCCNC(=O)Oc1cccc(CN(C)CCCOc2ccc3ccc(=O)oc3c2)c1', 'CCCCCCCNC(=O)Oc1cccc(CN(CCCOc2ccc3c(=O)c4ccccc4oc3c2)C(C)C)c1', 'CNC(=O)Oc1cccc(CN(C)CCCOc2ccc3c(=O)cc(-c4ccccc4)oc3c2)c1', 'CCCCNC(=O)Oc1cccc(CN(C)CCCOc2ccc3ccc(=O)oc3c2)c1', 'CCCCNC(=O)Oc1cccc(CN(C)CCCOc2ccc3ccc(=O)oc3c2)c1', 'CCCCCCCNC(=O)Oc1cccc(CN(C)CCCCOc2ccc3c(=O)c4ccccc4oc3c2)c1', 'CNC(=O)Oc1cccc(CN(C)CCCCOc2ccc3c(=O)c4ccccc4oc3c2)c1', 'CNC(=O)Oc1cccc(CN(C)CCCOc2ccc3ccc(=O)oc3c2)c1', 'CNC(=O)Oc1cccc(CN(C)CCCOc2ccc3ccc(=O)oc3c2)c1', 'CCCCCCCNC(=O)Oc1cccc(CN(C)CCCOc2ccc3c(=O)c4cccnc4oc3c2)c1', 'CCCCCCCNC(=O)Oc1cccc(CN(C)CCCOc2ccc3c(=O)c4cccnc4oc3c2)c1', 'CCCNC(=O)Oc1cccc(CN(C)CCCOc2ccc3c(=O)ccoc3c2)c1', 'CNC(=O)Oc1cccc(CN(C)CCCOc2ccc3c(=O)ccoc3c2)c1', 'c1ccc2c(NCCCCCCCCSc3c4c(nc5ccccc35)CCCC4)c3c(nc2c1)CCCC3', 'c1ccc2c(NCCCCCCCCSc3c4c(nc5ccccc35)CCCC4)c3c(nc2c1)CCCC3', 'c1ccc2c(NCCCCCCCCSc3c4c(nc5ccccc35)CCCC4)c3c(nc2c1)CCCC3', 'CCCCNC(=O)Oc1cccc(CN(C)CCCOc2ccc3c(=O)cc(-c4ccccc4)oc3c2)c1', 'CN(CCCOc1ccc2c(=O)c3ccccc3oc2c1)Cc1cccc(OC(=O)Nc2ccccc2)c1', 'CN(CCCOc1ccc2c(=O)c3ccccc3oc2c1)Cc1cccc(OC(=O)Nc2ccccc2)c1', 'CN(CCCNc1c2c(nc3ccccc13)CCCC2)CCCNc1c2c(nc3ccccc13)CCCC2', 'CN(CCCNc1c2c(nc3ccccc13)CCCC2)CCCNc1c2c(nc3ccccc13)CCCC2', 'CCN(CCCOc1ccc2c(=O)c3ccccc3oc2c1)Cc1cccc(OC(=O)NC)c1', 'CCN(CCCOc1ccc2c(=O)c3ccccc3oc2c1)Cc1cccc(OC(=O)NC)c1', 'CNC(=O)Oc1cccc(CN(C)CCCCCOc2ccc3c(=O)c4ccccc4oc3c2)c1', 'CCCCNC(=O)Oc1cccc(CN(CCCOc2ccc3c(=O)c4ccccc4oc3c2)C(C)C)c1', 'CCNC(=O)Oc1cccc(CN(C)CCCOc2ccc3c(=O)c4ccccc4oc3c2)c1', 'CCCN(CCCOc1ccc2c(=O)c3ccccc3oc2c1)Cc1cccc(OC(=O)NC)c1', 'CCCN(CCCOc1ccc2c(=O)c3ccccc3oc2c1)Cc1cccc(OC(=O)NC)c1', 'CCCCNC(=O)Oc1cccc(CN(C)CCCOc2ccc3c(=O)c4cccnc4oc3c2)c1', 'CNC(=O)Oc1cccc(CN(CCCOc2ccc3c(=O)c4ccccc4oc3c2)C(C)C)c1', 'CCCNC(=O)Oc1cccc(CN(C)CCCOc2ccc3c(=O)c4ccccc4oc3c2)c1', 'CCCCNC(=O)Oc1cccc(CN(CCC)CCCOc2ccc3c(=O)c4ccccc4oc3c2)c1', 'CCCCNC(=O)Oc1cccc(CN(CCC)CCCOc2ccc3c(=O)c4ccccc4oc3c2)c1', 'CCN(CC)C(C)CN1c2ccccc2Sc2ccccc21', 'CCN(CC)C(C)CN1c2ccccc2Sc2ccccc21', 'CCN(CC)C(C)CN1c2ccccc2Sc2ccccc21', 'CCN(CC)C(C)CN1c2ccccc2Sc2ccccc21', 'CCCCNC(=O)Oc1cccc(CN(CC)CCCOc2ccc3c(=O)c4ccccc4oc3c2)c1', 'CNC(=O)Oc1cccc(CN(C)CCCOc2ccc3c(=O)c4cccnc4oc3c2)c1', 'O=C1/C(=C/c2ccc[nH]2)CN(Cc2ccccc2)C/C1=C\\\\c1ccc[nH]1', 'O=C1CCN(Cc2ccccc2)C/C1=C\\\\c1cccn1C(=O)c1ccccc1', 'O=C1CCN(Cc2ccccc2)C/C1=C\\\\c1cc[nH]c1', 'O=C1CCN(Cc2ccccc2)C/C1=C\\\\c1ccc[nH]1', 'CCCCNC(=O)Oc1cccc(CN(C)CCCOc2ccc3c(=O)c4ccccc4oc3c2)c1', 'O=C1CCN(Cc2ccccc2)C/C1=C\\\\c1cn(C(=O)c2ccc(F)cc2)c2ccccc12', 'COc1ccc2c(c1)c(/C=C1\\\\CN(Cc3ccccc3)CCC1=O)cn2C(=O)c1ccccc1', 'O=C1CCN(Cc2ccccc2)C/C1=C\\\\c1c[nH]c2ccccc12', 'O=C1CCN(Cc2ccccc2)C/C1=C\\\\c1c[nH]c2ccc(OCc3ccccc3)cc12', 'COc1ccc2[nH]cc(/C=C3\\\\CN(Cc4ccccc4)CCC3=O)c2c1', 'N#Cc1ccc(C(=O)n2cc(/C=C3\\\\CN(Cc4ccccc4)CCC3=O)c3ccccc32)cc1', 'CC(=O)n1cc(/C=C2\\\\CN(Cc3ccccc3)CCC2=O)c2ccccc21', 'O=C1CCN(Cc2ccccc2)C/C1=C\\\\c1cn(C(=O)c2ccc([N+](=O)[O-])cc2)c2ccccc12', 'CC(C)(C)OC(=O)n1cc(/C=C2\\\\CN(Cc3ccccc3)CCC2=O)c2ccccc21', 'O=C1CCN(Cc2ccccc2)C/C1=C\\\\c1cn(C(=O)c2ccccc2)c2ccccc12', 'Cc1[nH]c(C)c(/C=C2\\\\CN(Cc3ccccc3)CCC2=O)c1C=O', 'O=C1/C(=C/c2cc[nH]c2)CN(Cc2ccccc2)C/C1=C\\\\c1cc[nH]c1', 'O=C1CCN(Cc2ccccc2)C/C1=C\\\\c1ccn(C(=O)c2ccccc2)c1', 'COc1ccc(C(=O)n2cc(/C=C3\\\\CN(Cc4ccccc4)CCC3=O)c3ccccc32)cc1', 'O=C1CCN(Cc2ccccc2)C/C1=C\\\\c1cn(C(=O)c2ccc(Cl)cc2)c2ccccc12', 'CCc1ccccc1NC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'CCc1ccccc1NC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'Cc1ccc(NC(=O)Oc2ccc3c(c2)[C@]2(C)CCN(C)[C@@H]2N3C)cc1', 'CCc1cccc(CC)c1NC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'CCc1cccc(CC)c1NC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'Cc1cccc(NC(=O)Oc2ccc3c(c2)[C@]2(C)CCN(C)[C@@H]2N3C)c1C', 'Cc1cccc(C)c1NC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'Cc1ccc(C)c(NC(=O)Oc2ccc3c(c2)[C@]2(C)CCN(C)[C@@H]2N3C)c1', 'Cc1ccc(C)c(NC(=O)Oc2ccc3c(c2)[C@]2(C)CCN(C)[C@@H]2N3C)c1', 'CN(C(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C)c1ccccc1', 'CN(C(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C)c1ccccc1', 'Cc1cccc(NC(=O)Oc2ccc3c(c2)[C@]2(C)CCN(C)[C@@H]2N3C)c1', 'CC(C)c1ccccc1NC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'CC(C)c1ccccc1NC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'CN(C)Cc1cc2c(cc1OC(=O)Nc1ccccc1)[C@]1(C)CCN(C)[C@@H]1N2C', 'CN(C)Cc1cc2c(cc1OC(=O)Nc1ccccc1)[C@]1(C)CCN(C)[C@@H]1N2C', 'Cc1cc(C)c(NC(=O)Oc2ccc3c(c2)[C@]2(C)CCN(C)[C@@H]2N3C)c(C)c1', 'Cc1ccccc1NC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'Cc1ccccc1NC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'Cc1ccccc1NC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'Cc1ccccc1NC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'Cc1cc2c(cc1OC(=O)Nc1ccccc1)[C@]1(C)CCN(C)[C@@H]1N2C', 'Cc1cc(C)cc(NC(=O)Oc2ccc3c(c2)[C@]2(C)CCN(C)[C@@H]2N3C)c1', 'Cc1cc(C)cc(NC(=O)Oc2ccc3c(c2)[C@]2(C)CCN(C)[C@@H]2N3C)c1', 'Cc1ccc(NC(=O)Oc2ccc3c(c2)[C@]2(C)CCN(C)[C@@H]2N3C)cc1C', 'CC(C)c1ccc(NC(=O)Oc2ccc3c(c2)[C@]2(C)CCN(C)[C@@H]2N3C)cc1', 'CC(C)c1ccc(NC(=O)Oc2ccc3c(c2)[C@]2(C)CCN(C)[C@@H]2N3C)cc1', 'CC(C)c1ccc(NC(=O)Oc2ccc3c(c2)[C@]2(C)CCN(C)[C@@H]2N3C)cc1', 'CC(C)c1ccc(NC(=O)Oc2ccc3c(c2)[C@]2(C)CCN(C)[C@@H]2N3C)cc1', 'CC(C)c1ccc(NC(=O)Oc2ccc3c(c2)[C@]2(C)CCN(C)[C@@H]2N3C)cc1', 'CC(C)c1ccc(NC(=O)Oc2ccc3c(c2)[C@]2(C)CCN(C)[C@@H]2N3C)cc1', 'Cc1ccc(NC(=O)Oc2ccc3c(c2)[C@]2(C)CCN(C)[C@@H]2N3C)c(C)c1', 'CSc1nc(-c2ccc(Cl)cc2)nn1C(=O)N(C)C', 'COc1ccc(-c2nc(SC)n(C(=O)N(C)C)n2)cc1', 'CCCCCCSc1nc(-c2ccc(C)cc2)nn1C(=O)N(C)C', 'CSc1nc(-c2ccc(Cl)cc2)nn1C(=O)N(C)c1ccccc1', 'O=C(N1CCCCC1)n1nc(-c2ccc(Cl)cc2)nc1SCC1CC1', 'O=C(N1CCCCC1)n1nc(-c2ccc(Cl)cc2)nc1SCC(F)(F)F', 'CSc1nc(-c2ccc(Cl)cc2)nn1C(=O)N1CCCCC1', 'CSc1nc(-c2ccc(C)cc2)nn1C(=O)N(C)c1ccccc1', 'CSc1nc(-c2ccc(OC(F)(F)F)cc2)nn1C(=O)N(C)C', 'CSc1nc(-c2ccc(-c3ccccc3)cc2)nn1C(=O)N(C)C', 'Cc1ccc(-c2nc(SCC(F)(F)F)n(C(=O)N(C)C)n2)cc1', 'CCSc1nc(-c2ccc(Cl)cc2)nn1C(=O)N(C)C', 'CCCSc1nc(-c2ccc(Cl)cc2)nn1C(=O)N(C)C', 'CSc1nc(-c2ccc(C(F)(F)F)cc2)nn1C(=O)N(C)C', 'CCOc1nn(-c2cccc(OCc3ccccc3)c2)c(=O)o1', 'CSc1nc(-c2ccc3ccccc3c2)nn1C(=O)N(C)C', 'CCSc1nc(-c2ccc(OC)cc2)nn1C(=O)N(C)c1ccccc1', 'CSc1nc(-c2ccc(C)cc2)nn1C(=O)N(C)C', 'Nc1c2c(nc3cnccc13)OCCC2', 'Nc1c2c(nc3cnccc13)OCCC2', 'Nc1c2c(nc3cnccc13)CCCC2', 'Nc1c2c(nc3cccc(Cl)c13)OCCC2', 'Nc1c2c(nc3cccc(Cl)c13)CCCC2', 'Nc1c2c(nc3cccc(Cl)c13)CCCC2', 'Nc1c2c(nc3cccc(Cl)c13)CCCC2', 'Nc1c2c(nc3cccc(F)c13)CCCC2', 'Nc1c2c(nc3cccc(F)c13)CCCC2', 'Nc1c2c(nc3ccccc13)OCCC2', 'Nc1c2c(nc3ccccc13)OCCC2', 'COc1cccc2nc3c(c(N)c12)CCCO3', 'Nc1c2c(nc3ncccc13)OCCC2', 'Nc1c2c(nc3ncccc13)OCCC2', 'Nc1c2c(nc3ncccc13)CCCC2', 'COc1cccc2nc3c(c(N)c12)CCCC3', 'COc1cccc2nc3c(c(N)c12)CCCC3', 'Cc1cccc2nc3c(c(N)c12)CCCO3', 'Cc1cccc2nc3c(c(N)c12)CCCC3', 'Nc1c2c(nc3c1CCCO3)CCCC2', 'Nc1c2c(nc3cccc(F)c13)OCCC2', 'Nc1c2c(nc3ccc(Cl)cc13)OCCC2', 'Nc1c2c(nc3ccc(Cl)cc13)OCCC2', 'Nc1c2c(nc3c1CCCC3)CCCC2', 'Nc1c2c(nc3c1CCCO3)CCC2', 'COc1ccccc1CNCCCCCC(=O)NCCCCCCCCNC(=O)CCCCCNCc1ccccc1OC', 'COc1ccccc1CNCCCCCC(=O)N(C)CCCCCCCCN(C)C(=O)CCCCCNCc1ccccc1OC', 'COc1ccccc1CNCCCCCCNCCCCCNCCCCCCNCc1ccccc1OC', 'COc1ccccc1CNCCCCCCNCCCCCCCNCCCCCCNCc1ccccc1OC', 'O=C(O)CCCC[C@@H]1CCSS1', 'CCC(=O)Oc1cccc([N+](C)(C)C)c1', 'CC(=O)Oc1ccc(C)c([N+](C)(C)C)c1', 'C=CC[N+](C)(C)c1ccc(CCC(=O)CCc2ccc([N+](C)(C)CC=C)cc2)cc1', 'C=CC[N+](C)(C)c1ccc(CCC(=O)CCc2ccc([N+](C)(C)CC=C)cc2)cc1', 'CCC(=O)Oc1ccc(C)c([N+](C)(C)C)c1', 'CCC(=O)Oc1cc([N+](C)(C)C)ccc1C', 'CC(=O)Oc1cc([N+](C)(C)C)ccc1C', 'CC(=O)Oc1cccc([N+](C)(C)C)c1C', 'CC(=O)Oc1cccc([N+](C)(C)C)c1', 'Cc1ccc([N+](C)(C)C)cc1O', 'Cc1ccc(O)cc1[N+](C)(C)C', 'C[N+](C)(C)CCCBr', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CC[N+](C)(C)C1N2C', 'C[C@@H]([C@H]1CC[C@H]2[C@@H]3CC[C@H]4C(=O)C(NC(=O)c5ccccc5)=CC[C@]4(C)[C@H]3CC[C@]12C)N(C)C', 'C[C@@H]([C@H]1CC[C@H]2[C@@H]3CC[C@H]4C[C@@H](NC(=O)c5ccccc5)CC[C@]4(C)[C@H]3CC[C@]12C)N(C)C', 'CC(=O)N(C)[C@@H](C)[C@H]1CC[C@H]2[C@@H]3CC=C4C[C@@H](N(C)C)CC[C@]4(C)[C@H]3CC[C@]12C', 'CC(=O)CCC[N+](C)(C)C', 'C/C(=C\\\\C(=O)N(C)[C@H]1CC[C@@]2(C)[C@@H](CC[C@@H]3[C@@H]2CC[C@]2(C)C([C@H](C)N(C)C)=CC[C@@H]32)C1)C(C)C', 'C[N+](C)(C)c1cccc(O)c1', 'C/C(=C\\\\C(=O)N(C)[C@H]1CC[C@@]2(C)[C@@H](CC[C@@H]3[C@@H]2CC[C@]2(C)[C@@H]([C@H](C)N(C)C)CC[C@@H]32)C1)C(C)C', 'C[C@@H]([C@H]1CC[C@H]2[C@@H]3CC[C@H]4C[C@@H](N(C)C(=O)/C=C/c5ccccc5)CC[C@]4(C)[C@H]3CC[C@]12C)N(C)C', 'C/C=C(\\\\C)C(=O)N[C@@H]1[C@H](OC(C)=O)[C@@H]2CC[C@H]3C4=CC[C@H]([C@H](C)N(C)C)[C@@]4(C)CC[C@@H]3[C@@]2(C)C[C@@H]1O', 'C[C@@H]([C@H]1CC[C@H]2[C@@H]3CC[C@H]4C[C@@H](NC(=O)c5ccccc5)[C@@H](O)C[C@]4(C)[C@H]3CC[C@]12C)N(C)C', 'C/C=C(\\\\C)C(=O)N[C@H]1CC[C@@]2(C)C(=CC[C@H]3[C@@H]4CC[C@H]([C@H](C)N(C)C)[C@@]4(C)CC[C@@H]32)C1=O', 'CN[C@H]1CC[C@@]2(C)C(CC[C@H]3[C@@H]4CC[C@H]([C@H](C)N(C)C)[C@@]4(C)CC[C@@H]32)C1', 'C/C=C(\\\\C)C(=O)N[C@H]1CC[C@@]2(C)C(=CC[C@H]3C4=CC[C@H]([C@H](C)N(C)C)[C@@]4(C)CC[C@@H]32)C1=O', 'C/C=C(\\\\C)C(=O)N[C@H]1C(OC(C)=O)C[C@@]2(C)C(CC[C@H]3C4CC=C([C@H](C)N(C)C)[C@@]4(C)CC[C@@H]32)[C@H]1OC(C)=O', 'C/C=C(\\\\C)C(=O)N[C@@H]1C=C2CC[C@H]3[C@@H]4CC[C@H]([C@H](C)N(C)C)[C@@]4(C)CC[C@@H]3[C@@]2(C)C[C@@H]1O', 'CN[C@H]1CC[C@@]2(C)[C@@H](CC[C@@H]3[C@@H]2CC[C@]2(C)C([C@H](C)N(C)C)=CC[C@@H]32)C1', 'CN[C@@H](C)C1=CC[C@H]2[C@@H]3CC=C4C[C@@H](OC)CC[C@]4(C)[C@H]3CC[C@]12C', 'CC(=O)N[C@H]1CC[C@@]2(C)[C@@H](CC[C@@H]3[C@@H]2CC[C@]2(C)[C@@H]([C@H](C)N(C)C)CC[C@@H]32)C1', 'C/C=C(\\\\C)C(=O)N[C@@H]1C=C2CC[C@H]3C4=CC[C@H]([C@H](C)N(C)C)[C@@]4(C)CC[C@@H]3[C@@]2(C)CC1', 'C/C=C(\\\\C)C(=O)N[C@@H]1[C@H](O)C2CC[C@H]3C4=CC[C@H]([C@H](C)N(C)C)[C@@]4(C)CC[C@@H]3[C@@]2(C)C[C@@H]1O', 'CO[C@H]1CC[C@@]2(C)C(=CC[C@H]3[C@@H]4CC[C@H]([C@H](C)N(C)C)[C@@]4(C)CC[C@@H]32)C1', 'C[C@@H]([C@H]1CC[C@H]2[C@@H]3CC=C4C[C@@H](N(C)C)CC[C@]4(C)[C@H]3CC[C@]12C)N(C)C', 'CC(=O)N(C)[C@H]1CC[C@@]2(C)[C@@H](CC[C@@H]3[C@@H]2CC[C@]2(C)[C@@H]([C@H](C)N(C)C)CC[C@@H]32)C1', 'CO[C@H]1CC[C@@]2(C)C(=CC[C@@H]3[C@@H]2CC[C@]2(C)C([C@H](C)N(C)C=O)=CC[C@@H]32)C1', 'CC(=O)N(C)[C@@H](C)[C@H]1CC[C@H]2[C@@H]3CC[C@H]4C[C@@H](N(C)C)CC[C@]4(C)[C@H]3CC[C@]12C', 'C/C=C(\\\\C)C(=O)NC1=CC[C@@]2(C)[C@@H](CC[C@H]3C4CC[C@H]([C@H](C)N(C)C)[C@@]4(C)CC[C@@H]32)C1=O', 'CC(=O)O[C@@H]1C2CC[C@H]3C4CC=C([C@H](C)N(C)C)[C@@]4(C)CC[C@@H]3[C@@]2(C)CC[C@@H]1NC(=O)C=C(C)C', 'C[C@H](NC=O)[C@H]1CC[C@H]2[C@@H]3CC[C@H]4C[C@@H](N(C)C)CC[C@]4(C)[C@H]3CC[C@]12C', 'CN1CCC(CCN2C(=O)c3ccc([N+](=O)[O-])cc3C2=O)CC1', 'O=C1c2cccc([N+](=O)[O-])c2C(=O)N1CCC1CCN(Cc2ccccc2)CC1', 'O=C(c1ccccc1)c1ccc2c(c1)C(=O)N(CCC1CCN(Cc3ccccc3)CC1)C2=O', 'COc1ccc(CN2CCC(CCN3C(=O)c4ccc([N+](=O)[O-])cc4C3=O)CC2)cc1', 'O=C(C1CCCCC1)N(CCC1CCN(Cc2ccccc2)CC1)c1ccccc1', 'COc1ccc2c(c1)C(=O)N(CCC1CCN(Cc3ccccc3)CC1)C2=O', 'O=C(Nc1cccc2c1C(=O)N(CCC1CCN(Cc3ccccc3)CC1)C2=O)c1ccccc1', 'O=C(Nc1ccc2c(c1)C(=O)N(CCC1CCN(Cc3ccccc3)CC1)C2=O)c1ccccc1', 'CC(=O)Nc1ccc2c(c1)C(=O)N(CCC1CCN(Cc3ccccc3)CC1)C2=O', 'Nc1cccc2c1C(=O)N(CCC1CCN(Cc3ccccc3)CC1)C2=O', 'Nc1ccc2c(c1)C(=O)N(CCC1CCN(Cc3ccccc3)CC1)C2=O', 'O=c1[nH]c2cc(Cl)ccc2c(=O)n1CCC1CCN(Cc2ccccc2)CC1', 'O=C1CCCCN1CCC1CCN(Cc2ccccc2)CC1', 'O=c1c2ccccc2ccn1CCC1CCN(Cc2ccccc2)CC1', 'O=C1Nc2ccccc2CN1CCC1CCN(Cc2ccccc2)CC1', 'CC(=O)N(CCC1CCN(Cc2ccccc2)CC1)c1cccc(F)c1', 'COc1ccc(N(CCC2CCN(Cc3ccccc3)CC2)C(C)=O)cc1', 'CCC(=O)N(CCC1CCN(Cc2ccccc2)CC1)c1ccccc1', 'O=c1c2ccccc2ncn1CCC1CCN(Cc2ccccc2)CC1', 'O=C1Cc2ccccc2CN1CCC1CCN(Cc2ccccc2)CC1', 'O=c1[nH]c2ccccc2c(=O)n1CCC1CCN(Cc2ccccc2)CC1', 'O=C1c2ccccc2NCN1CCC1CCN(Cc2ccccc2)CC1', 'O=C1Cc2ccccc2C(=O)N1CCC1CCN(Cc2ccccc2)CC1', 'c1ccc(CN2CCC(CCN3CCc4ccccc4C3)CC2)cc1', 'O=C1c2ccccc2CCN1CCC1CCN(Cc2ccccc2)CC1', 'CC(=O)N(CCC1CCN(Cc2ccccc2)CC1)c1ccncc1', 'CCN(CCC1CCN(Cc2ccccc2)CC1)c1ccccc1', 'O=C1c2cccnc2C(=O)N1CCC1CCN(Cc2ccccc2)CC1', 'COc1ccc(C(=O)N(CCC2CCN(Cc3ccccc3)CC2)c2ccccc2)cc1', 'O=C(c1ccc(F)cc1)N(CCC1CCN(Cc2ccccc2)CC1)c1ccccc1', 'CCC1=CC2Cc3nc4cc(F)ccc4c(N)c3C(C1)C2', 'CCC1=CC2Cc3nc4cc(F)ccc4c(N)c3C(C1)C2', 'CCC1=CC2Cc3nc4cc(F)ccc4c(N)c3C(C1)C2', 'CCC1=CC2Cc3nc4cc(F)ccc4c(N)c3C(C1)C2', 'CC1=CC2Cc3nc4cc(F)cc(F)c4c(N)c3C(C1)C2', 'CCC1=CC2Cc3nc4cc(Cl)ccc4c(N)c3C(C1)C2', 'CCC1=CC2Cc3nc4ccc(Cl)cc4c(N)c3C(C1)C2', 'CCC1=CC2Cc3nc4cccc(Cl)c4c(N)c3C(C1)C2', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(N)c3C(C1)C2', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(N)c3C(C1)C2', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(N)c3C(C1)C2', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(N)c3C(C1)C2', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(N)c3C(C1)C2', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(N)c3C(C1)C2', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(N)c3C(C1)C2', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(N)c3C(C1)C2', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(N)c3C(C1)C2', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(N)c3C(C1)C2', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(N)c3C(C1)C2', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(N)c3C(C1)C2', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(N)c3C(C1)C2', 'CCC1=CC2Cc3nc4cccc(F)c4c(N)c3C(C1)C2', 'CCC1=CC2Cc3nc4cc(C)cc(C)c4c(N)c3C(C1)C2', 'CCC1=CC2Cc3nc4cc(F)cc(F)c4c(N)c3C(C1)C2', 'CCC1=CC2Cc3nc4cc(Cl)cc(Cl)c4c(N)c3C(C1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3[N+](=O)[O-])CC1)C2', 'Clc1ccc(CO/N=C(\\\\Cn2ccnc2)c2ccc(Cl)cc2Cl)c(Cl)c1', 'CC1CCN(CCc2ccccc2)CC1', 'CCCCCCNC(=O)Oc1ccc2c(c1)[C@@]1(C)CCN(CC)[C@H]1C2', 'Cn1cc[n+](COC[n+]2ccn(C)c2/C=N/O)c1/C=N/O', 'Cn1cc[n+](COCC2CCCc3ccccc32)c1/C=N/O.[Cl-]', 'CCC(OC[n+]1ccn(C)c1/C=N/O)C(C)(C)C.[Cl-]', 'CCCCCCOC[n+]1ccn(C)c1/C=N/O.[Cl-]', 'CC(CC(C)(C)C)OC[n+]1ccn(C)c1/C=N/O.[Cl-]', 'CC(OC[n+]1ccn(C)c1/C=N/O)C1CCCCC1.[Cl-]', 'Cn1cc[n+](COCC2CCCCC2)c1/C=N/O.[Cl-]', 'Cc1n(C)cc[n+]1COC(C)C(C)(C)C.[Cl-]', 'C#CC(C)C(C)OC[n+]1ccn(C)c1/C=N/O.[Cl-]', 'C#CCCCOC[n+]1ccn(C)c1/C=N/O.[Cl-]', 'C#CCC(CCC)OC[n+]1ccn(C)c1/C=N/O.[Cl-]', 'C#CC(CC)OC[n+]1ccn(C)c1/C=N/O.[Cl-]', 'C#CCCOC[n+]1ccn(C)c1/C=N/O.[Cl-]', 'C#CC(CCC)OC[n+]1ccn(C)c1/C=N/O.[Cl-]', 'CC#CCCOC[n+]1ccn(C)c1/C=N/O.[Cl-]', 'C#CC(C)(C)OC[n+]1ccn(C)c1/C=N/O.[Cl-]', 'C#CC(C)OC[n+]1ccn(C)c1/C=N/O.[Cl-]', 'C#CCCOC[n+]1ccc(/C=N/O)cc1.[Cl-]', 'C#CCCCC[n+]1cn(C)c(/C=N/O)n1.[Cl-]', 'C#CCCCC[n+]1ccn(C(C)(C)C)c1/C=N/O.[Cl-]', 'C#CC1(OC[n+]2ccn(C)c2/C=N/O)CCCC1.[Cl-]', 'C#CC1CCCCC1OC[n+]1ccn(C)c1/C=N/O.[Cl-]', 'C#CCC(C)OC[n+]1ccn(C)c1/C=N/O.[Cl-]', 'C#CCOC[n+]1ccn(C)c1/C=N/O.[Cl-]', 'C#CCCCC[n+]1ccccc1/C=N/O.[Cl-]', 'C#CCCCC[n+]1ccn(C)c1/C=N/O.[Cl-]', 'C#CCCOC[n+]1ccn(C)c1C.[Cl-]', 'C#CCN(C)C(C)Cc1cccc(OC(=O)N(C)C2CCCCC2)c1', 'C#CCN(C)C(C)Cc1cccc(OC(=O)N(C)CCCCCC)c1', 'C#CCN(C)C(C)Cc1cccc(OC(=O)N(C)CCCCCC)c1', 'C#CCN(C)C(C)Cc1cccc(OC(=O)N(C)CCCCCC)c1', 'C#CCN(C)C(C)Cc1cccc(OC(=O)N(C)CCCCCC)c1', 'C#CCN(C)C(C)Cc1cccc(OC(=O)N(C)CCCCCC)c1', 'C#CCN(C)C(C)Cc1cccc(OC(=O)N(C)CCC)c1', 'C#CC(C)NC1CCc2ccc(SC(=O)N(C)C)cc21', 'C#CCNC1CCc2ccc(OC(=O)N(C)C)cc2C1', 'C#CCC1CCCc2ccc(OC(=O)N(C)CC)cc21', 'C#CCC1CCCc2ccc(OC(=O)N(C)C)cc21', 'CCN(C)C(=O)Oc1ccc2c(c1)CC(N)CC2', 'CN(C)CCc1cccc(OC(=O)N(C)C)c1', 'CCN(C)C(=O)Oc1cccc(CCNC)c1', 'CC(c1cccc(OC(=O)N(C)C)c1)N(C)C', 'C#CCNC(C)Cc1cccc(OC(=O)N(C)CCC)c1', 'C#CCNC(C)Cc1cccc(OC(=O)N(C)CC)c1', 'C#CCNC(C)Cc1cccc(OC(=O)N(C)C)c1', 'C#CCN(C)CCc1cccc(OC(=O)N(C)CC)c1', 'CCN(C)C(=O)Oc1cccc(CCN)c1', 'CN(C)C(=O)Oc1ccc2c(c1)CC(N)CC2', 'CCN(C)C(=O)Oc1ccc2c(c1)C(N)CCC2', 'CN(C)C(=O)Oc1ccc2c(c1)C(N)CCC2', 'CN(C)C(=O)Oc1cccc(CCN)c1', 'CNCCc1cccc(OC(=O)N(C)C)c1', 'C#CCNC(C)Cc1cccc(OC(=O)N(C)C2CCCCC2)c1', 'C#CCN(C)C(C)Cc1cccc(OC(=O)N(C)C)c1', 'C#CCNC(C)Cc1cccc(OC(=O)N(C)CCCC)c1', 'CCCN(C)C(=O)Oc1cccc(CCN)c1', 'CCN(C)C(=O)Oc1cccc(C(C)N(C)C)c1', 'C#CCNCCc1cccc(OC(=O)N(C)C)c1', 'C#CC(C)NCCc1cccc(OC(=O)N(C)CC)c1', 'C#CCN(C)CCc1cccc(OC(=O)N(C)C)c1', 'C#CCNCCc1cccc(OC(=O)N(C)CCC)c1', 'C#CCNCCc1cccc(OC(=O)N(C)CC)c1', 'C#CC(C)NCCc1cccc(OC(=O)N(C)C)c1', 'Cc1cc(-c2ccc(Cl)cc2)nnc1NCCN1CCOCC1', 'CN(C)Cc1ccc(CNCCN2CCNC2=C(C#N)C#N)o1', 'N#CC(C#N)=C1NCCN1CCNCc1ccc(CN2CCCCC2)o1', 'CC1CCN(Cc2ccc(CNCCN3CCNC3=C(C#N)C#N)o2)CC1', 'N#CC(C#N)=C1NCCN1CCNCc1ccc(CN2CCC(O)CC2)o1', 'CC1CCCCN1Cc1ccc(CNCCN2CCNC2=C(C#N)C#N)o1', 'Oc1nc2ccccc2n1CCNCc1ccc(CN2CCCCC2)o1', 'CC1CCCC(C)N1Cc1ccc(CNCCN2CCNC2=C(C#N)C#N)o1', 'COc1cc(N)c(Cl)cc1C(=O)NCCNCc1ccc(CN(C)C)o1', 'N#CC(C#N)=C1NCCN1CCNCc1ccc(CN2CCOCC2)o1', 'N#CC(C#N)=C1NCCN1CCNCc1ccc(CN2CCCC(O)C2)o1', 'CNC(NCCNCc1ccc(CN(C(C)C)C(C)C)o1)=C(C#N)C#N', 'CNC(NCCNCc1ccc(CN(C)C)o1)=C(C#N)C#N', 'CC1CCCN(Cc2ccc(CNCCN3CCNC3=C(C#N)C#N)o2)C1', 'C/N=c1\\\\c(O)c(O)\\\\c1=N/CCNCc1ccc(CN2CCCCC2)o1', 'CNC(NCCNCc1ccc(CN2CCCC2)o1)=C(C#N)C#N', 'CN1CCN(Cc2ccc(CNCCN3CCNC3=C(C#N)C#N)o2)CC1', 'N#CC(C#N)=C1NCCN1CCNCc1ccc(CN2CCCC2)o1', 'N#CC(C#N)=C1NCCN1CCNCc1ccc(CN2CCSCC2)o1', 'CC1Cc2ccccc2C1=O', 'CC1Cc2ccccc2C1=O', 'Cc1cccc(F)c1', 'Cc1cccc(F)c1', 'CC1Cc2ccc(F)cc2C1=O', 'CC1Cc2ccc(F)cc2C1=O', 'COc1ccc(C)cc1', 'COc1ccc(C)cc1', 'COc1cccc(C)c1', 'COc1cccc(C)c1', 'Cc1ccc([N+](=O)[O-])cc1', 'Cc1ccc([N+](=O)[O-])cc1', 'COc1cc2c(cc1O)CC(C)C2=O', 'COc1cc2c(cc1O)CC(C)C2=O', 'Cc1ccc(F)cc1', 'Cc1ccc(F)cc1', 'CCOc1cc2c(cc1OCC)C(=O)C(C)C2', 'CCOc1cc2c(cc1OCC)C(=O)C(C)C2', 'Cc1cccc2c1CC(C)C2=O', 'Cc1cccc2c1CC(C)C2=O', 'COc1cc2c(cc1O)C(=O)C(C)C2', 'COc1cc2c(cc1O)C(=O)C(C)C2', 'COc1cc2c(cc1OC)C(=O)C(C)C2', 'COc1cc2c(cc1OC)C(=O)C(C)C2', 'N#CC(C#N)=C1Nc2ccccc2N1CCNCc1ccc(CN2CCCCC2)o1', 'CCN(C)Cc1ccc(CNCCN2CCNC2=C(C#N)C#N)o1', 'COc1cc(C)cc(OC)c1OC', 'COc1cc(C)cc(OC)c1OC', 'COc1ccc(OC)c2c1CC(C)C2=O', 'COc1ccc(OC)c2c1CC(C)C2=O', 'CC1Cc2cc3c(cc2C1=O)OCO3', 'CC1Cc2cc3c(cc2C1=O)OCO3', 'COc1cc2c(cc1OC(C)C)CC(C)C2=O', 'COc1cc2c(cc1OC(C)C)CC(C)C2=O', 'COc1ccc2c(c1OC)C(=O)C(C)C2', 'COc1ccc2c(c1OC)C(=O)C(C)C2', 'COc1ccc2c(c1)C(=O)C(C)C2', 'COc1ccc2c(c1)C(=O)C(C)C2', 'Cc1ccccc1F', 'Cc1ccccc1F', 'COc1ccc2c(c1OC)CC(C)C2=O', 'COc1ccc2c(c1OC)CC(C)C2=O', 'COc1cc2c(c(OC)c1OC)C(=O)C(C)C2', 'COc1cc2c(c(OC)c1OC)C(=O)C(C)C2', 'COc1cccc2c1CC(C)C2=O', 'COc1cccc2c1CC(C)C2=O', 'Cc1ccc2c(c1)C(=O)C(C)C2', 'Cc1ccc2c(c1)C(=O)C(C)C2', 'COc1cc2c(c(OC)c1)C(=O)C(C)C2', 'COc1cc2c(c(OC)c1)C(=O)C(C)C2', 'C=CC(=O)N1C/C(=C\\\\c2ccc(F)cc2)C(=O)/C(=C/c2ccc(F)cc2)C1', 'C=CC(=O)N1C/C(=C\\\\c2ccc(F)cc2)C(=O)/C(=C/c2ccc(F)cc2)C1', 'C=CC(=O)N1C/C(=C\\\\c2ccc(Cl)cc2)C(=O)/C(=C/c2ccc(Cl)cc2)C1', 'C=CC(=O)N1C/C(=C\\\\c2ccc(Cl)cc2)C(=O)/C(=C/c2ccc(Cl)cc2)C1', 'CC[N+](C)(CC)CCC[n+]1c(-c2ccccc2)c2cc(N)ccc2c2ccc(N)cc21.[I-].[I-]', 'CC[N+](C)(CC)CCC[n+]1c(-c2ccccc2)c2cc(N)ccc2c2ccc(N)cc21.[I-].[I-]', 'CC[N+](C)(CC)CCC[n+]1c(-c2ccccc2)c2cc(N)ccc2c2ccc(N)cc21.[I-].[I-]', 'CC[N+](C)(CC)CCC[n+]1c(-c2ccccc2)c2cc(N)ccc2c2ccc(N)cc21.[I-].[I-]', 'CC[N+](C)(CC)CCC[n+]1c(-c2ccccc2)c2cc(N)ccc2c2ccc(N)cc21.[I-].[I-]', 'CC[N+](C)(CC)CCC[n+]1c(-c2ccccc2)c2cc(N)ccc2c2ccc(N)cc21.[I-].[I-]', 'CC[N+](C)(CC)CCC[n+]1c(-c2ccccc2)c2cc(N)ccc2c2ccc(N)cc21.[I-].[I-]', 'CC[N+](C)(CC)CCC[n+]1c(-c2ccccc2)c2cc(N)ccc2c2ccc(N)cc21.[I-].[I-]', 'CC[N+](C)(CC)CCC[n+]1c(-c2ccccc2)c2cc(N)ccc2c2ccc(N)cc21.[I-].[I-]', 'CC[N+](C)(CC)CCC[n+]1c(-c2ccccc2)c2cc(N)ccc2c2ccc(N)cc21.[I-].[I-]', 'CC[N+](C)(CC)CCC[n+]1c(-c2ccccc2)c2cc(N)ccc2c2ccc(N)cc21.[I-].[I-]', 'CC[N+](C)(CC)CCC[n+]1c(-c2ccccc2)c2cc(N)ccc2c2ccc(N)cc21.[I-].[I-]', 'CC[N+](C)(CC)CCC[n+]1c(-c2ccccc2)c2cc(N)ccc2c2ccc(N)cc21.[I-].[I-]', 'CC[N+](C)(CC)CCC[n+]1c(-c2ccccc2)c2cc(N)ccc2c2ccc(N)cc21.[I-].[I-]', 'C=CC(=O)N1C/C(=C\\\\c2ccccc2)C(=O)/C(=C/c2ccccc2)C1', 'C=CC(=O)N1C/C(=C\\\\c2ccccc2)C(=O)/C(=C/c2ccccc2)C1', 'CC1CCN(CC2Cc3ccccc3C2=O)CC1', 'CN1CCC(CCCC2Cc3ccccc3C2=O)CC1', 'CN1CCC(CC2=Cc3ccccc3C2)CC1', 'CC1CCN(C(=O)c2ccccc2)CC1', 'Cc1ccccc1CN1CCC(C)CC1', 'CC1CCN(Cc2ccccc2)CC1', 'CN1CCC(CC/C=C2\\\\Cc3ccccc3C2=O)CC1', 'CN1CCN(CC2Cc3ccccc3C2=O)CC1', 'CN1CCC(C2Cc3ccccc3C2=O)CC1', 'CN1CCC(=C2Cc3ccccc3C2=O)CC1', 'CN1CCC(/C=C2\\\\Cc3ccccc3C2=O)CC1', 'CN1CCC(/C=C/C=C2\\\\Cc3ccccc3C2=O)CC1', 'CN1CCC(C[C@H]2Cc3ccccc3C2=O)CC1', 'CC(C)N1CCN(c2ccc(OC[C@H]3CO[C@](Cn4cncn4)(c4ccc(Cl)cc4Cl)O3)cc2)CC1', 'CC1CCN(Cc2ccccc2[N+](=O)[O-])CC1', 'CC1CCN(CC2CCCCC2)CC1', 'CN1CCC(CCC2C(=O)Nc3ccccc3C2=O)CC1', 'CN1CCC(CCN2C(=O)c3ccccc3C2=O)CC1', 'CC1CCN(Cc2cccc3ccccc23)CC1', 'CC1CCN(Cc2ccc3ccccc3c2)CC1', 'CN1CCC(C[C@@H]2Cc3ccccc3C2=O)CC1', 'C/N=C1/CCc2c1n(C)c1ccc(OC(=O)NC)c(Cl)c21', 'C/N=C1/CCc2c1n(C)c1ccc(OC(=O)NC)cc21', 'C/N=C1/CCc2c1n(C)c1ccc(OC(=O)NC)c(Br)c21', 'CNC(=O)Oc1ccc2c(c1)c1c(n2C)/C(=N\\\\CCc2ccccc2)CC1', 'CCC/N=C1/CCc2c1n(C)c1ccc(OC(=O)NC)cc21', 'CC/N=C1/CCc2c1n(C)c1ccc(OC(=O)NC)c(Cl)c21', 'CC/N=C1/CCc2c1n(C)c1ccc(OC(=O)NC)c(Br)c21', 'C/N=C1/CCc2c1n(C)c1ccc(OC(=O)N(C)C)c(Br)c21', 'C/N=C1/CCc2c1n(C)c1ccc(OC(=O)N(C)C)c(Br)c21', 'CCCCNC(=O)Oc1ccc2c(c1Br)c1c(n2C)/C(=N\\\\C)CC1', 'C/N=C1/CCc2c1n(C)c1ccc(OC(=O)NCc3ccccc3)c(Br)c21', 'C/N=C1/CCc2c1n(C)c1cc(Cl)c(OC(=O)NC)cc21', 'CC/N=C1/CCc2c1n(C)c1ccc(OC(=O)NC)cc21', 'CCCn1c2c(c3c(Br)c(OC(=O)NC)ccc31)CC/C2=N/CC', 'Clc1ccc2c(c1)N=C1CCCCCN1C2', 'N=c1c2ccc(Cl)cc2nc2n1CCCCC2', 'Clc1cccc2c1N=C1CCCCCN1C2', 'Clc1ccc2c(c1)CN1CCCCCC1=N2', 'c1ccc2c(c1)CN1CCCC1=N2', 'c1ccc2c(c1)CN1CCCC1=N2', 'c1ccc2c(c1)CN1CCCCCC1=N2', 'c1ccc2c(c1)CN1CCCCCCCC1=N2', 'Clc1cccc2c1CN1CCCCCC1=N2', 'c1ccc2c(c1)CN1CCCCCCC1=N2', 'c1ccc2c(c1)CN1CCCCC1=N2', 'O=c1ccc2cc3ccoc3cc2o1', 'Nc1c2c(nc3c(Cl)cccc13)CCCC2', 'Nc1c2c(nc3c(Cl)cccc13)CCCC2', 'Nc1c2c(nc3cccc(Cl)c13)C1CCC2C1', 'Nc1c2c(nc3cccc(Cl)c13)C1CCC2C1', 'Nc1c2c(nc3ccc(Cl)cc13)C1CCC2C1', 'Nc1c2c(nc3ccc(Cl)cc13)C1CCC2C1', 'Nc1c2c(nc3c(Cl)cccc13)C1CCC2C1', 'Nc1c2c(nc3c(Cl)cccc13)C1CCC2C1', 'Nc1c2c(nc3cc(Cl)ccc13)C1CCC2C1', 'Nc1c2c(nc3cc(Cl)ccc13)C1CCC2C1', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccc(C)cc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(CC3CCCCC3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccc([N+](=O)[O-])cc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3cccc([N+](=O)[O-])c3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)/C(=C/C1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)/C(=C/C1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3cccc(C)c3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3C)CC1)C2', 'CC[N+](C)(CCCCCCOCCCCCCCCOCCCCCC[N+](C)(CC)Cc1ccccc1OC)Cc1ccccc1OC', 'CCN(CCCCCC(=O)N(C)CCCCCCCCN(C)C(=O)CCCCCN(CC)Cc1ccccc1OC)Cc1ccccc1OC', 'CCN(CCCCCC(=O)N(C)CCCCCCCCN(C)C(=O)CCCCCN(CC)Cc1ccccc1OC)Cc1ccccc1OC', 'CCN(CCCCCC(=O)N(C)CCCCCCCCN(C)C(=O)CCCCCN(CC)Cc1ccccc1OC)Cc1ccccc1OC', 'CCN(CCCCCC(=O)N(C)CCCCCCCCN(C)C(=O)CCCCCN(CC)Cc1ccccc1OC)Cc1ccccc1OC', 'CCN(CCCCCC(=O)N(C)CCCCCCCCN(C)C(=O)CCCCCN(CC)Cc1ccccc1OC)Cc1ccccc1OC', 'CCN(CCCCCC(=O)N(C)CCCCCCCCN(C)C(=O)CCCCCN(CC)Cc1ccccc1OC)Cc1ccccc1OC', 'COc1cccc(CN(C)CCCCCC(=O)N(C)CCCCCCCCN(C)C(=O)CCCCCN(C)Cc2cccc(OC)c2)c1', 'CCN(CCCCCC(=O)N(C)CCCCCCCCN(C)C(=O)CCCCCN(CC)Cc1ccccc1Cl)Cc1ccccc1Cl', 'CCN(CCCCCC(=O)N(C)CCCCCCCCN(C)C(=O)CCCCCN(CC)Cc1ccccc1C(F)(F)F)Cc1ccccc1C(F)(F)F', 'COc1ccc(CN(C)CCCCCC(=O)N(C)CCCCCCCCN(C)C(=O)CCCCCN(C)Cc2ccc(OC)cc2)cc1', 'CCN(CCCCCC(=O)N(C)CCCCCCCCN(C)C(=O)CCCCCN(CC)Cc1ccccc1)Cc1ccccc1', 'CC[N+](C)(CCCCCC(=O)N(CCCCCCCCN(C(=O)CCCCC[N+](C)(CC)Cc1ccccc1OC)C(C)C)C(C)C)Cc1ccccc1OC', 'COc1ccccc1CN(CCCCCC(=O)N(C)CCCCCCCCN(C)C(=O)CCCCCN(Cc1ccccc1OC)C(C)C)C(C)C', 'CCN(CCCCCCOCCCCCCCCOCCCCCCN(CC)Cc1ccccc1OC)Cc1ccccc1OC', 'CC[N+](C)(CCCCCC(=O)N(C)CCCCCCCCN(C)C(=O)CCCCC[N+](C)(CC)Cc1ccccc1OC)Cc1ccccc1OC', 'CC[N+](C)(CCCCCC(=O)N(C)CCCCCCCCN(C)C(=O)CCCCC[N+](C)(CC)Cc1ccccc1OC)Cc1ccccc1OC', 'CC[N+](C)(CCCCCC(=O)N(C)CCCCCCCCN(C)C(=O)CCCCC[N+](C)(CC)Cc1ccccc1OC)Cc1ccccc1OC', 'CC[N+](C)(CCCCCC(=O)N(C)CCCCCCCCN(C)C(=O)CCCCC[N+](C)(CC)Cc1ccccc1OC)Cc1ccccc1OC', 'CCCOc1ccccc1C[N+](C)(CC)CCCCCC(=O)N(C)CCCCCCCCN(C)C(=O)CCCCC[N+](C)(CC)Cc1ccccc1OCCC', 'CC[N+](C)(CCCCCC(=O)N(C)CCCCCCCCN(C)C(=O)CCCCC[N+](C)(CC)Cc1ccccc1C)Cc1ccccc1C', 'CCN(CCCCCC(=O)N(C)CCCCCCCCN(C)C(=O)CCCCCN(CC)Cc1ccccc1[N+](=O)[O-])Cc1ccccc1[N+](=O)[O-]', 'CCN(CCCCCC(=O)N(C)CCCCCCCCN(C)C(=O)CCCCCN(CC)Cc1ccccc1[N+](=O)[O-])Cc1ccccc1[N+](=O)[O-]', 'CCN(CCCCCC(=O)N(C)CCCCCCCCN(C)C(=O)CCCCCN(CC)Cc1ccccc1[N+](=O)[O-])Cc1ccccc1[N+](=O)[O-]', 'CCN(CCCCCC(=O)N(C)CCCCCCCCN(C)C(=O)CCCCCN(CC)Cc1ccccc1[N+](=O)[O-])Cc1ccccc1[N+](=O)[O-]', 'CCN(CCCCCC(=O)N(CCCCCCCCN(C(=O)CCCCCN(CC)Cc1ccccc1OC)C(C)C)C(C)C)Cc1ccccc1OC', 'CC[N+](C)(CCCCCC(=O)N(C)CCCCCCCCN(C)C(=O)CCCCC[N+](C)(CC)Cc1ccccc1)Cc1ccccc1', 'CC[N+](C)(CCCCCC(=O)N(C)CCCCCCCCN(C)C(=O)CCCCC[N+](C)(CC)Cc1ccccc1Cl)Cc1ccccc1Cl', 'CC[N+](C)(CCCCCC(=O)N(C)CCCCCCCCN(C)C(=O)CCCCC[N+](C)(CC)Cc1ccccc1C(F)(F)F)Cc1ccccc1C(F)(F)F', 'CCCOc1ccccc1CN(CC)CCCCCC(=O)N(C)CCCCCCCCN(C)C(=O)CCCCCN(CC)Cc1ccccc1OCCC', 'CCN(CCCCCC(=O)N(C)CCCCCCCCN(C)C(=O)CCCCCN(CC)Cc1ccccc1C)Cc1ccccc1C', 'CC(=O)N(CCCNc1c2c(nc3ccccc13)CCCC2)CCCSc1c2c(nc3ccccc13)CCCC2', 'CN(CCCCSc1c2c(nc3ccccc13)CCCC2)CCCNc1c2c(nc3ccccc13)CCCC2', 'CC(=O)N(CCCCSc1c2c(nc3ccccc13)CCCC2)CCCNc1c2c(nc3ccccc13)CCCC2', 'CCNC(=O)Oc1ccc2c(c1)C1(C)CCOC1O2', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCOC1N2C', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCOC1N2C', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCOC1N2C', 'Cc1ccccc1NC(=O)Oc1ccc2c(c1)C1(C)CCOC1O2', 'CCNC(=O)Oc1ccc2c(c1)[C@]1(C)CCOC1N2C', 'Cc1ccccc1NC(=O)Oc1ccc2c(c1)[C@]1(C)CCOC1N2C', 'CC(C)c1ccc(NC(=O)Oc2ccc3c(c2)C2(C)CCOC2O3)cc1', 'CCNC(=O)Oc1ccc2c(c1)C1(C)COC(C1)O2', 'CC(C)c1ccc(NC(=O)Oc2ccc3c(c2)[C@]2(C)CCOC2N3C)cc1', 'Cc1ccccc1NC(=O)Oc1ccc2c(c1)C1(C)COC(C1)O2', 'CC(C)c1ccc(NC(=O)Oc2ccc3c(c2)C2(C)COC(C2)O3)cc1', 'CC(C)c1ccc(NC(=O)Oc2ccc3c(c2)C2(C)COC(C2)O3)cc1', 'CCNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)C1N2C', 'Nc1ccc2c(c1)c(-c1ccccc1)[n+](CCCNCCCNCCCNc1c3c(nc4ccccc14)CCCC3)c1cc(N)ccc21', 'Nc1ccc2c(c1)c(-c1ccccc1)[n+](CCCNCCCNCCCNc1c3c(nc4ccccc14)CCCC3)c1cc(N)ccc21', 'Nc1ccc2c(c1)c(-c1ccccc1)[n+](CCCNCCCNCCCNc1c3c(nc4ccccc14)CCCC3)c1cc(N)ccc21', 'COc1ccccc1CN(C)CCCN(C)CCCNCCC[n+]1c(-c2ccccc2)c2cc(N)ccc2c2ccc(N)cc21', 'COc1ccccc1CN(C)CCCN(C)CCCNCCC[n+]1c(-c2ccccc2)c2cc(N)ccc2c2ccc(N)cc21', 'COc1cc2c(cc1OC)C(=O)C(Oc1ccc(CN(C)C)cc1)C2', 'COc1cc2c(cc1OC)C(=O)C(Oc1cccc(C(C)N(C)C)c1)C2', 'COc1cc2c(cc1OC)C(=O)C(Oc1cccc(CN(C)C)c1)C2', 'CCN(CC)Cc1ccc(OC2Cc3cc(OC)c(OC)cc3C2=O)cc1', 'CCN(CC)Cc1cccc(OC2Cc3cc(OC)c(OC)cc3C2=O)c1', 'COc1cc2c(cc1OC)C(=O)C(Oc1ccc(C(C)N(C)C)cc1)C2', 'CCN(CC)C(C)c1ccc(OC2Cc3cc(OC)c(OC)cc3C2=O)cc1', 'COc1cc2c(cc1OC)C(=O)C(Oc1cccc(CN3CCN(C)CC3)c1)C2', 'CCN(CC)C(C)c1cccc(OC2Cc3cc(OC)c(OC)cc3C2=O)c1', 'COc1cc2c(cc1OC)C(=O)C(Oc1cccc(CN3CCCC3)c1)C2', 'COc1cc2c(cc1OC)C(=O)C(Oc1ccc(CN3CCOCC3)cc1)C2', 'COc1cc2c(cc1OC)C(=O)C(Oc1cccc(CN3CCCCC3)c1)C2', 'COc1cc2c(cc1OC)C(=O)C(Oc1ccc(CN3CCN(C)CC3)cc1)C2', 'COc1cc2c(cc1OC)C(=O)C(Oc1cccc(CN3CCOCC3)c1)C2', 'COc1cc2c(cc1OC)C(=O)C(Oc1ccc(CN3CCCC3)cc1)C2', 'COc1cc2c(cc1OC)C(=O)C(Oc1ccc(CN3CCCC3)cc1)C2', 'COc1cc2c(cc1OC)C(=O)C(Oc1cccc(C(C)N3CCN(C)CC3)c1)C2', 'COc1cc2c(cc1OC)C(=O)C(Oc1ccc(CN3CCCCC3)cc1)C2', 'COc1cc2c(cc1OC)C(=O)C(Oc1cccc(C(C)N3CCCCC3)c1)C2', 'COc1cc2c(cc1OC)C(=O)C(Oc1ccc(C(C)N3CCCC3)cc1)C2', 'COc1cc2c(cc1OC)C(=O)C(Oc1ccc(C(C)N3CCCCC3)cc1)C2', 'COc1cc2c(cc1OC)C(=O)C(Oc1cccc(C(C)N3CCOCC3)c1)C2', 'COc1cc2c(cc1OC)C(=O)C(Oc1ccc(C(C)N3CCOCC3)cc1)C2', 'COc1cc2c(cc1OC)C(=O)C(Oc1cccc(C(C)N3CCCC3)c1)C2', 'COc1cc2c(cc1OC)C(=O)C(Oc1ccc(C(C)N3CCN(C)CC3)cc1)C2', 'COc1ccc(-c2cc3c(c(=O)o2)C[C@@]2(O)[C@@]4(C)C(=O)[C@@]5(OC)C(=O)O[C@]4(CC[C@@]2(C)O3)C5(C)C)cc1', 'COc1ccc(-c2cc3c(c(=O)o2)C[C@@]2(O)[C@@]4(C)C=CC(=O)C(C)(C)[C@@]4(O)CC[C@@]2(C)O3)cc1', 'COc1ccc(-c2cc3c(c(=O)o2)C[C@@]2(O)[C@@]4(C)CCC(=O)C(C)(C)[C@@]4(O)CC[C@@]2(C)O3)cc1', 'COC1=CC(=O)[C@]2(C)[C@]3(O)Cc4c(cc(-c5cc(OC)c(OC)c(OC)c5)oc4=O)O[C@]3(C)CC[C@]2(O)C1(C)C', 'COc1ccc(-c2cc3c(c(=O)o2)C[C@@]2(O)[C@@]4(C)CCC(=O)OC(C)(C)[C@@]4(O)CC[C@@]2(C)O3)cc1', 'COc1ccc(-c2cc3c(c(=O)o2)C[C@@]2(O)[C@@]4(C)CCC(=O)OC(C)(C)[C@@]4(O)CC[C@@]2(C)O3)cc1', 'CCCCNC(=O)OCCO', 'CCCCNC(=O)OCCCCCO', 'CCCCNC(=O)OCCCCCCCCO', 'CCCCNC(=O)OCCOC(=O)NCCCC', 'CCCCNC(=O)OCCCCCOC(=O)NCCCC', 'CCCCNC(=O)OCCCCCCCCOC(=O)NCCCC', 'CCCCNC(=O)OCCCCCCCCCCOC(=O)NCCCC', 'CCCCNC(=O)OCCCCCCCCCCCCOC(=O)NCCCC', 'CCCCNC(=O)OCCCCCCCCCCCCCCOC(=O)NCCCC', 'CCCCNC(=O)OCCCCCCCCCCCCCCCCOC(=O)NCCCC', 'CCCCNC(=O)OCCCCCCCCCCO', 'CCCCNC(=O)OCCCCCCCCCCCCO', 'CCCCNC(=O)OCCCCCCCCCCCCCCO', 'CCCCNC(=O)OCCCCCCCCCCCCCCCCO', 'CC[N+](CC)(CC)CCOc1cccc(OCC[N+](CC)(CC)CC)c1OCC[N+](CC)(CC)CC', 'CC1(C)C=Cc2c(ccc(C(=O)/C=C/c3ccc(O)cc3)c2O)O1', 'CC1(C)C=Cc2c(ccc(C(=O)/C=C/c3ccc(O)cc3)c2O)O1', 'CC1(C)C=Cc2c(ccc(C(=O)/C=C/c3ccc(O)cc3)c2O)O1', 'COc1ccc(/C=C/C(=O)c2ccc3c(c2O)C=CC(C)(C)O3)cc1', 'Cc1ccc(S(=O)(=O)N(Cc2ccccc2)c2ccc(N)cc2O)cc1', 'Cc1nn(S(=O)(=O)c2cc(C(F)(F)F)cc(C(F)(F)F)c2)cc1-c1nsc(Nc2ccccc2)n1', 'Cc1cc(C2(c3cc(C)c(O)c(C)c3)CCCCC2)cc(C)c1O', 'Cc1c(/N=C/c2ccccc2O)cc2c(c1N)C(C)(C)CC2(C)C', 'CC(Cc1ccc(O)cc1)C1CCC(C)C(c2ccc(O)cc2)C1', 'CN(C)c1ccc(-c2c3cc(O)c(=O)cc-3oc3cc(O)c(O)cc23)cc1', 'Fc1ccc(N(Cc2ccc3c(c2)OCO3)C(=S)Nc2cccc(C(F)(F)F)c2)cc1', 'O=C(CC1S/C(=N/c2ccc(C3CCCCC3)cc2)NC1=O)Nc1ccc(OC(F)(F)F)cc1', 'O=C(CC1S/C(=N/c2ccc(C3CCCCC3)cc2)NC1=O)Nc1ccc(OC(F)(F)F)cc1', 'Oc1ccc(C2CC(c3ccccc3O)=Nc3ccccc3S2)cc1', 'CC(C)Cc1ccc(C(=O)CC(Sc2ccccc2N)c2cccc([N+](=O)[O-])c2)cc1', 'Cc1nc(N)ncc1-c1nnnn1-c1ccc(-c2ccccc2)cc1', 'COc1ccc(-c2cc(-c3ccc(N(C)C)cc3)nc(NS(=O)(=O)c3ccc(NC(C)=O)cc3)n2)cc1', 'COc1ccc(/N=C/c2cn(-c3ccc(OC)cc3)cc2/C=N/c2ccc(OC)cc2)cc1', 'COc1cc2onc(CCC3CCN(Cc4ccccc4)CC3)c2cc1C', 'COc1cc2onc(CCC3CCN(Cc4ccccc4)CC3)c2cc1C', 'COc1cc2cc(C(=O)C3CC[N+](C)(Cc4ccccc4)CCC3O)sc2cc1OC', 'COc1cc2cc(C(=O)C3CC[N+](C)(Cc4ccccc4)CCC3O)sc2cc1OC', 'COc1cc2cc(C(=O)C3CC[N+](C)(Cc4ccccc4)CCC3OC)sc2cc1OC', 'COc1cc2cc(C(=O)C3CC[N+](C)(Cc4ccccc4)CCC3OC)sc2cc1OC', 'COc1cc2c(cc1OC)SC(C(=O)CCc1cc[n+](CC3CCC3)cc1)C2', 'COc1cc2c(cc1OC)SC(C(=O)CCc1cc[n+](CC3CCC3)cc1)C2', 'CCOCC[n+]1ccc(CCC(=O)C2Cc3cc(OC)c(OC)cc3S2)cc1', 'CCOCC[n+]1ccc(CCC(=O)C2Cc3cc(OC)c(OC)cc3S2)cc1', 'COc1cc2c(cc1OC)SC(C(=O)CCc1cc[n+](Cc3ccsc3)cc1)C2', 'COc1cc2c(cc1OC)SC(C(=O)CCc1cc[n+](Cc3ccsc3)cc1)C2', 'COc1cc2c(cc1OC)SC(C(=O)CCc1cc[n+](Cc3ccccc3)cc1)C2', 'COc1cc2c(cc1OC)SC(C(=O)CCc1cc[n+](Cc3ccccc3)cc1)C2', 'COc1cc2c(cc1OC)SC(C(=O)CC1C=CC[N+](C)(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)SC(C(=O)CC1C=CC[N+](C)(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)SC(CC1CC[N+](C)(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)SC(CC1CC[N+](C)(Cc3ccccc3)CC1)C2', 'O=C(CCc1cc[n+](Cc2ccccc2)cc1)c1ccc2c(c1)OCO2', 'O=C(CCc1cc[n+](Cc2ccccc2)cc1)c1ccc2c(c1)OCO2', 'COc1cc2c(cc1OC)C(=O)C(C1CC[N+](C)(Cc3ccccc3)CC1)=C2', 'COc1cc2c(cc1OC)C(=O)C(C1CC[N+](C)(Cc3ccccc3)CC1)=C2', 'COc1cc2cc(C(=O)C3CCC[N+](C)(Cc4ccccc4)CC3)sc2cc1OC', 'COc1cc2cc(C(=O)C3CCC[N+](C)(Cc4ccccc4)CC3)sc2cc1OC', 'COc1cc2cc(C(=O)CC3CCCC[N+](C)(Cc4ccccc4)CC3)sc2cc1OC', 'COc1cc2cc(C(=O)CC3CCCC[N+](C)(Cc4ccccc4)CC3)sc2cc1OC', 'COC(=O)c1ccc(C[n+]2ccc(CCC(=O)C3Cc4cc(OC)c(OC)cc4S3)cc2)cc1', 'COC(=O)c1ccc(C[n+]2ccc(CCC(=O)C3Cc4cc(OC)c(OC)cc4S3)cc2)cc1', 'CCC[n+]1ccc(CCC(=O)C2Cc3cc(OC)c(OC)cc3S2)cc1', 'CCC[n+]1ccc(CCC(=O)C2Cc3cc(OC)c(OC)cc3S2)cc1', 'C=CC[n+]1ccc(CCC(=O)C2Cc3cc(OC)c(OC)cc3S2)cc1', 'C=CC[n+]1ccc(CCC(=O)C2Cc3cc(OC)c(OC)cc3S2)cc1', 'COc1cc2c(cc1OC)SC(C(=O)CCc1cc[n+](CC3CC3)cc1)C2', 'COc1cc2c(cc1OC)SC(C(=O)CCc1cc[n+](CC3CC3)cc1)C2', 'COCC[n+]1ccc(CCC(=O)C2Cc3cc(OC)c(OC)cc3S2)cc1', 'COCC[n+]1ccc(CCC(=O)C2Cc3cc(OC)c(OC)cc3S2)cc1', 'COc1cc2c(cc1OC)SC(C(=O)CC1(O)CC[N+](C)(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)SC(C(=O)CC1(O)CC[N+](C)(Cc3ccccc3)CC1)C2', 'COc1cc2cc(C(=O)C3=CC[N+](C)(Cc4ccccc4)CC3)sc2cc1OC', 'COc1cc2cc(C(=O)C3=CC[N+](C)(Cc4ccccc4)CC3)sc2cc1OC', 'COc1cc2cc(C3CC[N+](C)(Cc4ccccc4)CC3O)sc2cc1OC', 'COc1cc2cc(C3CC[N+](C)(Cc4ccccc4)CC3O)sc2cc1OC', 'CN1C(=O)Cc2cc3onc(CCC4CCN(Cc5ccccc5)CC4)c3cc21', 'CN1C(=O)Cc2cc3onc(CCC4CCN(Cc5ccccc5)CC4)c3cc21', 'COc1cc2cc(C(=O)CC3CCC(O)C[N+](C)(Cc4ccccc4)CC3)sc2cc1OC', 'COc1cc2cc(C(=O)CC3CCC(O)C[N+](C)(Cc4ccccc4)CC3)sc2cc1OC', '[Br-].[Br-].c1cc(C[n+]2ccc(N3CCCCC3)cc2)cc(-c2cccc(C[n+]3ccc(N4CCCCC4)cc3)c2)c1', 'COc1cc2c(cc1OC)SC(C(=O)CCc1cc[n+](Cc3ccc(F)cc3)cc1)C2', 'COc1cc2c(cc1OC)SC(C(=O)CCc1cc[n+](Cc3ccc(F)cc3)cc1)C2', 'COC(=O)C[N+]1(C)CCC(CCC(=O)C2Cc3cc(OC)c(OC)cc3S2)CC1', 'COC(=O)C[N+]1(C)CCC(CCC(=O)C2Cc3cc(OC)c(OC)cc3S2)CC1', 'COc1cc2cc(C(=O)C3CCC[N+](C)(CCOc4ccccc4)CC3)sc2cc1OC', 'COc1cc2cc(C(=O)C3CCC[N+](C)(CCOc4ccccc4)CC3)sc2cc1OC', 'COc1cc2cc(C(=O)C3CCC[N+](C)(CC#N)CC3)sc2cc1OC', 'COc1cc2cc(C(=O)C3CCC[N+](C)(CC#N)CC3)sc2cc1OC', 'COc1cc2cc(C3=CC[N+](C)(Cc4ccccc4)CC3)sc2cc1OC', 'COc1cc2cc(C3=CC[N+](C)(Cc4ccccc4)CC3)sc2cc1OC', 'COCC[N+]1(C)CCCC(C(=O)c2cc3cc(OC)c(OC)cc3s2)CC1', 'COCC[N+]1(C)CCCC(C(=O)c2cc3cc(OC)c(OC)cc3s2)CC1', 'COc1cc2cc(C(=O)C3CCC[N+](C)(CC(=O)OC(C)(C)C)CC3)sc2cc1OC', 'COc1cc2cc(C(=O)C3CCC[N+](C)(CC(=O)OC(C)(C)C)CC3)sc2cc1OC', 'C=[N+]1N=C(CCC2CCN(Cc3ccccc3)CC2)c2ccccc21', 'C=[N+]1N=C(CCC2CCN(Cc3ccccc3)CC2)c2ccccc21', 'COc1cc2cc(C(=O)C3CCC[N+](C)(CC4CCCCO4)CC3)sc2cc1OC', 'COc1cc2cc(C(=O)C3CCC[N+](C)(CC4CCCCO4)CC3)sc2cc1OC', '[Br-].[Br-].c1cc(C[n+]2ccc(N3CCCCC3)cc2)ccc1C[n+]1ccc(N2CCCCC2)cc1', 'COc1cc2c(cc1OC)SC(C(=O)CCc1cc[n+](C)cc1)C2', 'COc1cc2c(cc1OC)SC(C(=O)CCc1cc[n+](C)cc1)C2', 'CC[n+]1ccc(CCC(=O)C2Cc3cc(OC)c(OC)cc3S2)cc1', 'CC[n+]1ccc(CCC(=O)C2Cc3cc(OC)c(OC)cc3S2)cc1', 'COc1cc2c(cc1OC)SC(C(=O)CC(O)C1CC[N+](C)(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)SC(C(=O)CC(O)C1CC[N+](C)(Cc3ccccc3)CC1)C2', 'C[C@H]1COC2=C1C(=O)C(=O)c1c2ccc2c1CCCC2(C)C', 'CNC(=O)Oc1cccc(C(C)N(C)C)c1.Cl', 'CNC(=O)Oc1cccc2c1OCC1CCN(C)C21', 'CNC(=O)Oc1cccc2c1CCC1CCN(C)C21', 'CCCCCCCNC(=O)Oc1cccc2c1OCC1CCN(C)C21', 'CCNC(=O)Oc1cccc2c1OCC1CCN(C)C21', 'CNC(=O)Oc1cccc2c1SCC1CCN(C)C21', 'CC(NC(=O)Oc1cccc2c1OCC1CCN(C)C21)c1ccccc1', 'CCNC(=O)Oc1cccc2c1CCC1CCN(C)C21', 'CNC(=O)Oc1cccc(CN(C)CCCCCCCOc2ccc3c(c2)O/C(=C\\\\c2ccccc2)C3=O)c1', 'CNC(=O)Oc1cccc(CN(C)CCCCCCCOc2ccc3c(c2)O/C(=C\\\\c2ccccc2)C3=O)c1', 'CNC(=O)Oc1cccc(CN(C)CCCCCCCOc2ccc3c(c2)O/C(=C\\\\c2cc(Cl)cc(Cl)c2)C3=O)c1', 'CNC(=O)Oc1cccc(CN(C)CCCCCCCOc2ccc3c(c2)O/C(=C\\\\c2cc(Cl)cc(Cl)c2)C3=O)c1', 'CNC(=O)Oc1cccc(CN(C)CCCCCCCOc2ccc3c(c2)C/C(=C\\\\c2cc(OC)c(OC)c(OC)c2)C3=O)c1', 'CNC(=O)Oc1cccc(CN(C)CCCCCCCOc2ccc3c(c2)C/C(=C\\\\c2cc(OC)c(OC)c(OC)c2)C3=O)c1', 'CNC(=O)Oc1cccc(CN(C)CCCOc2ccc3c(c2)O/C(=C\\\\c2cccc4ccccc24)C3=O)c1', 'CNC(=O)Oc1cccc(CN(C)CCCOc2ccc3c(c2)O/C(=C\\\\c2cccc4ccccc24)C3=O)c1', 'CNC(=O)Oc1cccc(CN(C)CCCOc2ccc3c(c2)O/C(=C\\\\c2ccc4ccccc4c2)C3=O)c1', 'CNC(=O)Oc1cccc(CN(C)CCCOc2ccc3c(c2)O/C(=C\\\\c2ccc4ccccc4c2)C3=O)c1', 'CNC(=O)Oc1cccc(CN(C)CCCCCCCOc2ccc3c(c2)O/C(=C\\\\c2c4ccccc4cc4ccccc24)C3=O)c1', 'CNC(=O)Oc1cccc(CN(C)CCCCCCCOc2ccc3c(c2)O/C(=C\\\\c2c4ccccc4cc4ccccc24)C3=O)c1', 'CNC(=O)Oc1cccc(CN(C)CCCCCCCOc2ccc3c(c2)O/C(=C\\\\c2ccc(Cl)c(Cl)c2)C3=O)c1', 'CNC(=O)Oc1cccc(CN(C)CCCCCCCOc2ccc3c(c2)O/C(=C\\\\c2ccc(Cl)c(Cl)c2)C3=O)c1', 'CNC(=O)Oc1cccc(CN(C)CCCCCCCOc2ccc3c(c2)O/C(=C\\\\c2ccc(Cl)c(Cl)c2)C3=O)c1', 'CNC(=O)Oc1cccc(CN(C)CCCCCCCOc2ccc3c(c2)O/C(=C\\\\c2cc(OC)c(OC)c(OC)c2)C3=O)c1', 'CNC(=O)Oc1cccc(CN(C)CCCCCCCOc2ccc3c(c2)O/C(=C\\\\c2cccc4ccccc24)C3=O)c1', 'CNC(=O)Oc1cccc(CN(C)CCCCCCCOc2ccc3c(c2)O/C(=C\\\\c2cccc4ccccc24)C3=O)c1', 'CNC(=O)Oc1cccc(CN(C)CCCCCCCOc2ccc3c(c2)O/C(=C\\\\c2cccc4ccccc24)C3=O)c1', 'CCC(=O)Oc1cccc(CN(C)CCCCCCCOc2ccc3c(c2)O/C(=C\\\\c2ccc4ccccc4c2)C3=O)c1', 'CNC(=O)Oc1cccc(CN(C)CCCCCCCOc2ccc3c(c2)OC/C(=C\\\\c2cc(OC)c(OC)c(OC)c2)C3=O)c1', 'CNC(=O)Oc1cccc(CN(C)CCCCCCCOc2ccc3c(c2)CC/C(=C\\\\c2cc(OC)c(OC)c(OC)c2)C3=O)c1', 'CNC(=O)Oc1cccc(CN(C)CCCOc2ccc3c(c2)O/C(=C\\\\c2cc(OC)c(OC)c(OC)c2)C3=O)c1', 'CNC(=O)Oc1cccc(CN(C)CCCCCCCOc2ccc3c(c2)OCC3=O)c1', 'CNC(=O)Oc1cccc(CN(C)CCCCCCCOc2ccc3c(c2)OCC3=O)c1', 'CNC(=O)Oc1cccc(CN(C)CCCCCCCOc2ccc3c(=O)c4ccccc4oc3c2)c1', 'CNC(=O)Oc1cccc(CN(C)CCCCCCCOc2ccc3c(=O)c4ccccc4oc3c2)c1', 'CNC(=O)Oc1cccc(CN(C)CCCCCCCOc2ccc3c(=O)c4ccccc4oc3c2)c1', 'CNC(=O)Oc1cccc(CN(C)CCCCCCCOc2ccc3c(=O)c4ccccc4oc3c2)c1', 'CNC(=O)Oc1cccc(CN(C)CCCCCCCOc2ccc3c(=O)c4ccccc4oc3c2)c1', 'CC(C)N(CCN1CC(=O)N(CCc2ccc(Cl)cc2Cl)CC1=O)C(C)C', 'COc1ccc(CCN2CC(=O)N(CCc3ccccn3)CC2=O)cc1OC', 'CC1CCCCN1CCCN1CC(=O)N(CCc2ccc(F)cc2)CC1=O', 'O=C1CN(CCN2CCOCC2)C(=O)CN1CCC(c1ccccc1)c1ccccc1', 'CCN(CC)CCCN1CC(=O)N(C2CC2)CC1=O', 'CCN(CC)CCN1CC(=O)N(CCc2ccccc2)CC1=O', 'O=C1CN(CCN2CCCC2)C(=O)CN1CCCn1ccnc1', 'O=C1C(=O)C(Cl)=C(Cl)C(Cl)=C1Cl', 'O=C1C(Cl)=C(Cl)C(=O)C(Cl)=C1Cl', 'Cc1c(Cl)nc2ccccc2c1C(=O)NCCCCCCCNc1c2c(nc3ccccc13)CCCC2', 'Cc1c(N2CCN(C)CC2)nc2ccccc2c1C(=O)NCCCCCCCNc1c2c(nc3ccccc13)CCCC2', 'Cc1c(N2CCN(C)CC2)nc2ccccc2c1C(=O)NCCCCCCCNc1c2c(nc3ccccc13)CCCC2', 'Cc1c(N2CCN(C)CC2)nc2ccccc2c1C(=O)NCCCCCCCNc1c2c(nc3ccccc13)CCCC2', 'O=C(CCCCC1CCSS1)NCCCCCNc1c2c(nc3ccccc13)CCCC2', 'O=C(CCCCC1CCSS1)NCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'O=C(CCCCC1CCSS1)NCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'O=C(CCCCC1CCSS1)NCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'O=C(CCCCC1CCSS1)NCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'O=C(CCCCC1CCSS1)NCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'O=C(CCCCC1CCSS1)NCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'O=C(CCCCC1CCSS1)NCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'O=C(CCCCC1CCSS1)NCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'Nc1c2c(nc3cc(Cl)ccc13)CC(CNC(=O)CCCCC1CCSS1)CC2', 'O=C(CCCCC1CCSS1)NCCNc1c2c(nc3ccccc13)CCCC2', 'O=C(CCCCC1CCSS1)NCCCCNc1c2c(nc3ccccc13)CCCC2', 'O=C(CCCCC1CCSS1)NCCCCCCCNc1c2c(nc3ccccc13)CCCC2', 'O=C(CCCCC1CCSS1)NCCCNc1c2c(nc3ccccc13)CCCC2', 'O=C(CCCCC1CCSS1)NCCCCCCNc1c2c(nc3ccccc13)CCCC2', 'NCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'NCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'O=C(Nc1ccccc1)OC1CN2CCC1CC2', 'COc1cc2ccnc3c2c(c1OC)COC3(CC(O)CO)OC', 'C=CCC1(OC)OCc2c(OC)c(OC)cc3ccnc1c23', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCNC2', 'COc1cc2ccnc3c2c(c1OC)C(Br)OC3=O', 'COc1cc2ccnc3c2c(c1OC)COC3=O', 'CCCCCCCCc1ccc(O)cc1', 'CN[C@@H](CCOc1ccc([N+](=O)[O-])cc1)c1ccc(OC(=O)N(C)C)cc1', 'CN[C@@H](CCOc1ccc([N+](=O)[O-])cc1)c1ccc(OC(=O)N(C)C)cc1', 'CN(C)C(=O)Oc1ccc2c(c1)C=CCN(C)[C@@H]2CCOc1ccc([N+](=O)[O-])cc1', 'O=C(CCCCCNc1c2c(nc3ccccc13)CCCC2)NCCc1c[nH]c2ccc(O)cc12', 'O=C(CCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2)NCCc1c[nH]c2ccccc12', 'O=C(CCCCCNc1c2c(nc3cccc(Cl)c13)CCCC2)NCCc1c[nH]c2ccccc12', 'O=C(CCCCCCNc1c2c(nc3cc(Cl)cc(Cl)c13)CCCC2)NCCc1c[nH]c2ccccc12', 'COc1ccc2[nH]cc(CCNC(=O)CCCCCCNc3c4c(nc5ccccc35)CCCC4)c2c1', 'COc1ccc2[nH]cc(CCNC(=O)CCCCCCNc3c4c(nc5cc(Cl)cc(Cl)c35)CCCC4)c2c1', 'O=C(CCCCCCNc1c2c(nc3ccccc13)CCCC2)NCCc1c[nH]c2ccccc12', 'COc1cc2c(cc1OC)-c1cc3ccc(OC)c(OC)c3c[n+]1CC2', 'CNC(=O)Oc1ccc2c(c1)[C@@]1(C)CCO[C@H]1N2C', 'CCNC(=O)Oc1ccc2c(c1)[C@]1(C)CCO[C@@H]1N2C', 'Cc1ccccc1NC(=O)Oc1ccc2c(c1)[C@]1(C)CCO[C@@H]1N2C', 'CCNC(=O)Oc1ccc2c(c1)[C@]1(C)CCO[C@@H]1O2', 'CCNC(=O)Oc1ccc2c(c1)[C@]1(C)CCO[C@@H]1O2', 'CCNC(=O)Oc1ccc2c(c1)[C@@]1(C)CCO[C@H]1O2', 'Cc1ccccc1NC(=O)Oc1ccc2c(c1)[C@]1(C)CCO[C@@H]1O2', 'Cc1ccccc1NC(=O)Oc1ccc2c(c1)[C@]1(C)CCO[C@@H]1O2', 'Cc1ccccc1NC(=O)Oc1ccc2c(c1)[C@@]1(C)CCO[C@H]1O2', 'CC(C)c1ccc(NC(=O)Oc2ccc3c(c2)[C@]2(C)CCO[C@@H]2O3)cc1', 'CC(C)c1ccc(NC(=O)Oc2ccc3c(c2)[C@@]2(C)CCO[C@H]2O3)cc1', 'Cc1ccccc1NC(=O)Oc1ccc2c(c1)[C@@]1(C)CCO[C@H]1N2C', 'CC(C)c1ccc(NC(=O)Oc2ccc3c(c2)[C@]2(C)CCO[C@@H]2N3C)cc1', 'Cc1ccccc1NC(=O)Oc1ccc2c(c1)[C@@]1(C)CO[C@H](C1)O2', 'Cc1ccccc1NC(=O)Oc1ccc2c(c1)[C@]1(C)CO[C@@H](C1)O2', 'CC(C)c1ccc(NC(=O)Oc2ccc3c(c2)[C@]2(C)CO[C@@H](C2)O3)cc1', 'CCNC(=O)Oc1ccc2c(c1)[C@@]1(C)CO[C@H](C1)O2', 'CCNC(=O)Oc1ccc2c(c1)[C@]1(C)CO[C@@H](C1)O2', 'CNC(=O)Oc1ccc2c(c1)[C@@]1(C)CCN(C)[C@H]1N2C', 'CCNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'CCNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCO[C@@H]1N2C', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCO[C@@H]1N2C', 'Cc1ccccc1NC(=O)Oc1ccc2c(c1)[C@@]1(C)CCN(C)[C@H]1N2C', 'COc1cc2ccnc(C(O)c3ccccc3OC)c2cc1OC', 'COc1ccc(C(O)c2nccc3cc(OC)c(OC)cc23)cc1OC', 'COc1ccc(CC2=[N+](C)CCc3cc(OC)c(OC)cc32)cc1OC', 'C/C=C1\\\\C2C=C(C)C[C@]1(N)CC(NCCCCCCCNc1c3c(nc4ccccc14)CCCC3)C2(C)C', 'C/C=C1\\\\C2C=C(C)C[C@]1(N)CC(NCCCCCCCNc1c3c(nc4ccccc14)CCCC3)C2', 'C/C=C1\\\\C2C=C(C)C[C@]1(C(=O)OC)CC(NCCCCCCCNc1c3c(nc4ccccc14)CCCC3)C2', 'CCC1=CC2Cc3nc4cc(Cl)ccc4c(N)c3[C@@H](C1)C2', 'CCC1=CC2Cc3nc4cc(Cl)ccc4c(N)c3[C@@H](C1)C2', 'CCC1=CC2Cc3nc4cc(Cl)ccc4c(N)c3[C@@H](C1)C2', 'CCC1=CC2Cc3nc4cc(Cl)ccc4c(N)c3[C@@H](C1)C2', 'CCC1=CC2Cc3nc4cc(Cl)ccc4c(N)c3[C@@H](C1)C2', 'CCC1=CC2Cc3nc4cc(Cl)ccc4c(N)c3[C@@H](C1)C2', 'CCC1=CC2Cc3nc4cc(Cl)ccc4c(N)c3[C@@H](C1)C2', 'Fc1ccc(C(c2ccc(F)cc2)N2CCN(CCN3CCOCC3)CC2)cc1', 'Fc1ccc(C(c2ccc(F)cc2)N2CCN(CCN3CCCCC3)CC2)cc1', 'Fc1ccc(C(c2ccc(F)cc2)N2CCN(CCN3CCCC3)CC2)cc1', 'Cc1nc2ccccn2c(=O)c1CCN1CCN(C(c2ccc(F)cc2)c2ccc(F)cc2)CC1', 'CC1=C(CCN2CCN(C(c3ccc(F)cc3)c3ccc(F)cc3)CC2)C(=O)C2CCCCC2=N1', 'Cc1cc2c(cc1CN1CCN(C(c3ccc(F)cc3)c3ccc(F)cc3)CC1)OCO2', 'COc1cc(Br)c(CN2CCN(C(c3ccc(F)cc3)c3ccc(F)cc3)CC2)cc1OC', 'N#Cc1ccccc1-c1ccc(CN2CCN(C(c3ccc(F)cc3)c3ccc(F)cc3)CC2)cc1', 'CN(C)C(=O)Oc1cccc([N+](C)(C)C)c1.COS(=O)(=O)[O-]', 'CN(C)C(=O)Oc1cccc([N+](C)(C)C)c1.COS(=O)(=O)[O-]', 'CN(C)C(=O)Oc1cccc([N+](C)(C)C)c1.COS(=O)(=O)[O-]', 'CCN(C)C(=O)Oc1cccc([C@H](C)N(C)C)c1.O=C(O)C(O)C(O)C(=O)O', 'NC(=O)c1cc[n+](COC[n+]2ccccc2/C=N/O)cc1', 'NC(=O)c1cc[n+](COC[n+]2ccccc2/C=N/O)cc1', 'NC(=O)c1cc[n+](COC[n+]2ccccc2/C=N/O)cc1', 'C[n+]1ccccc1C=NO', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(N)c3C(C1)C2NC=O', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(N)c3C(C1)C2NS(C)(=O)=O', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(N)c3C(C1)C2N', 'COc1cc(C(=O)NCCCCCCC(=O)NNc2c3c(nc4ccccc24)CCCC3)cc(OC)c1OC', 'COc1cc(C(=O)NCCCCCCCC(=O)NNc2c3c(nc4ccccc24)CCCC3)cc(OC)c1OC', 'COc1cc(C(=O)NCCCCCCCCC(=O)NNc2c3c(cc4ccccc24)CCCC3)cc(OC)c1OC', 'COc1cc(CCC(=O)NNc2c3c(nc4ccccc24)CCCC3)cc(OC)c1OC', 'COc1cc(CCC(=O)NCC(=O)NNc2c3c(nc4ccccc24)CCCC3)cc(OC)c1OC', 'COc1cc(CCC(=O)NCCC(=O)NNc2c3c(nc4ccccc24)CCCC3)cc(OC)c1OC', 'O=c1[nH]c(=O)c2nc[nH]c2[nH]1', 'COc1cc(C(=O)NNc2c3c(nc4ccccc24)CCCC3)cc(OC)c1OC', 'COc1cc(CCC(=O)NCCCC(=O)NNc2c3c(nc4ccccc24)CCCC3)cc(OC)c1OC', 'COc1cc(C(=O)NCC(=O)NNc2c3c(nc4ccccc24)CCCC3)cc(OC)c1OC', 'COc1cc(CCC(=O)NCCCCC(=O)NNc2c3c(nc4ccccc24)CCCC3)cc(OC)c1OC', 'COc1cc(C(=O)NCCC(=O)NNc2c3c(nc4ccccc24)CCCC3)cc(OC)c1OC', 'COc1cc(CCC(=O)NCCCCCC(=O)NNc2c3c(nc4ccccc24)CCCC3)cc(OC)c1OC', 'COc1cc(C(=O)NCCCC(=O)NNc2c3c(nc4ccccc24)CCCC3)cc(OC)c1OC', 'COc1cc(C(=O)NCCCCC(=O)NNc2c3c(nc4ccccc24)CCCC3)cc(OC)c1OC', 'COc1cc(C(=O)NCCCCCC(=O)NNc2c3c(nc4ccccc24)CCCC3)cc(OC)c1OC', 'CCOC(=O)C1=C(C)Nc2nc3c(c(N)c2C1c1ccccc1)CCCC3', 'CCOC(=O)C1=C(C)Nc2nc3c(c(N)c2C1c1ccccc1)CCCC3', 'CCOC(=O)C1=C(C)Nc2nc3c(c(N)c2C1c1ccccc1)CCCC3', 'CCOC(=O)C1=C(C)Nc2nc3c(c(N)c2C1c1ccc(F)cc1)CCCC3', 'CCOC(=O)C1=C(C)Nc2nc3c(c(N)c2C1c1ccc(F)cc1)CCCC3', 'CCOC(=O)C1=C(C)Nc2nc3c(c(N)c2C1c1ccc(F)cc1)CCCC3', 'CCOC(=O)C1=C(C)Nc2nc3c(c(N)c2C1c1ccccc1[N+](=O)[O-])CCCC3', 'CCOC(=O)C1=C(C)Nc2nc3c(c(N)c2C1c1ccccc1[N+](=O)[O-])CCCC3', 'CCOC(=O)C1=C(C)Nc2nc3c(c(N)c2C1c1cccc([N+](=O)[O-])c1)CCCC3', 'CCOC(=O)C1=C(C)Nc2nc3c(c(N)c2C1c1cccc([N+](=O)[O-])c1)CCCC3', 'CC[C@H]1C[C@@H]2C[C@H]3c4[nH]c5cc([C@@H]6C[C@H]7C(C(=O)OC)[C@@H](Cc8c6[nH]c6ccccc86)N(C)C[C@H]7CC)ccc5c4CCN(C2)[C@@H]13', 'CCOC(=O)C1=C(C)Nc2nc3c(c(N)c2C1c1ccc([N+](=O)[O-])cc1)CCCC3', 'CCOC(=O)C1=C(C)Nc2nc3c(c(N)c2C1c1ccc([N+](=O)[O-])cc1)CCCC3', 'CCOC(=O)C1=C(C)Nc2nc3c(c(N)c2C1c1ccc(C)cc1)CCCC3', 'CCOC(=O)C1=C(C)Nc2nc3c(c(N)c2C1c1ccc(C)cc1)CCCC3', 'CCOC(=O)C1=C(C)Nc2nc3c(c(N)c2C1c1ccc(C)cc1)CCCC3', 'CCOC(=O)C1=C(C)Nc2nc3c(c(N)c2C1c1ccccc1OC)CCCC3', 'CCOC(=O)C1=C(C)Nc2nc3c(c(N)c2C1c1ccccc1OC)CCCC3', 'CCOC(=O)C1=C(C)Nc2nc3c(c(N)c2C1c1cccc(OC)c1)CCCC3', 'CCOC(=O)C1=C(C)Nc2nc3c(c(N)c2C1c1cccc(OC)c1)CCCC3', 'CCOC(=O)C1=C(C)Nc2nc3c(c(N)c2C1c1ccc(OC)cc1)CCCC3', 'CCOC(=O)C1=C(C)Nc2nc3c(c(N)c2C1c1ccc(OC)cc1)CCCC3', 'CCOC(=O)C1=C(C)Nc2nc3c(c(N)c2C1c1ccc(OC)cc1)CCCC3', 'CCOC(=O)C1=C(C)Nc2nc3c(c(N)c2C1c1ccc(OC)cc1)CCCC3', 'CCOC(=O)C1=C(C)Nc2nc3c(c(N)c2C1c1ccc(OC)cc1)CCCC3', 'COc1ccc2c(c1)c1ccnc(C)c1n2C', 'COc1ccc2c(c1)c1ccnc(C)c1n2C', 'COc1ccc2[nH]c3c[n+](C)ccc3c2c1', 'COc1ccc2[nH]c3c[n+](C)ccc3c2c1', 'COc1ccc2c(c1)c1cc[n+](C)cc1n2C', 'COc1ccc2c(c1)c1cc[n+](C)cc1n2C', 'COc1ccc2[nH]c3c(C)[n+](C)ccc3c2c1', 'COc1ccc2[nH]c3c(C)[n+](C)ccc3c2c1', 'C[n+]1ccc2c(c1)[nH]c1ccc(O)cc12', 'C[n+]1ccc2c(c1)[nH]c1ccc(O)cc12', 'Cn1c2ccc(O)cc2c2cc[n+](C)cc21', 'Cn1c2ccc(O)cc2c2cc[n+](C)cc21', 'Cc1c2[nH]c3ccc(O)cc3c2cc[n+]1C', 'Cc1c2[nH]c3ccc(O)cc3c2cc[n+]1C', 'Cc1c2c(cc[n+]1C)c1cc(O)ccc1n2C', 'Cc1c2c(cc[n+]1C)c1cc(O)ccc1n2C', 'CC(C)=CCC/C(C)=C/Cc1c(O)cc2c(c1O)C(=O)C[C@@H](c1ccc(O)cc1)O2', 'CC(C)=CCC/C(C)=C/Cc1c(O)cc2c(c1O)C(=O)C[C@@H](c1ccc(O)c(O)c1)O2', 'CC(C)=CCC/C(C)=C/Cc1c(O)cc2c(c1O)C(=O)C[C@@H](c1ccc(O)c(O)c1)O2', 'O=C1C(=O)N(Cc2ccc(Cc3ccc(CN4C(=O)C(=O)c5ccccc54)cc3)cc2)c2ccccc21', 'O=C1C(=O)N(Cc2ccc(Cl)c(Cl)c2)c2ccccc21', 'COc1ccccc1CN(C)CCCCCC(=O)N(C)CCCCCCCCN(C)C(=O)CCCCCN(C)Cc1ccccc1OC.O=C(O)C(=O)O', 'COc1ccccc1CN(C)CCCCCC(=O)N(C)CCCCCCCCN(C)C(=O)CCCCCN(C)Cc1ccccc1OC.O=C(O)C(=O)O', 'CCN(CCCCCC(=O)N(C)CCCCCCCCN(C)C(=O)CCCCCN(CC)Cc1ccccc1OC)Cc1ccccc1OC.O=C(O)C(=O)O', 'CCN(CCCCCC(=O)N(C)CCCCCCCCN(C)C(=O)CCCCCN(CC)Cc1ccccc1OC)Cc1ccccc1OC.O=C(O)C(=O)O', 'CCN(CCCCCC(=O)N1CCC(C2CCN(C(=O)CCCCCN(CC)Cc3ccccc3OC)CC2)CC1)Cc1ccccc1OC.O=C(O)C(=O)O', 'CCN(CCCCCC(=O)N1CCC(C2CCN(C(=O)CCCCCN(CC)Cc3ccccc3OC)CC2)CC1)Cc1ccccc1OC.O=C(O)C(=O)O', 'CCN(CCCCCC(=O)N1CCC(CC2CCN(C(=O)CCCCCN(CC)Cc3ccccc3OC)CC2)CC1)Cc1ccccc1OC.O=C(O)C(=O)O', 'CCN(CCCCCC(=O)N1CCC(CCC2CCN(C(=O)CCCCCN(CC)Cc3ccccc3OC)CC2)CC1)Cc1ccccc1OC.O=C(O)C(=O)O', 'CCN(CCCCCC(=O)N1CCC(CCCC2CCN(C(=O)CCCCCN(CC)Cc3ccccc3OC)CC2)CC1)Cc1ccccc1OC.O=C(O)C(=O)O', 'CCN(CCCCCC(=O)Nc1ccc(-c2ccc(NC(=O)CCCCCN(CC)Cc3ccccc3OC)cc2)cc1)Cc1ccccc1OC.O=C(O)C(=O)O', 'CCN(CCCCCC(=O)Nc1ccc(Cc2ccc(NC(=O)CCCCCN(CC)Cc3ccccc3OC)cc2)cc1)Cc1ccccc1OC.O=C(O)C(=O)O', 'CCN(CCCCCC(=O)Nc1ccc(CCc2ccc(NC(=O)CCCCCN(CC)Cc3ccccc3OC)cc2)cc1)Cc1ccccc1OC.O=C(O)C(=O)O', 'CC[N+](C)(CCCCCC(=O)N1CCC(CCC2CCN(C(=O)CCCCC[N+](C)(CC)Cc3ccccc3OC)CC2)CC1)Cc1ccccc1OC.[I-].[I-]', 'CC[N+](C)(CCCCCC(=O)N1CCC(CCCC2CCN(C(=O)CCCCC[N+](C)(CC)Cc3ccccc3OC)CC2)CC1)Cc1ccccc1OC.[I-].[I-]', 'CC[N+](C)(CCCCCC(=O)Nc1ccc(CCc2ccc(NC(=O)CCCCC[N+](C)(CC)Cc3ccccc3OC)cc2)cc1)Cc1ccccc1OC.[I-].[I-]', 'CCN(CCCCCCNc1ccc(-c2ccc(NCCCCCCN(CC)Cc3ccccc3OC)cc2)cc1)Cc1ccccc1OC', 'CCN(CCCCCCNc1ccc(Cc2ccc(NCCCCCCN(CC)Cc3ccccc3OC)cc2)cc1)Cc1ccccc1OC', 'N#Cc1ccc2[nH]cc(CCC(=O)NCCCCCCNc3c4c(nc5cc(Cl)ccc35)CCCC4)c2c1', 'O=C(/C=C/c1c[nH]c2ccccc12)NCCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'O=C(NCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2)c1c[nH]c2ccccc12', 'O=C(NCCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2)c1c[nH]c2ccccc12', 'O=C(NCCCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2)c1c[nH]c2ccccc12', 'O=C(NCCCCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2)c1c[nH]c2ccccc12', 'O=C(Cc1c[nH]c2ccccc12)NCCCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'O=C(Cc1c[nH]c2ccccc12)NCCCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'O=C(Cc1c[nH]c2ccccc12)NCCCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'O=C(Cc1c[nH]c2ccccc12)NCCCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'O=C(Cc1c[nH]c2ccc(Br)cc12)NCCCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'O=C(Cc1c[nH]c2ccc(Br)cc12)NCCCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'O=C(Cc1c[nH]c2ccc(Br)cc12)NCCCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'O=C(Cc1c[nH]c2ccc(Br)cc12)NCCCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'O=C(CCCc1c[nH]c2ccccc12)NCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'O=C(CCCc1c[nH]c2ccccc12)NCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'O=C(CCCc1c[nH]c2ccccc12)NCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'O=C(CCCc1c[nH]c2ccccc12)NCCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'Cn1cc(C(=O)NCCCCCCCNc2c3c(nc4cc(Cl)ccc24)CCCC3)c2ccccc21', 'O=C(NCCCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2)c1n[nH]c2ccccc12', 'O=C(CCc1c[nH]c2ccccc12)NCCCCCNc1c2c(nc3ccccc13)CCCC2', 'O=C(CCc1c[nH]c2ccccc12)NCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'O=C(CCc1c[nH]c2ccccc12)NCCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'O=C(CCc1c[nH]c2ccccc12)NCCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'O=C(CCc1c[nH]c2ccccc12)NCCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'O=C(CCc1c[nH]c2ccccc12)NCCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'O=C(CCc1c[nH]c2ccccc12)NCCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'O=C(CCc1c[nH]c2ccccc12)NCCCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'O=C(CCc1c[nH]c2ccccc12)NCCCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'O=C(CCc1c[nH]c2ccccc12)NCCCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'O=C(CCc1c[nH]c2ccccc12)NCCCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'O=C(CCc1c[nH]c2ccccc12)NCCCCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'CN(CCCNC(=O)CCc1c[nH]c2ccccc12)CCCNc1c2c(nc3ccccc13)CCCC2', 'CN(CCCNC(=O)CCc1c[nH]c2ccccc12)CCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'CN(CCCCCCCOc1ccc2c(=O)c3ccccc3oc2c1)Cc1cccc(Cl)c1', 'CN(CCCCCCCOc1ccc2c(=O)c3ccccc3oc2c1)Cc1ccc(Cl)cc1', 'CN(CCCOc1ccc2c(=O)c3ccccc3oc2c1)Cc1ccccc1', 'CN(CCCCOc1ccc2c(=O)c3ccccc3oc2c1)Cc1ccccc1', 'CN(CCCCCOc1ccc2c(=O)c3ccccc3oc2c1)Cc1ccccc1', 'CN(CCCCCOc1ccc2c(=O)c3ccccc3oc2c1)Cc1ccccc1', 'COc1cccc(CN(C)CCCCCCCOc2ccc3c(=O)c4ccccc4oc3c2)c1OC', 'CN(CCCCCCOc1ccc2c(=O)c3ccccc3oc2c1)Cc1ccccc1', 'CCN(CCCCCCCOc1ccc2c(=O)c3ccccc3oc2c1)Cc1ccccc1OC', 'CN(CCCCCCCOc1ccc2c(=O)c3ccccc3oc2c1)Cc1ccccc1', 'CN(CCCCCCCOc1ccc2c(=O)c3ccccc3oc2c1)Cc1ccccc1', 'CN(CCCCCCCCOc1ccc2c(=O)c3ccccc3oc2c1)Cc1ccccc1', 'COc1ccc2c(=O)c3ccc(OCCCCCCCN(C)Cc4ccccc4)cc3oc2c1', 'COc1cc2oc3cc(OCCCCCCCN(C)Cc4ccccc4)ccc3c(=O)c2cc1OC', 'COc1ccccc1CN(C)CCCOc1ccc2c(=O)c3ccccc3oc2c1', 'COc1ccccc1CN(C)CCCCCCCOc1ccc2c(=O)c3ccccc3oc2c1', 'COc1cccc(CN(C)CCCCCCCOc2ccc3c(=O)c4ccccc4oc3c2)c1', 'COc1cccc(CN(C)CCCCCCCOc2ccc3c(=O)c4ccccc4oc3c2)c1', 'COc1ccc(CN(C)CCCCCCCOc2ccc3c(=O)c4ccccc4oc3c2)cc1', 'C[C@@H]1O[C@@H](OC[C@H]2O[C@@H](Oc3c(-c4ccc(O)c(O)c4)oc4cc(O)cc(O)c4c3=O)[C@H](O)[C@@H](O)[C@@H]2O)[C@H](O)[C@H](O)[C@H]1O', '[Br-].[Br-].c1cc[n+](CCCCCC[n+]2ccccc2)cc1', '[Br-].[Br-].c1cc[n+](CCCCCCCC[n+]2ccccc2)cc1', '[Br-].[Br-].c1cc[n+](CCCCCCCCCC[n+]2ccccc2)cc1', '[Br-].[Br-].c1ccc2c(c1)ccc[n+]2CCCCCCCCCC[n+]1cccc2ccccc21', '[Br-].[Br-].c1ccc2c(c1)ccc[n+]2CCCCCCCCCC[n+]1cccc2ccccc21', '[Br-].[Br-].c1ccc2c(c1)ccc[n+]2CCCCCCCCCC[n+]1cccc2ccccc21', 'C[C@H]1C=C2N3CC[C@@H](O)C24[C@H](CC(=O)[C@H]4C[C@H](O)C3)C1', 'CC1=C[C@H]2[C@H](O)C(=O)[C@H]3CCCN4CCC[C@H]2[C@]34C1', 'Cc1cccc2c3c(ccc12)C1=C(C(=O)C3=O)[C@@H](C)CO1', 'Cc1cccc2c3c(ccc12)C1=C(C(=O)C3=O)[C@@H](C)CO1', 'Cc1cccc2c3c(ccc12)C1=C(C(=O)C3=O)[C@@H](C)CO1', 'COc1cc2cc(-c3cccc(CN(C)Cc4ccccc4)c3)c(=O)oc2cc1OC', 'COc1ccc2cc(-c3cccc(CN(C)Cc4ccccc4)c3)c(=O)oc2c1', 'COc1ccc2cc(-c3ccc(CN(C)Cc4ccccc4)cc3)c(=O)oc2c1', 'COc1ccc2oc(=O)c(-c3cccc(CN(C)Cc4ccccc4)c3)cc2c1', 'COc1ccc2oc(=O)c(-c3ccc(CN(C)Cc4ccccc4)cc3)cc2c1', 'COc1cc2cc(-c3ccc(CN(C)Cc4ccccc4[N+](=O)[O-])cc3)c(=O)oc2cc1OC', 'COc1cc2cc(-c3ccc(CN(C)Cc4cccc([N+](=O)[O-])c4)cc3)c(=O)oc2cc1OC', 'COc1cc2cc(-c3ccc(CN(C)Cc4ccc([N+](=O)[O-])cc4)cc3)c(=O)oc2cc1OC', 'COc1cc2cc(-c3ccc(CN(C)Cc4ccccc4C)cc3)c(=O)oc2cc1OC', 'COc1cc2cc(-c3ccc(CN(C)Cc4cccc(C)c4)cc3)c(=O)oc2cc1OC', 'COc1cc2cc(-c3ccc(CN(C)Cc4ccc(C)cc4)cc3)c(=O)oc2cc1OC', 'COc1ccccc1CN(C)Cc1ccc(-c2cc3cc(OC)c(OC)cc3oc2=O)cc1', 'COc1cccc(CN(C)Cc2ccc(-c3cc4cc(OC)c(OC)cc4oc3=O)cc2)c1', 'COc1ccc(CN(C)Cc2ccc(-c3cc4cc(OC)c(OC)cc4oc3=O)cc2)cc1', 'CCN(Cc1ccccc1)Cc1ccc(-c2cc3cc(OC)c(OC)cc3oc2=O)cc1', 'CCN(Cc1ccccc1)Cc1ccc(-c2cc3cc(OC)c(OC)cc3oc2=O)cc1', 'CCN(Cc1ccccc1)Cc1ccc(-c2cc3cc(OC)c(OC)cc3oc2=O)cc1', 'COc1cc2cc(-c3ccc(CN(CCO)Cc4ccccc4)cc3)c(=O)oc2cc1OC', 'CN(Cc1ccccc1)Cc1ccc(-c2cc3cc([N+](=O)[O-])ccc3oc2=O)cc1', 'CN(Cc1ccccc1)Cc1ccc(-c2cc3cc(N)ccc3oc2=O)cc1', 'COc1cc2oc3cc(CN(C)Cc4ccccc4)ccc3c(=O)c2cc1OC', 'COc1cc2occ(-c3ccc(CN(C)Cc4ccccc4)cc3)c(=O)c2cc1OC', 'COc1cc2occ(-c3cccc(CN(C)Cc4ccccc4)c3)c(=O)c2cc1OC', 'CCN(Cc1ccccc1)Cc1cccc(-c2coc3cc(OC)c(OC)cc3c2=O)c1', 'COc1cc2oc(-c3cccc(CN(C)Cc4ccccc4)c3)cc(=O)c2cc1OC', 'COc1cc2oc(-c3ccc(CN(C)Cc4ccccc4)cc3)cc(=O)c2cc1OC', 'COc1ccc2oc(-c3ccc(CN(C)Cc4ccccc4)cc3)cc(=O)c2c1', 'COc1ccc2c(=O)cc(-c3ccc(CN(C)Cc4ccccc4)cc3)oc2c1', 'COc1cc2cc(-c3ccc(C[N+](C)(C)Cc4ccccc4)cc3)c(=O)oc2cc1OC.[I-]', 'CCN(CCCCCCNC1=CC(=O)C(NCCCCCCN(CC)Cc2ccccc2OC)=CC1=O)Cc1ccccc1OC', 'CCN(CCCCCCNC1=CC(=O)C(NCCCCCCN(CC)Cc2ccccc2OC)=CC1=O)Cc1ccccc1OC', 'CCN(CCCCCCNC1=CC(=O)C(NCCCCCCN(CC)Cc2ccccc2OC)=CC1=O)Cc1ccccc1OC', 'CCN(CCCCCCNC1=CC(=O)C(NCCCCCCN(CC)Cc2ccccc2OC)=CC1=O)Cc1ccccc1OC', 'CCN(CCCCCCNC1=CC(=O)C(NCCCCCCN(CC)Cc2ccccc2OC)=CC1=O)Cc1ccccc1OC', 'CCN(CCCCCCNC1=CC(=O)C(NCCCCCCN(CC)Cc2ccccc2OC)=CC1=O)Cc1ccccc1OC', 'CCN(CCCCCCNC1=CC(=O)C(NCCCCCCN(CC)Cc2ccccc2OC)=CC1=O)Cc1ccccc1OC', 'CCN(CCCCCCNC1=CC(=O)C(NCCCCCCN(CC)Cc2ccccc2OC)=CC1=O)Cc1ccccc1OC', 'CCN(CCCCCCNC1=CC(=O)C(NCCCCCCN(CC)Cc2ccccc2OC)=CC1=O)Cc1ccccc1OC', 'CCN(CCCCCCNC1=CC(=O)C(NCCCCCCN(CC)Cc2ccccc2OC)=CC1=O)Cc1ccccc1OC', 'CCN(CCCCCCNC1=CC(=O)C(NCCCCCCN(CC)Cc2ccccc2OC)=CC1=O)Cc1ccccc1OC', 'CCN(CCCCCCNC1=CC(=O)C(NCCCCCCN(CC)Cc2ccccc2OC)=CC1=O)Cc1ccccc1OC', 'CCN(CCCCCCNC1=CC(=O)C(NCCCCCCN(CC)Cc2ccccc2OC)=CC1=O)Cc1ccccc1OC', 'CCN(CCCCCCNC1=CC(=O)C(NCCCCCCN(CC)Cc2ccccc2OC)=CC1=O)Cc1ccccc1OC', 'CCN(CCCCCCNC1=C(F)C(=O)C(NCCCCCCN(CC)Cc2ccccc2OC)=C(F)C1=O)Cc1ccccc1OC', 'CCN(CCCCCCNC1=C(Cl)C(=O)C(NCCCCCCN(CC)Cc2ccccc2OC)=C(Cl)C1=O)Cc1ccccc1OC', 'CCN(CCCCCCNC1=C(Br)C(=O)C(NCCCCCCN(CC)Cc2ccccc2OC)=C(Br)C1=O)Cc1ccccc1OC', 'CCN(CCCCCCNC1=C(C)C(=O)C(NCCCCCCN(CC)Cc2ccccc2OC)=C(C)C1=O)Cc1ccccc1OC', 'CCN(CCCCCCNC1=C(c2ccccc2)C(=O)C(NCCCCCCN(CC)Cc2ccccc2OC)=C(c2ccccc2)C1=O)Cc1ccccc1OC', 'CCN(CCCCCCNc1ccc(NCCCCCCN(CC)Cc2ccccc2OC)cc1)Cc1ccccc1OC', 'CCN(CCNC1=CC(=O)C(NCCN(CC)Cc2ccccc2OC)=CC1=O)Cc1ccccc1OC', 'CCN(CCCNC1=CC(=O)C(NCCCN(CC)Cc2ccccc2OC)=CC1=O)Cc1ccccc1OC', 'CCN(CCCCNC1=CC(=O)C(NCCCCN(CC)Cc2ccccc2OC)=CC1=O)Cc1ccccc1OC', 'CCN(CCCCCNC1=CC(=O)C(NCCCCCN(CC)Cc2ccccc2OC)=CC1=O)Cc1ccccc1OC', 'CCN(CCCCCCCNC1=CC(=O)C(NCCCCCCCN(CC)Cc2ccccc2OC)=CC1=O)Cc1ccccc1OC', 'CCN(CCCCCCNC1=CC(=O)C(NCCCCCCN(CC)CCc2ccccc2OC)=CC1=O)CCc1ccccc1OC', 'CCN(Cc1ccccc1OC)C(=O)CCCCCNC1=CC(=O)C(NCCCCCC(=O)N(CC)Cc2ccccc2OC)=CC1=O', 'COc1ccccc1CNCCCCCCNC1=CC(=O)C(NCCCCCCNCc2ccccc2OC)=CC1=O', 'COc1ccccc1CN(C)CCCCCCNC1=CC(=O)C(NCCCCCCN(C)Cc2ccccc2OC)=CC1=O', 'COc1ccccc1CN(CCCCCCNC1=CC(=O)C(NCCCCCCN(Cc2ccccc2OC)C(C)C)=CC1=O)C(C)C', 'CCN(CCCCCCNC1=CC(=O)C(NCCCCCCN(CC)Cc2ccccc2)=CC1=O)Cc1ccccc1', 'CCN(CCCCCCNC1=CC(=O)C(NCCCCCCN(CC)Cc2ccc(OC)cc2)=CC1=O)Cc1ccc(OC)cc1', 'CCN(CCCCCCNC1=CC(=O)C(NCCCCCCN(CC)Cc2cccc(OC)c2)=CC1=O)Cc1cccc(OC)c1', 'CCN(CCCCCCNC1=CC(=O)C(NCCCCCCN(CC)Cc2ccccc2C)=CC1=O)Cc1ccccc1C', 'CCN(CCCCCCNC1=CC(=O)C(NCCCCCCN(CC)Cc2ccccc2Cl)=CC1=O)Cc1ccccc1Cl', 'CCN(CCCCCCNC1=CC(=O)C(NCCCCCCN(CC)Cc2ccccc2[N+](=O)[O-])=CC1=O)Cc1ccccc1[N+](=O)[O-]', 'CCN(CCCCCCNC1=CC(=O)C(NCCCCCCN(CC)Cc2ccco2)=CC1=O)Cc1ccco1', 'CCN(CCCCCCNC1=CC(=O)C(NCCCCCCN(CC)Cc2cccs2)=CC1=O)Cc1cccs1', 'CCN(CCCCCCNC1=CC(=O)C(NCCCCCCN(CC)Cc2ccccn2)=CC1=O)Cc1ccccn1', 'CCN(CCCCCCNC1=CC(=O)C(NCCCCCCN(CC)Cc2cccnc2)=CC1=O)Cc1cccnc1', 'CCN(CCCCCCNC1=CC(=O)C(NCCCCCCN(CC)Cc2ccncc2)=CC1=O)Cc1ccncc1', 'COc1ccccc1CNCCCCCCN1CCC(CCC2CCN(CCCCCCNCc3ccccc3OC)CC2)CC1', 'COc1ccccc1CNCCCCCC(=O)N1CCC(CCC2CCN(C(=O)CCCCCNCc3ccccc3OC)CC2)CC1', 'C/C=C1\\\\[C@H]2C=C(C)C[C@]1(N)c1ccc(=O)[nH]c1C2', 'C/C=C1\\\\[C@H]2C=C(C)C[C@]1(N)c1ccc(=O)[nH]c1C2', 'C/C=C1\\\\[C@H]2C=C(C)C[C@]1(N)c1ccc(=O)[nH]c1C2', 'C/C=C1\\\\[C@H]2C=C(C)C[C@]1(N)c1ccc(=O)[nH]c1C2', 'C/C=C1\\\\[C@H]2C=C(C)C[C@]1(N)c1ccc(=O)[nH]c1C2', 'C/C=C1\\\\[C@H]2C=C(C)C[C@]1(N)c1ccc(=O)[nH]c1C2', 'CC1=C[C@H]2Cc3[nH]c(=O)ccc3[C@]3(C1)NCCC[C@H]23', 'CC1=C[C@H]2Cc3[nH]c(=O)ccc3[C@]3(C1)NCCC[C@H]23', 'O=C(CCCNc1c2c(nc3ccccc13)CCCC2)CCCNc1c2c(nc3ccccc13)CCCC2', 'O=C(NCCNc1c2c(nc3ccccc13)CCCC2)C(=O)NCCNc1c2c(nc3ccccc13)CCCC2', 'c1ccc2c(NCCOCCOCCNc3c4c(nc5ccccc35)CCCC4)c3c(nc2c1)CCCC3', 'O=C(c1ccccc1)N1c2ccccc2Sc2ccccc21', 'COc1ccc(C(=O)N2c3ccccc3Sc3ccccc32)cc1', 'O=C(Cc1ccccc1)N1c2ccccc2Sc2ccccc21', 'O=C(CCc1ccccc1)N1c2ccccc2Sc2ccccc21', 'O=C(c1c2ccccc2cc2ccccc12)N1c2ccccc2Sc2ccccc21', 'O=C(c1c2ccccc2cc2ccccc12)N1c2ccccc2Sc2ccccc21', 'CC(C)C1=N[C@H]2CC=C3CC4C(=O)C[C@]5(C)[C@@H]([C@H](C)N(C)C)[C@H](O)C[C@@]5(C)[C@@H]4CC[C@H]3[C@]2(C)CO1', 'CC1=N[C@H]2CC=C3C[C@H]4C(=O)C[C@]5(C)[C@@H]([C@H](C)N(C)C)[C@H](O)C[C@@]5(C)[C@@H]4CC[C@H]3[C@]2(C)CO1', 'C[C@@H]([C@H]1[C@H](O)C[C@@]2(C)[C@@H]3CC[C@@H]4C(=CC[C@@H]5N=C(C(C)(C)C)OC[C@]54C)C[C@H]3C(=O)C[C@]12C)N(C)C', 'CC[C@H](C)C1=N[C@H]2CC=C3C[C@H]4C(=O)C[C@]5(C)[C@@H]([C@H](C)N(C)C)[C@H](O)C[C@@]5(C)[C@@H]4CC[C@H]3[C@]2(C)CO1', 'CC(C)C1=N[C@H]2CC=C3C[C@H]4C(=O)C[C@]5(C)[C@@H]([C@H](C)N(C)C)[C@H](OC(=O)C(C)(C)C)C[C@@]5(C)[C@@H]4CC[C@H]3[C@]2(C)CO1', 'CN[C@@H](C)[C@H]1[C@H](O)C[C@@]2(C)[C@@H]3CC[C@@H]4C(=CC[C@@H]5N=C(C(C)C)OC[C@]54C)C[C@H]3C(=O)C[C@]12C', 'CC(C)C1=N[C@H]2CC[C@]34C[C@]35C(=O)C[C@]3(C)[C@@H]([C@H](C)N(C)C)[C@H](O)C[C@@]3(C)[C@@H]5CC[C@H]4[C@]2(C)CN1', 'CC[C@H](C)C1=N[C@H]2CC[C@]34C[C@]35C(=O)C[C@]3(C)[C@@H]([C@H](C)N(C)C)[C@H](O)C[C@@]3(C)[C@@H]5CC[C@H]4[C@]2(C)CN1', 'CC[C@H](C)C1=N[C@H]2CC=C3C[C@H]4C(=O)C[C@]5(C)[C@@H]([C@H](C)N(C)C)[C@H](O)C[C@@]5(C)[C@@H]4CC[C@H]3[C@]2(C)CN1', 'NC(=O)c1cc[n+](CCC[n+]2ccc(/C=N/O)cc2)cc1.[Br-].[Br-]', 'NC(=O)c1cc[n+](CCC[n+]2ccc(/C=N/O)cc2)cc1.[Br-].[Br-]', 'NC(=O)c1cc[n+](CCC[n+]2ccc(/C=N/O)cc2)cc1.[Br-].[Br-]', 'NC(=O)c1cc[n+](C/C=C/C[n+]2ccc(/C=N/O)cc2)cc1.[Br-].[Br-]', 'NC(=O)c1cc[n+](C/C=C/C[n+]2ccc(/C=N/O)cc2)cc1.[Br-].[Br-]', 'O=C1C(=O)c2ccc([N+](=O)[O-])c3c([N+](=O)[O-])ccc1c23', 'CCCCC1=NC2(CCCC2)C(=O)N1Cc1cc(OC)c(OC)cc1Br', 'CCCCC1=NC2(CCCC2)C(=O)N1Cc1ccc([N+](=O)[O-])cc1', 'CCCCC1=NC2(CCCC2)C(=O)N1CCN1C(=O)c2ccccc2C1=O', 'CCCCC1=NC2(CCCC2)C(=O)N1Cc1cc2c(cc1C)OCO2', 'CCCCC1=NC2(CCCC2)C(=O)N1CC(=O)c1ccc(Cl)cc1', 'CCCCC1=NC2(CCCC2)C(=O)N1Cc1ccc(-c2ccccc2-n2nnnc2C(c2ccccc2)(c2ccccc2)c2ccccc2)cc1', 'CCCCC1=NC2(CCCC2)C(=O)N1Cc1ccc(Br)cc1', 'C/C(=C\\\\CC[C@@H](C)[C@H]1CC[C@@]2(C)C3=CC[C@H]4C(C)(C)[C@@H](O)CC[C@]4(C)C3=CC[C@]12C)CO', 'CC(C)=CCc1c(O)cc(O)c2c1O[C@H](c1ccccc1)CC2=O', 'CCOC(=O)C1=C(C)Oc2nc3c(c(N)c2C1c1ccc(C)cc1)CCCC3', 'CCOC(=O)C1=C(C)Oc2nc3c(c(N)c2C1c1ccc(OC)cc1)CCCC3', 'CCOC(=O)C1=C(C)Oc2nc3c(c(N)c2C1c1ccc(OC)cc1)CCCC3', 'CCOC(=O)c1c(C)nc2nc3c(c(N)c2c1-c1ccccc1)CCC3', 'CCOC(=O)c1c(C)nc2nc3c(c(N)c2c1-c1ccccc1)CCCC3', 'CCOC(=O)c1c(C)nc2nc3c(c(N)c2c1-c1ccccc1)CCCCC3', 'CCOC(=O)c1c(C)nc2nc3c(c(N)c2c1-c1ccc(OC)cc1)CCC3', 'CCOC(=O)c1c(C)nc2nc3c(c(N)c2c1-c1ccc(OC)cc1)CCCC3', 'CCOC(=O)c1c(C)nc2nc3c(c(N)c2c1-c1ccc(OC)cc1)CCCCC3', 'CCOC(=O)c1c(C)nc2nc3c(c(N)c2c1-c1cccc(OC)c1)CCCC3', 'CCOC(=O)c1c(C)nc2nc3c(c(N)c2c1-c1ccc(OC)c(OC)c1)CCCC3', 'CCOC(=O)c1c(C)nc2nc3c(c(N)c2c1-c1ccc(F)cc1)CCCC3', 'CCOC(=O)c1c(C)nc2nc3c(c(N)c2c1-c1ccc(F)cc1)CCCCC3', 'CCOC(=O)c1c(C)nc2nc3c(c(N)c2c1-c1ccc(Cl)cc1)CCCC3', 'CCOC(=O)c1c(C)nc2nc3c(c(N)c2c1-c1cccc([N+](=O)[O-])c1)CCCC3', 'CCOC(=O)c1c(C)nc2nc3c(c(N)c2c1-c1ccc(OC)c(OC)c1)CCCCC3', 'Cc1nc2nc3c(c(N)c2c(-c2ccccc2)c1C(=O)OC(C)C)CCCC3', 'CCOC(=O)c1c(C)nc2nc3c(c(N)c2c1-c1ccncc1)CCC3', 'CCOC(=O)c1c(C)nc2nc3c(c(N)c2c1-c1ccncc1)CCCC3', 'CCOC(=O)c1c(C)nc2nc3c(c(N)c2c1-c1ccncc1)CCCCC3', 'Oc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCNC2', 'COc1cc2c(cc1OC)[C@]1(OC2=O)[C@H](O)[C@@H](O)C=C2CCN(C)[C@H]21', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31[C@H](O)CN(C)C2', 'COc1ccc2c3c1O[C@H]1C[C@H](O)C=C[C@@]31[C@H](O)CN(C)C2', 'CN1CC[C@@]23C=C[C@H](O)C[C@@H]2Oc2c(O)ccc(c23)C1', 'COc1cc2c(cc1OC)-c1cccc3c1N(CC3)C2', 'CC(=O)O[C@H]1[C@H]2c3cc4c(cc3CN3CCC(=C[C@@H]1O)[C@H]23)OCO4', 'CC(=O)O[C@H]1[C@H]2c3cc4c(cc3CN3CCC(=C[C@@H]1O)[C@H]23)OCO4', 'C[N+](C)(C)CCOC(=O)Nc1cc(Cl)nc(Cl)c1.[I-]', 'CCN(CCCCCC(=O)N1CCC(C2CCN(C(=O)CCCCCN(CC)Cc3ccccc3OC)CC2)CC1)Cc1ccccc1OC', 'CCN(CCCCCC(=O)N1CCC(C2CCN(C(=O)CCCCCN(CC)Cc3ccccc3OC)CC2)CC1)Cc1ccccc1OC', 'CCN(CCCCCC(=O)Nc1ccc(-c2ccc(NC(=O)CCCCCN(CC)Cc3ccccc3OC)cc2)cc1)Cc1ccccc1OC', 'COc1ccccc1CNCCCNCCCNCCC[n+]1c(-c2ccccc2)c2cc(N)ccc2c2ccc(N)cc21', 'C#CCN[C@@H]1CCc2cc(Cl)c(OC(=O)N(C)CCC)cc21', 'C#CCN[C@@H]1CCc2ccc(OC(=O)N(C)CC)cc21', 'C#CCN[C@@H]1CCc2ccc(OC(=O)N(C)CC)cc21', 'C#CCN[C@@H]1CCc2ccc(OC(=O)N(C)CC)cc21', 'NCCCCCCCCNc1c2c(nc3ccccc13)CCCC2', 'CC[C@@]1(c2cccc(O)c2)CCCCN(CCCCCCCCCCN2CCCC[C@@](CC)(c3cccc(O)c3)C2)C1', 'CC[C@@]1(c2cccc(O)c2)CCCCN(CCCCCCCCCN2CCCC[C@@](CC)(c3cccc(O)c3)C2)C1', 'COc1ccc2c(c[n+](C)c3c4cc5c(cc4ccc23)OCO5)c1OC.[Cl-]', 'COc1ccc2c(c[n+](C)c3c4cc5c(cc4ccc23)OCO5)c1OC.[Cl-]', 'COc1ccc2c(c[n+](C)c3c4cc5c(cc4ccc23)OCO5)c1OC.[Cl-]', 'Cc1ccc2[nH]c3ccncc3c2c1', 'OCCC1CCN(Cc2ccc(OCCCN3CCCCC3)cc2)CC1', 'OCC1CCN(Cc2ccc(OCCCN3CCCCC3)cc2)CC1', 'CCN(Cc1ccccc1)Cc1ccc(-c2cc3cc(OCCNC(=O)Cc4cc(F)cc(F)c4)ccc3oc2=O)cc1', 'CCN(Cc1ccccc1)Cc1ccc(-c2cc3cc(OCCNC(=O)/C=C/c4cc(F)cc(F)c4)ccc3oc2=O)cc1', 'CCN(Cc1ccccc1)Cc1ccc(-c2cc3cc(OCCNC(=O)/C=C/c4cc(F)cc(F)c4)ccc3oc2=O)cc1', 'CCN(Cc1ccccc1)Cc1ccc(-c2cc3cc(OCCNC(=O)CCc4ccc(F)c(F)c4)ccc3oc2=O)cc1', 'CCN(Cc1ccccc1)Cc1ccc(-c2cc3ccc(OCCNC(=O)/C=C/c4cc(F)cc(F)c4)cc3oc2=O)cc1', 'CCN(Cc1ccccc1)Cc1ccc(-c2cc3ccc(OCCNC(=O)CCc4ccc(F)c(F)c4)cc3oc2=O)cc1', 'CCN(Cc1ccccc1)Cc1ccc(-c2cc3ccc(OCCNC(=O)/C=C/c4ccc(Cl)c(Cl)c4)cc3oc2=O)cc1', 'CCN(Cc1ccccc1)Cc1ccc(-c2cc3ccc(OCCNC(=O)Cc4cc(F)cc(F)c4)cc3oc2=O)cc1', 'O=C(CO/N=[N+](\\\\[O-])N1CCCC1)NCCCNc1c2c(nc3ccccc13)CCCC2', 'O=[N+]([O-])OCCCCCCNCCCCNc1c2c(nc3ccccc13)CCCC2', 'O=[N+]([O-])OCCCNCCCCNc1c2c(nc3ccccc13)CCCC2', 'O=[N+]([O-])OCCNCCCCNc1c2c(nc3ccccc13)CCCC2', 'O=[N+]([O-])OCCCCCCNCCCNc1c2c(nc3ccccc13)CCCC2', 'O=[N+]([O-])OCCCNCCCNc1c2c(nc3ccccc13)CCCC2', 'O=[N+]([O-])OCCNCCCNc1c2c(nc3ccccc13)CCCC2', 'O=C(CCO[N+](=O)[O-])NCCCCNc1c2c(nc3ccccc13)CCCC2', 'O=C(CO[N+](=O)[O-])NCCCCNc1c2c(nc3ccccc13)CCCC2', 'O=C(CCO[N+](=O)[O-])NCCCNc1c2c(nc3ccccc13)CCCC2', 'O=C(CO[N+](=O)[O-])NCCCNc1c2c(nc3ccccc13)CCCC2', 'CC(C)(C)C(=O)NCCCCNc1c2c(nc3ccccc13)CCCC2', 'CC(C)(CO[N+](=O)[O-])C(=O)NCCCCNc1c2c(nc3ccccc13)CCCC2', 'CC(C)(CO[N+](=O)[O-])C(=O)NCCCNc1c2c(nc3ccccc13)CCCC2', 'O=C(CO/N=[N+](\\\\[O-])N1CCCC1)NCCCCNc1c2c(nc3ccccc13)CCCC2', 'COc1cc2c3cc1Oc1c(O)c(OC)cc4c1[C@@H](Cc1ccc(O)c(c1)Oc1ccc(cc1)C[C@@H]3N(C)CC2)N(C)CC4', 'Br.COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'Br.COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'Br.COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(C)C2', 'COc1ccc2c(=O)oc3c(OC)cc(CCN(C)C)c4c(=O)oc1c2c34', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)CC[C@@]31CCN(C)C2', 'CC(C)=CCc1c(-c2ccc(O)cc2O)oc2c3c(cc(O)c2c1=O)OC(C)(C)C=C3', 'CC(C)=CCc1c(-c2ccc(O)cc2O)oc2c(CC=C(C)C)c(O)cc(O)c2c1=O', 'COc1cc([C@H]2OC[C@H]3[C@@H]2CO[C@@H]3c2cc(OC)c(OC)c(OC)c2)cc(OC)c1OC', 'CC(C)=CCOc1c2ccoc2cc2oc(=O)ccc12', 'CC(C)(O[C@@H]1O[C@H](CO)[C@@H](O)[C@H](O)[C@H]1O)[C@H]1Cc2cc3ccc(=O)oc3cc2O1', 'C=CC(=O)N1C/C(=C\\\\c2ccc(C)cc2)C(=O)/C(=C/c2ccc(C)cc2)C1', 'C=CC(=O)N1C/C(=C\\\\c2ccc(C)cc2)C(=O)/C(=C/c2ccc(C)cc2)C1', 'O=c1c2ccccc2nc2n1CCC2', 'O=c1c2ccccc2nc2n1CCC2', 'O=c1c2ccccc2nc2n1CCC2', 'CN(C)C(=O)Oc1cc(OC(=O)N(C)C)cc(C(O)CNC(C)(C)C)c1', 'CN(C)C(=O)Oc1cc(OC(=O)N(C)C)cc(C(O)CNC(C)(C)C)c1', 'CN(C)C(=O)Oc1cc(OC(=O)N(C)C)cc(C(O)CNC(C)(C)C)c1', 'COc1cc2c(cc1OC)C(=O)/C(=C/c1cccc(CN(C)C)c1)C2', 'COc1cc2c(cc1OC)C(=O)/C(=C/c1ccc(CN(C)C)cc1)C2', 'CCN(C)Cc1cccc(/C=C2\\\\Cc3cc(OC)c(OC)cc3C2=O)c1', 'CCN(C)Cc1ccc(/C=C2\\\\Cc3cc(OC)c(OC)cc3C2=O)cc1', 'CCN(CC)Cc1cccc(/C=C2\\\\Cc3cc(OC)c(OC)cc3C2=O)c1', 'CCN(CC)Cc1ccc(/C=C2\\\\Cc3cc(OC)c(OC)cc3C2=O)cc1', 'CCN(CC)Cc1ccc(/C=C2\\\\Cc3cc(OC)c(OC)cc3C2=O)cc1', 'COc1cc2c(cc1OC)C(=O)/C(=C/c1cccc(CN3CCCC3)c1)C2', 'COc1cc2c(cc1OC)C(=O)/C(=C/c1ccc(CN3CCCC3)cc1)C2', 'COc1cc2c(cc1OC)C(=O)/C(=C/c1cccc(CN3CCCCC3)c1)C2', 'COc1cc2c(cc1OC)C(=O)/C(=C/c1ccc(CN3CCCCC3)cc1)C2', 'COc1cc2c(cc1OC)C(=O)C(Cc1cccc(CN(C)C)c1)C2', 'COc1cc2c(cc1OC)C(=O)C(Cc1ccc(CN(C)C)cc1)C2', 'CCN(C)Cc1cccc(CC2Cc3cc(OC)c(OC)cc3C2=O)c1', 'CCN(C)Cc1ccc(CC2Cc3cc(OC)c(OC)cc3C2=O)cc1', 'CCN(CC)Cc1cccc(CC2Cc3cc(OC)c(OC)cc3C2=O)c1', 'CCN(CC)Cc1ccc(CC2Cc3cc(OC)c(OC)cc3C2=O)cc1', 'COc1cc2c(cc1OC)C(=O)C(Cc1cccc(CN3CCCC3)c1)C2', 'COc1cc2c(cc1OC)C(=O)C(Cc1ccc(CN3CCCC3)cc1)C2', 'COc1cc2c(cc1OC)C(=O)C(Cc1cccc(CN3CCCCC3)c1)C2', 'COc1cc2c(cc1OC)C(=O)C(Cc1ccc(CN3CCCCC3)cc1)C2', 'COc1ccc(-c2csc(NC(=O)CCN3CCCC3)n2)cc1', 'CCOC(=O)C1=C(C)Nc2nc3c(c(N)c2[C@@H]1c1ccc(OC)cc1)CCCC3', 'COc1ccccc1CN(C)Cc1ccc(C(=O)c2ccc(OC)c(OC)c2)cc1', 'COc1ccc(C(=O)c2ccc(CN(C)Cc3cccc(C)c3)cc2)cc1OC', 'CCN(Cc1ccccc1)Cc1ccc(C(=O)c2ccc(OC)c(OC)c2)cc1', 'COc1ccc(C(=O)c2ccc(CN(CCO)Cc3ccccc3)cc2)cc1OC', 'COc1ccc(C(=O)c2ccc(/C=C/CN(C)Cc3ccccc3)cc2)cc1OC', 'COc1ccc(C(=O)c2ccc(CN(C)Cc3ccccc3)cc2)cc1', 'COc1ccc(C(=O)c2ccc(CN(C)Cc3ccccc3)cc2)cc1', 'COc1ccc(C(=O)c2ccc(CN(C)Cc3ccccc3)cc2)cc1F', 'CN(Cc1ccccc1)Cc1ccc(C(=O)c2ccc3ccccc3c2)cc1', 'COc1ccc(C(=O)c2ccc(CN(CCN(C)C)Cc3ccccc3)cc2)cc1OC', 'CCOC(=O)C1=C(C)Nc2nc3c(c(N)c2C1c1ccccc1C(F)(F)F)CCCC3', 'CCOC(=O)C1=C(C)Nc2nc3c(c(N)c2C1c1ccc(-c2ccccc2)cc1)CCCC3', 'COc1ccc(C(=O)c2ccc(CN(C)Cc3ccccc3)cc2)cc1OC', 'CCOC(=O)C1=C(C)Nc2nc3c(c(N)c2C1c1ccc(OC)c(OC)c1)CCCC3', 'CCOC(=O)C1=C(C)Nc2nc3c(c(N)c2C1c1cccnc1)CCCC3', 'CCOC(=O)C1=C(C)Nc2nc3c(c(N)c2C1c1ccncc1)CCCC3', 'CCOC(=O)C1=C(C)Nc2nc3c(c(N)c2[C@H]1c1ccc(OC)cc1)CCCC3', 'CCOC(=O)C1=C(C)Nc2nc3c(c(N)c2[C@H]1c1ccc(OC)cc1)CCCC3', 'CCN(CC)Cc1ccc(C(=O)c2ccc(OC)c(OC)c2)cc1', 'COc1ccc(C(=O)c2ccc(CN(C)CCN(C)C)cc2)cc1OC', 'C#CCN(C)Cc1ccc(C(=O)c2ccc(OC)c(OC)c2)cc1', 'COc1ccc(C(=O)c2ccc(CN3CCc4ccccc4C3)cc2)cc1OC', 'COc1ccc(C(=O)c2ccc(CN(C)Cc3cccc([N+](=O)[O-])c3)cc2)cc1OC', 'C=CC[N+](C)(C)c1ccc(CCC(=O)CCc2ccc([N+](C)(C)CC=C)cc2)cc1.[Br-].[Br-]', 'C=CC[N+](C)(C)c1ccc(CCC(=O)CCc2ccc([N+](C)(C)CC=C)cc2)cc1.[Br-].[Br-]', 'C=CC[N+](C)(C)c1ccc(CCC(=O)CCc2ccc([N+](C)(C)CC=C)cc2)cc1.[Br-].[Br-]', 'C=CC[N+](C)(C)c1ccc(CCC(=O)CCc2ccc([N+](C)(C)CC=C)cc2)cc1.[Br-].[Br-]', 'C=CC[N+](C)(C)c1ccc(CCC(=O)CCc2ccc([N+](C)(C)CC=C)cc2)cc1.[Br-].[Br-]', 'C=CC[N+](C)(C)c1ccc(CCC(=O)CCc2ccc([N+](C)(C)CC=C)cc2)cc1.[Br-].[Br-]', 'C=CC[N+](C)(C)c1ccc(CCC(=O)CCc2ccc([N+](C)(C)CC=C)cc2)cc1.[Br-].[Br-]', 'C=CC[N+](C)(C)c1ccc(CCC(=O)CCc2ccc([N+](C)(C)CC=C)cc2)cc1.[Br-].[Br-]', 'C=CC[N+](C)(C)c1ccc(CCC(=O)CCc2ccc([N+](C)(C)CC=C)cc2)cc1.[Br-].[Br-]', 'C=CC[N+](C)(C)c1ccc(CCC(=O)CCc2ccc([N+](C)(C)CC=C)cc2)cc1.[Br-].[Br-]', 'C=CC[N+](C)(C)c1ccc(CCC(=O)CCc2ccc([N+](C)(C)CC=C)cc2)cc1.[Br-].[Br-]', 'C=CC[N+](C)(C)c1ccc(CCC(=O)CCc2ccc([N+](C)(C)CC=C)cc2)cc1.[Br-].[Br-]', 'C=CC[N+](C)(C)c1ccc(CCC(=O)CCc2ccc([N+](C)(C)CC=C)cc2)cc1.[Br-].[Br-]', 'COC(=O)CC[C@@H](C)[C@H]1CC(=O)[C@@]2(C)C3=C(C(=O)[C@@H](OC(C)=O)[C@]12C)[C@@]1(C)CC[C@H](O)C(C)(C)[C@@H]1CC3=O', 'C[C@H](CCC(=O)O)[C@H]1CC(=O)[C@@]2(C)C3=C(C(=O)C[C@]12C)[C@@]1(C)CCC(=O)C(C)(C)[C@@H]1C[C@@H]3O', 'CC(C)(O)[C@@H]1Cc2cc3ccc(=O)oc3cc2O1', 'C[C@H](CCC(=O)O)[C@H]1CC(=O)[C@@]2(C)C3=C(C(=O)C[C@]12C)[C@@]1(C)CC[C@H](O)C(C)(C)[C@@H]1C[C@@H]3O', 'C[C@H](CC(=O)C[C@@H](C)[C@H]1CC(=O)[C@@]2(C)C3=C(C(=O)C[C@]12C)[C@@]1(C)CCC(=O)C(C)(C)[C@@H]1CC3=O)C(=O)O', 'COc1cc([C@H]2Oc3cc(O)c(C/C=C(\\\\C)CCC=C(C)C)c(O)c3C(=O)[C@@H]2O)ccc1O', 'COc1cc([C@H]2Oc3cc(O)c(C/C=C(\\\\C)CCC=C(C)C)c(O)c3C(=O)[C@@H]2O)ccc1O', 'COc1ccccc1CNCCCCCCNCCCCCCCCNCCCCCCNCc1ccccc1OC.Cl.Cl.Cl.Cl', 'COc1ccc([C@H]2OC[C@H]3[C@@H]2CO[C@@H]3c2cc(OC)c(OC)c(OC)c2)cc1OC', 'Cc1ccc2c(c1)C(=O)C(=O)N2Cc1ccc(Br)cc1', '[O-]c1cc2c3c(c1)c1cc4c(cc1c[n+]3CC2)OCO4', 'CC1(C)Oc2cc3oc(=O)ccc3cc2C[C@@H]1O', 'C=C[C@@H]1[C@H]2C=C(C)C[C@]1(NC)c1ccc(=O)[nH]c1C2', 'O=C(CCCCCCCCc1ccc(O)cc1)c1c(O)cccc1O', 'O=C(CCCCCCCCc1ccc(O)cc1)c1c(O)cccc1O', 'O=C(CCCCCCCCc1ccc(O)c(O)c1)c1c(O)cccc1O', 'O=C(CCCCCCCCc1ccc(O)c(O)c1)c1c(O)cccc1O', 'O=C(OC[C@H]1O[C@@H](OC(=O)c2cc(O)c(O)c(O)c2)[C@H](OC(=O)c2cc(O)c(O)c(O)c2)[C@@H](OC(=O)c2cc(O)c(O)c(O)c2)[C@@H]1O)c1cc(O)c(O)c(O)c1', 'CN(CCCCCCCOc1ccc(-c2cc3ccccc3o2)cc1)Cc1ccccc1', 'CC(=O)c1c(-c2ccc(OCCCCCCCN(C)Cc3ccccc3)cc2)oc2ccccc12', 'CN(CCCCCCCOc1ccc(-c2oc3ccccc3c2C(=O)c2ccccc2)cc1)Cc1ccccc1', 'Cc1ccc(C(=O)c2c(-c3ccc(OCCCCCCCN(C)Cc4ccccc4)cc3)oc3ccccc23)cc1', 'Clc1ccc2c(NCCCNCC34CC5CC(CC(C5)C3)C4)ccnc2c1', 'CC1(C)CC(=O)C2=C(C1)Nc1nc3c(c(N)c1C2c1ccccc1)CCCC3', 'CC1(C)CC(=O)C2=C(C1)Nc1nc3c(c(N)c1C2c1ccc(F)cc1)CCCC3', 'Cc1ccc(C2C3=C(CC(C)(C)CC3=O)Nc3nc4c(c(N)c32)CCCC4)cc1', 'COc1ccc(C2C3=C(CC(C)(C)CC3=O)Nc3nc4c(c(N)c32)CCCC4)cc1', 'CC1(C)CC(=O)C2=C(C1)Nc1nc3c(c(N)c1C2c1ccncc1)CCCC3', 'Cc1ccc(Nc2nccc(N(C)c3ccc4c(C)n(C)nc4c3)n2)cc1S(N)(=O)=O', 'Clc1ccc2c(NCCCNCCCOc3cccc4[nH]c5ccccc5c34)c3c(nc2c1)CCCC3', 'Clc1ccc2c(NCCCNCCCCOc3cccc4[nH]c5ccccc5c34)c3c(nc2c1)CCCC3', 'Clc1ccc2c(NCCCNCCCCCOc3cccc4[nH]c5ccccc5c34)c3c(nc2c1)CCCC3', 'Clc1ccc2c(NCCCNCCCCCCOc3cccc4[nH]c5ccccc5c34)c3c(nc2c1)CCCC3', 'CN[C@@H](Cc1ccccc1)C(=O)NCC(=O)Nc1c2c(nc3ccccc13)CCCC2', 'N[C@@H](Cc1ccc2ccccc2c1)C(=O)NCC(=O)Nc1c2c(nc3ccccc13)CCCC2', 'O=C(CNC(=O)[C@@H]1Cc2ccccc2CN1)Nc1c2c(nc3ccccc13)CCCC2', 'N[C@@H](Cc1ccccc1)C(=O)NCC(=O)Nc1c2c(nc3ccccc13)CCCC2', 'N[C@@H](Cc1c[nH]c2ccccc12)C(=O)NCC(=O)Nc1c2c(nc3ccccc13)CCCC2', 'CN[C@@H](Cc1c[nH]c2ccccc12)C(=O)NCC(=O)Nc1c2c(nc3ccccc13)CCCC2', 'CC(C)(C)OC(=O)N[C@@H](Cc1c[nH]c2ccccc12)C(=O)NCCC(=O)Nc1c2c(nc3ccccc13)CCCC2', 'N[C@@H](Cc1c[nH]c2ccccc12)C(=O)NCCC(=O)Nc1c2c(nc3ccccc13)CCCC2', 'CC(C)(C)OC(=O)N[C@@H](Cc1c[nH]c2ccccc12)C(=O)NCCNc1c2c(nc3ccccc13)CCCC2', 'N[C@@H](Cc1c[nH]c2ccccc12)C(=O)NCCNc1c2c(nc3ccccc13)CCCC2', 'CC(C)(C)OC(=O)N[C@@H](CCC(=O)NCCNc1c2c(nc3ccccc13)CCCC2)C(=O)NCCNc1c2c(nc3ccccc13)CCCC2', 'N[C@@H](CCC(=O)NCCNc1c2c(nc3ccccc13)CCCC2)C(=O)NCCNc1c2c(nc3ccccc13)CCCC2', 'O=C(NCCCCCNc1c2c(nc3ccccc13)CCCC2)[C@@H]1CCCN1CCNc1c2c(nc3ccccc13)CCCC2', 'CO[C@@H]1[C@@H](O)[C@H]2c3cc4c(cc3CN3CC=C([C@H]1O)[C@H]23)OCO4', 'O=C(O)C(F)(F)F.O=C1C=C2S[C@H]3C[C@]2(C=C1Br)C1=C(N3)C(=O)c2[nH]cc3c2C1=NCC3', 'O=C(O)C(F)(F)F.O=C1C=C2S[C@H]3C[C@]2(C=C1Br)C1=C(N3)C(=O)c2[nH]cc3c2C1=NCC3', 'Cl.Nc1c2c(nc3ccccc13)CCCC2', 'Cl.Nc1c2c(nc3ccccc13)CCCC2', 'Cl.Nc1c2c(nc3ccccc13)CCCC2', 'Cl.Nc1c2c(nc3ccccc13)CCCC2', 'Cl.Nc1c2c(nc3ccccc13)CCCC2', 'Cl.Nc1c2c(nc3ccccc13)CCCC2', 'Cl.Nc1c2c(nc3ccccc13)CCCC2', 'Cl.Nc1c2c(nc3ccccc13)CCCC2', 'Cl.Nc1c2c(nc3ccccc13)CCCC2', 'Cl.Nc1c2c(nc3ccccc13)CCCC2', 'Cl.Nc1c2c(nc3cc(Cl)ccc13)CCCC2', 'Cl.Nc1c2c(nc3cc(Cl)ccc13)CCCC2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2.Cl', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2.Cl', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2.Cl', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2.Cl', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2.Cl', 'CC(=O)N(CCCCNc1c2c(nc3ccccc13)CCCC2)CCCSc1c2c(nc3ccccc13)CCCC2', 'CC(=O)N(CCCCNc1c2c(nc3ccccc13)CCCC2)CCCSc1c2c(nc3ccccc13)CCCC2', 'c1ccc2c(NCCCCNCCCSc3c4c(nc5ccccc35)CCCC4)c3c(nc2c1)CCCC3', 'CC(=O)N(CCCCNc1c2c(nc3ccccc13)CCCC2)CCCNc1c2c(nc3ccccc13)CCCC2', 'CN(CCCCNc1c2c(nc3ccccc13)CCCC2)CCCNc1c2c(nc3ccccc13)CCCC2', 'CN(CCCCNc1c2c(nc3ccccc13)CCCC2)CCCNc1c2c(nc3ccccc13)CCCC2', 'CCN(CCCCNc1c2c(nc3ccccc13)CCCC2)CCCNc1c2c(nc3ccccc13)CCCC2', 'C=CCN(CCCCNc1c2c(nc3ccccc13)CCCC2)CCCNc1c2c(nc3ccccc13)CCCC2', 'OCCN(CCCCNc1c2c(nc3ccccc13)CCCC2)CCCNc1c2c(nc3ccccc13)CCCC2', 'c1ccc2c(NCCCN3CCN(CCCNc4c5c(nc6ccccc46)CCCC5)CC3)c3c(nc2c1)CCCC3', 'c1cc(CCNc2c3c(nc4ccccc24)CCCC3)cc(CCNc2c3c(nc4ccccc24)CCCC3)c1', 'c1cc(CCNc2c3c(nc4ccccc24)CCCC3)nc(CCNc2c3c(nc4ccccc24)CCCC3)c1', 'c1ccc2c(NCCc3ccc(CCNc4c5c(nc6ccccc46)CCCC5)cc3)c3c(nc2c1)CCCC3', 'Cc1cc(CCNc2c3c(nc4ccccc24)CCCC3)cc(CCNc2c3c(nc4ccccc24)CCCC3)c1', 'c1ccc2c(NCCc3cocc3CCNc3c4c(nc5ccccc35)CCCC4)c3c(nc2c1)CCCC3', 'CCOP(=O)(C#N)N(C)C', 'CCc1ccccc1NC(=O)Oc1ccc2c(c1)[C@]1(C)CC[N+](C)([O-])[C@@H]1N2C', 'CC(C)=CC(=O)N[C@H]1CC[C@@]2(C)[C@@H](CC[C@@H]3[C@@H]2CC[C@]2(C)C([C@H](C)N(C)C)=CC[C@@H]32)[C@H]1O', 'C[C@@H]([C@H]1CC=C2[C@@H]3CCC4=C[C@@H](N(C)C)CC[C@]4(C)[C@H]3CC[C@@]21C)N(C)C', 'C[C@@H]([C@H]1CC[C@H]2[C@@H]3CC[C@H]4C[C@@H](N)CC[C@]4(C)[C@H]3CC[C@]12C)N(C)C', 'C[C@@H]([C@H]1CC[C@H]2[C@@H]3CC[C@H]4C[C@@H](N(C)C)CC[C@]4(C)[C@H]3CC[C@]12C)N(C)C', 'CN[C@@H](C)[C@H]1CC[C@H]2[C@@H]3CC=C4C(=O)[C@@H](NC(=O)C=C(C)C)CC[C@]4(C)[C@H]3CC[C@]12C', 'C/C=C(\\\\C)C(=O)N[C@H]1CC[C@]2(C)[C@H]3CC[C@]4(C)[C@@H]([C@H](C)NC)CC[C@H]4[C@@H]3CC[C@H]2[C@H]1OC(C)=O', 'Oc1cccc(C2=Nc3ccccc3SC(c3ccc(Cl)cc3)C2)c1', 'Oc1cccc(C2=Nc3ccccc3SC(c3ccccc3F)C2)c1', 'Oc1cccc(C2=Nc3ccccc3SC(c3cccc(O)c3)C2)c1', 'Cc1ccc(C2CC(c3cccc(O)c3)=Nc3ccccc3S2)cc1', 'Oc1cccc(C2=Nc3ccccc3SC(c3cccs3)C2)c1', 'Oc1cccc(C2=Nc3ccccc3SC(c3ccccc3)C2)c1', 'CCN(CCCCCC(=O)N1CCN(C(=O)CCCCCN(CC)Cc2ccccc2OC)CC1)Cc1ccccc1OC', 'CCN(CCCCCC(=O)N[C@H]1CCCC[C@H]1NC(=O)CCCCCN(CC)Cc1ccccc1OC)Cc1ccccc1OC', 'CCN(CCCCCC(=O)N[C@H]1CCCC[C@@H]1NC(=O)CCCCCN(CC)Cc1ccccc1OC)Cc1ccccc1OC', 'CCN(CCCCCC(=O)N[C@H]1CC[C@H](NC(=O)CCCCCN(CC)Cc2ccccc2OC)CC1)Cc1ccccc1OC', 'CCN(CCCCCC(=O)N1Cc2ccc3c4c(ccc(c24)C1)CN(C(=O)CCCCCN(CC)Cc1ccccc1OC)C3)Cc1ccccc1OC', 'CCN(CCCCCCN1CCN(CCCCCCN(CC)Cc2ccccc2OC)C(=O)C1=O)Cc1ccccc1OC', 'CCN(CCCCCCN1CC(=O)N(CCCCCCN(CC)Cc2ccccc2OC)CC1=O)Cc1ccccc1OC', 'CCN(CCCCCCn1c(=O)c(=O)n(CCCCCCN(CC)Cc2ccccc2OC)c2ccccc21)Cc1ccccc1OC', 'CCN(CCCCCCN1CCN(CCCCCCN(CC)Cc2ccccc2OC)C1=O)Cc1ccccc1OC', 'CCN(CCCCCCN1C(=O)c2ccc(-c3ccc4c(c3)C(=O)N(CCCCCCN(CC)Cc3ccccc3OC)C4=O)cc2C1=O)Cc1ccccc1OC', 'CCN(CCCCCCn1c(=O)c2cc3c(=O)n(CCCCCCN(CC)Cc4ccccc4OC)c(=O)c3cc2c1=O)Cc1ccccc1OC', 'CCN(CCCCCCN1C(=O)c2ccc3c4c(ccc(c24)C1=O)C(=O)N(CCCCCCN(CC)Cc1ccccc1OC)C3=O)Cc1ccccc1OC', 'CCN(CCCCCCN1C(=O)c2ccc3c4c(ccc(c24)C1=O)C(=O)N(CCCCCCN(CC)Cc1ccccc1OC)C3=O)Cc1ccccc1OC', 'CCN(CCCCCCN1C(=O)c2cccc3cccc(c23)C1=O)Cc1ccccc1OC', 'CCn1c(C)nc2cc(C(=O)CCC3CCN(Cc4ccccc4)CC3)ccc21.Cl', 'Cc1nc2cc(C(=O)CCC3CCN(Cc4ccccc4)CC3)ccc2[nH]1.Cl', 'Cc1nc2ccc(C(=O)CCC3CCN(Cc4ccccc4)CC3)cc2s1.Cl', 'Cl.O=C(CCC1CCN(Cc2ccccc2)CC1)c1ccccc1', 'CNC(=O)Oc1cccc(CN(C)CCCOc2cccc(Cc3ccccc3)c2)c1.Cl', 'CNC(=O)Oc1cccc(CN(C)CCCOc2ccc(C(=O)c3ccccc3)cc2)c1.Cl', 'CNC(=O)Oc1cccc(CN(C)CCCCCCCCCCOc2ccc3c(=O)c4ccccc4oc3c2)c1.Cl', 'CNC(=O)Oc1cccc(CN(C)CC#CCOc2ccc3c(=O)c4ccccc4oc3c2)c1.Cl', 'CNC(=O)Oc1cccc(CN(C)CCCOc2ccc3ccccc3c2)c1.Cl', 'CNC(=O)Oc1cccc(CN(C)CCCCCCCCCOc2ccc3c(=O)c4ccccc4oc3c2)c1.Cl', 'CNC(=O)Oc1cccc(CN(C)CCCCCCCOc2ccc3c(=O)c4ccccc4oc3c2)c1.Cl', 'CCC1=CC2CC(C1)Cc1nc3ccccc3c(N)c12.Cl', 'CCN(C)C(=O)Oc1cccc2c1C(N)CC2.Cl', 'C#CCNC1CCc2cccc(OC(=O)N(C)CCC)c21.Cl', 'C#CCNC1CCc2ccc(OC(=O)N(C)C3CCCCC3)cc21.Cl', 'C#CCNC1CCc2ccc(OC(=O)N(C)c3ccccc3)cc21.Cl', 'COc1ccc(N(C)C(=O)Oc2ccc3c(c2)C(N)CC3)cc1.Cl', 'C#CCNC1CCc2ccc(OC(=O)NCCC)cc21.Cl', 'CCCCCCN(C)C(=O)Oc1ccc2c(c1)C(N)CC2.Cl', 'C#CCN(C)C1CCc2cccc(OC(=O)N(C)C)c21.Cl', 'C#CCNC1CCc2ccc(OC(=O)N(C)CCCCCC)cc21.Cl', 'CCN(C)C(=O)Oc1ccc2c(c1)C(N)CC2.Cl', 'CN(C)C(=O)Oc1ccc2c(c1)C(N)CC2.Cl', 'C#CCN(CC)C1CCc2ccc(OC(=O)N(C)C)cc21.Cl', 'C#CCNC1CCc2ccc(OC(=O)N(CC)C3CCCCC3)cc21.Cl', 'C#CCNC1CCc2ccc(OC(=O)NCC)cc21.Cl', 'CCCNC(=O)Oc1ccc2c(c1)C(N)CC2.Cl', 'CN(C)C(=O)Oc1cccc2c1CCC2N.Cl', 'C#CCNC1CCc2ccc(OC(=O)N(C)C)cc21.Cl', 'C#CCNC1CCc2c(Cl)cc(OC(=O)N(C)CC)cc21.Cl', 'CN(C(=O)Oc1ccc2c(c1)C(N)CC2)C1CCCCC1.Cl', 'CCN(C)C(=O)Oc1cccc2c1CCC2N.Cl', 'CN(C)C(=O)Oc1cccc2c1CCC2N(C)C.Cl', 'C#CCNC1CCc2ccc(OC(=O)N(C)CC)cc21.Cl', 'CNC1CCc2ccc(OC(=O)N(C)C)cc21.Cl', 'C#CCNC1CCc2ccc(OC(=O)N(C)CCC)cc21.Cl', 'C#CCNC1CCc2c(OC(=O)N(C)CC)cccc21.Cl', 'CCNC1CCc2ccc(OC(=O)N(C)C)cc21.Cl', 'CCN(C)C(=O)Oc1ccc2c(c1)C(NC)CC2.Cl', 'C#CCNC1CCc2ccc(OC(=O)N(C)Cc3ccccc3)cc21.Cl', 'C#CCNC1CCc2ccc(OC(=O)N(C)c3ccc(OC)cc3)cc21.Cl', 'C#CCNC1CCc2c(OC(=O)N(C)C)cccc21.Cl', 'C#CCN(C)C1CCc2c(OC(=O)N(C)CC)cccc21.Cl', 'CCNC(=O)Oc1ccc2c(c1)C(N)CC2.Cl', 'CCCN(C)C(=O)Oc1ccc2c(c1)C(N)CC2.Cl', 'CN(C)C(=O)Oc1ccc2c(c1)C(N(C)C)CC2.Cl', 'Cl.c1ccc(-c2ccc(NCCCCCN3CCc4ccccc4C3)nn2)cc1', 'CCC1=CC2Cc3nc4ccccc4c(NCCCCCCCCNc4c5c(nc6ccccc46)CCCC5)c3C(C1)C2.Cl.Cl', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(N)c3C(C1)C2.Cl', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(N)c3C(C1)C2.Cl', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(N)c3C(C1)C2.Cl', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(N)c3C(C1)C2.Cl', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(N)c3C(C1)C2.Cl', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(N)c3C(C1)C2.Cl', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(NCCCCCCCNc4c5c(nc6ccccc46)CCCC5)c3C(C1)C2.Cl.Cl', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(NCCCCCCCCNc4c5c(nc6ccccc46)CCCC5)c3C(C1)C2.Cl.Cl', 'COc1ccccc1CN(C)CCCCCC(=O)N(C)CCCCCCCCN(C)C(=O)CCCCCN(C)Cc1ccccc1OC.Cl.Cl', 'Cl.O=C(CCC1CCN(Cc2ccccc2)CC1)c1ccc2[nH]c(-c3ccccc3)nc2c1', 'Cl.O=C(CCC1CCN(Cc2ccccc2)CC1)c1ccc2c(c1)OCCO2', 'Cc1c(C(=O)NN2CCCCC2)nn(-c2ccc(Cl)cc2Cl)c1-c1ccc(Cl)cc1.Cl', 'CNC(=O)Oc1ccc2c(c1)CN(CCCOc1ccc3c(=O)c4ccccc4oc3c1)CC2.Cl', 'CNC(=O)Oc1cccc(CN(C)CCCCCCCCOc2ccc3c(=O)c4ccccc4oc3c2)c1.Cl', 'CNC(=O)Oc1cccc(CN(C)CCCOc2ccccc2)c1.Cl', 'CCC1=CC2Cc3nc4ccccc4c(N)c3C(C1)C2.Cl', 'CC1=CC2Cc3nc4ccccc4c(N)c3C(C1)C2.Cl', 'C#CCNC1CCc2cccc(OC(=O)N(C)C)c21.Cl', 'C#CCN(C)C1CCc2ccc(OC(=O)N(C)C)cc21.Cl', 'C#CCNC1CCc2ccc(OC(=O)N(CC)CCCC)cc21.Cl', 'CN(CCCCCNc1ccc(-c2ccccc2)nn1)Cc1ccccc1.Cl', 'C#CCNC1CCc2ccc(OC(=O)N(C)CCCC)cc21.Cl', 'CN(C)C(=O)Oc1cccc2c1C(N)CC2.Cl', 'CC1=CC2CC(C1)Cc1nc3ccccc3c(N)c12.Cl', 'CNC1CCc2cccc(OC(=O)N(C)C)c21.Cl', 'CCCNC1CCc2ccc(OC(=O)N(C)CC)cc21.Cl', 'C#CCNC1CCc2c(Cl)cc(OC(=O)N(C)CCC)cc21.Cl', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(NCCCCCCNc4c5c(nc6ccccc46)CCCC5)c3C(C1)C2.Cl.Cl', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(NCCCCCCNc4c5c(nc6cc(Cl)ccc46)CCCC5)c3C(C1)C2.Cl.Cl', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(NCCCCCCCNc4c5c(nc6cc(Cl)ccc46)CCCC5)c3C(C1)C2.Cl.Cl', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(NCCCCCCCCNc4c5c(nc6cc(Cl)ccc46)CCCC5)c3C(C1)C2.Cl.Cl', 'C[n+]1ccn(CCN2CCCC2)c1/C=N/O.[Cl-]', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CC[N@@+](C)([O-])[C@@H]1N2C.Cl', 'CN1c2ccc(OC(=O)Nc3ccccc3)cc2[C@]2(C)CC[N@@+](C)([O-])[C@H]12.Cl', 'Cc1ccccc1NC(=O)Oc1ccc2c(c1)[C@]1(C)CC[N@@+](C)([O-])[C@@H]1N2C.Cl', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CC[N+](C)(C)C1N2C.COS(=O)(=O)[O-]', 'CCc1ccccc1NC(=O)Oc1ccc2c(c1)[C@]1(C)CC[N+](C)([O-])[C@@H]1N2C.Cl', 'CC[N+](CC)(CC)CCOc1ccc(C(=O)NCCCCCC(=O)NNc2c3c(nc4cc(Cl)ccc24)CCCC3)cc1.[Br-]', 'CC[N+](CC)(CC)CCOc1cc(OCC[N+](CC)(CC)CC)cc(C(=O)NCCCCCC(=O)NNc2c3c(nc4cc(Cl)ccc24)CCCC3)c1.[Br-].[Br-]', 'CC[N+](CC)(CC)CCOc1cc(OCC[N+](CC)(CC)CC)c(C(=O)NCCCCCC(=O)NNc2c3c(nc4cc(Cl)ccc24)CCCC3)cc1OCC[N+](CC)(CC)CC.[Br-].[Br-].[Br-]', 'CCc1ccccc1NC(=O)Oc1ccc2c(c1)[C@]1(C)CC[N@@+](C)([O-])[C@@H]1N2C.Cl', 'Cn1cc[n+](COC[n+]2ccccc2/C=N/O)c1/C=N/O.[Cl-].[Cl-]', 'C=C1C[C@]23C[C@H]1CC[C@H]2[C@]1(C)CCC[C@](C)(CO)[C@@H]1C[C@@H]3O', 'CCN(CCCCCCNC1=CC(=O)C(NCCCCCCN(CC)[C@@H](C)c2ccccc2OC)=CC1=O)[C@H](C)c1ccccc1OC', 'CCN(CCCCCCNC1=CC(=O)C(NCCCCCCN(CC)[C@@H](C)c2ccccc2OC)=CC1=O)[C@H](C)c1ccccc1OC', 'CCN(CCCCCCNC1=CC(=O)C(NCCCCCCN(CC)[C@H](C)c2ccccc2OC)=CC1=O)[C@H](C)c1ccccc1OC', 'CCN(CCCCCCNC1=CC(=O)C(NCCCCCCN(CC)[C@H](C)c2ccccc2OC)=CC1=O)[C@H](C)c1ccccc1OC', 'C[C@]1(CO)CCC[C@]2(C)[C@H]1C[C@H](O)[C@@]13C[C@@H](CC[C@@H]21)[C@]1(C)O[C@@H]13', 'CC(=O)O[C@H]1[C@H]2c3cc4c(cc3CN3CCC(=C[C@@H]1O[Si](C)(C)C(C)(C)C)[C@H]23)OCO4', 'CCN(CCCCCCNC1=CC(=O)C(NCCCCCCN(CC)[C@@H](C)c2ccccc2OC)=CC1=O)[C@@H](C)c1ccccc1OC', 'CCN(CCCCCCNC1=CC(=O)C(NCCCCCCN(CC)[C@@H](C)c2ccccc2OC)=CC1=O)[C@@H](C)c1ccccc1OC', 'CC(C)(C)[Si](C)(C)O[C@H]1C=C2CCN3Cc4cc5c(cc4[C@H]([C@@H]1O)[C@@H]23)OCO5', 'CC1=CC2Cc3nc4oc(C)c(C)c4c(N)c3C(C1)C2', 'CCC1=CC2Cc3nc4oc(C)c(C)c4c(N)c3C(C1)C2', 'CC1=CC2Cc3nc4oc(C5CC5)nc4c(N)c3C(C1)C2', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(NCCN=[N+]=[N-])c3C(C1)C2', 'CCC1=CC2Cc3nc4cc(Cl)ccc4c(NCCN=[N+]=[N-])c3C(C1)C2', 'C#CCCCCCCN1CCc2cc(OC)c(OC)cc2C1c1cccc([N+](=O)[O-])c1', 'CCC1=CC2Cc3nc4oc(C5CC5)nc4c(N)c3C(C1)C2', 'CC1=CC2Cc3nc4oc(C5CCC5)nc4c(N)c3C(C1)C2', 'COc1cc2c(cc1OC)C(c1cccc([N+](=O)[O-])c1)N(CCCCCCc1cn(CCNc3c4c(nc5cc(Cl)ccc35)CC3C=C(C)CC4C3)nn1)CC2', 'CCC1=CC2Cc3nc4cc(Cl)ccc4c(NCCn4cc(CCCCCCN5CCc6cc(OC)c(OC)cc6C5c5cccc([N+](=O)[O-])c5)nn4)c3C(C1)C2', 'CCCSc1nc2nc3c(c(N)c2s1)C1CC(C)=CC(C3)C1', 'CCCSc1nc2nc3c(c(N)c2s1)C1CC(CC)=CC(C3)C1', 'CSc1n[nH]c2nc3c(c(N)c12)C1CC(C)=CC(C3)C1', 'CC1=CC2Cc3nc4[nH]ncc4c(N)c3C(C1)C2', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(NC(=O)CCl)c3C(C1)C2', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(O)c3C(C1)C2', 'C#CCCCCCCN1CCc2cc(OC)c(OC)cc2C1c1ccc([N+](=O)[O-])cc1', 'COc1cc2nc3c(c(N)c2cc1OC)C1CC(C)=CC(C3)C1', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(Cl)c3C(C1)C2', 'CCC1=CC2Cc3nc4cc(Cl)ccc4c(Cl)c3C(C1)C2', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(NCCO)c3C(C1)C2', 'CCC1=CC2Cc3nc4cc(OC)c(OC)cc4c(N)c3C(C1)C2', 'CCC1=CC2Cc3nc4cc(Cl)ccc4c(NCCO)c3C(C1)C2', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(NCCCl)c3C(C1)C2', 'CC1=CC2Cc3nc4ncccc4c(N)c3C(C1)C2', 'CCC1=CC2Cc3nc4ncccc4c(N)c3C(C1)C2', 'CCC1=CC2Cc3nc4cnccc4c(N)c3C(C1)C2', 'C[C@@H]1CCC[C@H](C)N1S(C)(=O)=O', 'C[C@@H]1CCC[C@H](C)N1S(=O)(=O)c1ccc(Cl)cc1', 'C[C@@H]1CCC[C@H](C)N1S(=O)(=O)c1cc(Cl)ccc1Cl', 'C[C@@H]1CCC[C@H](C)N1S(=O)(=O)c1ccccc1', 'Cc1ccc(S(=O)(=O)N2[C@H](C)CCC[C@@H]2C)cc1', 'C[C@@H]1CCC[C@H](C)N1S(=O)(=O)c1ccc(C(C)(C)C)cc1', 'C[C@@H]1CCC[C@H](C)N1S(=O)(=O)c1ccccc1[N+](=O)[O-]', 'C[C@@H]1CCC[C@H](C)N1S(=O)(=O)c1cccc([N+](=O)[O-])c1', 'C[C@@H]1CCC[C@H](C)N1S(=O)(=O)c1ccc([N+](=O)[O-])cc1', 'CCN(CCCCCCNC1=CC(=O)C(NCCCCCCNC(=O)CCCCC2CCSS2)=CC1=O)Cc1ccccc1OC', 'CCN(CCCCCCNC1=CC(=O)C(NCCCNC(=O)CCCCC2CCSS2)=CC1=O)Cc1ccccc1OC', 'CCN(CCCNC1=CC(=O)C(NCCCCCCNC(=O)CCCCC2CCSS2)=CC1=O)Cc1ccccc1OC', 'CCN(CCCNC1=CC(=O)C(NCCCNC(=O)CCCCC2CCSS2)=CC1=O)Cc1ccccc1OC', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(CCCN1CCCCC1)C2', 'O=S(=O)(/N=C(\\\\NCCCCNc1c2c(nc3ccccc13)CCCC2)N1CC(c2ccccc2)C(c2ccc(Cl)cc2)=N1)c1ccc(Cl)cc1', 'O=S(=O)(/N=C(\\\\NCCCCCCCNc1c2c(nc3ccccc13)CCCC2)N1CC(c2ccccc2)C(c2ccc(Cl)cc2)=N1)c1ccc(Cl)cc1', 'CCc1c(C(=O)NCCCCNc2c3c(nc4ccccc24)CCCC3)nc(-c2ccccc2Cl)n1-c1ccc(Cl)cc1', 'CCc1c(C(=O)NCCCCCCCNc2c3c(nc4ccccc24)CCCC3)nc(-c2ccccc2Cl)n1-c1ccc(Cl)cc1', 'C[n+]1c(/C=C/c2ccc(F)cc2)ccc2ccccc21.[I-]', 'CCSc1nc2sc3c(c2c(=O)n1-c1ccccc1)CCN(Cc1ccccc1)C3', 'Cc1ccc2c(c1)c1c(n2CCc2ccc(C)nc2)CCN(C)C1', 'COc1cc2occ(-c3ccc(N4CCCC4)cc3)c(=O)c2cc1OC', 'C/C=C1\\\\[C@H]2C=C(C)C[C@]1(/N=C/c1ccc(OC)cc1)c1ccc(=O)[nH]c1C2', 'C/C=C1\\\\[C@H]2C=C(C)C[C@]1(/N=C/c1ccc(O)c(OCC)c1)c1ccc(=O)[nH]c1C2', 'C/C=C1\\\\[C@H]2C=C(C)C[C@]1(/N=C/c1cc(OC)cc(OC)c1)c1ccc(=O)[nH]c1C2', 'C/C=C1\\\\[C@H]2C=C(C)C[C@]1(/N=C/c1ccc(OC)cc1OC)c1ccc(=O)[nH]c1C2', 'C/C=C1\\\\[C@H]2C=C(C)C[C@]1(/N=C/c1ccc(C#N)cc1)c1ccc(=O)[nH]c1C2', 'C/C=C1\\\\[C@H]2C=C(C)C[C@]1(/N=C/C=C/c1ccccc1)c1ccc(=O)[nH]c1C2', 'C/C=C1\\\\[C@H]2C=C(C)C[C@]1(/N=C/C(=C/c1ccccc1)CCCCC)c1ccc(=O)[nH]c1C2', 'C/C=C1\\\\[C@H]2C=C(C)C[C@]1(/N=C/C(C)=C/c1ccccc1)c1ccc(=O)[nH]c1C2', 'C/C=C1\\\\[C@H]2C=C(C)C[C@]1(/N=C/C=C/c1ccc(N(C)C)cc1)c1ccc(=O)[nH]c1C2', 'C/C=C1\\\\[C@H]2C=C(C)C[C@]1(/N=C/c1ccccc1OS(=O)(=O)[O-])c1ccc(=O)[nH]c1C2.[Na+]', 'C=CCOc1ccc(/C=N/[C@@]23CC(C)=C[C@@H](Cc4[nH]c(=O)ccc42)/C3=C\\\\C)cc1', 'C/C=C1\\\\[C@H]2C=C(C)C[C@]1(/N=C/c1ccc(O)c(OC)c1)c1ccc(=O)[nH]c1C2', 'C/C=C1\\\\[C@H]2C=C(C)C[C@]1(/N=C/c1ccc(N(C)C)cc1)c1ccc(=O)[nH]c1C2', 'COc1ccc(/C=C2\\\\Oc3ccccc3C2=O)cc1', 'CC(C)(C)c1cc[n+](CCCCCCCCCCCC[n+]2ccc(C(C)(C)C)cc2)cc1.[Br-].[Br-]', 'NC(=O)c1cc[n+](C/C=C/C[n+]2ccc(/C=N/O)c(F)c2)cc1.[Br-].[Br-]', 'Cn1ccc2nc3ccccc3c-2c1.I', 'COc1cc2c(cc1OC)C(=O)/C(=C/c1ccc(CN(C)Cc3ccccc3)cc1)C2', 'COc1ccc2c(c1)C/C(=C\\\\c1ccc(CN(C)Cc3ccccc3)cc1)C2=O', 'Clc1cccc(Cl)c1CO/N=C/c1cc[n+](CCC[n+]2ccc(/C=N/OCc3c(Cl)cccc3Cl)cc2)cc1.[Br-].[Br-]', 'COc1ccc2c(c1)C(=O)/C(=C/c1ccc(CN(C)Cc3ccccc3)cc1)C2', 'CCN(Cc1ccccc1)Cc1ccc(/C=C2\\\\Cc3ccc(OC)cc3C2=O)cc1', 'CN(Cc1ccccc1)Cc1ccc(/C=C2\\\\Cc3ccccc3C2=O)cc1', 'CCN(CC)CCOc1ccc2c(c1)C/C(=C\\\\c1ccc(CN(C)Cc3ccccc3)cc1)C2=O', 'CCN(CC)CCCOc1ccc2c(c1)C/C(=C\\\\c1ccc(CN(C)Cc3ccccc3)cc1)C2=O', 'CCN(CC)CCCCOc1ccc2c(c1)C/C(=C\\\\c1ccc(CN(C)Cc3ccccc3)cc1)C2=O', 'CCN(CC)CCOc1ccc2c(c1)C(=O)/C(=C/c1ccc(CN(C)Cc3ccccc3)cc1)C2', 'CCN(CC)CCCOc1ccc2c(c1)C(=O)/C(=C/c1ccc(CN(C)Cc3ccccc3)cc1)C2', 'CCN(CC)CCCCOc1ccc2c(c1)C(=O)/C(=C/c1ccc(CN(C)Cc3ccccc3)cc1)C2', 'CN(Cc1ccccc1)Cc1ccc(/C=C2\\\\Cc3ccc(OCCCCN4CCOCC4)cc3C2=O)cc1', 'CN(Cc1ccccc1)Cc1ccc(/C=C2\\\\Cc3ccc(OCCCCN4CCCCC4)cc3C2=O)cc1', 'CCN(CC)CCCCCOc1ccc2c(c1)C(=O)/C(=C/c1ccc(CN(C)Cc3ccccc3)cc1)C2', 'CN(Cc1ccccc1)Cc1ccc(/C=C2\\\\Cc3ccc(OCCCCCN4CCCCC4)cc3C2=O)cc1', 'CN(Cc1ccccc1)Cc1ccc(/C=C2\\\\Cc3ccc(OCCCCCN4CCCCC4)cc3C2=O)cc1', 'CCN(CC)CCCCCCOc1ccc2c(c1)C(=O)/C(=C/c1ccc(CN(C)Cc3ccccc3)cc1)C2', 'CCN(CC)CCCCCCCOc1ccc2c(c1)C(=O)/C(=C/c1ccc(CN(C)Cc3ccccc3)cc1)C2', 'COc1ccc2c(c1)CC/C(=C\\\\c1ccc(CN(C)Cc3ccccc3)cc1)C2=O', 'COc1ccc2c(c1)C(=O)/C(=C/c1ccc(CN(C)Cc3ccccc3)cc1)CC2', 'COc1cc2c(cc1OC)C(=O)/C(=C/c1ccc(CN(C)Cc3ccccc3)cc1)CC2', 'CCN(CC)CCCCCOc1ccc2c(c1)CC/C(=C\\\\c1ccc(CN(C)Cc3ccccc3)cc1)C2=O', 'CN(Cc1ccccc1)Cc1ccc(/C=C2\\\\CCc3cc(OCCCCCN4CCCCC4)ccc3C2=O)cc1', 'CN(Cc1ccccc1)Cc1ccc(/C=C2\\\\CCc3cc(OCCCCCN4CCCCC4)ccc3C2=O)cc1', 'CN(Cc1ccccc1)Cc1ccc(/C=C2\\\\CCc3cc(OCCCCCN4CCCCC4)ccc3C2=O)cc1', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@]1(C)N2C', 'NC(=O)N1c2ccccc2Sc2ccccc21', 'CNC(=O)N1c2ccccc2Sc2ccccc21', 'CO[P@]1(=O)OC[C@H]2COC(=O)C2=C(C)O1', 'CO[P@]1(=O)OC[C@H]2COC(=O)C2=C(C)O1', 'CO[P@]1(=O)OC[C@H]2COC(=O)C2=C(C)O1', 'CO[P@]1(=O)OC[C@H]2COC(=O)C2=C(C)O1', 'CO[P@@]1(=O)CC[C@H]2COC(=O)C2=C(C)O1', 'CO[P@@]1(=O)CC[C@H]2COC(=O)C2=C(C)O1', 'CO[P@]1(=O)CC[C@H]2COC(=O)C2=C(C)O1', 'CO[P@]1(=O)CC[C@H]2COC(=O)C2=C(C)O1', 'CO[P@]1(=O)CC[C@H]2COC(=O)C2=C(C)O1', 'COC(=O)C1=C(C)O[P@@](=O)(OC)CC[C@H]1COCc1ccccc1', 'COC(=O)C1=C(C)O[P@](=O)(OC)CC[C@H]1COCc1ccccc1', 'COC(=O)C1=C(C)OP(=O)(OC)CCC1', 'COC(=O)C1=C(C)OP(=O)(OC)CCC1', 'COC(=O)C1=C(C)OP(=O)(OC)CCC1', 'COC(=O)C1=C(C)OP(=O)(OC)CCC1', 'COC(=O)C1=C(C)OP(=O)(OC)CC1', 'COP(=O)(OC)O/C(C)=C1\\\\CCOC1=O', 'CCN(CC)CCNC(=O)N1c2ccccc2Sc2ccccc21.Cl', 'CC(C)N(CCNC(=O)N1c2ccccc2Sc2ccccc21)C(C)C', 'O=C(NCCN1CCCC1)N1c2ccccc2Sc2ccccc21', 'O=C(NCCN1CCCCC1)N1c2ccccc2Sc2ccccc21', 'CS(=O)(=O)[O-].CS(=O)(=O)[O-].O/N=C/c1cc[n+](COC[n+]2ccc(/C=N/O)cc2)cc1', 'CS(=O)(=O)[O-].CS(=O)(=O)[O-].O/N=C/c1cc[n+](COC[n+]2ccc(/C=N/O)cc2)cc1', 'CS(=O)(=O)[O-].CS(=O)(=O)[O-].O/N=C/c1cc[n+](COC[n+]2ccc(/C=N/O)cc2)cc1', 'CS(=O)(=O)[O-].CS(=O)(=O)[O-].O/N=C/c1cc[n+](COC[n+]2ccc(/C=N/O)cc2)cc1', 'CS(=O)(=O)[O-].CS(=O)(=O)[O-].O/N=C/c1cc[n+](COC[n+]2ccc(/C=N/O)cc2)cc1', 'CS(=O)(=O)[O-].CS(=O)(=O)[O-].O/N=C/c1cc[n+](COC[n+]2ccc(/C=N/O)cc2)cc1', '[Br-].[Br-].c1ccc2c(c1)ccc[n+]2CCCCCC[n+]1cccc2ccccc21', 'COc1cc2cc(C(=O)CCc3cc[n+](Cc4ccc([N+](=O)[O-])o4)cc3)sc2cc1OC.[Br-]', 'COc1cc2cc(C(=O)CCc3cc[n+](Cc4ccc([N+](=O)[O-])o4)cc3)sc2cc1OC.[Br-]', 'CC[N+](C)(CCCCCC(=O)N(C)CCCCCCCCN(C)C(=O)CCCCC[N+](C)(CC)Cc1ccccc1[N+](=O)[O-])Cc1ccccc1[N+](=O)[O-].[I-].[I-]', 'CC[N+](C)(CCCCCC(=O)N(C)CCCCCCCCN(C)C(=O)CCCCC[N+](C)(CC)Cc1ccccc1[N+](=O)[O-])Cc1ccccc1[N+](=O)[O-].[I-].[I-]', 'CC[N+](C)(CCCCCC(=O)N(C)CCCCCCCCN(C)C(=O)CCCCC[N+](C)(CC)Cc1ccccc1[N+](=O)[O-])Cc1ccccc1[N+](=O)[O-].[I-].[I-]', 'CC[N+](C)(CCCCCC(=O)N(C)CCCCCCCCN(C)C(=O)CCCCC[N+](C)(CC)Cc1ccccc1[N+](=O)[O-])Cc1ccccc1[N+](=O)[O-].[I-].[I-]', 'COc1cc2c(cc1OC)SC(C(=O)CCc1cc[n+](Cc3coc([N+](=O)[O-])c3)cc1)C2.[I-]', 'COc1cc2c(cc1OC)SC(C(=O)CCc1cc[n+](Cc3coc([N+](=O)[O-])c3)cc1)C2.[I-]', 'COc1cc2cc(C(=O)C3CCC[N+](C)(Cc4ccc([N+](=O)[O-])o4)CC3)sc2cc1OC.[I-]', 'COc1cc2cc(C(=O)C3CCC[N+](C)(Cc4ccc([N+](=O)[O-])o4)CC3)sc2cc1OC.[I-]', 'CCN(CCCCCCNc1ccc(CCc2ccc(NCCCCCCN(CC)Cc3ccccc3OC)cc2)cc1)Cc1ccccc1OC', 'COc1ccc(NC(=O)Oc2ccc3c(c2)[C@]2(C)CCN(C)C2N3C)cc1', 'COc1ccc(NC(=O)Oc2ccc3c(c2)[C@]2(C)CCN(C)C2N3C)cc1', 'CCCCNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)C1N2C', 'CCCCNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)C1N2C', 'CC(C)NC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)C1N2C', 'CC(C)NC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)C1N2C', 'CCN(CC)C(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)C1N2C', 'CCN(CC)C(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)C1N2C', 'CN(C(=O)NCc1ccccc1)C(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)C1N2C', 'CN(C(=O)NCc1ccccc1)C(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)C1N2C', 'CN1CC[C@@]2(C)c3cc(OC(=O)NCc4ccccc4)ccc3N(C)C12', 'CN1CC[C@@]2(C)c3cc(OC(=O)NCc4ccccc4)ccc3N(C)C12', 'CN(C)C(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)C1N2C', 'CN(C)C(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)C1N2C', 'CCCCCCCCNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)C1N2C', 'CCCCCCCCNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)C1N2C', 'CN1CC[C@@]2(C)c3cc(OC(=O)Nc4ccc(Cl)cc4)ccc3N(C)C12', 'CN1CC[C@@]2(C)c3cc(OC(=O)Nc4ccc(Cl)cc4)ccc3N(C)C12', 'CCCCCCOC(=O)[C@H](CCC(=O)NCCC1CCN(Cc2ccccc2)CC1)NC(=O)OC(C)(C)C', 'CCCCCCOC(=O)[C@H](CCC(=O)NCCC1CCN(Cc2ccccc2)CC1)NC(=O)OCc1ccccc1', 'CCCCCCOC(=O)[C@H](CCC(=O)NCCC1CCN(Cc2ccccc2)CC1)NC(=O)Cc1cc2ccc(Cl)cc2s1', 'CCCCCCOC(=O)[C@H](CCC(=O)NCCC1CCN(Cc2ccccc2)CC1)NC(=O)c1ccccc1', 'CCCCCCOC(=O)[C@H](CCC(=O)NCCC1CCN(Cc2ccccc2)CC1)NC(=O)c1cccs1', 'CCCCCCOC(=O)[C@H](CCC(=O)NCCC1CCN(Cc2ccccc2)CC1)NC(=O)c1cc(Br)cs1', 'CCCCCCOC(=O)[C@H](CCC(=O)NCCC1CCN(Cc2ccccc2)CC1)NC(=O)c1cc2ccccc2s1', 'CCCCCCOC(=O)[C@H](CCC(=O)NCCC1CCN(Cc2ccccc2)CC1)NC(=O)c1cc2cccnc2s1', 'CCCCCCOC(=O)[C@H](CCC(=O)NCCC1CCN(Cc2ccccc2)CC1)NC(=O)c1cc2ccsc2s1', '[Br-].[Br-].c1cc[n+](Cc2ccc3ccc(C[n+]4ccccc4)cc3c2)cc1', '[Br-].[Br-].c1cc[n+](Cc2ccc3ccc(C[n+]4ccccc4)cc3c2)cc1', '[Br-].[Br-].c1cc[n+](Cc2ccc3ccc(C[n+]4ccccc4)cc3c2)cc1', 'CC(C)c1ccc(NC(=O)Oc2ccc3c(c2)[C@]2(C)CCN(CCc4ccccc4)[C@@H]2N3C)cc1', 'CC(C)c1ccc(NC(=O)Oc2ccc3c(c2)[C@]2(C)CCN(CCc4ccccc4)[C@@H]2N3C)cc1', 'CN1c2ccc(OC(=O)NC3CCCCC3)cc2[C@]2(C)CCN(CCc3ccccc3)[C@H]12', 'CN1c2ccc(OC(=O)NCC3CCCCC3)cc2[C@]2(C)CCN(CCc3ccccc3)[C@H]12', 'CN1c2ccc(OC(=O)NCC3CCCCC3)cc2[C@]2(C)CCN(CCc3ccccc3)[C@H]12', 'CC(CC(=O)C[C@@H](C)[C@H]1C[C@H](O)[C@@]2(C)C3=C(C(=O)C[C@]12C)[C@@]1(C)CCC(=O)C(C)(C)[C@@H]1CC3)C(=O)O', 'COC(=O)C(C)CC(=O)C[C@@H](C)[C@H]1C[C@H](O)[C@@]2(C)C3=C(C(=O)C[C@]12C)[C@@]1(C)CCC(=O)C(C)(C)[C@@H]1C[C@@H]3O', 'CC(CC(=O)C[C@@H](C)[C@H]1CC(=O)[C@@]2(C)C3=C(C(=O)C[C@]12C)[C@@]1(C)CC[C@H](O)C(C)(C)[C@@H]1C[C@@H]3O)C(=O)O', 'CC(C)=CCC/C(C)=C/Cc1cc(C2CC(=O)c3c(O)cc(O)cc3O2)c(O)cc1O', 'C[C@H](CC[C@@H](O)C(C)(C)O)[C@H]1CC[C@@]2(C)C3=CC[C@H]4C(C)(C)C(=O)CC[C@]4(C)C3=CC[C@]12C', 'CCOC(=O)c1cc2c(N)c3c(nc2nc1C)CCCC3', 'CCOC(=O)c1cc2c(N)c3c(nc2nc1C)CCCC3', 'CCOC(=O)c1cc2c(N)c3c(nc2nc1C)CCCC3', 'CCCCCCNC(=O)Oc1ccc2c(c1)C1CCN(CCC)C1C2', 'CCCCCCNC(=O)Oc1cccc(CN(CC)CCCOc2ccc3c(=O)c4ccccc4oc3c2)c1', 'c1ccc2c(NCCCCCCCCCNc3ccncc3)c3c(nc2c1)CCCC3', 'c1ccc2c(NCCCCCCCCCCNc3ccncc3)c3c(nc2c1)CCCC3', 'c1ccc(NCCCCCCCCCCCCNc2c3c(nc4ccccc24)CCCC3)cc1', 'c1ccc2c(NCCCCCCCNc3c4c(nc5ccccc35)CCCC4)ccnc2c1', 'Cc1ccc2nc3c(c(Nc4ccccc4)c2c1)CCCC3', 'O=C(CCC1CCN(Cc2ccccc2)CC1)c1ccc2c(c1)CCCN2', 'O=C(CCC1CCN(Cc2ccccc2)CC1)c1ccc2c(c1)CCCN2', 'CCCCCCNC(=O)Oc1cccc(CN(CCC)CCCOc2ccc3c(=O)c4ccccc4oc3c2)c1', 'c1ccc2c(NCCCCCCCCNc3c4c(nc5ccccc35)CCCC4)ccnc2c1', 'c1ccc2c(NCCCCCCCCCNc3c4c(nc5ccccc35)CCCC4)ccnc2c1', 'Cc1ccc2c(Nc3ccccc3)c3c(nc2c1)CCCC3', 'Clc1ccc2c(Nc3ccccc3)c3c(nc2c1)CCCC3', 'O=[N+]([O-])c1ccc2nc3c(c(Nc4ccccc4)c2c1)CCCC3', 'O=[N+]([O-])c1ccc2c(Nc3ccccc3)c3c(nc2c1)CCCC3', 'CN1CCCc2cc(C(=O)CCC3CCN(Cc4ccccc4)CC3)ccc21', 'O=C(CCC1CCN(Cc2ccccc2)CC1)c1ccc2c(c1)CCCN2c1ccccc1', 'CCCCCCNC(=O)Oc1cccc(CN(CCCOc2ccc3c(=O)c4ccccc4oc3c2)C(C)C)c1', 'CNC(=O)Oc1cccc(CN(C)CCCOc2ccc3c(c2)O/C(=C\\\\c2cc(O)c(O)c(O)c2)C3=O)c1', 'O=C(CCC1CCN(Cc2ccccc2)CC1)c1ccc2c(c1)N(c1ccccc1)CCC2', 'Cc1cc(-c2ccccc2)nnc1NCCN1CCCCC1', 'Cc1cc(-c2ccc(Cl)cc2)nnc1NCCN1CCCCC1', 'Cc1cc(-c2ccc3c(c2)OCO3)nnc1NCCN1CCCCC1', 'CNC(=O)Oc1cccc(CN(C)CCCCCCCOc2ccc3c(c2)O/C(=C\\\\c2cc(O)c(O)c(O)c2)C3=O)c1', 'CNC(=O)Oc1cccc(CN(C)CCCCCCCOc2ccc3c(c2)O/C(=C\\\\c2ccc4ccccc4c2)C3=O)c1', 'COC(=O)c1cc2c(N)c3c(nc2nc1C)CCC3', 'CCN1CCCC1CNc1ccc(-c2ccccc2)nn1', 'c1ccc(-c2ccc(NCCN3CCc4ccccc4C3)nn2)cc1', 'O=C1c2ccccc2CC1CC1CCN(c2ccccc2)CC1', 'O=C1c2ccccc2CCC1CC1CCN(c2ccccc2)CC1', 'O=C1c2ccccc2CCCC1CC1CCN(c2ccccc2)CC1', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(c3ccccc3)CC1)C2', 'CNC(=O)Oc1cccc(CN(C)CCCCCCCOc2ccc3c(c2)C/C(=C\\\\c2cc(O)c(O)c(O)c2)C3=O)c1', 'CNC(=O)Oc1cccc(CN(C)CCCCCCCOc2ccc3c(c2)OC/C(=C/c2cc(O)c(O)c(O)c2)C3=O)c1', 'CNC(=O)Oc1cccc(CN(C)CCCCCCCOc2ccc3c(c2)CC/C(=C/c2cc(O)c(O)c(O)c2)C3=O)c1', 'COC(=O)c1cc2c(N)c3c(nc2nc1C)CCCC3', 'COC(=O)c1cc2c(N)c3c(nc2nc1C)CCCCC3', 'COC(=O)c1cc2c(N)c3c(nc2nc1C)CCCCCC3', 'CCOC(=O)c1cc2c(N)c3c(nc2nc1C)CCC3', 'CCOC(=O)c1cc2c(N)c3c(nc2nc1C)CCCCC3', 'c1ccc(-c2ccc(NCCCN3CCc4ccccc4C3)nn2)cc1', 'c1ccc(-c2ccc(NCCCCCN3Cc4ccccc4CN3)nn2)cc1', 'CN(CCCNc1ccc(-c2ccccc2)nn1)Cc1ccccc1', 'COc1cc2c(cc1OC)C(O)C(CC1CCN(c3ccccc3)CC1)C2', 'COc1cc2c(cc1OC)CC(CC1CCN(c3ccccc3)CC1)=C2', 'O=C(CCc1c[nH]c2ccccc12)NCCCCCCNc1c2c(nc3ccccc13)CCCC2', 'O=C(CCc1c[nH]c2ccccc12)NCCCCCCCNc1c2c(nc3ccccc13)CCCC2', 'CCOC(=O)c1cc2c(N)c3c(nc2nc1C)CCCCCC3', 'O=C(Nc1ccccc1)c1ccc2c(c1)C(=O)N(CCC1CCN(Cc3ccccc3)CC1)C2=O', 'CN(CCCCNc1ccc(-c2ccccc2)nn1)Cc1ccccc1', 'CN(CCCCCNc1ccc(-c2ccccc2)nn1)Cc1ccccc1', 'c1ccc(CN2CCC(Nc3ccc(-c4ccccc4)nn3)CC2)cc1', 'c1ccc(CN2CCC(CNc3ccc(-c4ccccc4)nn3)CC2)cc1', 'CNC(=O)Oc1cccc(CN(C)CCCCCCCCOc2ccc3c(=O)c4ccccc4oc3c2)c1', 'CNC(=O)Oc1cccc(CN(C)CCCCCCCCCOc2ccc3c(=O)c4ccccc4oc3c2)c1', 'CNC(=O)Oc1cccc(CN(C)CCCCCCCCCOc2ccc3c(=O)c4ccccc4oc3c2)c1', 'CNC(=O)Oc1cccc(CN(C)CCCCCCCCCCOc2ccc3c(=O)c4ccccc4oc3c2)c1', 'CNC(=O)Oc1cccc(CN(C)CCCCCCCCCCOc2ccc3c(=O)c4ccccc4oc3c2)c1', 'O=C(CCc1c[nH]c2ccccc12)NCCCCCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'O=C(CCc1c[nH]c2ccccc12)NCCCCCCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'c1ccc(-c2ccc(NCN3CCCCC3)nc2)cc1', 'c1ccc(-c2cnc(NCN3CCCCC3)nc2)cc1', 'c1ccc(-c2ncc(NCN3CCCCC3)nn2)cc1', 'c1ccc(-c2nnc(NCN3CCCCC3)s2)cc1', 'c1ccc(-c2cnc(NCN3CCCCC3)nn2)cc1', 'c1ccc(C2=NNC(NCN3CCCCC3)=NC2)cc1', 'CNC(=O)Oc1cccc(CN(C)CCCOc2ccc(C(=O)c3ccccc3)cc2)c1', 'CNC(=O)Oc1cccc(CN(C)CCCOc2ccc(Cc3ccccc3)cc2)c1', 'CNC(=O)Oc1cccc(CN(C)CCCOc2ccc3ccccc3c2)c1', 'CNC(=O)Oc1cccc(CN(C)CCCOc2ccccc2)c1', 'CN(C)C(=O)Oc1ccc(-c2cn3c(Cl)cccc3[n+]2C)cc1.[Cl-]', 'Cc1cccc2n1cc(-c1ccc(OC(=O)N(C)C)cc1)[n+]2C.[Cl-]', 'CN(C)C(=O)Oc1ccc(-c2cn3ccccc3[n+]2C)cc1.Cc1ccc(S(=O)(=O)[O-])cc1', 'CN(C)C(=O)Oc1ccc(-c2cn3c(C(F)(F)F)cccc3[n+]2C)cc1.[Cl-]', 'COc1cccc2n1cc(-c1ccc(OC(=O)N(C)C)cc1)[n+]2C.[Cl-]', 'CN(C)C(=O)Oc1ccc(-c2cn3c(NC=O)cccc3[n+]2C)cc1.[Cl-]', 'O=C(CCC1CCN(Cc2ccccc2)CC1)c1ccccc1', 'O=C(CCC1CCN(Cc2ccccc2)CC1)c1ccccc1', 'O=C(CCC1CCN(Cc2ccccc2)CC1)c1ccc2c(c1)OCO2', 'CCn1c(C)nc2cc(C(=O)CCC3CCN(Cc4ccccc4)CC3)ccc21', 'CCn1c(C)nc2cc(C(=O)CCC3CCN(Cc4ccccc4)CC3)ccc21', 'Cc1nc2ccc(C(=O)CCC3CCN(Cc4ccccc4)CC3)cc2s1', 'Cc1nc2ccc(C(=O)CCC3CCN(Cc4ccccc4)CC3)cc2s1', 'CNC(=O)Oc1cccc(CN(C)CC#CCOc2ccc3c(=O)c4ccccc4oc3c2)c1', 'CC(=O)Nc1cccc2n1cc(-c1ccc(OC(=O)N(C)C)cc1)[n+]2C.[Cl-]', 'CC(=O)N(C)c1cccc2n1cc(-c1ccc(OC(=O)N(C)C)cc1)[n+]2C.[Cl-]', 'CN(C)C(=O)Oc1ccc(-c2cn3c(NC(=O)c4ccccc4)cccc3[n+]2C)cc1.[Cl-]', 'CNC(=O)Nc1cccc2n1cc(-c1ccc(OC(=O)N(C)C)cc1)[n+]2C.[Cl-]', 'COC(=O)Nc1cccc2n1cc(-c1ccc(OC(=O)N(C)C)cc1)[n+]2C.[Cl-]', 'Cc1nc2cc(C(=O)CCC3CCN(Cc4ccccc4)CC3)ccc2[nH]1', 'Cc1nc2cc(C(=O)CCC3CCN(Cc4ccccc4)CC3)ccc2[nH]1', 'O=C(CCC1CCN(Cc2ccccc2)CC1)c1ccc2[nH]c(-c3ccccc3)nc2c1', 'CN(C)C(=O)Nc1cccc2n1cc(-c1ccc(OC(=O)N(C)C)cc1)[n+]2C.[Cl-]', 'CNC(=O)Oc1ccc(-c2cn3ccccc3[n+]2C)cc1.[I-]', 'CNC(=O)Oc1ccc(-c2cn3c(C)cccc3[n+]2C)cc1.[I-]', 'CNC(=O)Oc1ccc(-c2cn3c(NC(C)=O)cccc3[n+]2C)cc1.[I-]', 'CN(C)C(=O)Oc1cccc(-c2cn3ccccc3[n+]2C)c1.[Cl-]', 'Cc1cccc2n1cc(-c1cccc(OC(=O)N(C)C)c1)[n+]2C.[Cl-]', 'O=C1CNc2cc3onc(CCC4CCN(Cc5ccccc5)CC4)c3cc2C1', 'O=C(CCOCCc1c[nH]c2ccccc12)NCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'CN(C)C(=O)Oc1cccc(-c2cn3c(Cl)cccc3[n+]2C)c1.[Cl-]', 'CN(C)C(=O)Oc1cccc(-c2cn3c(C(F)(F)F)cccc3[n+]2C)c1.[Cl-]', 'COc1cccc2n1cc(-c1cccc(OC(=O)N(C)C)c1)[n+]2C.[Cl-]', 'CC(=O)Nc1cccc2n1cc(-c1cccc(OC(=O)N(C)C)c1)[n+]2C.[Cl-]', 'CNC(=O)Oc1cccc(-c2cn3ccccc3[n+]2C)c1.[I-]', 'c1ccc(CN2CCC(CNc3nsc4ccccc34)CC2)cc1', 'c1ccc(CN2CCC(CNc3n[nH]c4ccccc34)CC2)cc1', 'CCCCCCNC(=O)Oc1cccc(CN(C)CCCCOc2ccc3c(=O)c4ccccc4oc3c2)c1', 'CCCCCCNC(=O)Oc1cccc(CN(C)CCCCCOc2ccc3c(=O)c4ccccc4oc3c2)c1', 'CN(CCOCCNC(=S)NC(=O)c1ccc2c(c1)C(=O)c1ccccc1-2)Cc1ccccc1', 'CN(CCOCCNC(=S)NC(=O)c1ccc2c(c1)C(=O)c1ccccc1C2=O)Cc1ccccc1', 'O=C(CCOCCc1c[nH]c2ccccc12)NCCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'O=C(CCOCCc1c[nH]c2ccccc12)NCCCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'CNC(=O)Oc1cccc(-c2cn3c(NC(C)=O)cccc3[n+]2C)c1.[I-]', 'Cc1cn2cc(C(N)=O)ccc2[n+]1C.[I-]', 'C[n+]1c(-c2ccccc2)cn2cc(C(N)=O)ccc21.[I-]', 'COC(=O)Nc1ccc2n(c1)cc(-c1ccccc1)[n+]2C.[Cl-]', 'COc1ccc2c(c1OC)C(=O)CC2CCC1CCN(Cc2ccccc2)CC1', 'CCCCCCCNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1C2', 'CCCCCCNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1C2', 'CCCCCCCNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(CC)[C@@H]1C2', 'CN(CCOCCNC(=S)Nc1ccccn1)Cc1ccccc1', 'CCCCNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(CC)[C@@H]1C2', 'CCN1CC[C@@]2(C)c3cc(OC(=O)NC(C)(C)C)ccc3C[C@@H]12', 'CCCNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(CC)[C@@H]1C2', 'CCN1CC[C@@]2(C)c3cc(OC(=O)NC)ccc3C[C@@H]12', 'CCN1CC[C@@]2(C)c3cc(OC(=O)Nc4ccccc4)ccc3C[C@@H]12', 'CCCCCCNC(=O)Oc1cccc(CN(C)CCCOc2ccc3c(=O)c4cccnc4oc3c2)c1', 'NCCCCCCCNc1c2c(nc3ccccc13)CCCC2', 'NCCCCCCCCCNc1c2c(nc3ccccc13)CCCC2', 'C/C(=N\\\\O)c1ccc(Cl)c(NC(=O)c2c(-c3ccccc3Cl)noc2C)c1', 'O=C(CCC1CCN(Cc2ccccc2)CC1)c1ccc2c(c1)CCN2c1ccccc1', 'CCN1CC[C@@]2(C)c3cc(OC(=O)NC(C)c4ccccc4)ccc3C[C@@H]12', 'CCN1CC[C@@]2(C)c3cc(OC(=O)NCc4ccccc4)ccc3C[C@@H]12', 'CCCCCCCNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(CCC)[C@@H]1C2', 'CCCCCCNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(CCC)[C@@H]1C2', 'CCCCCCCNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(Cc3ccccc3)[C@@H]1C2', 'CCCCCCNC(=O)Oc1cccc(CN(C)CCCOc2ccc3ccc(=O)oc3c2)c1', 'CCCCNC(=O)Oc1cccc(CN(C)CCCOc2ccc3c(=O)ccoc3c2)c1', 'NCCCCCCCCCCNc1c2c(nc3ccccc13)CCCC2', 'NCCCCCCCCCCCCNc1c2c(nc3ccccc13)CCCC2', 'CN(C)CCCCCCCNc1c2c(nc3ccccc13)CCCC2', 'CN(C)CCCCCCCCNc1c2c(nc3ccccc13)CCCC2', 'CN(C)CCCCCCCCCNc1c2c(nc3ccccc13)CCCC2', 'c1ccc2c(NCCCCCCNc3c4c(nc5ncccc35)CCCCC4)c3c(nc2c1)CCCCC3', 'CCCc1cc(N2CCC=N2)ccc1C(=O)O/N=C(\\\\N)c1ccc(C(F)(F)F)cc1', 'CCCCCCCNC(=O)Oc1ccc2c(c1)[C@@H]1CCN(CC)[C@@H]1C2', 'CCCCCCNC(=O)Oc1ccc2c(c1)[C@@H]1CCN(CC)[C@@H]1C2', 'CCCCNC(=O)Oc1ccc2c(c1)C1CCN(CC)C1C2', 'CCCNC(=O)Oc1ccc2c(c1)C1CCN(CC)C1C2', 'CCN1CCC2c3cc(OC(=O)NC)ccc3CC21', 'CCCCCCCNC(=O)Oc1ccc2c(c1)C1CCN(CCC)C1C2', 'CCCCCCNC(=O)Oc1cccc(CN(C)CCCOc2ccc3c(=O)ccoc3c2)c1', 'CCCCCCNC(=O)Oc1cccc(CN(C)CCCOc2ccc3c(=O)cc(-c4ccccc4)oc3c2)c1', 'CN(C)CCCCCCCCCCNc1c2c(nc3ccccc13)CCCC2', 'CN(C)CCCCCCCCCCCCNc1c2c(nc3ccccc13)CCCC2', 'c1ccc2c(NCCCCCCCNc3ccncc3)c3c(nc2c1)CCCC3', 'c1ccc2c(NCCCCCCCCNc3ccncc3)c3c(nc2c1)CCCC3', 'Nc1ccc2c(c1)c(-c1ccccc1)[n+](CCCNCCCNCCCNc1c3c(nc4ccccc14)CCCC3)c1cc(N)ccc21.[Cl-]', 'COc1ccccc1CN(C)CCCN(C)CCCNCCC[n+]1c(-c2ccccc2)c2cc(N)ccc2c2ccc(N)cc21.[Cl-]', 'c1ccc(CNc2ccnc(N3CCCC3)n2)cc1', 'c1ccc(CNc2ccnc(N3CCOCC3)n2)cc1', 'c1ccc(CNc2ccnc(N3CCSCC3)n2)cc1', 'CN1CCN(c2nccc(NCc3ccccc3)n2)CC1', 'CC1CCN(c2nccc(NCc3ccccc3)n2)CC1', 'c1ccc(CCNc2ccnc(N3CCCC3)n2)cc1', 'c1ccc(CCNc2ccnc(N3CCOCC3)n2)cc1', 'c1ccc(CCNc2ccnc(N3CCSCC3)n2)cc1', 'CN1CCN(c2nccc(NCCc3ccccc3)n2)CC1', 'CC1CCN(c2nccc(NCCc3ccccc3)n2)CC1', 'c1ccc2c(CNc3ccnc(N4CCCC4)n3)cccc2c1', 'c1ccc2c(CNc3ccnc(N4CCOCC4)n3)cccc2c1', 'c1ccc2c(CNc3ccnc(N4CCSCC4)n3)cccc2c1', 'CN1CCN(c2nccc(NCc3cccc4ccccc34)n2)CC1', 'CN1CCN(c2nccc(NCc3cccc4ccccc34)n2)CC1', 'NC1=C2CCCCC2=NC2CCCCC12', 'Nc1c2c(nc3cccc(F)c13)C1CC(C2)C1', 'Nc1c2c(nc3ccc(O)cc13)CCCC2', 'C=C1c2c(Cl)cccc2N=C2CCCCCN12', 'C=C1c2ccc(Cl)cc2N=C2CCCCCN12', 'C=C1c2cc(Cl)ccc2N=C2CCCCCN12', 'C=C1c2ccccc2N=C2CCCCCN12', 'C=C1c2cccc(Cl)c2N=C2CCCCCN12', 'CC1=C[C@@H]2Cc3nc4cc(Cl)ccc4c(N)c3[C@H](C1)C2', 'CN(C)c1cccc(OC(=O)Nc2ccccc2)c1', 'COc1cc2c(cc1OC)[C@@H]1[C@H](O)[C@@H](OC)C=C3CCN(C2)[C@H]31', 'CC(C)c1ccc(NC(=O)Oc2ccc3c(c2)[C@]2(C)CC[N+](C)(CCc4ccccc4)C2N3C)cc1.[Br-]', 'COS(=O)(=O)[O-].C[N+](C)(C)c1cccc(OC(=O)Nc2ccccc2)c1', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CC[N+](C)(C)C1N2C.[Br-]', 'CN1c2ccc(OC(=O)Nc3ccccc3)cc2[C@]2(C)CC[N+](C)(C)C12.[Br-]', 'Cc1ccccc1NC(=O)Oc1ccc2c(c1)[C@]1(C)CC[N+](C)(C)C1N2C.[Br-]', 'CC(C)c1ccc(NC(=O)Oc2ccc3c(c2)[C@]2(C)CC[N+](C)(C)C2N3C)cc1.[Br-]', 'CN1C(=O)Cc2cc3c(CCC4CCN(Cc5ccccc5)CC4)noc3cc21', 'OC1CCN2Cc3ccccc3N=C12', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(CCCNc3c4c(nc5cc(Cl)ccc35)CCCC4)CC1)C2', 'C#CCN(C)C1CCc2c(OC(=O)N(C)CC)cccc21', 'N#CC(c1ccc2c(c1)OCO2)N1CCOCC1', 'C#CCNC1CCc2c(OC(=O)N(C)C)cccc21', 'O=C(NCCCCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2)c1ccc2nc(-c3ccc(Cl)cc3)c3c(c2c1)OCCC3', 'O=C(CCC1CCN(Cc2ccccc2)CC1)c1ccc2c(c1)OCCO2', 'CC[C@]1(O)CC[C@H]2[C@@H]3CCC4=CCCC[C@@H]4[C@H]3CC[C@@]21C', 'CCN(CC)C(C)CN1c2ccccc2Sc2ccccc21.Cl', 'CCN(CC)C(C)CN1c2ccccc2Sc2ccccc21.Cl', 'CCN(CC)C(C)CN1c2ccccc2Sc2ccccc21.Cl', 'CCN(CC)C(C)CN1c2ccccc2Sc2ccccc21.Cl', 'CCN(CC)C(C)CN1c2ccccc2Sc2ccccc21.Cl', 'CCN(CC)C(C)CN1c2ccccc2Sc2ccccc21.Cl', 'CCN(C)C(=O)Oc1cccc([C@H](C)N(C)C)c1.O=C(O)[C@H](O)[C@@H](O)C(=O)O', 'CCCCOc1ccc(C(=O)CCN2CCCCC2)cc1', 'CN(C)Cc1ccc(CSCC/N=C/NCCSCc2ccc(CN(C)C)o2)o1.Cl', 'Cl.Cl.O.c1ccc(CN2CCC(CCNc3cc4c(nn3)-c3ccccc3CCC4)CC2)cc1', 'Cl.Cl.c1ccc(CN2CCC(CCSc3ccc(-c4ccccc4)nn3)CC2)cc1', 'Cl.Cl.O.c1ccc(CN2CCC(CCOc3ccc(-c4ccccc4)nn3)CC2)cc1', 'Cl.Cl.O.c1ccc(CN2CCC(CCNc3cc4ccc5ccccc5c4nn3)CC2)cc1', 'Cl.Cl.O.c1ccc(CN2CCC(CCNc3cc4c(nn3)-c3ccccc3CC4)CC2)cc1', 'Cl.N#CC(C#N)=C1NCCN1CCNCc1ccc(CN2CC=CCC2)o1', 'COC1CCCN(Cc2ccc(CNCCN3CCNC3=C(C#N)C#N)o2)C1.Cl', 'CNC(NCCNCc1ccc(CN2CCCCC2)o1)=C(C#N)C#N.Cl', 'Cl.N#CC(C#N)=C1NCCN1CCNCc1ccc(CN2CCCCCC2)o1', 'CCN(CC)Cc1ccc(CNCCN2CCNC2=C(C#N)C#N)o1.Cl', 'CC[N+](CC)(CC)CCOc1cc(OCC[N+](CC)(CC)CC)c(C(=O)NCCCCCC(=O)NNc2c3c(nc4ccccc24)CCCC3)cc1OCC[N+](CC)(CC)CC.Cl.[Br-].[Br-].[Br-]', 'CC[N+](CC)(CC)CCOc1ccc(C(=O)NCCCCCC(=O)NNc2c3c(nc4ccccc24)CCCC3)cc1.Cl.[Br-]', 'CC[N+](CC)(CC)CCOc1cc(OCC[N+](CC)(CC)CC)cc(C(=O)NCCCCCC(=O)NNc2c3c(nc4ccccc24)CCCC3)c1.Cl.[Br-].[Br-]', 'Cl.O.c1ccc(CN2CCC(CCN=c3cc4c(n[nH]3)-c3ccccc3C4)CC2)cc1', 'CCc1cc(=NCCC2CCN(Cc3ccccc3)CC2)[nH]nc1-c1ccccc1.Cl.Cl.O', 'Cc1cc(=NCCC2CCN(Cc3ccccc3)CC2)[nH]nc1-c1ccccc1.Cl.Cl.O', 'O=C(CCCN1C(=O)c2ccccc2C1=O)N1CCCCCC1', 'CC(C)(C)[Si](C)(C)O[C@H]1C=C2CCN3Cc4cc5c(cc4[C@H]([C@@H]1OC(=O)c1ccccc1)[C@@H]23)OCO5', 'O=C(O[C@H]1[C@H]2c3cc4c(cc3CN3CCC(=C[C@@H]1O)[C@H]23)OCO4)c1ccccc1', 'CC(=O)O[C@H]1C=C2CCN3Cc4cc5c(cc4[C@H]([C@@H]1OC(=O)c1ccccc1)[C@@H]23)OCO5', 'C[C@H](c1cccc(OC(=O)N(C)C)c1)N1CCCCC1', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2', 'CCNC(=O)Oc1ccc2c(c1)C1(C)COC(O2)O1', 'CN(C)c1ccc(/C=C/c2ccc3ccccc3[n+]2C)cc1.[I-]', 'CC(C)c1ccc(NC(=O)Oc2ccc3c(c2)[C@]2(C)CCOC2O3)cc1', 'Cc1ccccc1NC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2Cc1ccccc1', 'CN1CC[C@@]2(C)c3cc(OC(=O)Nc4ccccc4)ccc3N(Cc3ccccc3)[C@@H]12', 'Cc1ccccc1NC(=O)Oc1ccc2c(c1)[C@]1(C)CCN[C@@H]1N2', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(C)[C@@H]1N2C=O', 'CN1CC[C@@]2(C)c3cc(OC(=O)Nc4ccccc4)ccc3N(C=O)[C@@H]12', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(Cc3ccccc3)[C@@H]1N2Cc1ccccc1', 'CC(C)c1ccc(NC(=O)Oc2ccc3c(c2)C2(C)COC(O3)O2)cc1', 'CNC(=O)Oc1ccc2c(c1)[C@@]1(C)CCN(C)[C@@H]1N2C', 'C[C@@]12CCN(Cc3ccccc3)[C@@H]1N(Cc1ccccc1)c1ccc(OC(=O)Nc3ccccc3)cc12', 'CNC(=O)Oc1ccc2c(c1)SC[C@@H]1CCN(C)[C@H]21', 'CNC(=O)Oc1ccc2c(c1)CC[C@@H]1CCN(C)[C@H]21', 'CCOC(=O)C1=CN(C)c2cccc(OC(=O)N(C)C)c2C1', 'O=C(Nc1ccccc1Cl)Oc1ccc2c(c1)CCCN2Cc1ccccc1', 'O=C(CCCCCCCCc1ccccc1)c1c(O)cccc1O', 'C/C=C1\\\\[C@H]2C=C(C)C[C@@]1(N)c1ccc(=O)[nH]c1C2', 'C/C=C1\\\\[C@H]2C=C(C)C[C@@]1(N)c1ccc(=O)[nH]c1C2', 'C/C=C1\\\\[C@H]2C=C(C)C[C@@]1(N)c1ccc(=O)[nH]c1C2', 'C/C=C1\\\\[C@H]2C=C(C)C[C@@]1(N)c1ccc(=O)[nH]c1C2', 'C/C=C1\\\\[C@H]2C=C(C)C[C@@]1(N)c1ccc(=O)[nH]c1C2', 'C/C=C1\\\\[C@H]2C=C(C)C[C@@]1(N)c1ccc(=O)[nH]c1C2', 'C/C=C1\\\\[C@H]2C=C(C)C[C@@]1(N)c1ccc(=O)[nH]c1C2', 'C/C=C1\\\\[C@H]2C=C(C)C[C@@]1(N)c1ccc(=O)[nH]c1C2', 'C/C=C1\\\\[C@H]2C=C(C)C[C@@]1(N)c1ccc(=O)[nH]c1C2', 'C/C=C1\\\\[C@H]2C=C(C)C[C@@]1(N)c1ccc(=O)[nH]c1C2', 'C/C=C1\\\\[C@H]2C=C(C)C[C@@]1(N)c1ccc(=O)[nH]c1C2', 'C/C=C1\\\\[C@H]2C=C(C)C[C@@]1(N)c1ccc(=O)[nH]c1C2', 'C/C=C1\\\\[C@H]2C=C(C)C[C@@]1(N)c1ccc(=O)[nH]c1C2', 'C/C=C1\\\\[C@H]2C=C(C)C[C@@]1(N)c1ccc(=O)[nH]c1C2', 'C/C=C1\\\\[C@H]2C=C(C)C[C@@]1(N)c1ccc(=O)[nH]c1C2', 'C/C=C1\\\\[C@H]2C=C(C)C[C@@]1(N)c1ccc(=O)[nH]c1C2', 'C/C=C1\\\\[C@H]2C=C(C)C[C@@]1(N)c1ccc(=O)[nH]c1C2', 'C/C=C1\\\\[C@H]2C=C(C)C[C@@]1(N)c1ccc(=O)[nH]c1C2', 'C/C=C1\\\\[C@H]2C=C(C)C[C@@]1(N)c1ccc(=O)[nH]c1C2', 'COc1ccc2nc3c(c(N)c2c1)CCCC3', 'COc1ccc2nc3c(c(N)c2c1)CCCC3', 'COc1ccc2nc3c(c(N)c2c1)CCCC3', 'COc1ccc2nc3c(c(N)c2c1)CCCC3', 'COc1ccc2nc3c(c(N)c2c1)CCCC3', 'COc1ccc2nc3c(c(N)c2c1)CCCC3', 'COc1ccc2nc3c(c(N)c2c1)CCCC3', 'COc1ccc2nc3c(c(N)c2c1)CCCC3', 'COc1ccc2nc3c(c(N)c2c1)CCCC3', 'COc1ccc2nc3c(c(N)c2c1)CCCC3', 'COc1ccc2nc3c(c(N)c2c1)CCCC3', 'COc1ccc2nc3c(c(N)c2c1)CCCC3', 'COc1ccc2nc3c(c(N)c2c1)CCCC3', 'COc1ccc2nc3c(c(N)c2c1)CCCC3', 'COc1ccc2nc3c(c(N)c2c1)CCCC3', 'CCCCCCCCCCCCCCNc1c2c(nc3ccc(OC)cc13)CCCC2.Cl', 'CCCCCCCCCCCCCNc1c2c(nc3ccc(OC)cc13)CCCC2.Cl', 'CCCCCCCCCCCCNc1c2c(nc3ccc(OC)cc13)CCCC2.Cl', 'CCCCCCCCCNc1c2c(nc3ccc(OC)cc13)CCCC2.Cl', 'CCCCCCCCNc1c2c(nc3ccc(OC)cc13)CCCC2.Cl', 'CCCCCCCNc1c2c(nc3ccc(OC)cc13)CCCC2.Cl', 'CCCCCCNc1c2c(nc3ccc(OC)cc13)CCCC2.Cl', 'CCCCCNc1c2c(nc3ccc(OC)cc13)CCCC2.Cl', 'CCCCNc1c2c(nc3ccc(OC)cc13)CCCC2.Cl', 'CCCNc1c2c(nc3ccc(OC)cc13)CCCC2.Cl', 'CCNc1c2c(nc3ccc(OC)cc13)CCCC2.Cl', 'COc1ccc(C2CN(C)C3(C(=O)Nc4ccc([N+](=O)[O-])cc43)C23Cc2cc(OC)c(OC)cc2C3=O)cc1OC', 'COc1ccc(C2C(c3ccccc3)NC3(C(=O)Nc4ccccc43)C23Cc2cc(OC)c(OC)cc2C3=O)cc1OC', 'COc1cc2c(cc1OC)C(=O)C1(C2)C(c2ccc(F)cc2)C(c2ccccc2)NC12C(=O)Nc1ccc(Cl)cc12', 'COc1ccc(C2C(c3ccccc3)NC3(C(=O)Nc4ccc(Cl)cc43)C23Cc2cc(OC)c(OC)cc2C3=O)cc1OC', 'COc1cc2c(cc1OC)C(=O)C1(C2)C(c2ccccc2Cl)C(c2ccccc2)NC12C(=O)Nc1ccc(Cl)cc12', 'COc1cc2c(cc1OC)C(=O)C1(C2)C(c2ccc(F)cc2)C(c2ccccc2)NC12C(=O)Nc1ccc([N+](=O)[O-])cc12', 'COc1ccc(C2C(c3ccccc3)NC3(C(=O)Nc4ccc([N+](=O)[O-])cc43)C23Cc2cc(OC)c(OC)cc2C3=O)cc1OC', 'COc1cc2c(cc1OC)C(=O)C1(C2)C(c2ccccc2)C(c2ccccc2)NC12C(=O)Nc1ccc([N+](=O)[O-])cc12', 'COc1cc2c(cc1OC)C(=O)C1(C2)C(c2ccccc2Cl)C(c2ccccc2)NC12C(=O)Nc1ccc([N+](=O)[O-])cc12', 'COc1cc2c(cc1OC)C(=O)C1(C2)C(c2ccc(F)cc2)CN(C)C12C(=O)Nc1ccccc12', 'COc1ccc(C2CN(C)C3(C(=O)Nc4ccccc43)C23Cc2cc(OC)c(OC)cc2C3=O)cc1OC', 'COc1cc2c(cc1OC)C(=O)C1(C2)C(c2ccccc2)CN(C)C12C(=O)Nc1ccccc12', 'COc1cc2c(cc1OC)C(=O)C1(C2)C(c2ccccc2Cl)CN(C)C12C(=O)Nc1ccccc12', 'COc1cc2c(cc1OC)C(=O)C1(C2)C(c2ccc(F)cc2)CN(C)C12C(=O)Nc1ccc(Cl)cc12', 'COc1ccc(C2CN(C)C3(C(=O)Nc4ccc(Cl)cc43)C23Cc2cc(OC)c(OC)cc2C3=O)cc1OC', 'COc1cc2c(cc1OC)C(=O)C1(C2)C(c2ccccc2)CN(C)C12C(=O)Nc1ccc(Cl)cc12', 'COc1cc2c(cc1OC)C(=O)C1(C2)C(c2ccccc2Cl)CN(C)C12C(=O)Nc1ccc(Cl)cc12', 'COc1cc2c(cc1OC)C(=O)C1(C2)C(c2ccc(F)cc2)CN(C)C12C(=O)Nc1ccc([N+](=O)[O-])cc12', 'COc1cc2c(cc1OC)C(=O)C1(C2)C(c2ccccc2)CN(C)C12C(=O)Nc1ccc([N+](=O)[O-])cc12', 'COc1cc2c(cc1OC)C(=O)C1(C2)C(c2ccccc2Cl)CN(C)C12C(=O)Nc1ccc([N+](=O)[O-])cc12', 'COc1cc2c(cc1OC)C(=O)C1(C2)C(c2ccc(F)cc2)C(c2ccccc2)NC12C(=O)Nc1ccccc12', 'COc1cc2c(cc1OC)C(=O)C1(C2)C(c2ccccc2)C(c2ccccc2)NC12C(=O)Nc1ccccc12', 'COc1cc2c(cc1OC)C(=O)C1(C2)C(c2ccccc2Cl)C(c2ccccc2)NC12C(=O)Nc1ccccc12', 'COc1cc2c(cc1OC)C(=O)C1(C2)C(c2ccccc2)C(c2ccccc2)NC12C(=O)Nc1ccc(Cl)cc12', 'C[n+]1c(/C=C/c2ccc(O)cc2)ccc2ccccc21.[I-]', 'Cc1ccc(C(=O)Nc2cc3ccccc3oc2=O)cc1', 'COc1cccc(C(=O)N2c3ccccc3Sc3ccccc32)c1', 'COc1ccc(NC(S)=NCCN2CCC(C)CC2)cc1Cl', 'COc1ccc(C(C#N)N2CCCCC2)cc1OC', 'Clc1ccc(CNC2CCN(Cc3ccccc3)CC2)cc1', 'N#CC(c1ccc(O)cc1)N1CCCCC1', 'O=C1/C(=C/c2ccc(O)cc2)COc2ccccc21', 'Clc1ccc2c(c1)Nc1ccccc1S2', 'Fc1ccc(CNC2CCN(Cc3ccccc3)CC2)cc1', 'O=C(COc1ccc(Cl)cc1Cl)Nc1ccc(CN2CCCCC2)cc1', 'Cc1cc(N2CCCCC2)nc2ccccc12', 'CCCCCCCNc1c2c(nc3ccc(OC)cc13)CCCC2', 'CCCCCCNc1c2c(nc3ccc(OC)cc13)CCCC2', 'CNc1nc(NCc2ccccc2)c2ccccc2n1', 'CC(C)(C)c1cc[n+](C[n+]2ccc(C(C)(C)C)cc2)cc1.[Br-].[Br-]', 'CC(C)(C)c1cc[n+](CC[n+]2ccc(C(C)(C)C)cc2)cc1.[Br-].[Br-]', 'CC(C)(C)c1cc[n+](CCC[n+]2ccc(C(C)(C)C)cc2)cc1.[Br-].[Br-]', 'CC(C)(C)c1cc[n+](CCCC[n+]2ccc(C(C)(C)C)cc2)cc1.[Br-].[Br-]', 'CC(C)(C)c1cc[n+](CCCCC[n+]2ccc(C(C)(C)C)cc2)cc1.[Br-].[Br-]', 'CC(C)(C)c1cc[n+](CCCCCC[n+]2ccc(C(C)(C)C)cc2)cc1.[Br-].[Br-]', 'CC(C)(C)c1cc[n+](CCCCCCC[n+]2ccc(C(C)(C)C)cc2)cc1.[Br-].[Br-]', 'CC(C)(C)c1cc[n+](CCCCCCCC[n+]2ccc(C(C)(C)C)cc2)cc1.[Br-].[Br-]', 'CC(C)(C)c1cc[n+](CCCCCCCC[n+]2ccc(C(C)(C)C)cc2)cc1.[Br-].[Br-]', 'CC(C)(C)c1cc[n+](CCCCCCCCC[n+]2ccc(C(C)(C)C)cc2)cc1.[Br-].[Br-]', 'CC(C)(C)c1cc[n+](CCCCCCCCCC[n+]2ccc(C(C)(C)C)cc2)cc1.[Br-].[Br-]', 'CC(C)(C)c1cc[n+](CCCCCCCCCCC[n+]2ccc(C(C)(C)C)cc2)cc1.[Br-].[Br-]', 'CC(C)(C)c1cc[n+](COC[n+]2ccc(C(C)(C)C)cc2)cc1.[Cl-].[Cl-]', 'CC(C)(C)c1cc[n+](CCOCC[n+]2ccc(C(C)(C)C)cc2)cc1.[Br-].[Br-]', 'CC(C)(C)c1cc[n+](C/C=C/C[n+]2ccc(C(C)(C)C)cc2)cc1.[Br-].[Br-]', 'CC(C)(C)c1cc[n+](C/C=C\\\\C[n+]2ccc(C(C)(C)C)cc2)cc1.[Cl-].[Cl-]', 'CC(C)(C)c1cc[n+](Cc2ccccc2C[n+]2ccc(C(C)(C)C)cc2)cc1.[Br-].[Br-]', 'CC(C)(C)c1cc[n+](Cc2cccc(C[n+]3ccc(C(C)(C)C)cc3)c2)cc1.[Br-].[Br-]', 'CC(C)(C)c1cc[n+](Cc2ccc(C[n+]3ccc(C(C)(C)C)cc3)cc2)cc1.[Br-].[Br-]', 'CC(C)(C)c1cc[n+](/C=C2\\\\C=CC3=CC/C(=C\\\\[n+]4ccc(C(C)(C)C)cc4)C=C3C2)cc1.[Br-].[Br-]', 'CC(C)(C)c1cc[n+](/C=C2\\\\C=CC3=CC/C(=C\\\\[n+]4ccc(C(C)(C)C)cc4)C=C3C2)cc1.[Br-].[Br-]', '[Br-].[Br-].c1ccc2c[n+](CCCCCCCCCC[n+]3ccc4ccccc4c3)ccc2c1', 'CN[C@H]1CCC2=CC3=CC[C@]4(C)[C@@H]([C@H](C)N(C)C)[C@H](O)C[C@@]4(C)[C@@H]3CC[C@H]2C1(C)C', 'CC(=O)O[C@@H]1C[C@@]2(C)[C@@H]3CC[C@H]4[C@](C)(CO)[C@@H](NC(=O)c5ccccc5)C=C[C@]4(O)CC3=CC[C@]2(C)[C@H]1[C@H](C)N(C)C', 'CC(=O)O[C@@H]1C[C@@]2(C)[C@@H]3C[C@H]4OC[C@@]5(C)[C@@H](NC(=O)c6ccccc6)C=C[C@@](O)(CC3=CC[C@]2(C)[C@H]1[C@H](C)N(C)C)[C@@H]45', 'CC(=O)O[C@H]1C[C@@H]2C(=CC[C@]3(C)[C@@H]([C@H](C)N(C)C)[C@H](O)C[C@@]23C)C[C@@]23O[C@@H]2[C@H]2OC[C@](C)([C@H]2NC(=O)c2ccccc2)[C@H]13', 'C[C@@H]([C@H]1[C@H](O)C[C@@]2(C)[C@@H]3C[C@H](O)[C@H]4[C@]5(C)CO[C@]4(C=C[C@@H]5NC(=O)c4ccccc4)CC3=CC[C@]12C)N(C)C', 'C[C@@H]([C@H]1[C@H](O)C[C@@]2(C)[C@@H]3C=C[C@H]4C(C)(C)[C@@H](N(C)C)[C@H](O)C[C@@]45C[C@@]35CC[C@]12C)N(C)C', 'C[C@@H]1[C@@H]2CC[C@@H]3C(=CC[C@]4(C)[C@@H]([C@H](C)N(C)C)[C@H](O)C[C@@]34C)C=C2CC[C@@H]1N(C)C', 'C[C@@H]([C@H]1[C@H](O)C[C@@]2(C)[C@@H]3CC[C@@H]4C(=CC3=CC[C@]12C)CC[C@H](N(C)C)C4(C)C)N(C)C', 'C[C@@H]([C@H]1CC[C@@]2(C)[C@@H]3CC[C@@H]4C(=CC3=CC[C@]12C)CC[C@H](N(C)C)C4(C)C)N(C)C', 'C/C=C1/C(=O)C[C@@]2(C)[C@@H]3CC[C@H]4C(C)(C)[C@@H](N(C)C)CC[C@@]45C[C@@]35CC[C@]12C', 'O=C(CCC1CCN(Cc2ccccc2)CC1)c1ccc2c(c1)NC(c1ccccc1)N2', 'O=C(CCC1CCN(Cc2ccccc2)CC1)c1ccc2c(c1)CNCCC2', 'O=C(CCC1CCN(Cc2ccccc2)CC1)c1ccc2c(c1)CCNCC2', 'O=C(CCC1CCN(Cc2ccccc2)CC1)c1ccc2c(c1)CNCCO2', 'O=C(CCC1CCN(Cc2ccccc2)CC1)c1cc2c3c(c1)CC(=O)N3CCC2', 'O=C(CCC1CCN(Cc2ccccc2)CC1)c1cc2c3c(c1)CCN3C(=O)CC2', 'O=C(CCC1CCN(Cc2ccccc2F)CC1)c1cc2c3c(ccn3C(=O)CC2)c1', 'O=C(CCC1CCN(Cc2cccc(F)c2)CC1)c1cc2c3c(ccn3C(=O)CC2)c1', 'O=C(CCC1CCN(Cc2ccccc2Cl)CC1)c1cc2c3c(ccn3C(=O)CC2)c1', 'O=C(CCC1CCN(Cc2cccc(Cl)c2)CC1)c1cc2c3c(ccn3C(=O)CC2)c1', 'O=C(CCC1CCN(Cc2ccc(Cl)cc2)CC1)c1cc2c3c(ccn3C(=O)CC2)c1', 'COc1ccccc1CN1CCC(CCC(=O)c2cc3c4c(ccn4C(=O)CC3)c2)CC1', 'COc1cccc(CN2CCC(CCC(=O)c3cc4c5c(ccn5C(=O)CC4)c3)CC2)c1', 'COc1ccc(CN2CCC(CCC(=O)c3cc4c5c(ccn5C(=O)CC4)c3)CC2)cc1', 'O=C(CCC1CCN(Cc2ccccc2O)CC1)c1cc2c3c(ccn3C(=O)CC2)c1', 'O=C(CCC1CCN(Cc2cccc(O)c2)CC1)c1cc2c3c(ccn3C(=O)CC2)c1', 'O=C(CCC1CCN(Cc2ccccc2[N+](=O)[O-])CC1)c1cc2c3c(ccn3C(=O)CC2)c1', 'O=C(CCC1CCN(Cc2cccc([N+](=O)[O-])c2)CC1)c1cc2c3c(ccn3C(=O)CC2)c1', 'O=C(CCC1CCN(Cc2ccccc2)CC1)c1cc2c3c(c1)CCC(=O)N3CCC2', 'O=C(CCC1CCN(Cc2ccccc2)CC1)c1cc2c3c(c1)CCN3C(=O)CCC2', 'CS(=O)(=O)Nc1ccc2c(CCC3CCN(Cc4ccccc4)CC3)noc2c1', 'c1ccc(CN2CCC(CCc3noc4cc(C5CCCCC5)ccc34)CC2)cc1', 'O=C(CCC1CCN(Cc2ccc(F)cc2)CC1)c1cc2c3c(ccn3C(=O)CC2)c1', 'O=C(CCC1CCN(Cc2ccc(O)cc2)CC1)c1cc2c3c(ccn3C(=O)CC2)c1', 'O=C(CCC1CCN(Cc2ccc([N+](=O)[O-])cc2)CC1)c1cc2c3c(ccn3C(=O)CC2)c1', 'Cc1ccc([C@@H](C)CC(=O)CC(C)C)cc1', 'C[N+](C)(CCNC(=O)C(=O)NCC[N+](C)(C)Cc1ccccc1Cl)Cc1ccccc1Cl.[Cl-].[Cl-]', 'C[N+](C)(CCNC(=O)C(=O)NCC[N+](C)(C)Cc1ccccc1Cl)Cc1ccccc1Cl.[Cl-].[Cl-]', 'C[N+](C)(CCNC(=O)C(=O)NCC[N+](C)(C)Cc1ccccc1Cl)Cc1ccccc1Cl.[Cl-].[Cl-]', 'C[N+](C)(CCNC(=O)C(=O)NCC[N+](C)(C)Cc1ccccc1Cl)Cc1ccccc1Cl.[Cl-].[Cl-]', 'C[N+](C)(CCNC(=O)C(=O)NCC[N+](C)(C)Cc1ccccc1Cl)Cc1ccccc1Cl.[Cl-].[Cl-]', 'C[N+](C)(CCNC(=O)C(=O)NCC[N+](C)(C)Cc1ccccc1Cl)Cc1ccccc1Cl.[Cl-].[Cl-]', 'C[N+](C)(CCNC(=O)C(=O)NCC[N+](C)(C)Cc1ccccc1Cl)Cc1ccccc1Cl.[Cl-].[Cl-]', 'C[N+](C)(CCNC(=O)C(=O)NCC[N+](C)(C)Cc1ccccc1Cl)Cc1ccccc1Cl.[Cl-].[Cl-]', 'C[N+](C)(CCNC(=O)C(=O)NCC[N+](C)(C)Cc1ccccc1Cl)Cc1ccccc1Cl.[Cl-].[Cl-]', '[Br-].[Br-].c1ccc2c[n+](CCCC[n+]3ccc4ccccc4c3)ccc2c1', '[Br-].[Br-].c1ccc2c[n+](CCCCC[n+]3ccc4ccccc4c3)ccc2c1', '[Br-].[Br-].c1ccc2c[n+](CCCCCC[n+]3ccc4ccccc4c3)ccc2c1', '[Br-].[Br-].c1ccc2c[n+](CCCCCCC[n+]3ccc4ccccc4c3)ccc2c1', '[Br-].[Br-].c1ccc2c[n+](CCCCCCCC[n+]3ccc4ccccc4c3)ccc2c1', '[Br-].[Br-].c1ccc2c[n+](CCCCCCCC[n+]3ccc4ccccc4c3)ccc2c1', '[Br-].[Br-].c1ccc2c[n+](CCCCCCCC[n+]3ccc4ccccc4c3)ccc2c1', '[Cl-].[Cl-].c1ccc2c[n+](COC[n+]3ccc4ccccc4c3)ccc2c1', 'C(=C/C[n+]1ccc2ccccc2c1)\\\\C[n+]1ccc2ccccc2c1.[Br-].[Br-]', 'C(=C\\\\C[n+]1ccc2ccccc2c1)\\\\C[n+]1ccc2ccccc2c1.[Cl-].[Cl-]', '[Br-].[Br-].c1cc(C[n+]2ccc3ccccc3c2)cc(C[n+]2ccc3ccccc3c2)c1', '[Br-].[Br-].c1ccc2c[n+](Cc3ccc(C[n+]4ccc5ccccc5c4)cc3)ccc2c1', '[Br-].[Br-].c1ccc2c[n+](Cc3ccc4ccc(C[n+]5ccc6ccccc6c5)cc4c3)ccc2c1', '[Br-].[Br-].c1ccc2c[n+](Cc3ccc4ccc(C[n+]5ccc6ccccc6c5)cc4c3)ccc2c1', '[Br-].[Br-].c1ccc2c[n+](Cc3ccc4ccc(C[n+]5ccc6ccccc6c5)cc4c3)ccc2c1', 'COc1ccc(C(=O)NC2CCN(Cc3c(F)cccc3Cl)CC2)cc1OC', 'c1ccc(CN2CCc3[nH]c4ccccc4c3C2)cc1', 'CC(C)(O)CCc1c(-c2ccc(O)cc2O)oc2c3c(cc(O)c2c1=O)OC(C)(C)C=C3', 'O=C(NC1CCN(Cc2ccccc2)CC1)c1ccc2c(c1)OCCCO2', '[Br-].[Br-].c1ccc2c(c1)ccc[n+]2CCC[n+]1cccc2ccccc21', '[Br-].[Br-].c1ccc2c(c1)ccc[n+]2CCCC[n+]1cccc2ccccc21', '[Br-].[Br-].c1ccc2c(c1)ccc[n+]2CCCCC[n+]1cccc2ccccc21', '[Br-].[Br-].c1ccc2c(c1)ccc[n+]2CCCCCCC[n+]1cccc2ccccc21', '[Br-].[Br-].c1ccc2c(c1)ccc[n+]2CCCCCCCC[n+]1cccc2ccccc21', '[Br-].[Br-].c1ccc2c(c1)ccc[n+]2CCOCC[n+]1cccc2ccccc21', 'C(=C/C[n+]1cccc2ccccc21)\\\\C[n+]1cccc2ccccc21.[Br-].[Br-]', 'C(=C\\\\C[n+]1cccc2ccccc21)\\\\C[n+]1cccc2ccccc21.[Cl-].[Cl-]', '[Br-].[Br-].c1ccc(C[n+]2cccc3ccccc32)c(C[n+]2cccc3ccccc32)c1', '[Br-].[Br-].c1cc(C[n+]2cccc3ccccc32)cc(C[n+]2cccc3ccccc32)c1', '[Br-].[Br-].c1ccc2c(c1)ccc[n+]2Cc1ccc2ccc(C[n+]3cccc4ccccc43)cc2c1', '[Br-].[Br-].c1ccc2c(c1)ccc[n+]2Cc1ccc2ccc(C[n+]3cccc4ccccc43)cc2c1', '[Br-].[Br-].c1ccc2c(c1)ccc[n+]2Cc1ccc2ccc(C[n+]3cccc4ccccc43)cc2c1', 'COc1ccc(C2c3c(nc4c(c3N)CCCC4)Oc3ccc4ccccc4c32)cc1OC', 'CC(=O)N1CCN(c2nccc(NCc3ccccc3)n2)CC1', 'CC(C)(C)OC(=O)N1CCN(c2nccc(NCc3ccccc3)n2)CC1', 'c1ccc(CNc2ccnc(N3CCN(C4CCCCC4)CC3)n2)cc1', 'CC(C)N1CCN(c2nccc(NCc3ccccc3)n2)CC1', 'CC(C)C1CCN(c2nccc(NCc3ccccc3)n2)CC1', 'CCCN1CCN(c2nccc(NCc3ccccc3)n2)CC1', 'OCCN1CCN(c2nccc(NCc3ccccc3)n2)CC1', 'COCCN1CCN(c2nccc(NCc3ccccc3)n2)CC1', 'Clc1ccc(CN2CCN(c3nccc(NCc4ccccc4)n3)CC2)cc1', 'Brc1ccc(CN2CCN(c3nccc(NCc4ccccc4)n3)CC2)cc1', 'Fc1ccc(CN2CCN(c3nccc(NCc4ccccc4)n3)CC2)cc1', 'FC(F)(F)c1ccc(CN2CCN(c3nccc(NCc4ccccc4)n3)CC2)cc1', 'c1ccc(CNc2ccnc(NC3CCN(Cc4ccccc4)CC3)n2)cc1', '[O-][S+]1CCN(c2nccc(NCc3ccccc3)n2)CC1', 'O=S1(=O)CCN(c2nccc(NCc3ccccc3)n2)CC1', 'c1ccc(CNc2ccnc(N3CCNCC3)n2)cc1', 'CC(=O)N1CCN(c2nccc(NCCc3ccccc3)n2)CC1', 'CC1CCN(c2nccc(NCc3cccc4ccccc34)n2)CC1', 'CC1CCN(c2nccc(NCc3cccc4ccccc34)n2)CC1', 'CC(C)=CC1Oc2cc(O)ccc2-c2oc3c4c(cc(O)c3c(=O)c21)OC(C)(C)C=C4', 'CC1(C)C=Cc2c(cc(O)c3c(=O)c4c(oc23)-c2ccc(O)cc2OC(C(C)(C)O)C4)O1', 'COc1cc(CNCCCNC2=CC(=O)C(NCCCNCc3ccc(O)c(OC)c3)=CC2=O)ccc1O', 'COc1cc(CNCCCCCCNC2=CC(=O)C(NCCCCCCNCc3ccc(O)c(OC)c3)=CC2=O)ccc1O', 'O=C1C=C(NCCCNCc2cc3ccccc3o2)C(=O)C=C1NCCCNCc1cc2ccccc2o1', 'O=C1C=C(NCCCCCCNCc2nc3ccccc3s2)C(=O)C=C1NCCCCCCNCc1nc2ccccc2s1', 'O=C1C=C(NCCCNCc2ccc(-c3nc4ccccc4s3)cc2)C(=O)C=C1NCCCNCc1ccc(-c2nc3ccccc3s2)cc1', 'O=C1C=C(NCCCCCCNCc2ccc(-c3nc4ccccc4s3)cc2)C(=O)C=C1NCCCCCCNCc1ccc(-c2nc3ccccc3s2)cc1', '[Br-].[Br-].c1cc(C[N+]23CCC(CC2)CC3)cc(-c2cccc(C[N+]34CCC(CC3)CC4)c2)c1', 'COc1cc2c(cc1OC)CN(c1cc[n+](Cc3ccc(C[n+]4ccc(N5CCCCC5)cc4)cc3)cc1)CC2.[Br-].[Br-]', 'CCN(CC)CC(=O)Nc1ccc(C(=O)c2ccc(CN(C)Cc3ccccc3)cc2)cc1', 'CN(Cc1ccccc1)Cc1ccc(C(=O)c2ccc(NC(=O)CN3CCCCC3)cc2)cc1', 'CN(Cc1ccccc1)Cc1ccc(C(=O)c2ccc(NC(=O)CN3CCOCC3)cc2)cc1', 'CN(Cc1ccccc1)Cc1ccc(C(=O)c2ccc(NC(=O)CCCCN3CCCCC3)cc2)cc1', 'CCN(CC)CCCOc1ccc(C(=O)c2ccc(CN(C)Cc3ccccc3)cc2)cc1', 'CN(Cc1ccccc1)Cc1ccc(C(=O)c2ccc(OCCCN3CCCCC3)cc2)cc1', 'CN(Cc1ccccc1)Cc1ccc(C(=O)c2ccc(OCCCN3CCOCC3)cc2)cc1', 'CN(Cc1ccccc1)Cc1ccc(C(=O)c2ccc(OCCCN3CCC(n4c(=O)[nH]c5ccccc54)CC3)cc2)cc1', 'CCN(CC)CCCCCOc1ccc(C(=O)c2ccc(CN(C)Cc3ccccc3)cc2)cc1', 'CN(Cc1ccccc1)Cc1ccc(C(=O)c2ccc(OCCCCCN3CCCCC3)cc2)cc1', 'CCN(CC)CCCCCCOc1ccc(C(=O)c2ccc(CN(C)Cc3ccccc3)cc2)cc1', 'CN(Cc1ccccc1)Cc1ccc(C(=O)c2ccc(OCCCCCCN3CCCCC3)cc2)cc1', 'CCN(CC)CCCCCCCOc1ccc(C(=O)c2ccc(CN(C)Cc3ccccc3)cc2)cc1', 'CN(Cc1ccccc1)Cc1ccc(C(=O)c2ccc(OCCCCCCCN3CCCCC3)cc2)cc1', 'CCN(CC)CCc1ccc(Oc2ccc(C(=O)c3ccc(CN(C)Cc4ccccc4)cc3)cc2)cc1', 'CN(C)CC(C)(C)c1cccc(OC(=O)NCCCCN2CCOCC2)c1', 'CN(C)CC(C)(C)c1cccc(OC(=O)NCCCCN2CCOCC2)c1', 'CN(C)CC(C)(C)c1cccc(OC(=O)NCCCCN2CCOCC2)c1', 'CN(C)CC(C)(C)c1cccc(OC(=O)NCCCCN2CCOCC2)c1', 'CCN(CC)C(C)C(=O)N1c2ccccc2Sc2ccccc21.Cl', 'CCN(CC)C(C)C(=O)N1c2ccccc2Sc2ccccc21.Cl', 'CC(C)C1=N[C@H]2CC[C@]34C[C@]35C(=O)C[C@]3(C)[C@@H]([C@H](C)N(C)CCCN6C(=O)c7ccccc7C6=O)[C@H](O)C[C@@]3(C)[C@@H]5CC[C@H]4[C@]2(C)CS1', 'COc1cccc(CN(C)[C@@H](C)[C@H]2[C@H](O)C[C@@]3(C)[C@@H]4CC[C@H]5[C@]6(C)CSC(C(C)C)=N[C@H]6CC[C@@]56C[C@@]46C(=O)C[C@]23C)c1', 'COc1ccc(CN(C)[C@@H](C)[C@H]2[C@H](O)C[C@@]3(C)[C@@H]4CC[C@H]5[C@]6(C)CSC(C(C)C)=N[C@H]6CC[C@@]56C[C@@]46C(=O)C[C@]23C)cc1', 'CC(C)C1=N[C@H]2CC[C@]34C[C@]35C(=O)C[C@]3(C)[C@@H]([C@H](C)N(C)Cc6ccccc6C(F)(F)F)[C@H](O)C[C@@]3(C)[C@@H]5CC[C@H]4[C@]2(C)CS1', 'CC(C)C1=N[C@H]2CC[C@]34C[C@]35C(=O)C[C@]3(C)[C@@H]([C@H](C)N(C)Cc6cccc(C(F)(F)F)c6)[C@H](O)C[C@@]3(C)[C@@H]5CC[C@H]4[C@]2(C)CS1', 'CC(C)C1=N[C@H]2CC[C@]34C[C@]35C(=O)C[C@]3(C)[C@@H]([C@H](C)N(C)Cc6ccc(C(F)(F)F)cc6)[C@H](O)C[C@@]3(C)[C@@H]5CC[C@H]4[C@]2(C)CS1', 'CC(C)C1=N[C@H]2CC[C@]34C[C@]35C(=O)C[C@]3(C)[C@@H]([C@H](C)N(C)CCN6C(=O)c7ccccc7C6=O)[C@H](O)C[C@@]3(C)[C@@H]5CC[C@H]4[C@]2(C)CS1', 'CC(C)C1=N[C@H]2CC[C@]34C[C@]35C(=O)C[C@]3(C)[C@@H]([C@H](C)N(C)C)[C@H](O)C[C@@]3(C)[C@@H]5CC[C@H]4[C@]2(C)CS1', 'CN[C@@H](C)[C@H]1[C@H](O)C[C@@]2(C)[C@@H]3CC[C@H]4[C@]5(C)CSC(C(C)C)=N[C@H]5CC[C@@]45C[C@@]35C(=O)C[C@]12C', 'CC(=O)N(C)[C@@H](C)[C@H]1[C@H](O)C[C@@]2(C)[C@@H]3CC[C@H]4[C@]5(C)CSC(C(C)C)=N[C@H]5CC[C@@]45C[C@@]35C(=O)C[C@]12C', 'CC(C)C1=N[C@H]2CC[C@]34C[C@]35C(=O)C[C@]3(C)[C@@H]([C@H](C)N(C)C(=O)c6ccccc6)[C@H](O)C[C@@]3(C)[C@@H]5CC[C@H]4[C@]2(C)CS1', 'CC(C)C1=N[C@H]2CC[C@]34C[C@]35C(=O)C[C@]3(C)[C@@H]([C@H](C)N(C)C(=O)OC(C)(C)C)[C@H](O)C[C@@]3(C)[C@@H]5CC[C@H]4[C@]2(C)CS1', 'CC(C)C1=N[C@H]2CC[C@]34C[C@]35C(=O)C[C@]3(C)[C@@H]([C@H](C)N(C)Cc6ccccc6)[C@H](O)C[C@@]3(C)[C@@H]5CC[C@H]4[C@]2(C)CS1', 'CC(C)C1=N[C@H]2CC[C@]34C[C@]35C(=O)C[C@]3(C)[C@@H]([C@H](C)N(C)CCc6ccccc6)[C@H](O)C[C@@]3(C)[C@@H]5CC[C@H]4[C@]2(C)CS1', 'CC(C)C1=N[C@H]2CC[C@]34C[C@]35C(=O)C[C@]3(C)[C@@H]([C@H](C)N(C)CCCc6ccccc6)[C@H](O)C[C@@]3(C)[C@@H]5CC[C@H]4[C@]2(C)CS1', 'COc1ccccc1CN(C)[C@@H](C)[C@H]1[C@H](O)C[C@@]2(C)[C@@H]3CC[C@H]4[C@]5(C)CSC(C(C)C)=N[C@H]5CC[C@@]45C[C@@]35C(=O)C[C@]12C', 'C[C@@H]([C@H]1[C@H](O)C[C@@]2(C)[C@@H]3CC[C@H]4[C@]5(C)COC(C(C)(C)F)=N[C@H]5CC[C@@]45C[C@@]35C(=O)C[C@]12C)N(C)C', 'C[C@@H]([C@H]1[C@H](O)C[C@@]2(C)[C@@H]3CC[C@H]4[C@]5(C)COC(C(F)(C(F)(F)F)C(F)(F)F)=N[C@H]5CC[C@@]45C[C@@]35C(=O)C[C@]12C)N(C)C', 'CC(C)C1=N[C@H]2CC[C@]34C[C@]35C(=O)C[C@]3(C)[C@@H]([C@H](C)N(C)C)[C@H](O)C[C@@]3(C)[C@@H]5CC[C@H]4[C@]2(C)C=C1', 'CC(C)C1=N[C@H]2CC[C@]34C[C@]35C(=O)C[C@]3(C)[C@@H]([C@H](C)N(C)C)[C@H](O)C[C@@]3(C)[C@@H]5CC[C@H]4[C@]2(C)CC1', 'C[C@@H](c1cccc(OC(=O)N(C)[C@@H](C)Cc2ccccc2)c1)N(C)C.Cl', 'C[C@H](Cc1ccccc1)NC(=O)Oc1cccc([C@H](C)N(C)C)c1.Cl', 'C[C@@H](Cc1ccccc1)NC(=O)Oc1cccc([C@H](C)N(C)C)c1.Cl', 'C[C@H](Cc1ccccc1)N(C)C(=O)Oc1cccc([C@H](C)N(C)C)c1.Cl', 'C#CCN(C)[C@H](C)Cc1cccc(OC(=O)N(C)C2CCCCC2)c1', 'C#CCN(C)[C@H](C)Cc1cccc(OC(=O)N(C)CCCCCC)c1', 'CCN(C)C(=O)Oc1ccc2c(c1)[C@H](N)CC2.Cl', 'C#CCN[C@@H]1CCc2ccc(OC(=O)N(C)C)cc21.Cl', 'C#CCN[C@@H]1CCc2ccc(OC(=O)N(C)CC)cc21.Cl', 'C#CCN[C@H]1CCc2ccc(OC(=O)N(C)CCC)cc21.Cl', 'C#CCN[C@@H]1CCc2ccc(OC(=O)N(C)CCCC)cc21.Cl', 'CNC(=C[N+](=O)[O-])NCCSCc1ccc(CN(C)C)o1', 'CNC(=C[N+](=O)[O-])NCCSCc1ccc(CN(C)C)o1', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(CCCCCCCCN1C(=O)c3ccccc3S1(=O)=O)C2.O=C(O)/C=C/C(=O)O', 'O=C(c1ccccc1)N1c2ccccc2Sc2ccc(Cl)cc21', 'COc1ccc(C(=O)N2c3ccccc3Sc3ccc(Cl)cc32)cc1', 'Cl.O=C(NCCNc1c2c(nc3ccccc13)CCCC2)c1ccc(F)cc1', 'Cl.O=C(NCCCNc1c2c(nc3ccccc13)CCCC2)c1ccc(F)cc1', 'Cl.O=C(NCCCCNc1c2c(nc3ccccc13)CCCC2)c1ccc(F)cc1', 'c1ccc2c(NCCCCCCN3CCOCC3)c3c(nc2c1)CCCC3', 'c1ccc2c(NCCCCCCCN3CCOCC3)c3c(nc2c1)CCCC3', 'c1ccc2c(NCCCCCCCCN3CCOCC3)c3c(nc2c1)CCCC3', 'c1ccc2c(NCCCCCCCCCN3CCOCC3)c3c(nc2c1)CCCC3', 'c1ccc2c(NCCCCCCCCCCN3CCOCC3)c3c(nc2c1)CCCC3', 'O=c1c2ccc(OCCCCCCCNc3c4c(nc5ccccc35)CCCC4)cc2oc2ncccc12', 'c1ccc2c(c1)Cc1c-2nc2ccccc2c1NCCCCCCCNc1c2c(nc3ccccc13)CCCC2', 'Clc1ccc2c(NCCCCCCCNc3c4c(nc5ccccc35)-c3ccccc3C4)c3c(nc2c1)CCCC3', 'Clc1ccc2c(NCCCCCCCNc3c4c(nc5ccccc35)-c3ccccc3C4)c3c(nc2c1)CCCC3', 'Clc1ccc2c(NCCCCCCCNc3c4c(nc5cc(Cl)ccc35)-c3ccccc3C4)c3c(nc2c1)CCCC3', 'Clc1ccc2c(NCCCCCCCOc3ccc(-c4cc5ccccc5o4)cc3)c3c(nc2c1)CCCC3', 'Clc1ccc2c(NCCCCCCCOc3cccc(-c4cc5ccccc5o4)c3)c3c(nc2c1)CCCC3', 'c1ccc2c(c1)Cc1c-2nc2ccccc2c1NCCCCCCCNc1c2c(nc3ccccc13)-c1ccccc1C2', 'CCC(c1ccc(O)c(OC)c1)c1cccc(O)c1O', 'CC(C)N1CCN(c2nccc(NCc3cccc4ccccc34)n2)CC1', 'CC(C)C1CCN(c2nccc(NCc3cccc4ccccc34)n2)CC1', 'CCCN1CCN(c2nccc(NCc3cccc4ccccc34)n2)CC1', 'c1ccc2c(CNc3ccnc(N4CCN(C5CCCCC5)CC4)n3)cccc2c1', 'CC(=O)N1CCN(c2nccc(NCc3cccc4ccccc34)n2)CC1', 'CC(C)(C)OC(=O)N1CCN(c2nccc(NCc3cccc4ccccc34)n2)CC1', 'c1ccc2c(CNc3ccnc(N4CCNCC4)n3)cccc2c1', 'OCCN1CCN(c2nccc(NCc3cccc4ccccc34)n2)CC1', 'COCCN1CCN(c2nccc(NCc3cccc4ccccc34)n2)CC1', 'CN1CCN(c2nccc(NC(c3ccccc3)c3ccccc3)n2)CC1', 'CC1CCN(c2nccc(NC(c3ccccc3)c3ccccc3)n2)CC1', 'CC(C)N1CCN(c2nccc(NC(c3ccccc3)c3ccccc3)n2)CC1', 'CC(C)C1CCN(c2nccc(NC(c3ccccc3)c3ccccc3)n2)CC1', 'CCCN1CCN(c2nccc(NC(c3ccccc3)c3ccccc3)n2)CC1', 'c1ccc(C(Nc2ccnc(N3CCN(C4CCCCC4)CC3)n2)c2ccccc2)cc1', 'CC(=O)N1CCN(c2nccc(NC(c3ccccc3)c3ccccc3)n2)CC1', 'c1ccc(C(Nc2ccnc(N3CCNCC3)n2)c2ccccc2)cc1', 'OCCN1CCN(c2nccc(NC(c3ccccc3)c3ccccc3)n2)CC1', 'COCCN1CCN(c2nccc(NC(c3ccccc3)c3ccccc3)n2)CC1', 'CCCCC/C=C\\\\C/C=C\\\\CCCCCCCC(=O)OCCCc1cc(OC)c2oc(-c3ccc4c(c3)OCO4)cc2c1', 'CCCCC/C=C\\\\C/C=C\\\\CCCCCCCC(=O)OCCCc1ccc2oc(-c3ccc4c(c3)OCO4)cc2c1', 'CCCCCCCC/C=C\\\\CCCCCCCC(=O)OCCCc1cc(OC)c2oc(-c3ccc4c(c3)OCO4)cc2c1', 'CCCCCCCC/C=C\\\\CCCCCCCC(=O)OCCCc1ccc2oc(-c3ccc4c(c3)OCO4)cc2c1', 'CC[C@H](C)C(=O)OCCCc1cc(OC)c2oc(-c3ccc4c(c3)OCO4)cc2c1', 'CC[C@H](C)C(=O)OCCCc1ccc2oc(-c3ccc4c(c3)OCO4)cc2c1', 'COc1cc(CCCOC(=O)Nc2ccccc2)cc2cc(-c3ccc4c(c3)OCO4)oc12', 'O=c1c2ccccc2nc2n1CCC2O', 'O=C(CCCC[C@H]1CCSS1)NCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'O=C(CCCC[C@@H]1CCSS1)NCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'O=C(CCCCc1cccs1)NCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'CCN(CCCCCCNC(=O)CCCCC1CCSS1)Cc1ccccc1OC', 'COc1cccc(C(C)N(C)CCCNC(=O)CCCCC2CCSS2)c1', 'CC(c1cccc(OCCCNC(=O)CCCCC2CCSS2)c1)N(C)C', 'C=CC(CBr)Nc1c2c(nc3ccc(OC)cc13)CCCC2', 'COC(=O)[C@H](C)CC(=O)C[C@@H](C)[C@H]1C[C@@H]2OC(C)(C)O[C@H]3C[C@H]4C(C)(C)C(=O)CC[C@]4(C)C4=C3[C@@]2(C)[C@]1(C)CC4=O', 'CCCCOC(=O)C(C)CC(=O)C[C@@H](C)[C@H]1CC(=O)[C@@]2(C)C3=C(C(=O)[C@@H](OC(C)=O)[C@]12C)[C@@]1(C)CC[C@H](O)C(C)(C)[C@@H]1CC3=O', 'C/C(=C\\\\CC[C@@H](C)[C@H]1CC[C@@]2(C)C3=CC[C@H]4C(C)(C)[C@@H](O)CC[C@]4(C)C3=CC[C@]12C)C(=O)O', 'C/C(=C\\\\CC[C@@H](C)[C@H]1CC[C@@]2(C)C3=CC[C@H]4C(C)(C)[C@@H](O)CC[C@]4(C)C3=CC[C@]12C)C(=O)O', 'C[C@H](CCC=C(CO)CO)[C@H]1CC[C@@]2(C)C3=CC[C@H]4C(C)(C)C(=O)CC[C@]4(C)C3=CC[C@]12C', 'C[C@H](CC[C@H](O)C(C)(C)O)[C@H]1CC[C@@]2(C)C3=CC[C@H]4C(C)(C)[C@@H](O)CC[C@]4(C)C3=CC[C@]12C', 'C[C@H](CC[C@H](O)[C@](C)(O)CO)[C@H]1CC[C@@]2(C)C3=CC[C@H]4C(C)(C)C(=O)CC[C@]4(C)C3=CC[C@]12C', 'C/C(=C\\\\CC[C@@H](C)[C@H]1CC[C@@]2(C)C3=C(CC[C@]12C)[C@@]1(C)CC[C@H](O)C(C)(C)[C@@H]1CC3=O)CO', 'CCCCOC(=O)CC[C@@H](C)[C@H]1CC[C@@]2(C)C3=C(C(=O)C[C@]12C)[C@@]1(C)CC[C@H](O)C(C)(C)[C@@H]1C[C@@H]3O', 'CCCCOC(=O)CC[C@@H](C)[C@H]1CC[C@@]2(C)C3=C(C(=O)C[C@]12C)[C@@]1(C)CCC(=O)C(C)(C)[C@@H]1C[C@@H]3O', 'CCCOCCn1c(=O)nc(NC2CCC(O)CC2)c2nnc(-c3ccc(OC)nc3)cc21', 'Nc1c2c(nc3c1cc(-c1ccccc1)n3-c1ccccc1)CCCC2', 'C=CCCCNc1c2c(nc3ccc(OC)cc13)CCCC2', 'COc1ccc2nc3c(c(N4CCCCCN(c5c6c(nc7ccc(OC)cc57)CCCC6)CCCCC4)c2c1)CCCC3', 'C#CCOP(C)(=O)OC(C(F)(F)F)C(F)(F)F', 'C#CCOP(C)(=O)OC(C(=O)OC)C(F)(F)F', 'COc1c(CC=C(C)C)c(O)cc2c1C[C@H](c1ccc(O)c(CC=C(C)C)c1O)CO2', 'C#CCN(C)Cc1cc2cc(OCCCC3CCN(Cc4ccccc4)CC3)ccc2n1C', 'C#CCN(C)Cc1cc2cc(OCCCC3CCN(Cc4ccccc4)CC3)ccc2n1C', 'C#CCN(C)Cc1cc2cc(OCCCC3CCN(Cc4ccccc4)CC3)ccc2n1C', 'C#CCN(C)Cc1cc2cc(OCCCC3CCN(Cc4ccccc4)CC3)ccc2n1C', 'C#CCN(C)Cc1cc2cc(OCCCC3CCN(Cc4ccccc4)CC3)ccc2n1C', 'C#CCN(C)Cc1cc2cc(OCCCC3CCN(Cc4ccccc4)CC3)ccc2n1C', 'CCN(CCCCCCNC1=CC(=O)c2ccccc2C1=O)Cc1ccccc1OC', 'CCN(CCCCCCNC1=CC(=O)c2ccccc2C1=O)Cc1ccccc1OC', 'CCN(CCCCCCNC1=CC(=O)c2ncccc2C1=O)Cc1ccccc1OC', 'CCN(CCCCCCNC1=CC(=O)C(C)=C(C)C1=O)Cc1ccccc1OC', 'CCN(CCCCCCNC1=CC(=O)C(OC)=CC1=O)Cc1ccccc1OC', 'COc1ccccc1CNCCCCCCNC1=CC(=O)c2ccccc2C1=O', 'NCCCCCCNC1=CC(=O)c2ccccc2C1=O', 'COc1ccccc1CN1CCC(N2CCC(NC3=CC(=O)c4ccccc4C3=O)CC2)CC1', 'COC1=CC(=O)C(N2CCC(C3CCN(Cc4ccccc4OC)CC3)CC2)=CC1=O', 'COc1ccccc1NCc1cc(=O)oc2cc3oc4ccccc4c3cc12', 'COc1cc2c(C)c(OC)c(=O)oc2cc1OCCCCOc1cc(O)cc(N(C)C)c1', 'COc1cc2oc(=O)c(OCCCCOc3cc(O)cc(N(C)C)c3)c(C)c2cc1OC', 'CCCC/N=C(/C=N/O)N(C)C.Cl', 'CCCC/N=C(/C=N/O)N(C)C.Cl', 'CCCCC/N=C(/C=N/O)N(C)C.Cl', 'CC(C)CC/N=C(/C=N/O)N(C)C.Cl', 'Cl.O/N=C/C1=NCCN1Cc1ccccc1', 'Cl.O/N=C/C1=NCCN1Cc1ccc(Cl)cc1Cl', 'Cl.O/N=C/C1=NCCN1Cc1cc(C(F)(F)F)cc(C(F)(F)F)c1', 'CCCCCN1CCCN=C1/C=N/O.Cl', 'Cl.O/N=C/C1=NCCCN1Cc1ccccc1', 'Cl.O/N=C/C1=NCCCN1Cc1ccc(Cl)cc1Cl', 'Cl.O/N=C/C1=NCCCN1Cc1cc(C(F)(F)F)cc(C(F)(F)F)c1', 'CCCCN1CC(C)(C)CN=C1/C=N/O.Cl', 'CCCCCN1CC(C)(C)CN=C1/C=N/O.Cl', 'O=[N+]([O-])c1ccc2c(c1)c(OCc1ccccc1)nn2Cc1ccccc1', 'COc1cc([C@H]2OC[C@H]3[C@@H]2CO[C@@H]3c2cc(OC)c3c(c2)OCO3)cc(OC)c1OC', 'CC1=C[C@@H]2Cc3nc4cc(Cl)ccc4c(N)c3[C@H](C1)C2.Cl', 'Cc1ccc(S(=O)(=O)SCc2ccccc2)cc1', 'Cc1ccc(S(=O)(=O)SCc2ccccc2)cc1', 'CC1=C[C@@H]2Cc3nc4cc(Cl)ccc4c(N)c3[C@H](C1)C2', 'CC1=C[C@@H]2Cc3nc4cc(Cl)ccc4c(N)c3[C@H](C1)C2', 'COc1ccc([C@H]2Oc3cc(O)c(C/C=C(\\\\C)CCC=C(C)C)c(O)c3C(=O)[C@@H]2O)cc1O', 'COc1ccc([C@H]2Oc3cc(O)c(C/C=C(\\\\C)CCC=C(C)C)c(O)c3C(=O)[C@@H]2O)cc1O', 'COc1c(O)cc(C2Oc3cc(O)c(C/C=C(\\\\C)CCC=C(C)C)c(O)c3C(=O)[C@@H]2O)cc1O', 'COc1c(O)cc(C2Oc3cc(O)c(C/C=C(\\\\C)CCC=C(C)C)c(O)c3C(=O)[C@@H]2O)cc1O', 'COc1ccc([C@@H]2CC(=O)c3c(cc(O)c(C/C=C(\\\\C)CCC=C(C)C)c3O)O2)cc1O', 'COc1ccc([C@@H]2CC(=O)c3c(cc(O)c(C/C=C(\\\\C)CCC=C(C)C)c3O)O2)cc1O', 'COc1c(O)cc(C2CC(=O)c3c(cc(O)c(C/C=C(\\\\C)CCC=C(C)C)c3O)O2)cc1O', 'COc1c(O)cc(C2CC(=O)c3c(cc(O)c(C/C=C(\\\\C)CCC=C(C)C)c3O)O2)cc1O', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(NCCCCCCNc4c5c(nc6ccccc46)CCCC5)c3C(C1)C2.Cl', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(NCCCN(C)CCCNc4c5c(nc6ccccc46)CCCC5)c3C(C1)C2.Cl', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(NCCCCCCCCNc4c5c(nc6ccccc46)CCCC5)c3C(C1)C2.Cl', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(NCCCCCCCCNc4c5c(nc6ccccc46)CCCC5)c3C(C1)C2.Cl', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(NCCCCCCNc4c5c(nc6cc(Cl)ccc46)CCCC5)c3C(C1)C2.Cl', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(NCCCN(C)CCCNc4c5c(nc6cc(Cl)ccc46)CCCC5)c3C(C1)C2.Cl', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(NCCCCCCCCNc4c5c(nc6cc(Cl)ccc46)CCCC5)c3C(C1)C2.Cl', 'CC1=C[C@H]2Cc3nc4cc(Cl)ccc4c(N)c3[C@@H](C1)C2.Cl', 'CC1=C[C@H]2Cc3nc4cc(Cl)ccc4c(N)c3[C@@H](C1)C2.Cl', 'COc1ccc2c(ccc[n+]2C)c1.[I-]', 'COc1ccc2c(ccc[n+]2Cc2ccccc2)c1.[I-]', 'CC[C@H]1C[C@@H]2CN3CCc4c([nH]c5cc([C@H]6C[C@H]7C(C(=O)OC)[C@H](Cc8c6[nH]c6ccccc86)N(C)C[C@H]7CC)ccc45)[C@](C(=O)OC)(C2)[C@H]13', 'Cl.O=C(NCCCCCCCCCCNc1c2c(nc3ccccc13)CCCC2)c1cc(=O)c2ccccc2o1', 'Cl.O=C(NCCCCCCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2)c1cc(=O)c2ccccc2o1', 'COc1ccc2oc(C(=O)NCCCCCCCCCCNc3c4c(nc5ccccc35)CCCC4)cc(=O)c2c1.Cl', 'COc1ccc2oc(C(=O)NCCCCCCCCCCNc3c4c(nc5cc(Cl)ccc35)CCCC4)cc(=O)c2c1.Cl', 'COc1cc(OC)c2c(=O)cc(C(=O)NCCCCCCCCCCNc3c4c(nc5ccccc35)CCCC4)oc2c1.Cl', 'COc1cc(OC)c2c(=O)cc(C(=O)NCCCCCCCCCCNc3c4c(nc5cc(Cl)ccc35)CCCC4)oc2c1.Cl', 'COc1cc2oc(C(=O)NCCCCCCCCCCNc3c4c(nc5ccccc35)CCCC4)cc(=O)c2cc1OC.Cl', 'COc1cc2oc(C(=O)NCCCCCCCCCCNc3c4c(nc5cc(Cl)ccc35)CCCC4)cc(=O)c2cc1OC.Cl', 'Cl.O=C(NCCCCCCCCCCNc1c2c(nc3ccccc13)CCCC2)c1cc(=O)c2cc(O)ccc2o1', 'Cl.O=C(NCCCCCCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2)c1cc(=O)c2cc(O)ccc2o1', 'COc1cc(O)c2c(=O)cc(C(=O)NCCCCCCCCCCNc3c4c(nc5ccccc35)CCCC4)oc2c1.Cl', 'Cl.O=C(NCCCCCCCCCCNc1c2c(nc3ccccc13)CCCC2)c1cc(=O)c2c(O)cc(O)cc2o1', 'COc1cc(O)c2c(=O)cc(C(=O)NCCCCCCCCCCNc3c4c(nc5cc(Cl)ccc35)CCCC4)oc2c1.Cl', 'Cl.O=C(NCCCCCCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2)c1cc(=O)c2c(O)cc(O)cc2o1', 'Cl.O=C(NCCCCCCCCCCNc1c2c(nc3ccccc13)CCCC2)c1cc(=O)c2cc(O)c(O)cc2o1', 'Cl.O=C(NCCCCCCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2)c1cc(=O)c2cc(O)c(O)cc2o1', 'CC1=C[C@H]2Cc3nc4cc(Cl)ccc4c(N)c3[C@@H](C1)C2', 'C#CCN1CCc2nc3nc(N4CCCC4)c(C#N)cc3c(N)c2C1', 'Clc1ccccc1CNc1ccnc(NC2CCN(Cc3ccccc3)CC2)n1', 'Clc1cccc(CNc2ccnc(NC3CCN(Cc4ccccc4)CC3)n2)c1', 'Clc1ccc(CNc2ccnc(NC3CCN(Cc4ccccc4)CC3)n2)cc1', 'Brc1ccc(CNc2ccnc(NC3CCN(Cc4ccccc4)CC3)n2)cc1', 'Fc1ccc(CNc2ccnc(NC3CCN(Cc4ccccc4)CC3)n2)cc1', 'Cc1ccc(CNc2ccnc(NC3CCN(Cc4ccccc4)CC3)n2)cc1', 'COc1ccc(CNc2ccnc(NC3CCN(Cc4ccccc4)CC3)n2)cc1', 'COc1ccc(CNc2ccnc(NC3CCN(Cc4ccccc4)CC3)n2)cc1OC', 'COc1cc(CNc2ccnc(NC3CCN(Cc4ccccc4)CC3)n2)cc(OC)c1OC', 'c1ccc(CN2CCC(Nc3nccc(NCc4ccc5c(c4)OCO5)n3)CC2)cc1', 'CNC(=O)Oc1cccc(CN(C)CCCCCCCOc2ccc(-c3cc4ccccc4oc3=O)cc2)c1', 'CN(CCCOc1ccc2ccc(=O)oc2c1)Cc1cccc(OC(=O)NCCCCCc2ccccc2)c1', 'CN(CCCOc1ccc2ccc(=O)oc2c1)Cc1cccc(OC(=O)NCCCCCCCN2CCOCC2)c1', 'CN(CCCOc1ccc2c(=O)c3cccnc3oc2c1)Cc1cccc(OC(=O)NCCCCCc2ccccc2)c1', 'CN(CCCOc1ccc2c(=O)c3cccnc3oc2c1)Cc1cccc(OC(=O)NCCCCCCCN2CCOCC2)c1', 'O=C(CCN1CCCCC1)N1CCN(CCNc2c3c(nc4ccccc24)CCCC3)CC1', 'O=C(CCN1CCCCC1)N1CCN(CCNc2c3c(nc4ccccc24)CCCC3)CC1', 'O=C(CCN1CCCCC1)N1CCN(CCNc2c3c(nc4ccccc24)CCCC3)CC1', 'CN(CCC(=O)N1CCN(CCNc2c3c(nc4ccccc24)CCCC3)CC1)C1CCCCC1', 'CN(CCC(=O)N1CCN(CCNc2c3c(nc4ccccc24)CCCC3)CC1)C1CCCCC1', 'CN(CCC(=O)N1CCN(CCNc2c3c(nc4ccccc24)CCCC3)CC1)C1CCCCC1', 'CCN(CCC(=O)N1CCN(CCNc2c3c(nc4ccccc24)CCCC3)CC1)C1CCCCC1', 'CCN(CCC(=O)N1CCN(CCNc2c3c(nc4ccccc24)CCCC3)CC1)C1CCCCC1', 'CCN(CCC(=O)N1CCN(CCNc2c3c(nc4ccccc24)CCCC3)CC1)C1CCCCC1', 'CN(CCC(=O)N1CCN(CCNc2c3c(nc4ccccc24)CCCC3)CC1)c1ccccc1', 'CN(CCC(=O)N1CCN(CCNc2c3c(nc4ccccc24)CCCC3)CC1)c1ccccc1', 'CN(CCC(=O)N1CCN(CCNc2c3c(nc4ccccc24)CCCC3)CC1)c1ccccc1', 'CN(CCCN1CCN(CCNc2c3c(nc4ccccc24)CCCC3)CC1)C1CCCCC1', 'CN(CCCN1CCN(CCNc2c3c(nc4ccccc24)CCCC3)CC1)C1CCCCC1', 'CN(CCCN1CCN(CCNc2c3c(nc4ccccc24)CCCC3)CC1)C1CCCCC1', 'CCN(CCCN1CCN(CCNc2c3c(nc4ccccc24)CCCC3)CC1)C1CCCCC1', 'CN(CCCN1CCN(CCNc2c3c(nc4ccccc24)CCCC3)CC1)c1ccccc1', 'CN(CCCN1CCN(CCNc2c3c(nc4ccccc24)CCCC3)CC1)c1ccccc1', 'CN(CCCN1CCN(CCNc2c3c(nc4ccccc24)CCCC3)CC1)c1ccccc1', 'O=C(CCNCCNc1c2c(nc3ccccc13)CCCC2)N1CCN(CCNc2c3c(nc4ccccc24)CCCC3)CC1', 'CC(C)=CCC/C(C)=C/Cc1ccc(O)c2nc3cccc(O)c3nc12', 'CC(=O)Oc1cccc2nc3c(OC(C)=O)ccc(C/C=C(\\\\C)CCC=C(C)C)c3nc12', 'Oc1cccc2nc3c(O)cccc3nc12', 'N#Cc1c(N)nc(NC2CCN(Cc3ccccc3)CC2)c(C#N)c1-c1ccccc1', 'N#Cc1c(N)nc(NCCC2CCN(Cc3ccccc3)CC2)c(C#N)c1-c1ccccc1', 'N#Cc1c(N)nc(NCCCC2CCN(Cc3ccccc3)CC2)c(C#N)c1-c1ccccc1', 'N#Cc1c(N)nc(NCCCCC2CCN(Cc3ccccc3)CC2)c(C#N)c1-c1ccccc1', 'N#Cc1cc(C#N)c(NC2CCN(Cc3ccccc3)CC2)nc1N', 'N#Cc1cc(C#N)c(NCCC2CCN(Cc3ccccc3)CC2)nc1N', 'N#Cc1cc(C#N)c(NCCCC2CCN(Cc3ccccc3)CC2)nc1N', 'N#Cc1cc(C#N)c(NCCCCC2CCN(Cc3ccccc3)CC2)nc1N', 'C#CCN[C@@H]1CCc2ccc(OC(=O)N(C)CCC)cc21.Cl', 'C#CCN[C@H]1CCc2ccc(OC(=O)N(C)CC)cc21.Cl', 'C#CCN[C@H]1CCc2ccc(OC(=O)N(C)C)cc21.Cl', 'C#CCN(C)[C@@H](C)Cc1cccc(OC(=O)N(C)C2CCCCC2)c1', 'C#CCN(C)[C@@H](C)Cc1cccc(OC(=O)N(C)CCCCCC)c1', 'C#CCN[C@H]1CCc2ccc(OC(=O)N(C)CCCC)cc21.Cl', 'CC1=C[C@@H]2Cc3nc4cc(Cl)ccc4c(NCCCN(C)CCCCNc4c5c(nc6cc(Cl)ccc46)CCCC5)c3[C@H](C1)C2.Cl.Cl.Cl', 'CC1=C[C@@H]2Cc3nc4cc(Cl)ccc4c(NCCCN(C)CCCCNc4c5c(nc6ccccc46)CCCC5)c3[C@H](C1)C2.Cl.Cl.Cl', 'O=C(CCCCCCC(=O)NCCCCCCN1CC[C@H]2COc3ccccc3[C@H]21)NCCCCCCN1CC[C@H]2COc3ccccc3[C@H]21', 'CN(C)c1ccccc1CNCCCCCCCNc1c2c(nc3ccccc13)CCCC2', 'CN(C)c1ccccc1CNCCCCCCCCNc1c2c(nc3ccccc13)CCCC2', 'CN(C)c1ccccc1CNCCCCCCCCCNc1c2c(nc3ccccc13)CCCC2', 'CCCCCCCNC(=O)Oc1ccc2c(c1)CN1CCc3ccccc3C1N2C', 'CCCCCCCNC(=O)Oc1ccc2c(c1)CN1CCc3ccccc3C1N2C', 'CCCCCCCNC(=O)Oc1ccc2c(c1)CN1CCc3ccccc3C1N2C', 'CCCCCCCNC(=O)Oc1ccc2c(c1)CN1CCc3ccccc3C1N2C', 'CCCCCCCNC(=O)Oc1ccc2c(c1)CN1CCc3ccccc3C1N2C', 'CN(C)CCOc1ccc(C(=O)/C=C/c2ccccc2)cc1', 'CN(C)CCOc1ccc(C(=O)/C=C/c2ccccc2)cc1', 'CN(C)CCOc1ccc(C(=O)/C=C/c2ccccc2)cc1', 'O=C(NCCc1c[nH]c2ccccc12)c1ccc(OCCCCn2c3ccccc3c3ccccc32)cc1', 'CN(C)c1cc[n+](CCCCOc2ccc(C(=O)NCCc3c[nH]c4ccccc34)cc2)cc1.[Br-]', 'O=C(NCCc1c[nH]c2ccccc12)c1ccc(OCCCC[n+]2cccc3ccccc32)cc1.[Br-]', 'CC(=O)c1ccccc1NC(=O)c1ccc(OCCCC[n+]2cccc3ccccc32)cc1.[Br-]', 'CC(=O)c1ccccc1NC(=O)c1ccc(OCCCC[n+]2ccc3ccccc3c2)cc1.[Br-]', 'CC(=O)c1ccccc1NC(=O)c1ccc(OCCCCC[n+]2ccc3ccccc3c2)cc1.[Br-]', 'CC(=O)c1ccccc1NC(=O)c1ccc(OCCCCCC[n+]2ccc3ccccc3c2)cc1.[Br-]', 'CC(=O)c1ccccc1NC(=O)c1ccc(OCCCCC[n+]2cccc3ccccc32)cc1.[Br-]', 'CC(=O)c1ccccc1NC(=O)c1ccc(OCCCCC[n+]2ccccc2)cc1.[Br-]', 'CC(=O)c1ccccc1NC(=O)c1ccc(OCCCCCC[n+]2ccccc2)cc1.[Br-]', 'CN(CCCCCCCOc1ccc(-c2oc3ccccc3c2C(=O)c2c3ccccc3cc3ccccc23)cc1)Cc1ccccc1', 'CCN(CC)Cc1cccc(C(=O)c2c(-c3ccc(OCCCCCCCN(C)Cc4ccccc4)cc3)oc3ccccc23)c1', 'CCN(CC)Cc1ccc(C(=O)c2c(-c3ccc(OCCCCCCCN(C)Cc4ccccc4)cc3)oc3ccccc23)cc1', 'CCN(CC)CCOc1cccc(C(=O)c2c(-c3ccc(OCCCCCCCN(C)Cc4ccccc4)cc3)oc3ccccc23)c1', 'CCN(CC)CCOc1ccc(C(=O)c2c(-c3ccc(OCCCCCCCN(C)Cc4ccccc4)cc3)oc3ccccc23)cc1', 'CN(CCCCCCCOc1ccc(-c2oc3ccccc3c2C(=O)c2ccc(OCCN3CCOCC3)cc2)cc1)Cc1ccccc1', 'CNC(=O)Oc1cccc(CN(C)CCCCCCCOc2ccc(-c3oc4ccccc4c3C(=O)c3ccc(C)cc3)cc2)c1', 'CN(CCCCCCCOc1cccc(-c2oc3ccccc3c2C(=O)c2ccccc2)c1)Cc1ccccc1', 'COc1cc2c(cc1OC)-c1cc3ccc(OC)c(OC)c3c[n+]1CC2.O.[Cl-]', 'COc1cc(/C=C/C(=O)NCCCCCCNc2c3c(nc4ccccc24)CCCC3)ccc1O', 'CO[P@]1(=O)CC[C@@H]2COC(=O)C2=C(C)O1', 'CO[P@]1(=O)CC[C@@H]2COC(=O)C2=C(C)O1', 'CS(=O)(=O)[O-].CS(=O)(=O)[O-].NC(=O)c1cc[n+](COC[n+]2ccc(/C=N/O)cc2/C=N/O)cc1', 'CS(=O)(=O)[O-].CS(=O)(=O)[O-].NC(=O)c1cc[n+](COC[n+]2ccc(/C=N/O)cc2/C=N/O)cc1', 'CS(=O)(=O)[O-].CS(=O)(=O)[O-].NC(=O)c1cc[n+](COC[n+]2ccc(/C=N/O)cc2/C=N/O)cc1', 'CS(=O)(=O)[O-].CS(=O)(=O)[O-].NC(=O)c1cc[n+](COC[n+]2ccc(/C=N/O)cc2/C=N/O)cc1', 'COc1cc2c(cc1OC)C(c1ccccc1)N(CCCc1ccc(O)c(/C=N/O)n1)CC2', 'COc1cc2c(cc1OC)C(c1ccccc1)N(CCCCc1ccc(O)c(/C=N/O)n1)CC2', 'COc1cc2c(cc1OC)C(c1ccccc1)N(CCCCc1ccc(O)c(/C=N/O)n1)CC2', 'COc1cc2c(cc1OC)C(c1ccccc1)N(CCCCc1ccc(O)c(/C=N/O)n1)CC2', 'COc1cc2c(cc1OC)C(c1ccccc1)N(CCCCCc1ccc(O)c(/C=N/O)n1)CC2', 'COc1cc2c(cc1OC)C(c1ccccc1)N(CCCCCc1ccc(O)c(/C=N/O)n1)CC2', 'COc1cc2c(cc1OC)C(c1ccccc1)N(CCCCCc1ccc(O)c(/C=N/O)n1)CC2', 'COc1cc2c(cc1OC)C(c1ccccc1)N(CCCCCc1ccc(O)c(/C=N/O)n1)CC2', 'COc1cc2c(cc1OC)C(c1ccccc1)N(CCCCCc1ccc(O)c(/C=N/O)n1)CC2', 'COc1cc2c(cc1OC)C(c1ccccc1)N(CCCCCc1ccc(O)c(/C=N/O)n1)CC2', 'COc1cc2c(cc1OC)C(c1ccccc1)N(CCCCCCc1ccc(O)c(/C=N/O)n1)CC2', 'COc1cc2c(cc1OC)C(c1ccccc1)N(CCCCCCc1ccc(O)c(/C=N/O)n1)CC2', 'COc1cc2c(cc1OC)C(c1ccccc1)N(CCCCCCc1ccc(O)c(/C=N/O)n1)CC2', 'COc1cc2c(cc1OC)C(c1ccccc1)N(CCOCCCc1ccc(O)c(/C=N/O)n1)CC2', 'COc1cc2c(cc1OC)C(c1ccccc1)N(CCCCc1ccnc(/C=N/O)c1O)CC2', 'COc1cc2c(cc1OC)C(c1ccccc1)N(CCCCCc1ccnc(/C=N/O)c1O)CC2', 'COc1cc2c(cc1OC)C(c1ccccc1)N(CCCCCc1ccnc(/C=N/O)c1O)CC2', 'COc1cc2c(cc1OC)C(c1ccccc1)N(CCCCCCc1cc(C)nc(/C=N/O)c1O)CC2', 'COc1cc2c(cc1OC)C(c1ccccc1)N(CCCCCCc1cc(C)nc(/C=N/O)c1O)CC2', 'COc1cc2c(cc1OC)C(c1ccccc1)N(CCCCc1cnc(/C=N/O)c(O)c1)CC2', 'Nc1c2c(nc3c1C(c1ccccc1)c1ccc4ccccc4c1O3)CCCC2', 'Cc1ccc(C2c3ccc4ccccc4c3Oc3nc4c(c(N)c32)CCCC4)cc1', 'Nc1c2c(nc3c1C(c1ccc(O)cc1)c1ccc4ccccc4c1O3)CCCC2', 'COc1ccccc1C1c2ccc3ccccc3c2Oc2nc3c(c(N)c21)CCCC3', 'COc1cc(C2c3ccc4ccccc4c3Oc3nc4c(c(N)c32)CCCC4)ccc1O', 'COc1ccc(C2c3ccc4ccccc4c3Oc3nc4c(c(N)c32)CCCC4)c(OC)c1', 'COc1cc(C2c3ccc4ccccc4c3Oc3nc4c(c(N)c32)CCCC4)cc(OC)c1OC', 'Nc1c2c(nc3c1C(c1ccc([N+](=O)[O-])cc1)c1ccc4ccccc4c1O3)CCCC2', 'Nc1c2c(nc3c1C(c1c(Cl)cccc1Cl)c1ccc4ccccc4c1O3)CCCC2', 'Nc1c2c(nc3c1C(c1ccc(Cl)c(Cl)c1)c1ccc4ccccc4c1O3)CCCC2', 'CCOC(=O)C1=C(C)Oc2nc3c(c(N)c2[C@H]1c1cccc([N+](=O)[O-])c1)CCCC3', 'CCOC(=O)C1=C(C)Oc2nc3c(c(N)c2[C@H]1c1ccccc1)CCC3', 'CCOC(=O)C1=C(C)Oc2nc3c(c(N)c2[C@H]1c1cccnc1OC)CCCC3', 'CCOC(=O)C1=C(C)Oc2nc3c(c(N)c2[C@H]1c1cccnc1Br)CCCC3', 'CCOC(=O)C1=C(C)Oc2nc3c(c(N)c2[C@H]1c1cccnc1Cl)CCCC3', 'CC1(C)CC(=O)C2=C(C1)Oc1nc3c(c(N)c1[C@H]2c1ccccc1)CCCC3', 'CC1(C)CC(=O)C2=C(C1)Oc1nc3c(c(N)c1[C@H]2c1ccc(F)cc1)CCCC3', 'CC1(C)CC(=O)C2=C(C1)Oc1nc3c(c(N)c1[C@H]2c1ccccc1C(F)(F)F)CCCC3', 'CC1(C)CC(=O)C2=C(C1)Oc1nc3c(c(N)c1[C@H]2c1cccc([N+](=O)[O-])c1)CCCC3', 'CC1(C)CC(=O)C2=C(C1)Oc1nc3c(c(N)c1[C@H]2c1ccc([N+](=O)[O-])cc1)CCCC3', 'Cc1ccc([C@H]2C3=C(CC(C)(C)CC3=O)Oc3nc4c(c(N)c32)CCCC4)cc1', 'COc1ccccc1[C@H]1C2=C(CC(C)(C)CC2=O)Oc2nc3c(c(N)c21)CCCC3', 'COc1cccc([C@H]2C3=C(CC(C)(C)CC3=O)Oc3nc4c(c(N)c32)CCCC4)c1', 'COc1ccc([C@H]2C3=C(CC(C)(C)CC3=O)Oc3nc4c(c(N)c32)CCCC4)cc1', 'CCOC(=O)C1=C(C)Nc2nc3c(c(N)c2[C@H]1c1ccccc1)CCCC3', 'CCOC(=O)C1=C(C)Nc2nc3c(c(N)c2[C@H]1c1ccc(F)cc1)CCCC3', 'CCOC(=O)C1=C(C)Nc2nc3c(c(N)c2[C@H]1c1ccccc1[N+](=O)[O-])CCCC3', 'CCOC(=O)C1=C(C)Nc2nc3c(c(N)c2[C@H]1c1cccc([N+](=O)[O-])c1)CCCC3', 'CCOC(=O)C1=C(C)Nc2nc3c(c(N)c2[C@H]1c1ccc([N+](=O)[O-])cc1)CCCC3', 'CCOC(=O)C1=C(C)Nc2nc3c(c(N)c2[C@H]1c1ccc(C)cc1)CCCC3', 'CCOC(=O)C1=C(C)Nc2nc3c(c(N)c2[C@@H]1c1ccccc1OC)CCCC3', 'CCOC(=O)C1=C(C)Nc2nc3c(c(N)c2[C@H]1c1cccc(OC)c1)CCCC3', 'CC1(C)CC(=O)C2=C(C1)Nc1nc3c(c(N)c1[C@H]2c1ccccc1)CCCC3', 'CC1(C)CC(=O)C2=C(C1)Nc1nc3c(c(N)c1[C@H]2c1ccc(F)cc1)CCCC3', 'Cc1ccc([C@H]2C3=C(CC(C)(C)CC3=O)Nc3nc4c(c(N)c32)CCCC4)cc1', 'COc1ccc([C@H]2C3=C(CC(C)(C)CC3=O)Nc3nc4c(c(N)c32)CCCC4)cc1', 'CC1(C)CC(=O)C2=C(C1)Nc1nc3c(c(N)c1[C@H]2c1ccncc1)CCCC3', 'CCOC(=O)c1c(C)nc2nc3c(c(N)c2c1-c1ccc(C)cc1)CCCCC3', 'CCOC(=O)c1c(C)nc2nc3c(c(N)c2c1-c1ccccc1OC)CCCCC3', 'CCOC(=O)c1c(C)nc2nc3c(c(N)c2c1-c1ccc(Cl)cc1)CCCCC3', 'CCOC(=O)c1c(C)nc2nc3c(c(N)c2c1-c1cccc([N+](=O)[O-])c1)CCCCC3', 'CCOC(=O)c1c(C)nc2nc3c(c(N)c2c1-c1ccccc1)CCCCCC3', 'CCOC(=O)c1c(C)nc2nc3c(c(N)c2c1-c1ccc(OC)cc1)CCCCCC3', 'CCOC(=O)C1=C(C)Oc2nc3c(c(N)c2[C@H]1c1ccncc1)CCC3', 'CCOC(=O)C1=C(C)Oc2nc3c(c(N)c2[C@H]1c1cccs1)CCC3', 'CCOC(=O)C1=C(C)Oc2nc3c(c(N)c2[C@H]1c1ccc(OC)cc1)CCCC3', 'CCOC(=O)C1=C(C)Oc2nc3c(c(N)c2[C@H]1c1ccncc1)CCCC3', 'CCOC(=O)C1=C(C)Oc2nc3c(c(N)c2[C@H]1c1cccnc1)CCCC3', 'CCOC(=O)C1=C(C)Oc2nc3c(c(N)c2[C@H]1c1cccs1)CCCC3', 'CCOC(=O)C1=C(C)Oc2nc3c(c(N)c2[C@H]1c1ccco1)CCCC3', 'CCOC(=O)C1=C(C)Oc2nc3c(c(N)c2[C@H]1c1ccncc1)CCCCC3', 'CCOC(=O)C1=C(C)Oc2nc3c(c(N)c2[C@H]1c1cccnc1)CCCCC3', 'CCOC(=O)C1=C(C)Oc2nc3c(c(N)c2[C@H]1c1cccs1)CCCCC3', 'CCOC(=O)C1=C(C)Oc2nc3c(c(N)c2[C@H]1c1cccc(OC)c1)CCC3', 'CCOC(=O)C1=C(C)Oc2nc3c(c(N)c2[C@H]1c1ccc(OC)c(OC)c1)CCC3', 'CCOC(=O)C1=C(C)Oc2nc3c(c(N)c2[C@H]1c1cccc(OC)c1)CCCC3', 'CCOC(=O)C1=C(C)Oc2nc3c(c(N)c2[C@H]1c1ccc(OC)c(OC)c1)CCCC3', 'CCOC(=O)C1=C(C)Oc2nc3c(c(N)c2[C@H]1c1cccc(OC)c1)CCCCC3', 'CCOC(=O)C1=C(C)Oc2nc3c(c(N)c2[C@H]1c1ccccc1OC)CCCCC3', 'CCOC(=O)C1=C(C)Oc2nc3c(c(N)c2[C@H]1c1ccc(OC)c(OC)c1)CCCCC3', 'CCOC(=O)C1=C(C)Oc2nc3c(c(N)c2[C@H]1c1ccccc1)CCCC3', 'CCOC(=O)C1=C(C)Oc2nc3c(c(N)c2[C@H]1c1ccc(C)cc1)CCCC3', 'CCOC(=O)C1=C(C)Oc2nc3c(c(N)c2[C@H]1c1ccc(Cl)cc1)CCCC3', 'CCOC(=O)C1=C(C)Oc2nc3c(c(N)c2[C@H]1c1ccc(C#N)cc1)CCCC3', 'CNCOc1cccc(CN(C)CCCCCCCOc2ccc3c(=O)c4ccccc4oc3c2)c1', 'CCN(CCCCCOc1ccc2c(=O)c3ccccc3oc2c1)Cc1cccc(OC(=O)NC)c1', 'Nc1cc(-c2ccccc2)nc2nc(-c3ccccc3)cc(C(F)(F)F)c12', 'Nc1cc(-c2cccc(F)c2)nc2nc(-c3ccccc3)cc(C(F)(F)F)c12', 'Nc1cc(-c2ccc(F)cc2)nc2nc(-c3ccccc3)cc(C(F)(F)F)c12', 'Nc1cc(-c2ccc(Cl)cc2)nc2nc(-c3ccccc3)cc(C(F)(F)F)c12', 'Nc1cc(-c2ccccc2Br)nc2nc(-c3ccccc3)cc(C(F)(F)F)c12', 'COc1ccc(-c2cc(N)c3c(C(F)(F)F)cc(-c4ccccc4)nc3n2)cc1', 'Nc1cc(-c2cccs2)nc2nc(-c3ccccc3)cc(C(F)(F)F)c12', 'CC(C)Cc1cc(N)c2c(C(F)(F)F)cc(-c3ccccc3)nc2n1', 'Nc1c2c(nc3nc(-c4ccccc4)cc(C(F)(F)F)c13)CCC2', 'Nc1c2c(nc3nc(-c4ccccc4)cc(C(F)(F)F)c13)CCCC2', 'Nc1c2c(nc3nc(-c4ccccc4)cc(C(F)(F)F)c13)CCCCC2', 'Nc1c2c(nc3nc(-c4ccccc4)cc(C(F)(F)F)c13)CCCCCC2', 'CC1Cc2nc3nc(-c4ccccc4)cc(C(F)(F)F)c3c(N)c2C1', 'CC1CCc2c(nc3nc(-c4ccccc4)cc(C(F)(F)F)c3c2N)C1', 'CC1CCc2nc3nc(-c4ccccc4)cc(C(F)(F)F)c3c(N)c2C1', 'Nc1c2c(nc3nc(-c4ccccc4)cc(C(F)(F)F)c13)-c1ccccc1C2', 'Nc1c2c(nc3nc(-c4ccccc4)cc(C(F)(F)F)c13)-c1ccccc1CC2', 'CC1(C)CCCC2(C)OC(=O)C=C12', 'COc1cc(O)c(C2CC(=O)c3c(O)cc(O)cc3O2)cc1C/C=C(\\\\C)CCC=C(C)C', 'CC(C)=CCC/C(C)=C/Cc1cc(-c2cc(=O)c3c(O)cc(O)cc3o2)c(O)cc1O', 'CC(C)=CCC/C(C)=C/Cc1cc(-c2cc(=O)c3c(O)cc(O)cc3o2)c(O)cc1O', 'COc1cc(O)c(-c2cc(=O)c3c(O)cc(O)cc3o2)cc1C/C=C(\\\\C)CCC=C(C)C', 'COc1cc(O)c(-c2cc(=O)c3c(O)cc(O)cc3o2)cc1C/C=C(\\\\C)CCC=C(C)C', 'O=c1c(OC2O[C@H](CO)[C@H](O)[C@H](O)[C@H]2O)c(-c2ccc(O)cc2)oc2cc(O)cc(O)c12', 'COc1cc2occ(-c3ccc(OC4CCN(Cc5ccccc5)CC4)cc3)c(=O)c2cc1OC', 'CC(C)(C)c1ccc(/C(N)=N/OC(=O)c2cnn(-c3ccc([N+](=O)[O-])cc3)c2C(F)(F)F)cc1', 'N/C(=N\\\\OC(=O)c1cnn(-c2ccc([N+](=O)[O-])cc2)c1C(F)(F)F)c1ccc(Cl)cc1', 'O=C(Nc1ccc(OC(F)(F)F)cc1)N1CCCN(CCc2ccccc2)CC1', 'Cc1c(S(=O)(=O)c2ccc(Cl)cc2)csc1C(=O)NC1CCN(Cc2ccccc2)CC1', 'O=C(CN1CCN(Cc2ccccc2)CC1)Nc1ccc(C(F)(F)F)cc1Cl', 'O=C(Nc1ccc(OC(F)(F)F)cc1)OC1CN(C(c2ccccc2)c2ccccc2)C1', 'CSc1cccc(/N=C2\\\\NC(=O)C(CC(=O)Nc3ccc(F)c(F)c3)S2)c1', 'O=c1c(Cl)c(N2CCN(c3ccc(C(F)(F)F)cn3)CC2)cnn1-c1c(Cl)cc(C(F)(F)F)cc1Cl', 'O=[N+]([O-])c1ccc(OCC(O)CN2CCCN(c3nc4ccc(Cl)cc4s3)CC2)cc1', 'CC(CN1CCN(Cc2ccccc2)CC1)N(C(=O)c1cccc([N+](=O)[O-])c1)c1ccccn1', 'N/C(=N\\\\OC(=O)c1cnn(-c2ccc([N+](=O)[O-])cc2)c1C(F)(F)F)c1ccc(C(F)(F)F)cc1', 'Clc1ccc([C@@H]2CC(c3c4ccccc4cc4ccccc34)=NN2)cc1', 'c1ccc([C@@H]2CC(c3c4ccccc4cc4ccccc34)=NN2)cc1', 'Oc1ccccc1[C@@H]1CC(c2c3ccccc3cc3ccccc23)=NN1', 'Oc1ccc([C@@H]2CC(c3c4ccccc4cc4ccccc34)=NN2)c(O)c1', 'c1ccc([C@@H]2CC(c3c4ccccc4cc4ccccc34)=NN2)nc1', 'O=[N+]([O-])c1cccc([C@@H]2CC(c3c4ccccc4cc4ccccc34)=NN2)c1', 'COc1ccc([C@@H]2CC(c3c4ccccc4cc4ccccc34)=NN2)cc1', 'COc1cc2cc(NC(=O)[C@H]3CCC[C@@H](NCc4ccccc4)C3)c(=O)oc2cc1OC', 'COc1cc2cc(NC(=O)[C@H]3CCC[C@@H](NCc4ccccc4)C3)c(=O)oc2cc1OC', 'COc1cc2cc(NC(=O)[C@H]3CCC[C@@H](NCc4ccccc4)C3)c(=O)oc2cc1OC', 'COc1cc2cc(NC(=O)[C@H]3CCC[C@@H](NCc4ccccc4)C3)c(=O)oc2cc1OC', 'COc1cc2cc(NC(=O)[C@H]3CCC[C@@H](NCc4ccccc4)C3)c(=O)oc2cc1OC', 'COc1ccc(/C=N/NC(=O)CN2CCN(Cc3ccccc3)CC2)cc1OC', 'COc1ccc(/C=N/NC(=O)CN2CCN(Cc3ccccc3)CC2)cc1', 'CCOc1ccc(/C=N/NC(=O)CN2CCN(Cc3ccccc3)CC2)cc1', 'COc1ccc(/C=N/NC(=O)CN2CCC(Cc3ccccc3)CC2)cc1OC', 'COc1ccc(/C=N/NC(=O)CN2CCC(Cc3ccccc3)CC2)cc1', 'COc1ccc(/C=N/NC(=O)CN2CCC(Cc3ccccc3)CC2)cc1', 'CCOc1ccc(/C=N/NC(=O)CN2CCC(Cc3ccccc3)CC2)cc1', 'CCOc1ccc(/C=N/NC(=O)CN2CCC(Cc3ccccc3)CC2)cc1', 'CCOc1ccc(/C=N/NC(=O)CN2CCC(Cc3ccccc3)CC2)cc1', 'Cc1ccc(/C=C2\\\\CN(C(=O)C[C@H]3C[C@H]4CCCN4[C@]34C(=O)Nc3ccccc34)C[C@@]3(C[C@H]4CCCN4[C@@]34C(=O)Nc3ccccc34)C2=O)cc1', 'O=C(C[C@H]1C[C@H]2CCCN2[C@]12C(=O)Nc1ccccc12)N1C/C(=C\\\\c2ccc(Cl)cc2Cl)C(=O)[C@]2(C[C@H]3CCCN3[C@@]23C(=O)Nc2ccccc23)C1', 'O=C(C[C@H]1C[C@H]2CCCN2[C@]12C(=O)Nc1ccccc12)N1C/C(=C\\\\c2cccc([N+](=O)[O-])c2)C(=O)[C@]2(C[C@H]3CCCN3[C@@]23C(=O)Nc2ccccc23)C1', 'O=C(C[C@H]1C[C@H]2CCCN2[C@]12C(=O)Nc1ccccc12)N1C/C(=C\\\\c2ccccc2F)C(=O)[C@]2(C[C@H]3CCCN3[C@@]23C(=O)Nc2ccccc23)C1', 'O=C(C[C@H]1C[C@H]2CCCN2[C@]12C(=O)Nc1ccccc12)N1C/C(=C\\\\c2ccccc2Cl)C(=O)[C@]2(C[C@H]3CCCN3[C@@]23C(=O)Nc2ccccc23)C1', 'C=CC(=O)N1C/C(=C\\\\c2ccccc2Cl)C(=O)/C(=C/c2ccccc2Cl)C1', 'C=CC(=O)N1C/C(=C\\\\c2ccccc2Cl)C(=O)/C(=C/c2ccccc2Cl)C1', 'C=CC(=O)N1C/C(=C\\\\c2ccccc2F)C(=O)/C(=C/c2ccccc2F)C1', 'C=CC(=O)N1C/C(=C\\\\c2ccccc2F)C(=O)/C(=C/c2ccccc2F)C1', 'C=CC(=O)N1C/C(=C\\\\c2cccc([N+](=O)[O-])c2)C(=O)/C(=C/c2cccc([N+](=O)[O-])c2)C1', 'C=CC(=O)N1C/C(=C\\\\c2cccc([N+](=O)[O-])c2)C(=O)/C(=C/c2cccc([N+](=O)[O-])c2)C1', 'C=CC(=O)N1C/C(=C\\\\c2ccccc2C)C(=O)/C(=C/c2ccccc2C)C1', 'C=CC(=O)N1C/C(=C\\\\c2ccccc2C)C(=O)/C(=C/c2ccccc2C)C1', 'C=CC(=O)N1C/C(=C\\\\c2ccccc2OC)C(=O)/C(=C/c2ccccc2OC)C1', 'C=CC(=O)N1C/C(=C\\\\c2ccccc2OC)C(=O)/C(=C/c2ccccc2OC)C1', 'O=C(C[C@H]1C[C@H]2CCCN2[C@]12C(=O)Nc1ccccc12)N1C/C(=C\\\\c2ccc(F)cc2)C(=O)[C@]2(C[C@H]3CCCN3[C@@]23C(=O)Nc2ccccc23)C1', 'O=C(C[C@H]1C[C@H]2CCCN2[C@]12C(=O)Nc1ccccc12)N1C/C(=C\\\\c2ccc(Cl)cc2)C(=O)[C@]2(C[C@H]3CCCN3[C@@]23C(=O)Nc2ccccc23)C1', 'COc1ccccc1/C=C1\\\\CN(C(=O)C[C@H]2C[C@H]3CCCN3[C@]23C(=O)Nc2ccccc23)C[C@@]2(C[C@H]3CCCN3[C@@]23C(=O)Nc2ccccc23)C1=O', 'Cc1ccccc1/C=C1\\\\CN(C(=O)C[C@H]2C[C@H]3CCCN3[C@]23C(=O)Nc2ccccc23)C[C@@]2(C[C@H]3CCCN3[C@@]23C(=O)Nc2ccccc23)C1=O', 'O=C(C[C@H]1C[C@H]2CCCN2[C@]12C(=O)Nc1ccccc12)N1C/C(=C\\\\c2ccccc2)C(=O)[C@]2(C[C@H]3CCCN3[C@@]23C(=O)Nc2ccccc23)C1', 'O=C1/C(=C/c2cccc3ccccc23)CN(C(=O)C[C@H]2C[C@H]3CCCN3[C@]23C(=O)Nc2ccccc23)C/C1=C\\\\c1cccc2ccccc12', 'C=CC(=O)N1C/C(=C\\\\c2ccc(Cl)cc2Cl)C(=O)/C(=C/c2ccc(Cl)cc2Cl)C1', 'C=CC(=O)N1C/C(=C\\\\c2ccc(Cl)cc2Cl)C(=O)/C(=C/c2ccc(Cl)cc2Cl)C1', 'C=CC(=O)N1C/C(=C\\\\c2cccc3ccccc23)C(=O)/C(=C/c2cccc3ccccc23)C1', 'C=CC(=O)N1C/C(=C\\\\c2cccc3ccccc23)C(=O)/C(=C/c2cccc3ccccc23)C1', 'O=C1/C(=C/c2ccccc2)CN(C(=O)C[C@H]2C[C@H]3CCCN3[C@]23C(=O)Nc2ccccc23)C/C1=C\\\\c1ccccc1', 'Cc1ccccc1/C=C1\\\\CN(C(=O)C[C@H]2C[C@H]3CCCN3[C@]23C(=O)Nc2ccccc23)C/C(=C\\\\c2ccccc2C)C1=O', 'COc1ccccc1/C=C1\\\\CN(C(=O)C[C@H]2C[C@H]3CCCN3[C@]23C(=O)Nc2ccccc23)C/C(=C\\\\c2ccccc2OC)C1=O', 'O=C1/C(=C/c2ccccc2Cl)CN(C(=O)C[C@H]2C[C@H]3CCCN3[C@]23C(=O)Nc2ccccc23)C/C1=C\\\\c1ccccc1Cl', 'O=C1/C(=C/c2ccccc2F)CN(C(=O)C[C@H]2C[C@H]3CCCN3[C@]23C(=O)Nc2ccccc23)C/C1=C\\\\c1ccccc1F', 'O=C1/C(=C/c2cccc([N+](=O)[O-])c2)CN(C(=O)C[C@H]2C[C@H]3CCCN3[C@]23C(=O)Nc2ccccc23)C/C1=C\\\\c1cccc([N+](=O)[O-])c1', 'O=C1/C(=C/c2ccc(Cl)cc2Cl)CN(C(=O)C[C@H]2C[C@H]3CCCN3[C@]23C(=O)Nc2ccccc23)C/C1=C\\\\c1ccc(Cl)cc1Cl', 'Cc1ccc(/C=C2\\\\CN(C(=O)C[C@H]3C[C@H]4CCCN4[C@]34C(=O)Nc3ccccc34)C/C(=C\\\\c3ccc(C)cc3)C2=O)cc1', 'O=C1/C(=C/c2ccc(Cl)cc2)CN(C(=O)C[C@H]2C[C@H]3CCCN3[C@]23C(=O)Nc2ccccc23)C/C1=C\\\\c1ccc(Cl)cc1', 'O=C1/C(=C/c2ccc(F)cc2)CN(C(=O)C[C@H]2C[C@H]3CCCN3[C@]23C(=O)Nc2ccccc23)C/C1=C\\\\c1ccc(F)cc1', 'O=C(C[C@H]1C[C@H]2CCCN2[C@]12C(=O)Nc1ccccc12)N1C/C(=C\\\\c2cccc3ccccc23)C(=O)[C@]2(C[C@H]3CCCN3[C@@]23C(=O)Nc2ccccc23)C1', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3)CC1)C2.Cl.O', 'C/C=C(\\\\C)C(=O)N[C@H]1CC[C@@]2(C)C(=CC[C@H]3[C@@H]4CC[C@H]([C@H](C)N(C)C)[C@@]4(C)CC[C@@H]32)[C@H]1O', 'Fc1cccc(Cc2nnc3sc(-c4ccoc4)nn23)c1', 'COc1ccc(-c2nnc3sc(-c4ccoc4)nn23)cc1', 'Brc1ccc(-c2nnc3sc(-c4ccoc4)nn23)cc1', 'Brc1cccc(-c2nnc3sc(-c4ccoc4)nn23)c1', 'Clc1ccccc1-c1nnc2sc(-c3ccoc3)nn12', 'Clc1ccc(-c2nnc3sc(-c4ccoc4)nn23)cc1', 'Fc1ccccc1Cc1nnc2sc(-c3ccoc3)nn12', 'Fc1ccc(Cc2nnc3sc(-c4ccoc4)nn23)cc1', 'COc1ccccc1-c1nnc2sc(-c3ccoc3)nn12', 'COc1cccc(-c2nnc3sc(-c4ccoc4)nn23)c1', 'O=C1/C(=C/c2cccc3ccccc23)CN(C(=O)[C@H]2C[C@H]3CCCN3[C@]23C(=O)Nc2cc(Cl)ccc23)C/C1=C\\\\c1cccc2ccccc12', 'O=C1/C(=C/c2ccccc2)CN(C(=O)[C@H]2C[C@H]3CCCN3[C@]23C(=O)Nc2cc(Cl)ccc23)C/C1=C\\\\c1ccccc1', 'Cc1ccccc1/C=C1\\\\CN(C(=O)[C@H]2C[C@H]3CCCN3[C@]23C(=O)Nc2cc(Cl)ccc23)C/C(=C\\\\c2ccccc2C)C1=O', 'COc1ccccc1/C=C1\\\\CN(C(=O)[C@H]2C[C@H]3CCCN3[C@]23C(=O)Nc2cc(Cl)ccc23)C/C(=C\\\\c2ccccc2OC)C1=O', 'O=C1/C(=C/c2ccccc2Cl)CN(C(=O)[C@H]2C[C@H]3CCCN3[C@]23C(=O)Nc2cc(Cl)ccc23)C/C1=C\\\\c1ccccc1Cl', 'O=C1/C(=C/c2ccccc2F)CN(C(=O)[C@H]2C[C@H]3CCCN3[C@]23C(=O)Nc2cc(Cl)ccc23)C/C1=C\\\\c1ccccc1F', 'O=C1/C(=C/c2cccc([N+](=O)[O-])c2)CN(C(=O)[C@H]2C[C@H]3CCCN3[C@]23C(=O)Nc2cc(Cl)ccc23)C/C1=C\\\\c1cccc([N+](=O)[O-])c1', 'O=C1/C(=C/c2ccc(Cl)cc2Cl)CN(C(=O)[C@H]2C[C@H]3CCCN3[C@]23C(=O)Nc2cc(Cl)ccc23)C/C1=C\\\\c1ccc(Cl)cc1Cl', 'Cc1ccc(/C=C2\\\\CN(C(=O)[C@H]3C[C@H]4CCCN4[C@]34C(=O)Nc3cc(Cl)ccc34)C/C(=C\\\\c3ccc(C)cc3)C2=O)cc1', 'O=C1/C(=C/c2ccc(Cl)cc2)CN(C(=O)[C@H]2C[C@H]3CCCN3[C@]23C(=O)Nc2cc(Cl)ccc23)C/C1=C\\\\c1ccc(Cl)cc1', 'O=C1/C(=C/c2ccc(F)cc2)CN(C(=O)[C@H]2C[C@H]3CCCN3[C@]23C(=O)Nc2cc(Cl)ccc23)C/C1=C\\\\c1ccc(F)cc1', 'COc1ccc2cc(C(=O)CN3CCN(Cc4ccccc4)CC3)c(=O)oc2c1', 'CN(C)C(=O)[C@H]1C[C@@H]1c1ccc(-c2ncn(C)c2Sc2ccc(Cl)cn2)cc1', 'Cc1cc(=O)oc2cc(OCCN3CCN(CC(=O)Nc4c5c(nc6ccccc46)CCCC5)CC3)ccc12', 'CN(C)CCCN(c1nc2ccccc2[nH]1)c1nc2ccccc2[nH]1', 'c1ccc2[nH]c(N3CCCCC3)nc2c1', 'CC1CCCCN1c1nc2ccccc2[nH]1', 'CC1=C[C@H]2Cc3[nH]c(=O)ccc3[C@@]3(C1)[C@@H]2[C@H](Cl)CCN3C', 'CC1=C[C@H]2Cc3[nH]c(=O)ccc3[C@@]3(C1)[C@@H]2[C@H](C)CN3C', 'C=C[C@@H]1[C@H]2C=C(C)C[C@]1(N)c1ccc(=O)[nH]c1C2', 'CC(C)N(CCOc1ccc(-c2nc3ccccc3[nH]2)cc1)C(C)C', 'c1ccc2[nH]c(-c3ccc(OCCN4CCCC4)cc3)nc2c1', 'c1ccc2[nH]c(-c3ccc(OCCN4CCCCC4)cc3)nc2c1', 'Cc1ccc2[nH]c(-c3ccc(OCCN(C)C)cc3)nc2c1', 'CCN(CC)CCOc1ccc(-c2nc3cc(C)ccc3[nH]2)cc1', 'Cc1ccc2[nH]c(-c3ccc(OCCN4CCCC4)cc3)nc2c1', 'Cc1ccc2[nH]c(-c3ccc(OCCN4CCCCC4)cc3)nc2c1', 'Cc1ccc2[nH]c(-c3ccc(OCCN4CCOCC4)cc3)nc2c1', 'CN(C)CCOc1ccc(-c2nc3cc(Cl)ccc3[nH]2)cc1', 'CCN(CC)CCOc1ccc(-c2nc3cc(Cl)ccc3[nH]2)cc1', 'CC(C)N(CCOc1ccc(-c2nc3cc(Cl)ccc3[nH]2)cc1)C(C)C', 'Clc1ccc2[nH]c(-c3ccc(OCCN4CCCC4)cc3)nc2c1', 'Clc1ccc2[nH]c(-c3ccc(OCCN4CCCCC4)cc3)nc2c1', 'Clc1ccc2[nH]c(-c3ccc(OCCN4CCOCC4)cc3)nc2c1', 'CN(C)CCOc1ccc(-c2nc3ccccc3[nH]2)cc1', 'N#Cc1c(Cl)nc(NC2CCN(Cc3ccccc3)CC2)c(C#N)c1-c1ccccc1', 'N#Cc1c(Cl)nc(NCCC2CCN(Cc3ccccc3)CC2)c(C#N)c1-c1ccccc1', 'N#Cc1c(Cl)nc(NCCCC2CCN(Cc3ccccc3)CC2)c(C#N)c1-c1ccccc1', 'N#Cc1c(Cl)nc(NCCCCC2CCN(Cc3ccccc3)CC2)c(C#N)c1-c1ccccc1', 'N#Cc1cc(C#N)c(NC2CCN(Cc3ccccc3)CC2)nc1Cl', 'N#Cc1cc(C#N)c(NCCC2CCN(Cc3ccccc3)CC2)nc1Cl', 'N#Cc1cc(C#N)c(NCCCC2CCN(Cc3ccccc3)CC2)nc1Cl', 'N#Cc1cc(C#N)c(NCCCCC2CCN(Cc3ccccc3)CC2)nc1Cl', 'N#Cc1c(NCCC2CCN(Cc3ccccc3)CC2)nc(NCCC2CCN(Cc3ccccc3)CC2)c(C#N)c1-c1ccccc1', 'N#Cc1cc(C#N)c(NC2CCN(Cc3ccccc3)CC2)nc1NC1CCN(Cc2ccccc2)CC1', 'O=C(NNC=C1C(=O)NC(=S)NC1=O)Nc1ccccc1', 'O=C1NC(=S)NC(=O)C1=CNNC(=S)Nc1ccc(F)cc1', 'O=C1NC(=S)NC(=O)C1=CNNC(=S)Nc1ccc(Br)cc1', 'O=C1NC(=O)C(=CNNC(=S)Nc2cccc(C(F)(F)F)c2)C(=O)N1', 'O=C1NC(=S)NC(=O)C1=CNNC(=S)Nc1ccc(C(F)(F)F)cc1', 'CC(=O)NC=C1C(=O)NC(=O)NC1=O', 'COc1cccc(CCc2cccc(OC)[n+]2C)[n+]1C.O=S(=O)([O-])C(F)(F)F.O=S(=O)([O-])C(F)(F)F', 'COc1cccc(CCc2cccc(OC)[n+]2C)[n+]1C.O=S(=O)([O-])C(F)(F)F.O=S(=O)([O-])C(F)(F)F', 'COc1cccc(CCCCCc2cccc(OC)[n+]2C)[n+]1C.O=S(=O)([O-])C(F)(F)F.O=S(=O)([O-])C(F)(F)F', 'COc1cccc(CCCCCc2cccc(OC)[n+]2C)[n+]1C.O=S(=O)([O-])C(F)(F)F.O=S(=O)([O-])C(F)(F)F', 'COc1cccc(CCCCCCc2cccc(OC)[n+]2C)[n+]1C.O=S(=O)([O-])C(F)(F)F.O=S(=O)([O-])C(F)(F)F', 'COc1cccc(CCCCCCc2cccc(OC)[n+]2C)[n+]1C.O=S(=O)([O-])C(F)(F)F.O=S(=O)([O-])C(F)(F)F', 'COc1cccc(CCCCCCCc2cccc(OC)[n+]2C)[n+]1C.O=S(=O)([O-])C(F)(F)F.O=S(=O)([O-])C(F)(F)F', 'COc1cccc(CCCCCCCc2cccc(OC)[n+]2C)[n+]1C.O=S(=O)([O-])C(F)(F)F.O=S(=O)([O-])C(F)(F)F', 'COc1cccc(CCCCCCCCc2cccc(OC)[n+]2C)[n+]1C.O=S(=O)([O-])C(F)(F)F.O=S(=O)([O-])C(F)(F)F', 'COc1cccc(CCCCCCCCc2cccc(OC)[n+]2C)[n+]1C.O=S(=O)([O-])C(F)(F)F.O=S(=O)([O-])C(F)(F)F', 'COc1cc2c(cc1OC)C[N+](C)(CCCCc1cccc(OC)[n+]1C)CC2.O=S(=O)([O-])C(F)(F)F.O=S(=O)([O-])C(F)(F)F', 'COc1cc2c(cc1OC)C[N+](C)(CCCCc1cccc(OC)[n+]1C)CC2.O=S(=O)([O-])C(F)(F)F.O=S(=O)([O-])C(F)(F)F', 'COc1cc2c(cc1OC)C[N+](C)(CCCCCc1cccc(OC)[n+]1C)CC2.O=S(=O)([O-])C(F)(F)F.O=S(=O)([O-])C(F)(F)F', 'COc1cc2c(cc1OC)C[N+](C)(CCCCCc1cccc(OC)[n+]1C)CC2.O=S(=O)([O-])C(F)(F)F.O=S(=O)([O-])C(F)(F)F', 'COc1cc2c(cc1OC)C[N+](C)(CCCCCCc1cccc(OC)[n+]1C)CC2.O=S(=O)([O-])C(F)(F)F.O=S(=O)([O-])C(F)(F)F', 'COc1cc2c(cc1OC)C[N+](C)(CCCCCCc1cccc(OC)[n+]1C)CC2.O=S(=O)([O-])C(F)(F)F.O=S(=O)([O-])C(F)(F)F', 'COc1cc2c(cc1OC)C[N+](C)(CCCCCCCc1cccc(OC)[n+]1C)CC2.O=S(=O)([O-])C(F)(F)F.O=S(=O)([O-])C(F)(F)F', 'COc1cc2c(cc1OC)C[N+](C)(CCCCCCCc1cccc(OC)[n+]1C)CC2.O=S(=O)([O-])C(F)(F)F.O=S(=O)([O-])C(F)(F)F', 'COc1cc2c(cc1OC)C(=O)C(CCCCCc1cccc(OC)[n+]1C)C2.O=S(=O)([O-])C(F)(F)F', 'COc1cc2c(cc1OC)C(=O)C(CCCCCc1cccc(OC)[n+]1C)C2.O=S(=O)([O-])C(F)(F)F', 'COc1cc2c(cc1OC)C(=O)C(CCCCCCc1cccc(OC)[n+]1C)C2.O=S(=O)([O-])C(F)(F)F', 'COc1cc2c(cc1OC)C(=O)C(CCCCCCc1cccc(OC)[n+]1C)C2.O=S(=O)([O-])C(F)(F)F', 'COc1cc2c(cc1OC)C(=O)C(CCCCCCCc1cccc(OC)[n+]1C)C2.O=S(=O)([O-])C(F)(F)F', 'COc1cc2c(cc1OC)C(=O)C(CCCCCCCc1cccc(OC)[n+]1C)C2.O=S(=O)([O-])C(F)(F)F', 'COc1ccc(C(F)(F)F)c[n+]1CCCCCO.O=S(=O)([O-])C(F)(F)F', 'COc1ccc(C(F)(F)F)c[n+]1CCC[n+]1cc(C(F)(F)F)ccc1OC.O=S(=O)([O-])C(F)(F)F.O=S(=O)([O-])C(F)(F)F', 'COc1ccc(C(F)(F)F)c[n+]1CCC[n+]1cc(C(F)(F)F)ccc1OC.O=S(=O)([O-])C(F)(F)F.O=S(=O)([O-])C(F)(F)F', 'COc1ccc(C(F)(F)F)c[n+]1CCCCC[n+]1cc(C(F)(F)F)ccc1OC.O=S(=O)([O-])C(F)(F)F.O=S(=O)([O-])C(F)(F)F', 'COc1ccc(C(F)(F)F)c[n+]1CCCCC[n+]1cc(C(F)(F)F)ccc1OC.O=S(=O)([O-])C(F)(F)F.O=S(=O)([O-])C(F)(F)F', 'COc1ccc(C(F)(F)F)c[n+]1CCCOc1ccc2c(C)cc(=O)oc2c1.O=S(=O)([O-])C(F)(F)F', 'COc1ccc(C(F)(F)F)c[n+]1CCCOc1ccc2c(C)cc(=O)oc2c1.O=S(=O)([O-])C(F)(F)F', 'COc1ccc(C(F)(F)F)c[n+]1CCCCOc1ccc2c(C)cc(=O)oc2c1.O=S(=O)([O-])C(F)(F)F', 'COc1ccc(C(F)(F)F)c[n+]1CCCCOc1ccc2c(C)cc(=O)oc2c1.O=S(=O)([O-])C(F)(F)F', 'COc1ccc(C(F)(F)F)c[n+]1CCCCCOc1ccc2c(C)cc(=O)oc2c1.O=S(=O)([O-])C(F)(F)F', 'COc1ccc(C(F)(F)F)c[n+]1CCCCCOc1ccc2c(C)cc(=O)oc2c1.O=S(=O)([O-])C(F)(F)F', 'COc1c(F)c[n+](CCCOc2ccc3c(C)cc(=O)oc3c2)cc1F.O=S(=O)([O-])C(F)(F)F', 'COc1c(F)c[n+](CCCOc2ccc3c(C)cc(=O)oc3c2)cc1F.O=S(=O)([O-])C(F)(F)F', 'COc1c(F)c[n+](CCCCOc2ccc3c(C)cc(=O)oc3c2)cc1F.O=S(=O)([O-])C(F)(F)F', 'COc1c(F)c[n+](CCCCOc2ccc3c(C)cc(=O)oc3c2)cc1F.O=S(=O)([O-])C(F)(F)F', 'COc1c(F)c[n+](CCCCCOc2ccc3c(C)cc(=O)oc3c2)cc1F.O=S(=O)([O-])C(F)(F)F', 'COc1c(F)c[n+](CCCCCOc2ccc3c(C)cc(=O)oc3c2)cc1F.O=S(=O)([O-])C(F)(F)F', 'COc1cccc[n+]1C.F[B-](F)(F)F', 'COc1cccc[n+]1C.F[B-](F)(F)F', 'COc1c(F)ccc[n+]1C.F[B-](F)(F)F', 'COc1ccc(F)c[n+]1C.F[B-](F)(F)F', 'COc1ccc(F)c[n+]1C.F[B-](F)(F)F', 'COc1ccc(C(F)(F)F)c[n+]1C.F[B-](F)(F)F', 'COc1ccc(C(F)(F)F)c[n+]1C.F[B-](F)(F)F', 'COc1cccc(C(F)(F)F)[n+]1C.F[B-](F)(F)F', 'COc1cccc(C(F)(F)F)[n+]1C.F[B-](F)(F)F', 'COc1ccc([N+](=O)[O-])c[n+]1C.F[B-](F)(F)F', 'COc1ccc([N+](=O)[O-])c[n+]1C.F[B-](F)(F)F', 'COc1cc(C#N)cc[n+]1C.F[B-](F)(F)F', 'COc1cc(C#N)cc[n+]1C.F[B-](F)(F)F', 'COc1ccc(C#N)c[n+]1C.F[B-](F)(F)F', 'COc1ccc(C#N)c[n+]1C.F[B-](F)(F)F', 'COc1cccc(C#N)[n+]1C.F[B-](F)(F)F', 'COc1cccc(C#N)[n+]1C.F[B-](F)(F)F', 'COc1c(F)c[n+](C)cc1F.O=S(=O)([O-])C(F)(F)F', 'COc1c(F)c[n+](C)cc1F.O=S(=O)([O-])C(F)(F)F', 'COc1c(F)c[n+](CCC[n+]2cc(F)c(OC)c(F)c2)cc1F.O=S(=O)([O-])C(F)(F)F.O=S(=O)([O-])C(F)(F)F', 'COc1c(F)c[n+](CCC[n+]2cc(F)c(OC)c(F)c2)cc1F.O=S(=O)([O-])C(F)(F)F.O=S(=O)([O-])C(F)(F)F', 'Cl.Cl.O=C(CCc1ccc2nc(-c3ccccc3)c3c(c2c1)OCCC3)NCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'CCCCCCNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN(CCC)C1C2.Cc1ccc(C(=O)OC(C(=O)O)C(OC(=O)c2ccc(C)cc2)C(=O)O)cc1.O', 'C=CC(C)(C)c1cc([C@@H]2CC(=O)c3c(O)cc(O)c(CC=C(C)C)c3O2)c(O)cc1O', 'CCn1c(=O)n(C)s/c1=N\\\\CCC1CCN(Cc2ccccc2)CC1', 'COc1cc2[se]n(CCC3CCN(Cc4ccccc4)CC3)c(=O)c2cc1OC', 'COc1cc2[se]n(CCCC3CCN(Cc4ccccc4)CC3)c(=O)c2cc1OC', 'COc1cc2[se]n(CCCCC3CCN(Cc4ccccc4)CC3)c(=O)c2cc1OC', 'COc1cc2c(cc1OC)[Se](=O)N(CCC1CCN(Cc3ccccc3)CC1)C2=O', 'CC(C)Cc1ccc(C(C)C(=O)NCCCNCCCNC2=CC(=O)C(NCCCNCCCNC(=O)C(C)c3ccc(CC(C)C)cc3)=CC2=O)cc1', 'CC1=C(CC(=O)NCCCNCCCNC2=CC(=O)C(NCCCNCCCNC(=O)CC3=C(C)/C(=C\\\\c4ccc([S+](C)[O-])cc4)c4ccc(F)cc43)=CC2=O)c2cc(F)ccc2/C1=C/c1ccc([S+](C)[O-])cc1', 'O=C(Cc1ccccc1Nc1c(Cl)cccc1Cl)NCCCNCCCNC1=CC(=O)C(NCCCNCCCNC(=O)Cc2ccccc2Nc2c(Cl)cccc2Cl)=CC1=O', 'O=C(Cc1ccccc1Nc1c(Cl)cccc1Cl)NCCCNCCCNC1=CC(=O)C(NCCCNCCCNC(=O)Cc2ccccc2Nc2c(Cl)cccc2Cl)=CC1=O', 'COc1ccc2c(c1)c(CC(=O)NCCCNCCCNC1=CC(=O)C(NCCCNCCCNC(=O)Cc3c(C)n(C(=O)c4ccc(Cl)cc4)c4ccc(OC)cc34)=CC1=O)c(C)n2C(=O)c1ccc(Cl)cc1', 'C[C@@H](C(=O)NCCCNCCCNC1=CC(=O)C(NCCCNCCCNC(=O)[C@H](C)c2ccc(-c3ccccc3)c(F)c2)=CC1=O)c1ccc(-c2ccccc2)c(F)c1', 'C[C@H](C(=O)NCCCNCCCNC1=CC(=O)C(NCCCNCCCNC(=O)[C@@H](C)c2ccc(-c3ccccc3)c(F)c2)=CC1=O)c1ccc(-c2ccccc2)c(F)c1', 'COc1ccc(/C=C2\\\\COc3cc(OCCCCCNc4c5c(nc6ccccc46)CCCC5)ccc3C2=O)cc1', 'COc1ccc(/C=C2\\\\COc3cc(OCCCCCCNc4c5c(nc6ccccc46)CCCC5)ccc3C2=O)cc1', 'COc1ccc(/C=C2\\\\COc3cc(OCCCCCCCCNc4c5c(nc6ccccc46)CCCC5)ccc3C2=O)cc1', 'O=C1/C(=C/c2ccc(F)cc2)COc2cc(OCCCCCCNc3c4c(nc5ccccc35)CCCC4)ccc21', 'O=c1c2ccccc2[se]n1CCCCCCNc1c2c(nc3ccccc13)CCCC2', 'COc1cc2[se]n(CCCCCCNc3c4c(nc5ccccc35)CCCC4)c(=O)c2cc1OC', '[Br-].[Br-].c1cc[n+](CCCCCCC[n+]2ccc3ccccc3c2)cc1', '[Br-].[Br-].c1cc[n+](CCCCCCCC[n+]2ccc3ccccc3c2)cc1', '[Br-].[Br-].c1cc[n+](CCCCCCCCC[n+]2ccc3ccccc3c2)cc1', '[Br-].[Br-].c1cc[n+](CCCCCCCCCC[n+]2ccc3ccccc3c2)cc1', '[Br-].[Br-].c1cc[n+](CCCCCCCCCCC[n+]2ccc3ccccc3c2)cc1', '[Br-].[Br-].c1cc[n+](CCCCCCC[n+]2cccc3ccccc32)cc1', '[Br-].[Br-].c1cc[n+](CCCCCCCC[n+]2cccc3ccccc32)cc1', '[Br-].[Br-].c1cc[n+](CCCCCCCCC[n+]2cccc3ccccc32)cc1', '[Br-].[Br-].c1cc[n+](CCCCCCCCCC[n+]2cccc3ccccc32)cc1', '[Br-].[Br-].c1cc[n+](CCCCCCCCCC[n+]2cccc3ccccc32)cc1', '[Br-].[Br-].c1cc[n+](CCCCCCCCCC[n+]2cccc3ccccc32)cc1', '[Br-].[Br-].c1cc[n+](CCCCCCCCCCC[n+]2cccc3ccccc32)cc1', '[Br-].[Br-].c1cc[n+](CCCCCCCCCCCC[n+]2cccc3ccccc32)cc1', '[Br-].[Br-].c1cc[n+](CCCCCCCCCCCC[n+]2cccc3ccccc32)cc1', '[Br-].[Br-].c1cc[n+](CCCCCCCCCCCC[n+]2cccc3ccccc32)cc1', 'O=[N+]([O-])c1cccc2c(NCCCCCCCCNc3c4c(nc5ccccc35)CCCC4)c3c(nc12)CCCC3', 'Nc1cccc2c(NCCCCCCCCNc3c4c(nc5ccccc35)CCCC4)c3c(nc12)CCCC3', 'O=C(CC[C@H](NC(=O)CNC(=O)OCc1ccccc1)C(=O)N[C@@H](Cc1ccccc1)C(=O)OCc1ccccc1)NCC(=O)Nc1cccc2c(NCCCCCCCCNc3c4c(nc5ccccc35)CCCC4)c3c(nc12)CCCC3', 'CN(CCCCNc1c2c(nc3ccccc13)CCCC2)CCCNc1c2c(nc3c(NC(=O)CNC(=O)CC[C@H](NC(=O)CNC(=O)OCc4ccccc4)C(=O)N[C@@H](Cc4ccccc4)C(=O)OCc4ccccc4)cccc13)CCCC2', 'CN(CCCCNc1c2c(nc3c(NC(=O)CNC(=O)CC[C@H](NC(=O)CNC(=O)OCc4ccccc4)C(=O)N[C@@H](Cc4ccccc4)C(=O)OCc4ccccc4)cccc13)CCCC2)CCCNc1c2c(nc3ccccc13)CCCC2', 'COc1cc2[se]n(-c3ccc(CN4CCCC4)cc3)c(=O)c2cc1OC', 'COc1cc2[se]n(-c3ccc(CN4CCCCC4)cc3)c(=O)c2cc1OC', 'COc1cc2[se]n(-c3ccc(CCN4CCCC4)cc3)c(=O)c2cc1OC', 'COc1cc2[se]n(-c3ccc(CCN4CCCCC4)cc3)c(=O)c2cc1OC', 'COc1cc2[se]n(-c3ccc(OCCN4CCCCC4)cc3)c(=O)c2cc1OC', 'COc1cc2[se]n(-c3ccc(OCCCN4CCCCC4)cc3)c(=O)c2cc1OC', 'COc1cc2[se]n(-c3ccc(OCCCCN4CCCCC4)cc3)c(=O)c2cc1OC', 'O=c1c2ccccc2[se]n1-c1ccc(CN2CCCCC2)cc1', 'O=c1c2ccccc2[se]n1-c1ccc(OCCN2CCCCC2)cc1', 'COc1ccccc1/C=C1\\\\CN(C(=O)[C@@H]2CCN(C)[C@]23C(=O)Nc2ccccc23)C[C@]2(C1=O)[C@H](c1ccccc1OC)CN(C)[C@]21C(=O)Nc2ccccc21', 'CN1CC[C@@H](C(=O)N2C/C(=C\\\\c3ccccc3Cl)C(=O)[C@@]3(C2)[C@H](c2ccccc2Cl)CN(C)[C@]32C(=O)Nc3ccccc32)[C@@]12C(=O)Nc1ccccc12', 'CN1CC[C@@H](C(=O)N2C/C(=C\\\\c3ccccc3F)C(=O)[C@@]3(C2)[C@H](c2ccccc2F)CN(C)[C@]32C(=O)Nc3ccccc32)[C@@]12C(=O)Nc1ccccc12', 'CN1CC[C@@H](C(=O)N2C/C(=C\\\\c3cccc([N+](=O)[O-])c3)C(=O)[C@@]3(C2)[C@H](c2cccc([N+](=O)[O-])c2)CN(C)[C@]32C(=O)Nc3ccccc32)[C@@]12C(=O)Nc1ccccc12', 'CN1CC[C@@H](C(=O)N2C/C(=C\\\\c3ccc(Cl)cc3Cl)C(=O)[C@@]3(C2)[C@H](c2ccc(Cl)cc2Cl)CN(C)[C@]32C(=O)Nc3ccccc32)[C@@]12C(=O)Nc1ccccc12', 'Cc1ccc(/C=C2\\\\CN(C(=O)[C@@H]3CCN(C)[C@]34C(=O)Nc3ccccc34)C[C@]3(C2=O)[C@H](c2ccc(C)cc2)CN(C)[C@]32C(=O)Nc3ccccc32)cc1', 'CN1CC[C@@H](C(=O)N2C/C(=C\\\\c3ccc(Cl)cc3)C(=O)[C@@]3(C2)[C@H](c2ccc(Cl)cc2)CN(C)[C@]32C(=O)Nc3ccccc32)[C@@]12C(=O)Nc1ccccc12', 'CN1CC[C@@H](C(=O)N2C/C(=C\\\\c3ccc(F)cc3)C(=O)[C@@]3(C2)[C@H](c2ccc(F)cc2)CN(C)[C@]32C(=O)Nc3ccccc32)[C@@]12C(=O)Nc1ccccc12', 'CN1CC[C@@H](C(=O)N2C/C(=C\\\\c3ccc(F)cc3)C(=O)[C@@]3(C2)[C@H](c2ccc(F)cc2)CN(C)[C@]32C(=O)Nc3ccccc32)[C@@]12C(=O)Nc1ccccc12', 'CN1CC[C@@H](C(=O)N2C/C(=C\\\\c3cccc4ccccc34)C(=O)[C@@]3(C2)[C@H](c2cccc4ccccc24)CN(C)[C@]32C(=O)Nc3ccccc32)[C@@]12C(=O)Nc1ccccc12', 'C=CC(=O)N1C/C(=C\\\\c2ccccc2)C(=O)[C@@]2(C1)[C@H](c1ccccc1)CN(C)[C@]21C(=O)Nc2ccccc21', 'C=CC(=O)N1C/C(=C\\\\c2ccccc2C)C(=O)[C@@]2(C1)[C@H](c1ccccc1C)CN(C)[C@]21C(=O)Nc2ccccc21', 'C=CC(=O)N1C/C(=C\\\\c2ccccc2OC)C(=O)[C@@]2(C1)[C@H](c1ccccc1OC)CN(C)[C@]21C(=O)Nc2ccccc21', 'C=CC(=O)N1C/C(=C\\\\c2ccccc2Cl)C(=O)[C@@]2(C1)[C@H](c1ccccc1Cl)CN(C)[C@]21C(=O)Nc2ccccc21', 'C=CC(=O)N1C/C(=C\\\\c2ccccc2F)C(=O)[C@@]2(C1)[C@H](c1ccccc1F)CN(C)[C@]21C(=O)Nc2ccccc21', 'C=CC(=O)N1C/C(=C\\\\c2cccc([N+](=O)[O-])c2)C(=O)[C@@]2(C1)[C@H](c1cccc([N+](=O)[O-])c1)CN(C)[C@]21C(=O)Nc2ccccc21', 'C=CC(=O)N1C/C(=C\\\\c2ccc(Cl)cc2Cl)C(=O)[C@@]2(C1)[C@H](c1ccc(Cl)cc1Cl)CN(C)[C@]21C(=O)Nc2ccccc21', 'C=CC(=O)N1C/C(=C\\\\c2ccc(C)cc2)C(=O)[C@@]2(C1)[C@H](c1ccc(C)cc1)CN(C)[C@]21C(=O)Nc2ccccc21', 'C=CC(=O)N1C/C(=C\\\\c2ccc(Cl)cc2)C(=O)[C@@]2(C1)[C@H](c1ccc(Cl)cc1)CN(C)[C@]21C(=O)Nc2ccccc21', 'C=CC(=O)N1C/C(=C\\\\c2ccc(F)cc2)C(=O)[C@@]2(C1)[C@H](c1ccc(F)cc1)CN(C)[C@]21C(=O)Nc2ccccc21', 'C=CC(=O)N1C/C(=C\\\\c2cccc3ccccc23)C(=O)[C@@]2(C1)[C@H](c1cccc3ccccc13)CN(C)[C@]21C(=O)Nc2ccccc21', 'CN1CC[C@@H](C(=O)N2C/C(=C\\\\c3ccccc3)C(=O)[C@@]3(C2)[C@H](c2ccccc2)CN(C)[C@]32C(=O)Nc3ccccc32)[C@@]12C(=O)Nc1ccccc12', 'Cc1ccccc1/C=C1\\\\CN(C(=O)[C@@H]2CCN(C)[C@]23C(=O)Nc2ccccc23)C[C@]2(C1=O)[C@H](c1ccccc1C)CN(C)[C@]21C(=O)Nc2ccccc21', 'c1ccc2c(c1)c(OCC1CCCCC1)nn2CC1CCCCC1', 'c1ccc(COc2nn(Cc3ccccc3)c3ccccc23)cc1', 'CCCCCOc1nn(CCCCC)c2ccc([N+](=O)[O-])cc12', 'CCCCCn1nc(OCc2ccc(OC)cc2)c2cc([N+](=O)[O-])ccc21', 'COc1ccc(COc2nn(CCN(C(C)C)C(C)C)c3ccc([N+](=O)[O-])cc23)cc1', 'O=[N+]([O-])c1ccc2c(c1)c(OCc1cccc3ccccc13)nn2Cc1cccc2ccccc12', 'CCCCCn1nc(OCc2ccc3ccccc3c2)c2cc([N+](=O)[O-])ccc21', 'O=[N+]([O-])c1ccc2c(c1)c(OCc1ccc3ccccc3c1)nn2Cc1ccccc1', 'Nc1ccc2c(c1)c(OCc1ccccc1)nn2Cc1ccccc1', 'CCOC(=O)c1ccc2nc(-c3cccnc3)c3c(c2c1)N(Cc1ccccc1)CCC3', 'CCNC(=O)c1ccc2nc(-c3ccc(Cl)cc3)c3c(c2c1)N(Cc1ccccc1)CCC3', 'CCNC(=O)c1ccc2nc(-c3ccc(Cl)cc3)c3c(c2c1)N(Cc1ccccc1)CCC3', 'CCNC(=O)c1ccc2nc(-c3ccc(Cl)cc3)c3c(c2c1)N(Cc1ccccc1)CCC3', 'CCNCc1ccc2nc(-c3ccc(Cl)cc3)c3c(c2c1)N(Cc1ccccc1)CCC3', 'CCOC(=O)c1ccc2nc(-c3cccnc3)c3c(c2c1)NCCC3', 'CCNC(=O)c1ccc2nc(-c3ccc(Cl)cc3)c3c(c2c1)NCCC3', 'CCNC(=O)c1ccc2nc(-c3ccc(Cl)cc3)c3c(c2c1)NCCC3', 'CCNC(=O)c1ccc2nc(-c3ccc(Cl)cc3)c3c(c2c1)NCCC3', 'CCNC(=O)c1ccc2nc(-c3ccc(Cl)cc3)c3c(c2c1)NCCC3', 'CCNCc1ccc2nc(-c3ccc(Cl)cc3)c3c(c2c1)NCCC3', 'CCNCc1ccc2nc(-c3cccnc3)c3c(c2c1)NCCC3', 'CCOC(=O)c1ccc2nc(-c3ccc(Cl)cc3)c3c(c2c1)N(Cc1ccccc1)C(=O)CC3', 'CCOC(=O)c1ccc2nc(-c3cccnc3)c3c(c2c1)N(Cc1ccccc1)C(=O)CC3', 'CCN(CCCCOc1ccc(-c2coc3cc(O)cc(O)c3c2=O)cc1)Cc1ccccc1OC', 'CCN(CCCCOc1ccc(-c2coc3cc(OCCCCN(CC)Cc4ccccc4)cc(O)c3c2=O)cc1)Cc1ccccc1', 'CCN(CCCCOc1ccc(-c2coc3cc(OCCCCN(CC)Cc4ccccc4OC)cc(O)c3c2=O)cc1)Cc1ccccc1OC', 'CCN(CCCCCCOc1cc(O)c2c(=O)c(-c3ccc(O)cc3)coc2c1)Cc1ccccc1', 'Cn1ncc2c1-c1sccc1C2NC(=O)CN1CCN(Cc2ccccc2)CC1', 'Cn1ncc2c1-c1sccc1C2NC(=O)CN1CCN(Cc2ccccc2F)CC1', 'O=C(CN1CCN(Cc2ccccc2)CC1)NC1c2cn[nH]c2-c2c(Br)sc(Br)c21', 'Cn1ncc2c1-c1c(Br)sc(Br)c1C2NC(=O)CN1CCN(Cc2ccccc2)CC1', 'O=C(CN1CCN(Cc2ccccc2)CC1)NC1c2cnn(-c3ccccc3)c2-c2c(Br)sc(Br)c21', 'Cn1ncc2c1-c1c(Br)sc(Br)c1C2NC(=O)CN1CCN(Cc2ccccc2F)CC1', 'COc1cc2c(cc1OC)C(NC(=O)CN1CCN(Cc3ccccc3)CC1)c1cnn(C)c1-2', 'COc1cc2c(cc1OC)C(NC(=O)CN1CCN(Cc3ccccc3)CC1)c1cnn(-c3ccccc3)c1-2', 'COc1cc2c(cc1OC)C(NC(=O)CN1CCN(Cc3ccccc3F)CC1)c1cnn(C)c1-2', 'COc1cc2c(cc1OC)C(NC(=O)CN1CCN(Cc3ccccc3F)CC1)c1cnn(-c3ccccc3)c1-2', 'O=C(CN1CCN(Cc2ccccc2)CC1)NC1c2cn[nH]c2-c2sccc21', 'C[Si](C)(C)c1cccc(C(=O)C(F)(F)F)c1', 'C[Si](C)(C)c1cccc(C(=O)C(F)(F)F)c1', 'CNC(=C[N+](=O)[O-])NCCSCc1csc(CN(C)C)n1', 'Cl.Cl.c1ccc(CN2CCC(CCNc3ccc(-c4ccccc4)nn3)CC2)cc1', 'Cl.Cl.c1ccc(CN2CCC(CCNc3ccc(-c4ccccc4)nn3)CC2)cc1', 'Cl.Cl.Cl.Cl.O=C(NCCCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2)c1ccc2nc(-c3ccc(Cl)cc3)c3c(c2c1)OCCC3', 'Cl.Cl.Cl.O=C(CCc1ccc2nc(-c3ccccc3)c3c(c2c1)OCCC3)NCCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'Cl.Cl.Cl.O=C(CCc1ccc2nc(-c3ccccc3)c3c(c2c1)OCCC3)NCCCCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'Cl.Cl.Oc1c(CNCCCCCCCCCNc2c3c(nc4ccccc24)CCCC3)ccc2cccnc12', 'Cl.Cl.Cl.Cl.O=C(NCCCCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2)c1ccc2nc(-c3ccc(Cl)cc3)c3c(c2c1)OCCC3', 'Cl.Cl.Cl.Cl.O=C(NCCCCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2)c1ccc2nc(-c3ccc(Cl)cc3)c3c(c2c1)OCCC3', 'Cl.Cl.Cl.Cl.O=C(NCCCCCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2)c1ccc2nc(-c3ccc(Cl)cc3)c3c(c2c1)OCCC3', 'Cl.Cl.Cl.Cl.O=C(NCCCCCCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2)c1ccc2nc(-c3ccc(Cl)cc3)c3c(c2c1)OCCC3', 'Cc1ccc2ccc(CNCCCCCCCCNc3c4c(nc5ccccc35)CCCC4)c(O)c2n1.Cl.Cl', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(NCCCCCCCNc4c5c(nc6ccccc46)CCCC5)c3C(C1)C2.Cl.Cl.Cl', 'Cl.Cl.Cl.O=C(CCc1ccc2nc(-c3ccccc3)c3c(c2c1)OCCC3)NCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(NCCCCCCCCCNc4c5c(nc6ccccc46)CCCC5)c3C(C1)C2.Cl.Cl.Cl', 'COc1cc2c(cc1OC)CC(CC1CCN(CCNc3c4c(nc5ccccc35)CCCC4)CC1)C2.Cl.Cl', 'COc1cc2c(cc1OC)CC(CC1CCN(CCCNc3c4c(nc5ccccc35)CCCC4)CC1)C2.Cl.Cl', 'COc1cc2c(cc1OC)CC(CC1CCN(CCNc3c4c(nc5cc(Cl)ccc35)CCCC4)CC1)C2.Cl.Cl.Cl', 'Cl.Cl.Cl.O=C(CCc1ccc2nc(-c3ccccc3)c3c(c2c1)OCCC3)NCCCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(CCNc3c4c(nc5cc(Cl)ccc35)CCCC4)CC1)C2.Cl.Cl.Cl', 'Cl.Cl.Cl.Cl.O=C(NCCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2)c1ccc2nc(-c3ccc(Cl)cc3)c3c(c2c1)OCCC3', 'Cl.Cl.Cl.Oc1c(CNCCCCCCCCCNc2c3c(nc4ccccc24)CCCC3)cc(Cl)c2cccnc12', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(NCCCCCCCCCCNc4c5c(nc6ccccc46)CCCC5)c3C(C1)C2.Cl.Cl.Cl', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(NCCCCCCCNc4c5c(nc6cc(Cl)ccc46)CCCC5)c3C(C1)C2.Cl.Cl.Cl.Cl', 'CC1=C[C@@H]2Cc3nc4cc(Cl)ccc4c(NCCCCCCCNc4c5c(nc6cc(Cl)ccc46)CCCC5)c3[C@H](C1)C2.Cl.Cl.Cl.Cl', 'CC1=C[C@H]2Cc3nc4cc(Cl)ccc4c(NCCCCCCCNc4c5c(nc6cc(Cl)ccc46)CCCC5)c3[C@@H](C1)C2.Cl.Cl.Cl.Cl', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(CCCNc3c4c(nc5cc(Cl)ccc35)CCCC4)CC1)C2.Cl.Cl.Cl', 'CC1=C[C@@H]2Cc3nc4cc(Cl)ccc4c(NCCCCCCCNc4c5c(nc6ccccc46)CCCC5)c3[C@H](C1)C2.Cl.Cl.Cl', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(NCCCCCCCCCNc4c5c(nc6cc(Cl)ccc46)CCCC5)c3C(C1)C2.Cl.Cl.Cl.Cl', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(NCCCCCCCCCCNc4c5c(nc6cc(Cl)ccc46)CCCC5)c3C(C1)C2.Cl.Cl.Cl.Cl', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(CCCNc3c4c(nc5ccccc35)CCCC4)CC1)C2.Cl.Cl', 'COc1cc2c(cc1OC)CC(CC1CCN(CCCNc3c4c(nc5cc(Cl)ccc35)CCCC4)CC1)C2.Cl.Cl.Cl', 'CC1=C[C@H]2Cc3nc4cc(Cl)ccc4c(NCCCCCCCNc4c5c(nc6ccccc46)CCCC5)c3[C@@H](C1)C2.Cl.Cl.Cl', 'Cc1ccc(C(=O)Nc2cc3cc(C)ccc3oc2=O)cc1', 'COc1ccc(C(=O)Nc2cc3ccccc3oc2=O)cc1', 'O=C(Nc1cc2ccccc2oc1=O)c1ccc(Cl)cc1', 'O=C(Nc1cc2ccccc2oc1=O)c1ccc([N+](=O)[O-])cc1', 'O=C(Nc1cc2ccccc2oc1=O)c1ccc(Cl)c(Cl)c1', 'C[C@@]12CC[C@@H]3[C@@](CC[C@H]4[C@@]3(C)CCC[C@@]4(C)C(=O)OCC[N+](C)(C)Cc3ccccc3)(CC1=O)C2.[Br-]', 'C[C@@]12CC[C@@H]3[C@@](CC[C@H]4[C@@]3(C)CCC[C@@]4(C)C(=O)OCC[N+](C)(C)CCCCCCCCCC[N+](C)(C)CCOC(=O)[C@]3(C)CCC[C@@]4(C)[C@@H]5CC[C@@]6(C)C[C@]5(CC[C@@H]43)CC6=O)(CC1=O)C2.[Br-].[Br-]', 'C[C@@]12CC[C@@H]3[C@@](CC[C@H]4[C@@]3(C)CCC[C@@]4(C)C(=O)OCC[N+](C)(C)CCCCCCCCCCCC[N+](C)(C)CCOC(=O)[C@]3(C)CCC[C@@]4(C)[C@@H]5CC[C@@]6(C)C[C@]5(CC[C@@H]43)CC6=O)(CC1=O)C2.[Br-].[Br-]', 'C[C@@]12CC[C@@H]3[C@]4(CC[C@H]5[C@@]3(C)CCC[C@@]5(C)C(=O)OCC[N+](C)(C)CCCCCCCCC[N+](C)(C)CCOC(=O)[C@]3(C)CCC[C@@]5(C)[C@@H]6CC[C@@]7(C)C[C@]6(CC[C@@H]53)C[C@H]7OC(=O)CCCCCCCCC(=O)O[C@@H]1C4)C2.[Br-].[Br-]', 'CC[N+](CC)(CC)CCOCCOCCOC(=O)[C@]1(C)CCC[C@@]2(C)[C@@H]3CC[C@@]4(C)C[C@]3(CC[C@@H]21)CC4=O.[Br-]', 'C[C@H]1C[C@@]23CC[C@H]4[C@@](C)(CCC[C@@]4(C)C(=O)OCC[N+](C)(C)C)[C@@H]2CC[C@]1(Cl)C3.[I-]', 'C[C@H]1C[C@@]23CC[C@H]4[C@@](C)(CCC[C@@]4(C)C(=O)OCC[N+](C)(C)Cc4ccccc4)[C@@H]2CC[C@]1(Cl)C3.[Br-]', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(NCCCCCNC(=O)c4cc(O)c5c(c4)C(=O)c4cccc(O)c4C5=O)c3C(C1)C2.Cl', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(NCCCCCCNC(=O)c4cc(O)c5c(c4)C(=O)c4cccc(O)c4C5=O)c3C(C1)C2.Cl', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(NCCCCCCCNC(=O)c4cc(O)c5c(c4)C(=O)c4cccc(O)c4C5=O)c3C(C1)C2.Cl', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(NCCCCCCCCNC(=O)c4cc(O)c5c(c4)C(=O)c4cccc(O)c4C5=O)c3C(C1)C2.Cl', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(NCCCCCCCCCNC(=O)c4cc(O)c5c(c4)C(=O)c4cccc(O)c4C5=O)c3C(C1)C2.Cl', 'CC1=C[C@H]2Cc3nc4cc(Cl)ccc4c(NCCCCCCCCCNC(=O)c4cc(O)c5c(c4)C(=O)c4cccc(O)c4C5=O)c3[C@@H](C1)C2.Cl', 'CC1=C[C@@H]2Cc3nc4cc(Cl)ccc4c(NCCCCCCCCCNC(=O)c4cc(O)c5c(c4)C(=O)c4cccc(O)c4C5=O)c3[C@H](C1)C2.Cl', 'CC1=C[C@@H]2Cc3nc4cc(Cl)ccc4c(NCCCCCCCCCNC(=O)c4cc(O)c5c(c4)C(=O)c4cccc(O)c4C5=O)c3[C@H](C1)C2.Cl', 'CC1=C[C@@H]2Cc3nc4cc(Cl)ccc4c(NCCCCCCCCCNC(=O)c4cc(O)c5c(c4)C(=O)c4cccc(O)c4C5=O)c3[C@H](C1)C2.Cl', 'COc1cc2[nH]c(=O)c(C(=O)NCC3CCN(Cc4ccccc4)CC3)c(O)c2cc1OC', 'O=C(NCC1CCN(Cc2ccccc2)CC1)c1c(O)c2cc(O)c(O)cc2[nH]c1=O', 'COc1ccc(C(C#N)N2CCCC2)cc1OC', 'COc1ccc(C(C#N)N2CCOCC2)cc1OC', 'N#CC(c1ccc2c(c1)OCO2)N1CCCCC1', 'N#CC(c1ccc2c(c1)OCO2)N1CCCC1', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(NCCCCCCCCCCNC(=O)c4cc(O)c5c(c4)C(=O)c4cccc(O)c4C5=O)c3C(C1)C2.Cl', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(NCCCCCCCCCCCNC(=O)c4cc(O)c5c(c4)C(=O)c4cccc(O)c4C5=O)c3C(C1)C2.Cl', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(NCc4ccc(CNC(=O)c5cc(O)c6c(c5)C(=O)c5cccc(O)c5C6=O)cc4)c3C(C1)C2.Cl', 'NC(=O)c1cc[n+](CCC[n+]2ccccc2/C=N/O)cc1.[Cl-].[Cl-]', 'CN(CCNc1c2c(nc3ccccc13)CCCC2)Cc1ccnc(/C(N)=N/O)c1O', 'CN(CCCNc1c2c(nc3ccccc13)CCCC2)Cc1ccnc(/C(N)=N/O)c1O', 'O/N=C/c1nc(CCCCCNc2c3c(nc4ccccc24)CCCC3)ccc1O', 'O/N=C/c1nc(CCCCCNc2c3c(nc4ccccc24)CCCC3)ccc1O', 'O/N=C/c1nc(CCCCCNc2c3c(nc4ccccc24)CCCC3)ccc1O', 'O/N=C/c1nc(CCCCCNc2c3c(nc4ccccc24)CCCC3)ccc1O', 'O/N=C/c1nc(CCCCNc2c3c(nc4ccccc24)CCCC3)ccc1O', 'O/N=C/c1nc(CCCCNc2c3c(nc4ccccc24)CCCC3)ccc1O', 'O/N=C/c1nc(CCCCNc2c3c(nc4ccccc24)CCCC3)ccc1O', 'O/N=C/c1nc(CCCCNc2c3c(nc4ccccc24)CCCC3)ccc1O', 'O/N=C/c1nc(CCCCNc2c3c(nc4ccccc24)CCCC3)ccc1O', 'O/N=C/c1nc(CCCCNc2c3c(nc4ccccc24)CCCC3)ccc1O', 'O/N=C/c1ncc(CCCCCNc2c3c(nc4ccccc24)CCCC3)cc1O', 'N/C(=N\\\\O)c1nc(CCCCCNc2c3c(nc4ccccc24)CCCC3)ccc1O', 'O/N=C/c1nccc(CCCCCNc2c3c(nc4ccccc24)CCCC3)c1O', 'c1ccc(CCCCCNc2c3c(nc4ccccc24)CCCC3)nc1', 'CC(=O)/C(=N\\\\O)C(=O)NCC1CCN(Cc2ccccc2)CC1', 'Cl.O=C(/C=N/O)NCCCNc1c2c(nc3ccccc13)CCCC2', 'O=C(/C=N/O)NCCCCNc1c2c(nc3ccccc13)CCCC2', 'N#C/C(=N\\\\O)C(=O)NCCCNc1c2c(nc3ccccc13)CCCC2', 'O=C(/C=N/O)NCCCCCCNc1c2c(nc3ccccc13)CCCC2', 'O=C(/C=N/O)c1cccnc1OCC1CCN(Cc2ccccc2)CC1', 'O=C(/C=N/O)c1ccc(OCC2CCN(Cc3ccccc3)CC2)nc1', 'O=C(/C=N/O)c1cnc(OCC2CCN(Cc3ccccc3)CC2)nc1', 'O=C(CCCOc1cccc2[nH]c3ccccc3c12)NCCCNc1c2c(nc3ccccc13)CCCC2', 'O=C(CCCOc1cccc2[nH]c3ccccc3c12)NCCCNc1c2c(nc3ccccc13)CCCC2', 'c1ccc2c(NCCSSCCNc3c4c(nc5ccccc35)CCCC4)c3c(nc2c1)CCCC3', 'c1ccc2c(NCCSSCCNc3c4c(nc5ccccc35)CCCC4)c3c(nc2c1)CCCC3', 'c1ccc2c(NCCSSCCNc3c4c(nc5ccccc35)CCCC4)c3c(nc2c1)CCCC3', 'CN(Cc1ccccc1)Cc1ccc(C(=O)c2ccc(O)c(F)c2)cc1', 'O=C(c1ccc(CN2CCC(CCO)CC2)cc1)c1ccc(O)c(F)c1', 'CC[C@H]1[C@H](C[C@H](C)C(=O)OC)O[C@]23CC[C@@H]([C@@H]4C[C@H](C)C(=O)O4)N2CCCC[C@H]13', 'CC[C@H]1[C@H]2OC(=O)[C@](C)(O)[C@H]2[C@]23CC[C@@H]([C@@H]4C[C@@H](C)C(=O)O4)N2CCCC[C@@H]13', 'CC[C@@H]1[C@H]2OC(=O)[C@@](C)(O)[C@H]2[C@]23CC[C@@H]([C@@H]4C[C@H](C)C(=O)O4)N2CCCC[C@H]13', 'CC[C@H]1[C@@H]2OC(=O)[C@@](C)(O)[C@@H]2[C@@]23CC[C@@H]([C@@H]4C[C@H](C)C(=O)O4)N2CCCC[C@H]13', 'O=C(/C=N/O)Nc1ccc[n+](CC[n+]2cccc(NC(=O)/C=N/O)c2)c1.[Br-].[Br-]', 'O=C(/C=N/O)Nc1ccc[n+](CC[n+]2cccc(NC(=O)/C=N/O)c2)c1.[Br-].[Br-]', 'O=C(/C=N\\\\O)Nc1ccc[n+](CCC[n+]2cccc(NC(=O)/C=N\\\\O)c2)c1.[Br-].[Br-]', 'O=C(/C=N\\\\O)Nc1ccc[n+](CCC[n+]2cccc(NC(=O)/C=N\\\\O)c2)c1.[Br-].[Br-]', 'O=C(/C=N\\\\O)Nc1ccc[n+](CCCC[n+]2cccc(NC(=O)/C=N\\\\O)c2)c1.[Br-].[Br-]', 'O=C(/C=N\\\\O)Nc1ccc[n+](CCCC[n+]2cccc(NC(=O)/C=N\\\\O)c2)c1.[Br-].[Br-]', 'O=C(/C=N\\\\O)Nc1ccc[n+](CCCCC[n+]2cccc(NC(=O)/C=N\\\\O)c2)c1.[Br-].[Br-]', 'O=C(/C=N\\\\O)Nc1ccc[n+](CCCCC[n+]2cccc(NC(=O)/C=N\\\\O)c2)c1.[Br-].[Br-]', 'O=C(/C=N\\\\O)Nc1ccc[n+](CCCCCC[n+]2cccc(NC(=O)/C=N\\\\O)c2)c1.[Br-].[Br-]', 'O=C(/C=N\\\\O)Nc1ccc[n+](CCCCCC[n+]2cccc(NC(=O)/C=N\\\\O)c2)c1.[Br-].[Br-]', 'O=C(/C=N\\\\O)Nc1ccc[n+](CCCCCCC[n+]2cccc(NC(=O)/C=N\\\\O)c2)c1.[Br-].[Br-]', 'O=C(/C=N\\\\O)Nc1ccc[n+](CCCCCCC[n+]2cccc(NC(=O)/C=N\\\\O)c2)c1.[Br-].[Br-]', 'O=C(/C=N/O)Nc1ccc[n+](Cc2ccccc2C[n+]2cccc(NC(=O)/C=N/O)c2)c1.[Br-].[Br-]', 'O=C(/C=N/O)Nc1ccc[n+](Cc2ccccc2C[n+]2cccc(NC(=O)/C=N/O)c2)c1.[Br-].[Br-]', 'O=C(/C=N/O)Nc1ccc[n+](Cc2cccc(C[n+]3cccc(NC(=O)/C=N/O)c3)c2)c1.[Br-].[Br-]', 'O=C(/C=N/O)Nc1ccc[n+](Cc2cccc(C[n+]3cccc(NC(=O)/C=N/O)c3)c2)c1.[Br-].[Br-]', 'O=C(/C=N/O)Nc1ccc[n+](Cc2ccc(C[n+]3cccc(NC(=O)/C=N/O)c3)cc2)c1.[Br-].[Br-]', 'O=C(/C=N/O)Nc1ccc[n+](Cc2ccc(C[n+]3cccc(NC(=O)/C=N/O)c3)cc2)c1.[Br-].[Br-]', 'CC(C)Nc1nc(NCc2ccccc2)c2ccccc2n1', 'CCN(CC)CCCCCCOc1ccc(CC2NCCc3cc(OC)c(OC)cc32)cc1', 'COc1cc2c(cc1OC)C(Cc1ccc(OCCCCCCN(C)C)cc1)NCC2', 'CCCN(CCC)CCCCCCOc1ccc(CC2NCCc3cc(OC)c(OC)cc32)cc1', 'CCCCN(CCCC)CCCCCCOc1ccc(CC2NCCc3cc(OC)c(OC)cc32)cc1', 'COc1cc2c(cc1OC)C(Cc1ccc(OCCCCCCN3CCCC3C)cc1)NCC2', 'COc1cc2c(cc1OC)C(Cc1ccc(OCCCCCCN3CCCCC3C)cc1)NCC2', 'COc1cc2c(cc1OC)C(Cc1ccc(OCCCCCCN3CCCCC3)cc1)NCC2', 'COc1cc2c(cc1OC)C(Cc1ccc(OCCCCCCN3CCCC3)cc1)NCC2', 'COc1cc2c(cc1OC)C(Cc1ccc(OCCCCCCN3CCC(O)CC3)cc1)NCC2', 'COc1cc2c(cc1OC)C(Cc1ccc(OCCCCCCN3CCOCC3)cc1)NCC2', 'COc1cc2c(cc1OC)C(Cc1ccc(OCCCCCCN3CCC(O)(Cc4ccccc4)CC3)cc1)NCC2', 'COc1cc2c(cc1OC)C(Cc1ccc(OCCCCCCN3CCN(c4ccccc4)CC3)cc1)NCC2', 'COc1cc2c(cc1OC)C(Cc1ccc(OCCCCCCN3CCN(Cc4ccccc4)CC3)cc1)NCC2', 'COc1cc2c(cc1OC)C(Cc1ccc(OCCCCCCN3CCC(c4ccccc4)CC3)cc1)NCC2', 'CN(Cc1ccccc1)Cc1ccc(C(=O)NCCc2c[nH]c3ccccc23)cc1', 'CN(Cc1ccccc1)Cc1ccc(C(=O)NCCc2c[nH]c3ccc(O)cc23)cc1', 'COc1ccc2[nH]cc(CCNC(=O)c3ccc(CN(C)Cc4ccccc4)cc3)c2c1', 'COc1ccc2c(CCNC(=O)c3ccc(CN(C)Cc4ccccc4)cc3)c[nH]c2c1', 'CN(Cc1ccccc1)Cc1ccc(C(=O)NCCc2c[nH]c3cc(F)ccc23)cc1', 'CN(Cc1ccc(C(=O)NCCc2c[nH]c3ccccc23)cc1)Cc1ccccc1Cl', 'COc1ccc2[nH]cc(CCNC(=O)c3ccc(CN(C)Cc4ccccc4Cl)cc3)c2c1', 'CN(Cc1ccc(C(=O)NCCc2c[nH]c3ccccc23)cc1)Cc1cccc(Cl)c1', 'COc1ccc2[nH]cc(CCNC(=O)c3ccc(CN(C)Cc4cccc(Cl)c4)cc3)c2c1', 'COc1ccc2c(CCNC(=O)c3ccc(CN(C)Cc4cccc(Cl)c4)cc3)c[nH]c2c1', 'COc1ccccc1CN(C)Cc1ccc(C(=O)NCCc2c[nH]c3ccccc23)cc1', 'COc1ccc2[nH]cc(CCNC(=O)c3ccc(CN(C)Cc4ccccc4OC)cc3)c2c1', 'COc1cccc(CN(C)Cc2ccc(C(=O)NCCc3c[nH]c4ccccc34)cc2)c1', 'COc1cccc(CN(C)Cc2ccc(C(=O)NCCc3c[nH]c4ccc(OC)cc34)cc2)c1', 'CCOC(OCC)c1ccc(/C=C2\\\\CCC/C(=C\\\\c3ccc(C(OCC)OCC)cc3)C2=O)cc1', 'CCOC(OCC)c1ccc(/C=C2\\\\COC/C(=C\\\\c3ccc(C(OCC)OCC)cc3)C2=O)cc1', 'CCOC(OCC)c1ccc(/C=C2\\\\CNC/C(=C\\\\c3ccc(C(OCC)OCC)cc3)C2=O)cc1', 'CCOC(OCC)c1ccc(/C=C2\\\\CN(C)C/C(=C\\\\c3ccc(C(OCC)OCC)cc3)C2=O)cc1', 'CCOC(OCC)c1ccc(/C=C2\\\\CN(Cc3ccccc3)C/C(=C\\\\c3ccc(C(OCC)OCC)cc3)C2=O)cc1', 'CCOC(OCC)c1ccc(/C=C/C(=O)/C=C/c2ccc(C(OCC)OCC)cc2)cc1', 'CCOC(OCC)c1ccc(/C=C2\\\\CC/C(=C\\\\c3ccc(C(OCC)OCC)cc3)C2=O)cc1', 'CCOC(OCC)c1ccc(/C=C/C(=O)C2CCc3ccccc3C2=O)cc1', 'CN(C)c1ccc(/C=C2/CCC/C(=C\\\\c3ccc(N(C)C)cc3[N+](=O)[O-])C2=O)c([N+](=O)[O-])c1', 'CN(C)c1ccc(/C=C2/COC/C(=C\\\\c3ccc(N(C)C)cc3[N+](=O)[O-])C2=O)c([N+](=O)[O-])c1', 'CN(C)c1ccc(/C=C2/CNC/C(=C\\\\c3ccc(N(C)C)cc3[N+](=O)[O-])C2=O)c([N+](=O)[O-])c1', 'CN1C/C(=C/c2ccc(N(C)C)cc2[N+](=O)[O-])C(=O)/C(=C/c2ccc(N(C)C)cc2[N+](=O)[O-])C1', 'CN(C)c1ccc(/C=C2\\\\CCc3ccccc3C2=O)c([N+](=O)[O-])c1', 'CN(C)c1ccc(/C=C/C(=O)C2CCc3ccccc3C2=O)cc1', 'O=C1/C(=C\\\\c2ccc(N3CCCC3)cc2)CNC/C1=C\\\\c1ccc(N2CCCC2)cc1', 'CN1C/C(=C/c2ccc(N3CCCC3)cc2)C(=O)/C(=C/c2ccc(N3CCCC3)cc2)C1', 'O=C1/C(=C/c2ccc(N3CCCC3)cc2)CC/C1=C\\\\c1ccc(N2CCCC2)cc1', 'C#CCN(Cc1ccc(O)c2ncccc12)C(C#N)CCC1CCN(Cc2ccccc2)CC1', 'C#CCN(C)Cc1ccc(O)c2ncccc12', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(NCCCCCCCCCCNC(=O)c4cc(O)c5c(c4)C(=O)c4cccc(O)c4C5=O)c3C(C1)C2', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(NCc4ccc(CNC(=O)c5cc(O)c6c(c5)C(=O)c5cccc(O)c5C6=O)cc4)c3C(C1)C2', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(NCCCCCCCCCCCNC(=O)c4cc(O)c5c(c4)C(=O)c4cccc(O)c4C5=O)c3C(C1)C2', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(NCCCCCCCCCNC(=O)c4cc(O)c5c(c4)C(=O)c4cccc(O)c4C5=O)c3C(C1)C2', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(NCCCCCCCCCNC(=O)c4cc(O)c5c(c4)C(=O)c4cccc(O)c4C5=O)c3C(C1)C2', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(NCCCCCCCCNC(=O)c4cc(O)c5c(c4)C(=O)c4cccc(O)c4C5=O)c3C(C1)C2', 'CC1(C)C[C@@H](c2ccccc2)C(CN2C(=O)c3ccccc3C2=O)=NO1', 'COC(=O)C(CC1=NO[C@@H]2CCC[C@@H]2[C@H]1c1ccccc1)C(=O)OC', 'CC(=O)N1OC(C)(C)CC(c2ccccc2)=C1CN1C(=O)c2ccccc2C1=O', 'COC(=O)C(CC1=C(c2ccc(OC)cc2)CC(C)(C)ON1C(C)=O)C(=O)OC', 'COC(=O)C(CC1=C(c2ccccc2)CC(C)(C)ON1C(C)=O)C(=O)OC', 'COC(=O)C(CC1=C(c2ccc(Cl)cc2)CC(C)(C)ON1C(C)=O)C(=O)OC', 'O=C(C[n+]1ccccc1)N/N=C/c1ccc(/C=N/NC(=O)C[n+]2ccccc2)cc1.[Cl-].[Cl-]', 'COc1cc2oc(-c3ccc(CN4CCCC4)cc3)cc(=O)c2cc1OC', 'O=c1cc(-c2ccc(CN3CCCCC3)cc2)oc2ccccc12', 'Cn1ncc2cc(C(=O)Nc3ccc(Cl)c(Cl)c3)ccc21', 'CCN(CCC(=O)NCCNc1c2c(nc3ccccc13)CCCC2)C1CCCCC1', 'CCN(CCC(=O)NCCCNc1c2c(nc3ccccc13)CCCC2)C1CCCCC1', 'CCN(CCC(=O)NCCCNc1c2c(nc3ccccc13)CCCC2)C1CCCCC1', 'CCN(CCC(=O)NCCCNc1c2c(nc3ccccc13)CCCC2)C1CCCCC1', 'CCN(CCC(=O)NCCCCNc1c2c(nc3ccccc13)CCCC2)C1CCCCC1', 'CCN(CCC(=O)NCCCCNc1c2c(nc3ccccc13)CCCC2)C1CCCCC1', 'CCN(CCC(=O)NCCCCNc1c2c(nc3ccccc13)CCCC2)C1CCCCC1', 'CN(CCC(=O)NCCNc1c2c(nc3ccccc13)CCCC2)C1CCCCC1', 'CN(CCC(=O)NCCCNc1c2c(nc3ccccc13)CCCC2)C1CCCCC1', 'CN(CCC(=O)NCCCCNc1c2c(nc3ccccc13)CCCC2)C1CCCCC1', 'O=C(Cc1cc(=O)oc2cc(O)ccc12)NCCNc1c2c(nc3ccccc13)CCCC2', 'O=C(Cc1cc(=O)oc2cc(O)ccc12)NCCCNc1c2c(nc3ccccc13)CCCC2', 'O=C(Cc1cc(=O)oc2cc(O)ccc12)NCCCCNc1c2c(nc3ccccc13)CCCC2', 'O=C(Cc1cc(=O)oc2cc(O)ccc12)NCCCCNc1c2c(nc3ccccc13)CCCC2', 'O=C(Cc1cc(=O)oc2cc(O)ccc12)NCCCCNc1c2c(nc3ccccc13)CCCC2', 'O=C(Cc1cc(=O)oc2cc(O)ccc12)NNC(=S)Nc1c2c(nc3ccccc13)CCCC2', 'O=C(Cc1cc(=O)oc2cc(O)ccc12)NNC(=S)Nc1c2c(nc3ccccc13)CCCC2', 'O=C(Cc1cc(=O)oc2cc(O)ccc12)NNC(=S)Nc1c2c(nc3ccccc13)CCCC2', 'O=C(Cc1cc(=O)oc2cc(O)ccc12)N/N=C1\\\\SCC(=O)N1c1c2c(nc3ccccc13)CCCC2', 'O=C(Cc1cc(=O)oc2cc(O)ccc12)N/N=C1\\\\SCC(=O)N1c1c2c(nc3ccccc13)CCCC2', 'O=C(Cc1cc(=O)oc2cc(O)ccc12)N/N=C1\\\\SCC(=O)N1c1c2c(nc3ccccc13)CCCC2', 'Cl.O=C(NCCCCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2)c1ccc2nc(-c3ccc(Cl)cc3)c3c(c2c1)NCCC3', 'Cl.O=C(NCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2)c1ccc2nc(-c3ccc(Cl)cc3)c3c(c2c1)NCCC3', 'Cl.O=C(NCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2)c1ccc2nc(-c3ccc(Cl)cc3)c3c(c2c1)NCCC3', 'c1cc2c(cc1OCCCN1CCCCC1)CN1CCCC1=N2', 'c1cc2c(cc1OCCCN1CCCCC1)CN1CCCC1=N2', 'c1cc2c(cc1OCCCN1CCCCC1)CN1CCCC1=N2', 'c1cc2c(cc1OCCCN1CCCCC1)CN1CCCC1=N2', 'O=c1c2cc(OCCCN3CCCCC3)ccc2nc2n1Cc1ccccc1-2', 'O=c1c2cc(OCCCN3CCCCC3)ccc2nc2n1Cc1ccccc1-2', 'CCN(CC)CCCOc1ccc2nc3n(c(=O)c2c1)Cc1ccccc1-3', 'CCN(CC)CCCOc1ccc2nc3n(c(=O)c2c1)Cc1ccccc1-3', 'O=c1c2cc(OCCCN3CCCCC3)ccc2nc2n1CCc1ccccc1-2', 'O=c1c2cc(OCCCN3CCCCC3)ccc2nc2n1CCc1ccccc1-2', 'CCN(CC)CCCOc1ccc2nc3n(c(=O)c2c1)CCc1ccccc1-3', 'CCN(CC)CCCOc1ccc2nc3n(c(=O)c2c1)CCc1ccccc1-3', 'O=c1c2cc(OCCCN3CCCCC3)ccc2nc2n1CCCc1ccccc1-2', 'O=c1c2cc(OCCCN3CCCCC3)ccc2nc2n1CCCc1ccccc1-2', 'CCN(CC)CCCOc1ccc2nc3n(c(=O)c2c1)CCCc1ccccc1-3', 'CCN(CC)CCCOc1ccc2nc3n(c(=O)c2c1)CCCc1ccccc1-3', 'O=c1c2cc(OCCCn3ccnc3)ccc2nc2n1CCCc1ccccc1-2', 'O=c1c2cc(OCCCn3ccnc3)ccc2nc2n1CCCc1ccccc1-2', 'O=c1c2cc(OCCCN3CCCCC3)ccc2nc2n1CCC2', 'O=c1c2cc(OCCCN3CCCCC3)ccc2nc2n1CCC2', 'O=c1c2cc(OCCCN3CCCCC3)ccc2nc2n1CCC2', 'O=c1c2cc(OCCCN3CCCCC3)ccc2nc2n1CCC2', 'CCN(CC)CCCOc1ccc2nc3n(c(=O)c2c1)CCC3', 'CCN(CC)CCCOc1ccc2nc3n(c(=O)c2c1)CCC3', 'O=c1c2cc(OCCCN3CCCCC3)ccc2nc2n1CCCC2', 'O=c1c2cc(OCCCN3CCCCC3)ccc2nc2n1CCCC2', 'CCN(CC)CCCOc1ccc2nc3n(c(=O)c2c1)CCCC3', 'CCN(CC)CCCOc1ccc2nc3n(c(=O)c2c1)CCCC3', 'O=c1c2cc(OCCCN3CCCCC3)ccc2nc2n1CCCCC2', 'O=c1c2cc(OCCCN3CCCCC3)ccc2nc2n1CCCCC2', 'CCN(CC)CCCOc1ccc2nc3n(c(=O)c2c1)CCCCC3', 'CCN(CC)CCCOc1ccc2nc3n(c(=O)c2c1)CCCCC3', 'O=C(NCCCCCNc1c2c(nc3ccccc13)CCCC2)c1cc2ccccc2oc1=O', 'COc1ccc2cc(C(=O)NCCCCCNc3c4c(nc5ccccc35)CCCC4)c(=O)oc2c1', 'COc1ccc2oc(=O)c(C(=O)NCCCCCNc3c4c(nc5ccccc35)CCCC4)cc2c1', 'Cc1ccc2oc(=O)c(C(=O)NCCCCCNc3c4c(nc5ccccc35)CCCC4)cc2c1', 'COc1cc2cc(C(=O)NCCCCCNc3c4c(nc5ccccc35)CCCC4)c(=O)oc2cc1OC', 'O=C(NCCCCCNc1c2c(nc3ccccc13)CCCC2)c1cc2cc(OC(F)(F)F)ccc2oc1=O', 'O=C(NCCCCCCNc1c2c(nc3ccccc13)CCCC2)c1cc2ccccc2oc1=O', 'COc1ccc2cc(C(=O)NCCCCCCNc3c4c(nc5ccccc35)CCCC4)c(=O)oc2c1', 'COc1ccc2oc(=O)c(C(=O)NCCCCCCNc3c4c(nc5ccccc35)CCCC4)cc2c1', 'Cc1ccc2oc(=O)c(C(=O)NCCCCCCNc3c4c(nc5ccccc35)CCCC4)cc2c1', 'COc1cc2cc(C(=O)NCCCCCCNc3c4c(nc5ccccc35)CCCC4)c(=O)oc2cc1OC', 'O=C(NCCCCCCNc1c2c(nc3ccccc13)CCCC2)c1cc2cc(OC(F)(F)F)ccc2oc1=O', 'O=C(NCCCCCCCNc1c2c(nc3ccccc13)CCCC2)c1cc2ccccc2oc1=O', 'COc1ccc2cc(C(=O)NCCCCCCCNc3c4c(nc5ccccc35)CCCC4)c(=O)oc2c1', 'COc1ccc2oc(=O)c(C(=O)NCCCCCCCNc3c4c(nc5ccccc35)CCCC4)cc2c1', 'Cc1ccc2oc(=O)c(C(=O)NCCCCCCCNc3c4c(nc5ccccc35)CCCC4)cc2c1', 'COc1cc2cc(C(=O)NCCCCCCCNc3c4c(nc5ccccc35)CCCC4)c(=O)oc2cc1OC', 'O=C(NCCCCCCCNc1c2c(nc3ccccc13)CCCC2)c1cc2cc(OC(F)(F)F)ccc2oc1=O', 'CC(c1ccc2c(c1)oc(=O)c1ccccc12)N(C)C.Cl', 'C[C@@H](c1ccc2c(c1)oc(=O)c1ccccc12)N(C)C.Cl', 'COc1cc(C(C)N(C)C)cc2oc(=O)c3ccccc3c12.Cl', 'COc1cc(C(C)N(C)C)c2c(c1)oc(=O)c1ccccc12.Cl', 'CC(c1cc(O)c2c(c1)oc(=O)c1ccccc12)N(C)C.Cl', 'CC(c1cc(O)cc2oc(=O)c3ccccc3c12)N(C)C.Cl', 'CCN(C)C(=O)Oc1cc(C(C)N(C)C)cc2oc(=O)c3ccccc3c12.Cl', 'CN(CCOc1ccc2c3c(c(=O)oc2c1)CCCC3)Cc1ccccc1', 'COc1cccc(CN(C)CCOc2ccc3c4c(c(=O)oc3c2)CCCC4)c1', 'O=c1oc2cc(OCCN3CCC(Cc4ccccc4)CC3)ccc2c2c1CCCC2', 'COc1cccc(CC2CCN(CCOc3ccc4c5c(c(=O)oc4c3)CCCC5)CC2)c1', 'O=c1oc2cc(OCCN3CCN(Cc4ccccc4)CC3)ccc2c2c1CCCC2', 'COc1cccc(CN2CCN(CCOc3ccc4c5c(c(=O)oc4c3)CCCC5)CC2)c1', 'CN(CCCOc1ccc2c3c(c(=O)oc2c1)CCCC3)Cc1ccccc1', 'COc1cccc(CN(C)CCCOc2ccc3c4c(c(=O)oc3c2)CCCC4)c1', 'O=c1oc2cc(OCCCN3CCC(Cc4ccccc4)CC3)ccc2c2c1CCCC2', 'COc1cccc(CC2CCN(CCCOc3ccc4c5c(c(=O)oc4c3)CCCC5)CC2)c1', 'O=c1oc2cc(OCCCN3CCN(Cc4ccccc4)CC3)ccc2c2c1CCCC2', 'COc1cccc(CN2CCN(CCCOc3ccc4c5c(c(=O)oc4c3)CCCC5)CC2)c1', 'CN(CCCCOc1ccc2c3c(c(=O)oc2c1)CCCC3)Cc1ccccc1', 'COc1cccc(CN(C)CCCCOc2ccc3c4c(c(=O)oc3c2)CCCC4)c1', 'O=c1oc2cc(OCCCCN3CCC(Cc4ccccc4)CC3)ccc2c2c1CCCC2', 'COc1cccc(CC2CCN(CCCCOc3ccc4c5c(c(=O)oc4c3)CCCC5)CC2)c1', 'O=c1oc2cc(OCCCCN3CCN(Cc4ccccc4)CC3)ccc2c2c1CCCC2', 'COc1cccc(CN2CCN(CCCCOc3ccc4c5c(c(=O)oc4c3)CCCC5)CC2)c1', 'CN(CCOc1ccc2c(c1)oc(=O)c1ccccc12)Cc1ccccc1', 'COc1cccc(CN(C)CCOc2ccc3c(c2)oc(=O)c2ccccc23)c1', 'O=c1oc2cc(OCCN3CCC(Cc4ccccc4)CC3)ccc2c2ccccc12', 'COc1cccc(CC2CCN(CCOc3ccc4c(c3)oc(=O)c3ccccc34)CC2)c1', 'O=c1oc2cc(OCCN3CCN(Cc4ccccc4)CC3)ccc2c2ccccc12', 'COc1cccc(CN2CCN(CCOc3ccc4c(c3)oc(=O)c3ccccc34)CC2)c1', 'CN(CCCOc1ccc2c(c1)oc(=O)c1ccccc12)Cc1ccccc1', 'COc1cccc(CN(C)CCCOc2ccc3c(c2)oc(=O)c2ccccc23)c1', 'O=c1oc2cc(OCCCN3CCC(Cc4ccccc4)CC3)ccc2c2ccccc12', 'COc1cccc(CC2CCN(CCCOc3ccc4c(c3)oc(=O)c3ccccc34)CC2)c1', 'O=c1oc2cc(OCCCN3CCN(Cc4ccccc4)CC3)ccc2c2ccccc12', 'COc1cccc(CN2CCN(CCCOc3ccc4c(c3)oc(=O)c3ccccc34)CC2)c1', 'CN(CCCCOc1ccc2c(c1)oc(=O)c1ccccc12)Cc1ccccc1', 'COc1cccc(CN(C)CCCCOc2ccc3c(c2)oc(=O)c2ccccc23)c1', 'O=c1oc2cc(OCCCCN3CCC(Cc4ccccc4)CC3)ccc2c2ccccc12', 'COc1cccc(CC2CCN(CCCCOc3ccc4c(c3)oc(=O)c3ccccc34)CC2)c1', 'O=c1oc2cc(OCCCCN3CCN(Cc4ccccc4)CC3)ccc2c2ccccc12', 'COc1cccc(CN2CCN(CCCCOc3ccc4c(c3)oc(=O)c3ccccc34)CC2)c1', 'C[n+]1ccccc1/C=N/O.[Br-]', 'C[n+]1ccc(/C=N/O)cc1.[Br-]', 'C/C=C1\\\\[C@H]2C=C(C)C[C@]1(N[C@H]1OC(=O)C3=C4CC(C)(C)C[C@H]4[C@@H](C)[C@@H](O)C[C@]31OC)c1ccc(=O)[nH]c1C2', 'C/C=C1\\\\[C@H]2C=C(C)C[C@]1(N[C@H]1OC(=O)C3=C4CC(C)(C)C[C@H]4[C@@H](C)[C@@H](O)C[C@]31O)c1ccc(=O)[nH]c1C2', 'C/C=C1\\\\[C@H]2C=C(C)C[C@]1(NC1OCC3=C4CC(C)(C)C[C@H]4[C@@H](C)[C@H](O)CC31O)c1ccc(=O)[nH]c1C2', 'C/C=C1\\\\[C@H]2C=C(C)C[C@]1(NC1OCC3=C4CC(C)(C)[C@H](O)[C@H]4[C@@H](C)CCC31O)c1ccc(=O)[nH]c1C2', 'CN(C)CCCOc1ccc(C(=O)/C=C/c2ccccc2)cc1', 'CN(C)CCCCOc1ccc(C(=O)/C=C/c2ccccc2)cc1', 'CN(C)CCCCCOc1ccc(C(=O)/C=C/c2ccccc2)cc1', 'CN(C)CCCCCCOc1ccc(C(=O)/C=C/c2ccccc2)cc1', 'CCN(CC)CCOc1ccc(C(=O)/C=C/c2ccccc2)cc1', 'CCN(CC)CCCOc1ccc(C(=O)/C=C/c2ccccc2)cc1', 'CCN(CC)CCCCOc1ccc(C(=O)/C=C/c2ccccc2)cc1', 'CCN(CC)CCCCCOc1ccc(C(=O)/C=C/c2ccccc2)cc1', 'CCN(CC)CCCCCCOc1ccc(C(=O)/C=C/c2ccccc2)cc1', 'CCCN(CCC)CCOc1ccc(C(=O)/C=C/c2ccccc2)cc1', 'CCCN(CCC)CCCOc1ccc(C(=O)/C=C/c2ccccc2)cc1', 'CCCN(CCC)CCCCOc1ccc(C(=O)/C=C/c2ccccc2)cc1', 'CCCN(CCC)CCCCCOc1ccc(C(=O)/C=C/c2ccccc2)cc1', 'CCCN(CCC)CCCCCCOc1ccc(C(=O)/C=C/c2ccccc2)cc1', 'CCCCN(CCCC)CCCCOc1ccc(C(=O)/C=C/c2ccccc2)cc1', 'CCCCN(CCCC)CCCCCOc1ccc(C(=O)/C=C/c2ccccc2)cc1', 'COc1cc2c(cc1OCCN1CCCCC1)C(=O)/C(=C/c1ccc(N(C)C)cc1)C2', 'CCN(CC)c1ccc(/C=C2\\\\Cc3cc(OC)c(OCCN4CCCCC4)cc3C2=O)cc1', 'CNc1ccc(/C=C2\\\\Cc3cc(OC)c(OCCN4CCCCC4)cc3C2=O)cc1', 'CCN(C)c1ccc(/C=C2\\\\Cc3cc(OC)c(OCCN4CCCCC4)cc3C2=O)cc1', 'CCCN(C)c1ccc(/C=C2\\\\Cc3cc(OC)c(OCCN4CCCCC4)cc3C2=O)cc1', 'CCCN(CCC)c1ccc(/C=C2\\\\Cc3cc(OC)c(OCCN4CCCCC4)cc3C2=O)cc1', 'CCc1nc(C(=O)NCCCCCCNc2c3c(nc4ccccc24)CCCC3)cc2c1[nH]c1ccccc12', 'Cc1nc(C(=O)NCCCCNc2c3c(nc4ccccc24)CCCC3)cc2c1[nH]c1ccccc12', 'Cc1nc(C(=O)NCCCCCCNc2c3c(nc4ccccc24)CCCC3)cc2c1[nH]c1ccccc12', 'Cc1nc(C(=O)NCCCCCCCCNc2c3c(nc4ccccc24)CCCC3)cc2c1[nH]c1ccccc12', 'O=C(NCCCCCCNc1c2c(nc3ccccc13)CCCC2)c1cc2c(cn1)[nH]c1ccccc12', 'O=C(NCCCCCCNc1c2c(nc3ccccc13)CCCC2)c1cc2c([nH]c3ccccc32)c(-c2ccccc2)n1', 'O=C(NCCCCCCNc1c2c(nc3ccccc13)CCCC2)c1cc2c([nH]c3ccccc32)c(-c2ccc(F)cc2)n1', 'COc1ccc(-c2nc(C(=O)NCCCCCCNc3c4c(nc5ccccc35)CCCC4)cc3c2[nH]c2ccccc23)cc1', 'CC(C)(C)OC(=O)N1Cc2[nH]c3ccccc3c2C[C@H]1C(=O)NCCCCCCNc1c2c(nc3ccccc13)CCCC2', 'O=C(NCCCCCCNc1c2c(nc3ccccc13)CCCC2)[C@@H]1Cc2c([nH]c3ccccc23)CN1', 'CC1c2[nH]c3ccccc3c2C[C@@H](C(=O)NCCCCCCNc2c3c(nc4ccccc24)CCCC3)N1C(=O)OC(C)(C)C', 'CC1N[C@H](C(=O)NCCCCCCNc2c3c(nc4ccccc24)CCCC3)Cc2c1[nH]c1ccccc21', 'CC(C)(C)OC(=O)N[C@@H](Cc1c[nH]c2ccccc12)C(=O)NCCCCCCNc1c2c(nc3ccccc13)CCCC2', 'N[C@@H](Cc1c[nH]c2ccccc12)C(=O)NCCCCCCNc1c2c(nc3ccccc13)CCCC2', 'CC(=O)N[C@@H](Cc1c[nH]c2ccccc12)C(=O)NCCCCCCNc1c2c(nc3ccccc13)CCCC2', 'CC1=C[C@H]2Cc3nc4cc(Cl)ccc4c(NCCCCCCNc4c5c(nc6cc(Cl)ccc46)C[C@@H]4C=C(C)C[C@H]5C4)c3[C@@H](C1)C2', 'CC1=C[C@H]2Cc3nc4cc(Cl)ccc4c(NCCCCCCCCNc4c5c(nc6cc(Cl)ccc46)C[C@@H]4C=C(C)C[C@H]5C4)c3[C@@H](C1)C2', 'CC1=C[C@H]2Cc3nc4cc(Cl)ccc4c(NCCCCCCCCCCNc4c5c(nc6cc(Cl)ccc46)C[C@@H]4C=C(C)C[C@H]5C4)c3[C@@H](C1)C2', 'CC1=C[C@H]2Cc3nc4cc(Cl)ccc4c(NCCCCCCCCCCCCNc4c5c(nc6cc(Cl)ccc46)C[C@@H]4C=C(C)C[C@H]5C4)c3[C@@H](C1)C2', 'CNc1ccccc1-c1nc(C(=O)OC)cs1', 'CNc1ccccc1-c1nc(C(N)=O)cs1', 'CNc1ccccc1-c1nc(C(=O)O)cs1', 'COc1cc(CCC(=O)/C=C/CCCNc2c3c(nc4cc(Cl)ccc24)CC2CC(C)=CC3C2)ccc1O', 'COc1cc(CCC(=O)/C=C/c2ccc(CNc3c4c(nc5cc(Cl)ccc35)CC3CC(C)=CC4C3)cc2)ccc1O', 'COc1cc(CCC(=O)/C=C/c2ccc(CNc3c4c(nc5cc(Cl)ccc35)CC3CC(C)=CC4C3)cc2)cc(CN(C)C)c1O', 'C/C=C1/[C@@H]2Cc3[nH]c(=O)ccc3[C@@]1(N)C[C@]1(C)O[C@H]21', 'COc1ccc2nc3c(c(NCCNC4=CC(=O)c5ccccc5C4=O)c2c1)CCCC3', 'COc1ccc2nc3c(c(NCCCNC4=CC(=O)c5ccccc5C4=O)c2c1)CCCC3', 'O=C1C=C(NCCNc2c3c(nc4ccccc24)CCCC3)C(=O)c2ccccc21', 'O=C1C=C(NCCCNc2c3c(nc4ccccc24)CCCC3)C(=O)c2ccccc21', 'O=C1C=C(NCCNc2c3c(nc4cc(Cl)ccc24)CCCC3)C(=O)c2ccccc21', 'O=C1C=C(NCCCNc2c3c(nc4cc(Cl)ccc24)CCCC3)C(=O)c2ccccc21', 'O=C1C(NCCNc2c3c(nc4ccccc24)CCCC3)=CC(=O)c2c(O)cccc21', 'O=C1C(NCCCNc2c3c(nc4ccccc24)CCCC3)=CC(=O)c2c(O)cccc21', 'O=C1C(NCCNc2c3c(nc4cc(Cl)ccc24)CCCC3)=CC(=O)c2c(O)cccc21', 'O=C1C(NCCNc2c3c(nc4cc(Cl)ccc24)CCCC3)=CC(=O)c2c(O)cccc21', 'O=C1C(NCCCNc2c3c(nc4cc(Cl)ccc24)CCCC3)=CC(=O)c2c(O)cccc21', 'COc1ccc2nc3c(c(NCCNC4=CC(=O)c5c(O)cccc5C4=O)c2c1)CCCC3', 'COc1ccc2nc3c(c(NCCCNC4=CC(=O)c5c(O)cccc5C4=O)c2c1)CCCC3', 'COc1ccc2nc3c(c(NCCNC4=C(Cl)C(=O)c5ccccc5C4=O)c2c1)CCCC3', 'COc1ccc2nc3c(c(NCCCNC4=C(Cl)C(=O)c5ccccc5C4=O)c2c1)CCCC3', 'O=C1C(Cl)=C(NCCNc2c3c(nc4cc(Cl)ccc24)CCCC3)C(=O)c2ccccc21', 'O=C1C(Cl)=C(NCCCNc2c3c(nc4cc(Cl)ccc24)CCCC3)C(=O)c2ccccc21', 'O=C1C(Cl)=C(NCCNc2c3c(nc4ccccc24)CCCC3)C(=O)c2ccccc21', 'O=C1C(Cl)=C(NCCCNc2c3c(nc4ccccc24)CCCC3)C(=O)c2ccccc21', 'CN1CCN(c2ccc(-c3cnc4[nH]c5cnc(C#N)cc5c4c3)cc2)CC1', 'COc1cc2c(cc1OC)C(c1ccccc1)N(CCCCCn1ccnc1/C=N/O)CC2', 'COc1cc2c(cc1OC)C(c1ccccc1)N(CCCCCn1ccnc1/C=N/O)CC2', 'COc1cc2c(cc1OC)C(c1ccccc1)N(CCCCCCn1ccnc1/C=N/O)CC2', 'COc1cc2c(cc1OC)C(c1ccccc1)N(CCCCCCn1ccnc1/C=N/O)CC2', 'COc1cc2c(cc1OC)C(c1ccccc1)N(CCCCCCn1ccnc1/C=N/O)CC2', 'COC(=O)CC1=NO[C@@H]2CCCC[C@@H]2[C@H]1c1ccccc1', 'COC(=O)CC1=NO[C@@H]2[C@H]3CC[C@H](C3)[C@@H]2[C@H]1c1ccccc1', 'O=S(=O)(CCCN1CCN(Cc2ccccc2)CC1)NCCNc1cccc2ccccc12', 'c1ccc(COC[C@H]2NC[C@H](OCc3ccccc3)[C@@H](OCc3ccccc3)[C@@H]2OCc2ccccc2)cc1', 'C=CC[C@@H]1[C@H](O)[C@@H](OCc2ccccc2)[C@H](O)CN1CCCCCCCC', 'O=C1N[C@H](COCc2ccccc2)[C@@H](OCc2ccccc2)[C@H](OCc2ccccc2)[C@H]1OCc1ccccc1', 'CO[P@]1(=O)OC[C@@H]2COC(=O)C2=C(C)O1', 'CN(CCCCCN1C(=O)c2ccccc2C1=O)Cc1ccccc1.Cl', 'CN(CCCCCCN1C(=O)c2ccccc2C1=O)Cc1ccccc1.Cl', 'CN(CCCCCCCN1C(=O)c2ccccc2C1=O)Cc1ccccc1.Cl', 'CN(CCCCCCCCN1C(=O)c2ccccc2C1=O)Cc1ccccc1.Cl', 'CN(CCCCCN1C(=O)c2ccccc2C1=O)Cc1ccccc1F.Cl', 'CN(CCCCCCN1C(=O)c2ccccc2C1=O)Cc1ccccc1F.Cl', 'CN(CCCCCCCN1C(=O)c2ccccc2C1=O)Cc1ccccc1F.Cl', 'CN(CCCCCCCCN1C(=O)c2ccccc2C1=O)Cc1ccccc1F.Cl', 'CN(CCCCCN1C(=O)c2ccccc2C1=O)Cc1cccc(Cl)c1.Cl', 'CN(CCCCCCN1C(=O)c2ccccc2C1=O)Cc1cccc(Cl)c1.Cl', 'CN(CCCCCCCN1C(=O)c2ccccc2C1=O)Cc1cccc(Cl)c1.Cl', 'CN(CCCCCCCCN1C(=O)c2ccccc2C1=O)Cc1cccc(Cl)c1.Cl', 'COc1cc2oc(-c3ccc(OCC(=O)NCCCCCNc4c5c(nc6cc(Cl)ccc46)CCCC5)cc3)cc(=O)c2c(OC)c1OC', 'COc1cc2oc(-c3ccc(OCC(=O)NCCCCCCNc4c5c(nc6cc(Cl)ccc46)CCCC5)cc3)cc(=O)c2c(OC)c1OC', 'COc1cc2oc(-c3cccc(OCC(=O)NCCCCCNc4c5c(nc6cc(Cl)ccc46)CCCC5)c3)cc(=O)c2c(OC)c1OC', 'COc1cc2oc(-c3cccc(OCC(=O)NCCCCCCNc4c5c(nc6cc(Cl)ccc46)CCCC5)c3)cc(=O)c2c(OC)c1OC', 'C#CCN(C)Cc1cc2cc(OCCCC3CCN(Cc4ccccc4C)CC3)ccc2n1C', 'C#CCN(C)Cc1cc2cc(OCCCC3CCN(Cc4ccc(OC(=O)N(C)C)c5ncccc45)CC3)ccc2n1C', 'C#CCN(C)Cc1cc2cc(OCCCC3CCN(Cc4ccccc4)CC3)ccc2[nH]1', 'C#CCNCc1cc2cc(OCCCC3CCN(Cc4ccccc4)CC3)ccc2[nH]1', 'C=CCNCc1cc2cc(OCCCC3CCN(Cc4ccccc4)CC3)ccc2[nH]1', 'CCOC(=O)c1cc2cc(OCCCC3CCN(Cc4ccccc4)CC3)ccc2[nH]1', 'OCc1cc2cc(OCCCC3CCN(Cc4ccccc4)CC3)ccc2[nH]1', 'C#CCN(C)Cc1ccc(OC(=O)N(C)C)c2ncccc12', 'Cc1c(C)c2c(c(C)c1O)CCC(C)(C(=O)NCCNc1c3c(nc4ccccc14)CCCC3)O2', 'Cc1c(C)c2c(c(C)c1O)CCC(C)(C(=O)NCCNc1c3c(nc4ccccc14)CCCC3)O2', 'Cc1c(C)c2c(c(C)c1O)CCC(C)(C(=O)NCCCCNc1c3c(nc4ccccc14)CCCC3)O2', 'Cc1c(C)c2c(c(C)c1O)CCC(C)(C(=O)NCCCCNc1c3c(nc4ccccc14)CCCC3)O2', 'Cc1c(C)c2c(c(C)c1O)CCC(C)(C(=O)NCCCCCNc1c3c(nc4ccccc14)CCCC3)O2', 'Cc1c(C)c2c(c(C)c1O)CCC(C)(C(=O)NCCCCCNc1c3c(nc4ccccc14)CCCC3)O2', 'Cc1c(C)c2c(c(C)c1O)CCC(C)(C(=O)NCCCCCCNc1c3c(nc4ccccc14)CCCC3)O2', 'Cc1c(C)c2c(c(C)c1O)CCC(C)(C(=O)NCCCCCCNc1c3c(nc4ccccc14)CCCC3)O2', 'Cc1c(C)c2c(c(C)c1O)CCC(C)(C(=O)NCCCCCCCNc1c3c(nc4ccccc14)CCCC3)O2', 'Cc1c(C)c2c(c(C)c1O)CCC(C)(C(=O)NCCCCCCCNc1c3c(nc4ccccc14)CCCC3)O2', 'Cc1c(C)c2c(c(C)c1O)CCC(C)(C(=O)NCCCCCCCCNc1c3c(nc4ccccc14)CCCC3)O2', 'Cc1c(C)c2c(c(C)c1O)CCC(C)(C(=O)NCCCCCCCCNc1c3c(nc4ccccc14)CCCC3)O2', 'Cc1c(C)c2c(c(C)c1O)CCC(C)(C(=O)NCCCCCCCCCCNc1c3c(nc4ccccc14)CCCC3)O2', 'O=C1c2ccccc2C(=O)N1CCCCCNCc1ccccc1', 'O=C1c2ccccc2C(=O)N1CCCCCCNCc1ccccc1', 'O=C1c2ccccc2C(=O)N1CCCCCCCNCc1ccccc1', 'O=C1c2ccccc2C(=O)N1CCCCCCCCNCc1ccccc1', 'O=C1c2ccccc2C(=O)N1CCCCCNCc1ccccc1F', 'O=C1c2ccccc2C(=O)N1CCCCCCNCc1ccccc1F', 'O=C1c2ccccc2C(=O)N1CCCCCCCNCc1ccccc1F', 'O=C1c2ccccc2C(=O)N1CCCCCCCCNCc1ccccc1F', 'O=C1c2ccccc2C(=O)N1CCCCCNCc1ccc(F)cc1', 'O=C1c2ccccc2C(=O)N1CCCCCCNCc1ccc(F)cc1', 'O=C1c2ccccc2C(=O)N1CCCCCCCNCc1ccc(F)cc1', 'O=C1c2ccccc2C(=O)N1CCCCCNCc1ccc(F)cc1F', 'O=C1c2ccccc2C(=O)N1CCCCCCNCc1ccc(F)cc1F', 'O=C1c2ccccc2C(=O)N1CCCCCCCNCc1ccc(F)cc1F', 'O=C1c2ccccc2C(=O)N1CCCCCCCCNCc1ccc(F)cc1F', 'O=C1c2ccccc2C(=O)N1CCCCCNCc1cccc(Cl)c1', 'O=C1c2ccccc2C(=O)N1CCCCCCNCc1cccc(Cl)c1', 'O=C1c2ccccc2C(=O)N1CCCCCCCNCc1cccc(Cl)c1', 'O=C1c2ccccc2C(=O)N1CCCCCCCCNCc1cccc(Cl)c1', 'Nc1oc2ccccc2c(=O)c1/C=C1\\\\COc2ccccc2C1=O', 'COc1cc(N)c(Cl)cc1C(=O)CCC1CCN(CC2CC2)CC1', 'COc1cc(N)c(Cl)cc1C(=O)CCC1CCN(CC2CCC2)CC1', 'COc1cc(N)c(Cl)cc1C(=O)CCC1CCN(CC2CCCC2)CC1', 'COc1cc(N)c(Cl)cc1C(=O)CCC1CCN(CC2CCCCCC2)CC1', 'COc1cc(N)c(Cl)cc1C(=O)CCC1CCN(CC2CCNCC2)CC1.Cl', 'COc1cc(N)c(Cl)cc1C(=O)CCC1CCN(CCC2CCCCC2)CC1', 'COc1cc(N)c(Cl)cc1C(=O)CCC1CCN(CC2CCCCC2C)CC1', 'COc1cc(N)c(Cl)cc1C(=O)CCC1CCN(Cc2ccccc2)CC1', 'COc1cc(N)c(Cl)cc1C(=O)CCC1CCN(Cc2cccnc2)CC1', 'COc1cc(N)c(Cl)cc1C(=O)CCC1CCN(Cc2ccncc2)CC1', 'COc1cc(N)c(Cl)cc1/C(CCC1CCN(CC2CCCCC2)CC1)=N/O', 'COc1cc(N)c(Cl)cc1C(O)CCC1CCN(CC2CCCCC2)CC1', 'COc1cc(N)c(Cl)cc1C(=O)OCC1CCN(CC2CCCCC2)CC1', 'COc1cc(N)c(Cl)cc1C(=O)CCC1CCN(CC2CCCCC2)CC1', 'COc1cc(N)c(Cl)cc1C(=O)CCC1CCN(CC2CCCCC2)CC1', 'COc1cc(N)c(Cl)cc1C(=O)CCC1CCN(CC2CCCCC2)CC1', 'COc1cc(N)c(Cl)cc1C(=O)CCC1CCN(CC2CCCCC2)CC1', 'COc1cc(N)c(Cl)cc1C(=O)CCC1CCN(CC2CCCCC2)CC1', 'Cc1c(Cl)c(=O)oc2cc(OCCN3CCN(CCCNc4c5c(nc6ccccc46)CCCC5)CC3)ccc12', 'Cc1c(C)c2ccc(OCCN3CCN(CCCNc4c5c(nc6ccccc46)CCCC5)CC3)cc2oc1=O', 'COc1cc(/C=C/c2ccc3ccccc3[n+]2C)cc(OC)c1O.[I-]', 'C[n+]1c(/C=C/c2ccccc2)ccc2ccccc21.[I-]', 'COc1cc(/C=C/c2ccc3ccccc3[n+]2C)ccc1F.[I-]', 'COc1cc(/C=C/c2ccc3ccccc3[n+]2C)cc(OC)c1OC.[I-]', 'COc1cc(/C=C/c2ccc3ccccc3[n+]2C)ccc1N1CCOCC1.[I-]', 'C[n+]1c(/C=C/c2ccc(N3CCOCC3)cc2)ccc2ccccc21.[I-]', 'C[n+]1c(/C=C/c2cc3ccccc3[nH]2)ccc2ccccc21.[I-]', 'CCn1c2ccccc2c2cc(/C=C/c3ccc4ccccc4[n+]3C)ccc21.[I-]', 'CCN(CCCOc1ccc(-c2cc(=O)c3c(OC)c(OC)c(OC)cc3o2)cc1)Cc1ccccc1OC', 'COc1cc2oc(-c3ccc(OCCCCN(C)Cc4ccccc4)cc3)cc(=O)c2c(OC)c1OC', 'CCN(CCCCOc1ccc(-c2cc(=O)c3c(OC)c(OC)c(OC)cc3o2)cc1)Cc1ccccc1', 'COc1ccccc1CN(C)CCCCOc1ccc(-c2cc(=O)c3c(OC)c(OC)c(OC)cc3o2)cc1', 'CCN(CCCCOc1ccc(-c2cc(=O)c3c(OC)c(OC)c(OC)cc3o2)cc1)Cc1ccccc1OC', 'CCN(CCCCCCOc1ccc(-c2cc(=O)c3c(OC)c(OC)c(OC)cc3o2)cc1)Cc1ccccc1OC', 'CCN(CCCOc1ccc(-c2cc(=O)c3c(O)c(OC)c(OC)cc3o2)cc1)Cc1ccccc1OC', 'CCN(CCCCOc1ccc(-c2cc(=O)c3c(O)c(OC)c(OC)cc3o2)cc1)Cc1ccccc1OC', 'CCN(CCCCCCOc1ccc(-c2cc(=O)c3c(O)c(OC)c(OC)cc3o2)cc1)Cc1ccccc1OC', 'CCC(C)C(=O)[C@]12C(=O)[C@]3(CC=C(C)C)C[C@H](CC=C(C)C)[C@@]1(C)CC[C@@H](C(C)(C)O)OC2=C(CC=C(C)C)C3=O', 'C=C(C)[C@H]1CC[C@@](C)(O)[C@@H](C2=C(O)C(CC=C(C)C)(CC=C(C)C)C(=O)C(C(=O)C(C)C)=C2O)C1', 'CC(C)=CC[C@]12C[C@@H]3[C@@H]4[C@@H](O)C(C)(C)[C@@H](C(C)C)CC4(C1=O)C(=O)[C@](C(=O)c1ccccc1)(C2=O)C3(C)C', 'C/C(=C\\\\C[C@]12C[C@H]3C[C@@H]4C(C)(C)CC[C@@]4(C1=O)C(=O)[C@](C(=O)c1ccccc1)(C2=O)C3(C)C)CC/C=C/C(C)C', 'CN1CCN(c2cccc(-c3cnc4[nH]c5cnc(C#N)cc5c4c3)c2)CC1', 'N#Cc1cc2c(cn1)[nH]c1ncc(-c3ccc(CN4CCCCC4)cc3)cc12', 'C[C@@H]1CCC[C@H](C)N1Cc1ccc(-c2cnc3[nH]c4cnc(C#N)cc4c3c2)cc1', 'C[C@@H]1C[C@H](C)CN(Cc2ccc(-c3cnc4[nH]c5cnc(C#N)cc5c4c3)cc2)C1', 'CC1(C)CCCN(Cc2ccc(-c3cnc4[nH]c5cnc(C#N)cc5c4c3)cc2)C1', 'CC1(C)CCN(Cc2ccc(-c3cnc4[nH]c5cnc(C#N)cc5c4c3)cc2)CC1', 'CC(C)(c1ccc(-c2cnc3[nH]c4cnc(C#N)cc4c3c2)cc1)N1CCCCC1', 'N#Cc1cc2c(cn1)[nH]c1ncc(-c3ccc(CN4CCC(O)CC4)cc3)cc12', 'N#Cc1cc2c(cn1)[nH]c1ncc(-c3ccc(CN4CCC[C@@H](O)C4)cc3)cc12', 'N#Cc1cc2c(cn1)[nH]c1ncc(-c3ccc(CN4CCC(F)CC4)cc3)cc12', 'N#Cc1cc2c(cn1)[nH]c1ncc(-c3ccc(CN4CCC(C#N)CC4)cc3)cc12', 'N#Cc1cc2c(cn1)[nH]c1ncc(-c3ccc(CN4CCOCC4)cc3)cc12', 'N#Cc1cc2c(cn1)[nH]c1ncc(-c3ccc(CN4CCC5(CC4)COC5)cc3)cc12', 'N#Cc1cc2c(cn1)[nH]c1ncc(-c3ccc(CN4CCCCC4)nc3)cc12', 'N#Cc1cc2c(cn1)[nH]c1ncc(-c3nc(CN4CCCCC4)cs3)cc12', 'CCN1CCc2cc(-c3cnc4[nH]c5cnc(C#N)cc5c4c3)ccc2C1', 'CCN1CCc2sc(-c3cnc4[nH]c5cnc(C#N)cc5c4c3)cc2C1', 'NC(=O)c1cc2c(cn1)[nH]c1ncc(-c3ccc(CN4CCCCC4)cc3)cc12', 'c1ncc(-c2cc3c(cn2)[nH]c2ncc(-c4ccc(CN5CCCCC5)cc4)cc23)o1', 'c1ncc(-c2cc3c(cn2)[nH]c2ncc(-c4ccc(CN5CCCCC5)cc4)cc23)s1', 'c1nnc(-c2cc3c(cn2)[nH]c2ncc(-c4ccc(CN5CCCCC5)cc4)cc23)o1', 'c1cc(-c2cnc3[nH]c4cnc(-c5cnoc5)cc4c3c2)ccc1CN1CCCCC1', 'Cn1cc(-c2cc3c(cn2)[nH]c2ncc(-c4ccc(CN5CCCCC5)cc4)cc23)cn1', 'c1cncc(-c2cc3c(cn2)[nH]c2ncc(-c4ccc(CN5CCCCC5)cc4)cc23)c1', 'c1cc(-c2cc3c(cn2)[nH]c2ncc(-c4ccc(CN5CCCCC5)cc4)cc23)ccn1', 'c1cnc(-c2cc3c(cn2)[nH]c2ncc(-c4ccc(CN5CCCCC5)cc4)cc23)cn1', 'c1cc(-c2cc3c(cn2)[nH]c2ncc(-c4ccc(CN5CCCCC5)cc4)cc23)cnn1', 'c1ncc(-c2cc3c(cn2)[nH]c2ncc(-c4ccc(CN5CCCCC5)cc4)cc23)cn1', 'Cc1ccc2[nH]c3c(c2c1)CN(CCCCCCN1CCc2[nH]c4ccc(C)cc4c2C1)CC3', 'Cc1ccc2[nH]c3c(c2c1)CN(CCCCCCN1CCc2[nH]c4ccc(C)cc4c2C1)CC3', 'Cc1ccc2[nH]c3c(c2c1)CN(CCCCCCCN1CCc2[nH]c4ccc(C)cc4c2C1)CC3', 'COc1ccccc1C(C)NS(=O)(=O)NC(=O)OCc1ccccc1', 'COc1ccc(C(C)NS(=O)(=O)NC(=O)OCc2ccccc2)cc1', 'COc1ccc(C(C)NS(=O)(=O)NC(=O)OCc2ccccc2)cc1OC', 'COc1ccc(OC)c(C(C)NS(=O)(=O)NC(=O)OCc2ccccc2)c1', 'COc1ccc(OC)c(C(C)NS(=O)(=O)NC(=O)OCc2ccccc2)c1', 'COc1cccc(OC)c1C(C)NS(=O)(=O)NC(=O)OCc1ccccc1', 'COc1cccc(OC)c1C(C)NS(=O)(=O)NC(=O)OCc1ccccc1', 'COc1ccccc1C(C)NS(N)(=O)=O', 'COc1ccccc1C(C)NS(N)(=O)=O', 'COc1ccc(C(C)NS(N)(=O)=O)cc1', 'COc1ccc(C(C)NS(N)(=O)=O)cc1OC', 'COc1ccc(OC)c(C(C)NS(N)(=O)=O)c1', 'COc1cccc(OC)c1C(C)NS(N)(=O)=O', 'CC1(C)C(=O)CC[C@@]2(C)[C@H]1CC[C@@]1(C)CC3=CC(=O)[C@H]4C(C)(C)[C@H](O)CC[C@]4(C)[C@H]3CC[C@@H]12', 'COc1ccc(C(=O)O[C@H]2CC[C@@]3(C)[C@@H](CC[C@@]4(C)C[C@@]5(O)[C@H](CC[C@@H]43)[C@@]3(C)CC[C@@H](O)C(C)(C)[C@@H]3C[C@@H]5O)[C@@]2(C)C(=O)O)cc1O', 'CC(=O)O[C@H]1CC[C@@]2(C)[C@@H](CC[C@@]3(C)C[C@@]4(O)CC[C@H]5C(C)(C)[C@@H](OC(C)=O)CC[C@]5(C)[C@H]4CC[C@@H]32)C1(C)C', 'CC(=O)O[C@H]1CC[C@@]2(C)[C@@H](CC[C@@]3(C)C[C@@]4(O)CC[C@H]5C(C)(C)[C@@H](OC(C)=O)CC[C@]5(C)[C@H]4CC[C@@H]32)C1(C)C', 'C[C@@]12CC[C@@H]3[C@](C)(CC[C@H](OC(=O)CCc4ccc(O)cc4)[C@]3(C)C(=O)O)[C@H]1CC[C@H]1C(=CC[C@@H]3[C@]1(C)CC[C@@H](O)[C@]3(C)CO)C2', 'C[C@@]12CC[C@@H]3[C@](C)(CC[C@H](OC(=O)CCc4ccc(O)cc4)[C@]3(C)C(=O)O)[C@H]1CC[C@H]1C(=CC[C@@H]3[C@]1(C)CC[C@@H](O)[C@]3(C)CO)C2', 'CCCC[C@@H](O)/C=C/C=C/C(=O)O', 'CCCC[C@@H](O)/C=C/C=C/C(=O)O', 'Cc1c(C)c2ccc(OCCCN(C)Cc3ccccc3)cc2oc1=O.Cl', 'Cc1c(C)c2ccc(OCCCCN(C)Cc3ccccc3)cc2oc1=O', 'Cc1c(C)c2ccc(OCCCCCNCc3ccccc3)cc2oc1=O.Cl', 'Cc1c(C)c2ccc(OCCCCCCN(C)Cc3ccccc3)cc2oc1=O', 'CCN(CCCCCCOc1ccc2c(C)c(C)c(=O)oc2c1)Cc1ccccc1.Cl', 'CN(Cc1ccccc1)Cc1ccc(COc2ccc3ccc(=O)oc3c2)cc1', 'Cc1cc2ccc(OCc3ccc(CN(C)Cc4ccccc4)cc3)cc2oc1=O.Cl', 'Cc1cc(=O)oc2cc(OCc3ccc(CN(C)Cc4ccccc4)cc3)ccc12.Cl', 'Cc1c(C)c2ccc(OCc3ccc(CN(C)Cc4ccccc4)cc3)cc2oc1=O.Cl', 'Cc1cc(=O)oc2cc(OCc3ccc(CN(C)Cc4cccc(Cl)c4)cc3)ccc12.Cl', 'CN(Cc1ccc(C#N)cc1)Cc1ccc(COc2ccc3ccc(=O)oc3c2)cc1.Cl', 'Cc1cc(=O)oc2cc(OCc3ccc(CN(C)Cc4ccc(C#N)cc4)cc3)ccc12.Cl', 'Cc1c(C)c2ccc(OCc3ccc(CN(C)Cc4ccc(C#N)cc4)cc3)cc2oc1=O.Cl', 'CN(Cc1ccccc1)Cc1ccc(COc2ccc3c(CO)cc(=O)oc3c2)cc1.Cl', 'CN(Cc1ccccc1)Cc1ccc(COc2ccc3c(CO)cc(=O)oc3c2)cc1.Cl', 'CN(Cc1ccc(COc2ccc3c(CO)cc(=O)oc3c2)cc1)Cc1cccc(Cl)c1.Cl', 'CN(Cc1ccccc1)Cc1ccc(COc2ccc3ccc(=O)[nH]c3c2)cc1.Cl', 'CN(Cc1ccccc1)Cc1ccc(COc2ccc3c(CO)cc(=O)oc3c2)cc1', 'CCOC(=O)C1=C(Nc2ccccc2)C[C@@H](c2ccccc2)N(c2ccccc2)[C@@H]1c1ccccc1', 'COC(=O)C1=C(Nc2ccccc2)C[C@@H](c2ccccc2)N(c2ccccc2)[C@@H]1c1ccccc1', 'COC(=O)C1=C(Nc2ccccc2)C[C@@H](c2ccc(C)cc2)N(c2ccccc2)[C@@H]1c1ccc(C)cc1', 'CCOC(=O)C1=C(Nc2ccccc2)C[C@@H](c2ccc(C)cc2)N(c2ccccc2)[C@@H]1c1ccc(C)cc1', 'COC(=O)C1=C(Nc2ccc(C)cc2)C[C@@H](c2ccc(C)cc2)N(c2ccc(C)cc2)[C@@H]1c1ccc(C)cc1', 'COC(=O)C1=C(Nc2ccc(Br)cc2)C[C@@H](c2ccc(C)cc2)N(c2ccc(Br)cc2)[C@@H]1c1ccc(C)cc1', 'COC(=O)C1=C(Nc2ccc(Cl)cc2)C[C@@H](c2ccc(C)cc2)N(c2ccc(Cl)cc2)[C@@H]1c1ccc(C)cc1', 'COC(=O)C1=C(Nc2ccc(OC)cc2)C[C@@H](c2ccc(C)cc2)N(c2ccc(OC)cc2)[C@@H]1c1ccc(C)cc1', 'CCOC(=O)C1=C(Nc2ccc(OC)cc2)C[C@@H](c2ccc(C)cc2)N(c2ccc(OC)cc2)[C@@H]1c1ccc(C)cc1', 'CCOC(=O)C1=C(Nc2ccc(OC)cc2)C[C@@H](c2ccccc2)N(c2ccc(OC)cc2)[C@@H]1c1ccccc1', 'CCOC(=O)C1=C(Nc2ccc(Cl)cc2)C[C@@H](c2ccccc2)N(c2ccc(Cl)cc2)[C@@H]1c1ccccc1', 'CCOC(=O)C1=C(Nc2ccc(C)cc2)C[C@@H](c2ccccc2)N(c2ccc(C)cc2)[C@@H]1c1ccccc1', 'COC(=O)C1=C(Nc2ccc(F)cc2)C[C@@H](c2ccccc2)N(c2ccc(F)cc2)[C@@H]1c1ccccc1', 'CCOC(=O)C1=C(Nc2ccc(F)cc2)C[C@@H](c2ccc(Cl)cc2)N(c2ccc(F)cc2)[C@@H]1c1ccc(Cl)cc1', 'CCOC(=O)C1=C(Nc2ccccc2)C[C@@H](c2ccc(F)cc2)N(c2ccccc2)[C@@H]1c1ccc(F)cc1', 'COC(=O)C1=C(Nc2ccc(F)cc2)C[C@@H](c2ccc(F)cc2)N(c2ccc(F)cc2)[C@@H]1c1ccc(F)cc1', 'COC(=O)C1=C(Nc2ccc(Cl)cc2)C[C@@H](c2ccc(F)cc2)N(c2ccc(Cl)cc2)[C@@H]1c1ccc(F)cc1', 'CC(C)(C)OC(=O)C1=C(Nc2ccccc2)C[C@@H](c2ccccc2)N(c2ccccc2)[C@@H]1c1ccccc1', 'COC(=O)C1=C(Nc2ccccc2)C[C@@H](c2ccc(Cl)cc2)N(c2ccccc2)[C@@H]1c1ccc(Cl)cc1', 'CCOC(=O)C1=C(Nc2ccc(C)cc2)C[C@@H](c2ccc(Cl)cc2)N(c2ccc(C)cc2)[C@@H]1c1ccc(Cl)cc1', 'COC(=O)C1=C(Nc2ccc(Br)cc2)C[C@@H](c2ccc(Cl)cc2)N(c2ccc(Br)cc2)[C@@H]1c1ccc(Cl)cc1', 'COC(=O)C1=C(Nc2ccc(Br)cc2)C[C@@H](c2ccc(OC)cc2)N(c2ccc(Br)cc2)[C@@H]1c1ccc(OC)cc1', 'CCOC(=O)C1=C(Nc2ccc(Cl)cc2)C[C@@H](c2ccc(OC)cc2)N(c2ccc(Cl)cc2)[C@@H]1c1ccc(OC)cc1', 'COC(=O)C1=C(Nc2ccccc2)C[C@@H](c2ccc3c(c2)OCO3)N(c2ccccc2)[C@@H]1c1ccc2c(c1)OCO2', 'CN(Cc1ccccc1)Cc1ccc(/C=C2\\\\Cc3ccc(OCCCCCN4CCC(c5ccccc5)CC4)cc3C2=O)cc1', 'CN(Cc1ccccc1)Cc1ccc(/C=C2\\\\CCc3cc(OCCCCCN4CCN(Cc5ccc(F)cc5)CC4)ccc3C2=O)cc1', 'O=C(C[n+]1ccc(/C=N/O)cc1)Nc1nccs1.[Cl-]', 'O=C(C[n+]1ccc(/C=N/O)cc1)Nc1nccs1.[Cl-]', 'O=C(C[n+]1ccc(/C=N/O)cc1)Nc1nccs1.[Cl-]', 'O=C(C[n+]1cccc(/C=N/O)c1)Nc1nccs1.[Cl-]', 'O=C(C[n+]1cccc(/C=N/O)c1)Nc1nccs1.[Cl-]', 'O=C(C[n+]1ccc(/C=N/O)cc1)Nc1nc(-c2ccccc2)cs1.[Cl-]', 'O=C(C[n+]1ccc(/C=N/O)cc1)Nc1nc(-c2ccccc2)cs1.[Cl-]', 'O=C(C[n+]1ccc(/C=N/O)cc1)Nc1nc(-c2ccccc2)cs1.[Cl-]', 'Cc1ccc(-c2csc(NC(=O)C[n+]3ccc(/C=N/O)cc3)n2)cc1.[Cl-]', 'Cc1ccc(-c2csc(NC(=O)C[n+]3ccc(/C=N/O)cc3)n2)cc1.[Cl-]', 'Cc1ccc(-c2csc(NC(=O)C[n+]3ccc(/C=N/O)cc3)n2)cc1.[Cl-]', 'COc1ccc(-c2csc(NC(=O)C[n+]3ccc(/C=N/O)cc3)n2)cc1.[I-]', 'COc1ccc(-c2csc(NC(=O)C[n+]3ccc(/C=N/O)cc3)n2)cc1.[I-]', 'COc1ccc(-c2csc(NC(=O)C[n+]3ccc(/C=N/O)cc3)n2)cc1.[I-]', 'CCOC(=O)Cc1csc(NC(=O)C[n+]2ccc(/C=N/O)cc2)n1.[Cl-]', 'CCOC(=O)Cc1csc(NC(=O)C[n+]2ccc(/C=N/O)cc2)n1.[Cl-]', 'CCOC(=O)Cc1csc(NC(=O)C[n+]2ccc(/C=N/O)cc2)n1.[Cl-]', 'CCOC(=O)Cc1csc(NC(=O)C[n+]2cccc(/C=N/O)c2)n1.[Cl-]', 'CCOC(=O)c1csc(NC(=O)C[n+]2ccc(/C=N/O)cc2)n1.[Cl-]', 'CCOC(=O)c1csc(NC(=O)C[n+]2ccc(/C=N/O)cc2)n1.[Cl-]', 'CCOC(=O)c1csc(NC(=O)C[n+]2ccc(/C=N/O)cc2)n1.[Cl-]', 'CCOC(=O)c1csc(NC(=O)C[n+]2cccc(/C=N/O)c2)n1.[Cl-]', 'CCOC(=O)c1csc(NC(=O)C[n+]2cccc(/C=N/O)c2)n1.[Cl-]', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(NCCCCCCCCCCCCNc4c5c(nc6ccccc46)CCCC5)c3C(C1)C2', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(NCCCCCCCCCCCCNc4c5c(nc6cc(Cl)ccc46)CCCC5)c3C(C1)C2', 'CC1=CC2Cc3nc4ccccc4c(NCCCCCCCCCCNc4c5c(nc6ccccc46)CCCC5)c3C(C1)C2', 'CC1=CC2Cc3nc4ccccc4c(NCCCCCCCCCCCCNc4c5c(nc6ccccc46)CCCC5)c3C(C1)C2', 'CC1=CC2Cc3nc4ccccc4c(NCCCCCCCCCCNc4c5c(nc6cc(Cl)ccc46)CCCC5)c3C(C1)C2', 'CC1=CC2Cc3nc4ccccc4c(NCCCCCCCCCCCCNc4c5c(nc6cc(Cl)ccc46)CCCC5)c3C(C1)C2', 'CN(C)c1ccc(C(=O)NCCNc2c3c(nc4ccccc24)CCCC3)cc1.Cl', 'CN(C)c1ccc(C(=O)NCCNc2c3c(nc4ccccc24)CCCC3)cc1.Cl', 'CN(C)c1ccc(C(=O)NCCCNc2c3c(nc4ccccc24)CCCC3)cc1.Cl', 'CN(C)c1ccc(C(=O)NCCCCNc2c3c(nc4ccccc24)CCCC3)cc1.Cl', 'CN(C)c1ccc(C(=O)NCCCCCNc2c3c(nc4ccccc24)CCCC3)cc1.Cl', 'CN(C)c1ccc(C(=O)NCCCCCCNc2c3c(nc4ccccc24)CCCC3)cc1.Cl', 'CN(C)c1ccc(C(=O)NCCCCCCCNc2c3c(nc4ccccc24)CCCC3)cc1.Cl', 'CN(C)c1ccc(C(=O)NCCCCCCCCNc2c3c(nc4ccccc24)CCCC3)cc1.Cl', 'CN(C)c1ccc(C(=O)NCCCCCCCCCNc2c3c(nc4ccccc24)CCCC3)cc1.Cl', 'c1ccc2c(c1)c1cnccc1n2CCCCCCCCCn1c2ccccc2c2cnccc21', 'C[n+]1ccc2c(c1)c1ccccc1n2CCCCCCCCCn1c2ccccc2c2c[n+](C)ccc21.[I-].[I-]', 'Cc1ccccc1-c1nnc(-c2ccc3c(c2)CO[C@@]3(CCCN(C)C)c2ccc(F)cc2)[nH]1', 'CN(C)CCC[C@@]1(c2ccc(F)cc2)OCc2cc(-c3nnc(-c4ccc(Cl)cc4)[nH]3)ccc21', 'CC[N+](CC)(CCCCCn1c(C)cc(=O)n(CCCCC[N+](CC)(CC)Cc2ccccc2[N+](=O)[O-])c1=O)Cc1ccccc1[N+](=O)[O-].[Br-].[Br-]', 'CC[N+](CC)(CCCCCn1c(C)cc(=O)n(CCCCC[N+](CC)(CC)Cc2ccccc2[N+](=O)[O-])c1=O)Cc1ccccc1[N+](=O)[O-].[Br-].[Br-]', 'CC[N+]1(Cc2ccccc2[N+](=O)[O-])CCCCCC[N+](CC)(Cc2ccccc2[N+](=O)[O-])CCCCCn2c(=O)cc(C)n(c2=O)CCCCC1.[Br-].[Br-]', 'CC[N+]1(Cc2ccccc2[N+](=O)[O-])CCCCCn2c(C)cc(=O)n(c2=O)CCCCC[N+](CC)(Cc2ccccc2[N+](=O)[O-])Cc2ccc(cc2)C1.[Br-].[Br-]', 'CC[N+]1(Cc2ccccc2[N+](=O)[O-])CCCCCn2c(C)cc(=O)n(c2=O)CCCCC[N+](CC)(Cc2ccccc2[N+](=O)[O-])Cc2ccc(cc2)C1.[Br-].[Br-]', 'CC[N+]1(Cc2ccccc2[N+](=O)[O-])CCCCCn2c(C)cc(=O)n(c2=O)CCCCC[N+](CC)(Cc2ccccc2[N+](=O)[O-])CCCCCn2c(=O)cc(C)n(c2=O)CCCCC1.[Br-].[Br-]', 'CC[N+]1(Cc2ccccc2[N+](=O)[O-])CCCCCn2c(C)c3c(=O)n(c2=O)CCCCC[N+](CC)(Cc2ccccc2[N+](=O)[O-])CCCCCn2c(C)c(c(=O)n(c2=O)CCCCC1)C3.[Br-].[Br-]', 'COc1ccc2cc3[n+](cc2c1OCc1ccccc1)CCc1cc2c(cc1-3)OCO2.[Br-]', 'CC(C)n1cc(C(=O)C(F)(F)F)cn1', 'CC(C)n1cc(C(=O)C(F)(F)F)cn1', 'CCC(C)n1cc(C(=O)C(F)(F)F)cn1', 'CCC(C)n1cc(C(=O)C(F)(F)F)cn1', 'CCCC(C)n1cc(C(=O)C(F)(F)F)cn1', 'CCCC(C)n1cc(C(=O)C(F)(F)F)cn1', 'CCC(CC)n1cc(C(=O)C(F)(F)F)cn1', 'CCC(CC)n1cc(C(=O)C(F)(F)F)cn1', 'O=C(c1cnn(C2CCCC2)c1)C(F)(F)F', 'O=C(c1cnn(C2CCCC2)c1)C(F)(F)F', 'CC(C)Cn1cc(C(=O)C(F)(F)F)cn1', 'CC(C)Cn1cc(C(=O)C(F)(F)F)cn1', 'CC(C)(C)c1cccc(C(=O)C(F)F)c1', 'CC(C)(C)c1cccc(C(=O)C(F)F)c1', 'CC(C)n1cc(C(=O)C(F)F)cn1', 'CC(C)n1cc(C(=O)C(F)F)cn1', 'CCC(C)n1cc(C(=O)C(F)F)cn1', 'CCC(C)n1cc(C(=O)C(F)F)cn1', 'CCCC(C)n1cc(C(=O)C(F)F)cn1', 'CCCC(C)n1cc(C(=O)C(F)F)cn1', 'CCC(CC)n1cc(C(=O)C(F)F)cn1', 'CCC(CC)n1cc(C(=O)C(F)F)cn1', 'O=C(c1cnn(C2CCCC2)c1)C(F)F', 'O=C(c1cnn(C2CCCC2)c1)C(F)F', 'CC(C)Cn1cc(C(=O)C(F)F)cn1', 'CC(C)Cn1cc(C(=O)C(F)F)cn1', 'CC(C)(C)c1cccc(C(=O)CF)c1', 'CC(C)(C)c1cccc(C(=O)CF)c1', 'CCC(C)n1cc(C(=O)CF)cn1', 'CCC(C)n1cc(C(=O)CF)cn1', 'CCCC(C)n1cc(C(=O)CF)cn1', 'CCCC(C)n1cc(C(=O)CF)cn1', 'CCC(CC)n1cc(C(=O)CF)cn1', 'CCC(CC)n1cc(C(=O)CF)cn1', 'O=C(CF)c1cnn(C2CCCC2)c1', 'O=C(CF)c1cnn(C2CCCC2)c1', 'O=C(NCCc1c[nH]c2ccccc12)c1ccc[n+](Cc2ccccc2)c1.[Br-]', 'O=C(NCCc1c[nH]c2ccccc12)c1ccc[n+](Cc2ccccc2F)c1.[Br-]', 'O=C(NCCc1c[nH]c2ccccc12)c1cc[n+](Cc2ccccc2)cc1.[Br-]', 'O=C(NCCc1c[nH]c2ccccc12)c1cc[n+](Cc2ccccc2F)cc1.[Br-]', 'O=C(NCCc1c[nH]c2ccccc12)c1cc[n+](Cc2cccc(F)c2)cc1.[Br-]', 'O=C(NCCc1c[nH]c2ccccc12)c1cc[n+](Cc2ccc(F)cc2)cc1.[Br-]', 'Cc1cccc(C[n+]2ccc(C(=O)NCCc3c[nH]c4ccccc34)cc2)c1.[Br-]', 'Cc1ccc(C[n+]2ccc(C(=O)NCCc3c[nH]c4ccccc34)cc2)cc1.[Br-]', 'N#Cc1ccc(C[n+]2ccc(C(=O)NCCc3c[nH]c4ccccc34)cc2)cc1.[Br-]', 'COc1ccc2[nH]cc(CCNC(=O)c3cc[n+](Cc4ccccc4F)cc3)c2c1.[Br-]', 'COc1ccc2[nH]cc(CCNC(=O)c3cc[n+](Cc4cccc(F)c4)cc3)c2c1.[Br-]', 'COc1ccc2[nH]cc(CCNC(=O)c3cc[n+](Cc4ccc(F)cc4)cc3)c2c1.[Br-]', 'COc1ccc2[nH]cc(CCNC(=O)c3cc[n+](Cc4ccc(OC(=O)N(C)C)cc4)cc3)c2c1.[Br-]', 'COc1ccc2[nH]cc(CCNC(=O)/C=C/c3cc[n+](Cc4ccccc4F)cc3)c2c1.[Br-]', 'COc1ccc2[nH]cc(CCNC(=O)/C=C/c3cc[n+](Cc4cccc(F)c4)cc3)c2c1.[Br-]', 'COc1ccc2[nH]cc(CCNC(=O)/C=C/c3cc[n+](Cc4ccc(F)cc4)cc3)c2c1.[Br-]', 'COc1ccc2[nH]cc(CCNC(=O)CCc3cc[n+](Cc4ccccc4F)cc3)c2c1.[Br-]', 'COc1ccc2[nH]cc(CCNC(=O)CCc3cc[n+](Cc4cccc(F)c4)cc3)c2c1.[Br-]', 'COc1ccc2[nH]cc(CCNC(=O)CCc3cc[n+](Cc4ccc(F)cc4)cc3)c2c1.[Br-]', 'COc1ccc2nc3c(c(NCCNC(=O)C4(C)CCc5c(C)c(O)c(C)c(C)c5O4)c2c1)CCCC3', 'COc1ccc2nc3c(c(NCCCNC(=O)C4(C)CCc5c(C)c(O)c(C)c(C)c5O4)c2c1)CCCC3', 'COc1ccc2nc3c(c(NCCCCNC(=O)C4(C)CCc5c(C)c(O)c(C)c(C)c5O4)c2c1)CCCC3', 'COc1ccc2nc3c(c(NCCCCCNC(=O)C4(C)CCc5c(C)c(O)c(C)c(C)c5O4)c2c1)CCCC3', 'COc1ccc2nc3c(c(NCCCCCCNC(=O)C4(C)CCc5c(C)c(O)c(C)c(C)c5O4)c2c1)CCCC3', 'COc1ccc2nc3c(c(NCCCCCCCNC(=O)C4(C)CCc5c(C)c(O)c(C)c(C)c5O4)c2c1)CCCC3', 'COc1ccc2nc3c(c(NCCCCCCCCNC(=O)C4(C)CCc5c(C)c(O)c(C)c(C)c5O4)c2c1)CCCC3', 'COc1ccc(-c2cc3c(c(=O)o2)C[C@H]2[C@@](C)(CC[C@@]4(O)C(C)(C)C(=O)CC[C@]24C)O3)cc1', 'COc1ccc(-c2cc3c(c(=O)o2)C[C@]2(O)[C@@]4(C)CC[C@@H](OC(C)=O)C(C)(C)[C@]4(O)CC[C@@]2(C)O3)cc1', 'COc1cc(-c2cc3c(c(=O)o2)C[C@]2(O)[C@@]4(C)C(=O)C=CC(C)(C)[C@]4(O)CC[C@@]2(C)O3)cc(OC)c1O', 'Cc1c(C)c2c(c(C)c1O)CCC(C)(C(=O)NCCCNc1c3c(nc4ccccc14)CCCC3)O2', 'Cc1c(C)c2c(c(C)c1O)CCC(C)(C(=O)NCCNc1c3c(nc4cc(Cl)ccc14)CCCC3)O2', 'Cc1c(C)c2c(c(C)c1O)CCC(C)(C(=O)NCCCNc1c3c(nc4cc(Cl)ccc14)CCCC3)O2', 'Cc1c(C)c2c(c(C)c1O)CCC(C)(C(=O)NCCCCNc1c3c(nc4cc(Cl)ccc14)CCCC3)O2', 'Cc1c(C)c2c(c(C)c1O)CCC(C)(C(=O)NCCCCCNc1c3c(nc4cc(Cl)ccc14)CCCC3)O2', 'Cc1c(C)c2c(c(C)c1O)CCC(C)(C(=O)NCCCCCCNc1c3c(nc4cc(Cl)ccc14)CCCC3)O2', 'Cc1c(C)c2c(c(C)c1O)CCC(C)(C(=O)NCCCCCCCNc1c3c(nc4cc(Cl)ccc14)CCCC3)O2', 'Cc1c(C)c2c(c(C)c1O)CCC(C)(C(=O)NCCCCCCCCNc1c3c(nc4cc(Cl)ccc14)CCCC3)O2', 'Cc1c(C)c2c(c(C)c1O)CCC(C)(C(=O)NCCCCCCCCNc1c3c(nc4cc(Cl)ccc14)CCCC3)O2', 'Cc1c(C)c2c(c(C)c1O)CCC(C)(C(=O)NCCCCCCCCNc1c3c(nc4cc(Cl)ccc14)CCCC3)O2', 'CC(=O)NCCc1c[nH]c2ccc(OC(=O)NCCCCCCCNc3c4c(nc5ccccc35)CCCC4)cc12', 'CC(=O)NCCc1c[nH]c2ccc(OC(=O)NCCNc3c4c(nc5ccccc35)CCCC4)cc12', 'CC(=O)NCCc1c[nH]c2ccc(OC(=O)NCCNc3c4c(nc5ccccc35)CCCC4)cc12', 'CC(=O)NCCc1c[nH]c2ccc(OC(=O)NCCCCCCNc3c4c(nc5ccccc35)CCCC4)cc12', 'CC(=O)NCCc1c[nH]c2ccc(OC(=O)NCCCCCCCNc3c4c(nc5cc(Cl)ccc35)CCCC4)cc12', 'CC(=O)NCCc1c[nH]c2ccc(OC(=O)NCCNc3c4c(nc5cc(Cl)ccc35)CCCC4)cc12', 'CC(=O)O[C@@]12CCN(C(C)=O)[C@@H]1N(C(C)=O)c1ccc(OC(=O)NCCCCCCNc3c4c(nc5ccccc35)CCCC4)cc12', 'CC(=O)NCCc1c[nH]c2ccc(OC(=O)NCCCNc3c4c(nc5ccccc35)CCCC4)cc12', 'CC(=O)NCCc1c[nH]c2ccc(OC(=O)NCCCCNc3c4c(nc5ccccc35)CCCC4)cc12', 'CC(=O)NCCc1c[nH]c2ccc(OC(=O)NCCCCCNc3c4c(nc5ccccc35)CCCC4)cc12', 'CC(=O)NCCc1c[nH]c2ccc(OC(=O)NCCCCCCCCNc3c4c(nc5ccccc35)CCCC4)cc12', 'CC(=O)NCCc1c[nH]c2ccc(OC(=O)NCCCCCCCNc3c4c(nc5ccc(Cl)cc35)CCCC4)cc12', 'CC(=O)NCCc1c[nH]c2ccc(OC(=O)NCCNc3c4c(nc5ccc(Cl)cc35)CCCC4)cc12', 'CC(=O)NCCc1c[nH]c2ccc(OC(=O)NCCCCCCCCCCNc3c4c(nc5ccccc35)CCCC4)cc12', 'CC(=O)NCCc1c[nH]c2ccc(OC(=O)NCCCCCCCCCCCCNc3c4c(nc5ccccc35)CCCC4)cc12', 'CC(=O)NCCc1c[nH]c2ccc(OC(=O)NCCCCCCCCCCNc3c4c(nc5ccc(Cl)cc35)CCCC4)cc12', 'CC(=O)NCCc1c[nH]c2ccc(OC(=O)NCCCCCCCCCCNc3c4c(nc5cc(Cl)ccc35)CCCC4)cc12', 'CC(=O)NCCc1c[nH]c2ccc(OC(=O)NCCCCCCCCCCCCNc3c4c(nc5cc(Cl)ccc35)CCCC4)cc12', 'CC(=O)NCCc1c[nH]c2ccc(OC(=O)NCCCCCCCCCCCCNc3c4c(nc5ccc(Cl)cc35)CCCC4)cc12', 'Cc1c([C@@H](O)CN2CCN(C[C@H](O)c3ccc4c(c3C)COC4=O)CC2)ccc2c1COC2=O', 'CCOP1(=O)CCCC(C(=O)OC)=C(C)O1', 'CCOP1(=O)CCCC(C(=O)OC)=C(C)O1', 'COP1(=O)OCCC(C(=O)OC(C)(C)C)=C(C)O1', 'COP1(=O)OCCC(C(=O)OC(C)(C)C)=C(C)O1', 'COC(=O)C1=C(C)OP(=O)(OC)OCC1', 'COC(=O)C1=C(C)OP(=O)(OC)OCC1', 'O=C1OCc2cc(-c3ccc(-c4ccc(CO)cc4)s3)ccc21', 'CCN(CCCCCCCCc1cccc(OC)c1)Cc1ccccc1OC', 'CCN(CCCCCCCCc1cccc(OC)c1)Cc1ccccc1OC', 'O=C(NCCCCCCNc1c2c(nc3ccccc13)CCC2)c1cc2ccccc2o1', 'O=C(NCCCCCCNc1c2c(nc3ccccc13)CCCC2)c1cc2ccccc2o1', 'O=C(NCCCCCCNc1c2c(nc3ccccc13)CCCCC2)c1cc2ccccc2o1', 'COc1cccc2cc(C(=O)NCCCCCCNc3c4c(nc5ccccc35)CCC4)oc12', 'COc1cccc2cc(C(=O)NCCCCCCNc3c4c(nc5ccccc35)CCCC4)oc12', 'COc1cccc2cc(C(=O)NCCCCCCNc3c4c(nc5ccccc35)CCCCC4)oc12', 'O=C(NCCCCCCCNc1c2c(nc3ccccc13)CCC2)c1cc2ccccc2o1', 'O=C(NCCCCCCCNc1c2c(nc3ccccc13)CCCC2)c1cc2ccccc2o1', 'O=C(NCCCCCCCNc1c2c(nc3ccccc13)CCCCC2)c1cc2ccccc2o1', 'COc1cccc2cc(C(=O)NCCCCCCCNc3c4c(nc5ccccc35)CCC4)oc12', 'COc1cccc2cc(C(=O)NCCCCCCCNc3c4c(nc5ccccc35)CCCC4)oc12', 'COc1cccc2cc(C(=O)NCCCCCCCNc3c4c(nc5ccccc35)CCCCC4)oc12', 'c1ccc2oc(CNCCCCCCNc3c4c(nc5ccccc35)CCC4)cc2c1', 'COc1cccc2cc(CNCCCCCCNc3c4c(nc5ccccc35)CCC4)oc12', 'COc1cccc2cc(CNCCCCCCNc3c4c(nc5ccccc35)CCCC4)oc12', 'c1ccc2oc(CNCCCCCCCNc3c4c(nc5ccccc35)CCC4)cc2c1', 'c1ccc2oc(CNCCCCCCCNc3c4c(nc5ccccc35)CCCC4)cc2c1', 'c1ccc2oc(CNCCCCCCCNc3c4c(nc5ccccc35)CCCC4)cc2c1', 'c1ccc2oc(CNCCCCCCCNc3c4c(nc5ccccc35)CCCC4)cc2c1', 'COc1cccc2cc(CNCCCCCCCNc3c4c(nc5ccccc35)CCCCC4)oc12', 'c1ccc2oc(CN(CCCCCCNc3c4c(nc5ccccc35)CCC4)Cc3cc4ccccc4o3)cc2c1', 'COc1cccc2cc(CN(CCCCCCNc3c4c(nc5ccccc35)CCC4)Cc3cc4cccc(OC)c4o3)oc12', 'COc1cccc2cc(CN(CCCCCCNc3c4c(nc5ccccc35)CCCC4)Cc3cc4cccc(OC)c4o3)oc12', 'COc1cccc2cc(CN(CCCCCCNc3c4c(nc5ccccc35)CCCCC4)Cc3cc4cccc(OC)c4o3)oc12', 'c1ccc2oc(CN(CCCCCCCNc3c4c(nc5ccccc35)CCC4)Cc3cc4ccccc4o3)cc2c1', 'c1ccc2oc(CN(CCCCCCCNc3c4c(nc5ccccc35)CCCC4)Cc3cc4ccccc4o3)cc2c1', 'c1ccc2oc(CN(CCCCCCCNc3c4c(nc5ccccc35)CCCCC4)Cc3cc4ccccc4o3)cc2c1', 'COc1cccc2cc(CN(CCCCCCCNc3c4c(nc5ccccc35)CCCCC4)Cc3cc4cccc(OC)c4o3)oc12', 'Cl.Cl.c1ccc2c(NCCCCCCCNc3c4c(nc5ccccc35)CCCC4)c3c(nc2c1)CCCC3', 'CC(C)NCc1cccc2[nH]c3ccccc3c12', 'CCNCc1cccc2[nH]c3cc(Cl)ccc3c12', 'COc1cc(/C=C/C(=O)N(Cc2cccc3[nH]c4ccccc4c23)C(C)C)ccc1O', 'CCN(Cc1cccc2[nH]c3cc(Cl)ccc3c12)C(=O)/C=C/c1ccc(O)c(OC)c1', 'I.ICC1CN=C(Nc2ccccn2)S1', 'CC(C)=CC[C@H]1C[C@@]2(CC=C(C)C)C(=O)O[C@@](CC=C(C)C)(C(=O)[C@@H](C(=O)C(C)C)[C@]1(C)C/C=C/C(C)(C)O)C2=O', 'CCC(C)C(=O)[C@@H]1C(=O)[C@]2(CC=C(C)C)OC(=O)[C@](CC=C(C)C)(C[C@H](CC=C(C)C)[C@@]1(C)C/C=C/C(C)(C)O)C2=O', 'NS(=O)(=O)c1ccc(/N=C/c2cc(Br)cc(Br)c2O)cc1', 'NS(=O)(=O)c1ccc(/N=C/c2cc(Br)cc(Br)c2O)cc1', 'CC[C@H]1O[C@@H]2O[C@H](/C=C/C=C/C=C/c3oc(=O)cc(OC/C=C(\\\\C)C(=O)OC)c3C)[C@H](O)[C@]2(C)[C@@]1(C)O', 'COc1ccc2c3c1O[C@H]1CC(O)CC[C@@]31CCN(C)C2', 'N#CC1=C(N)N2CCNC2=C([N+](=O)[O-])C12C(=O)Nc1ccccc12', 'N#CC1=C(N)N2CCCNC2=C([N+](=O)[O-])C12C(=O)Nc1ccccc12', 'CC1(C)CNC2=C([N+](=O)[O-])C3(C(=O)Nc4ccccc43)C(C#N)=C(N)N2C1', 'N#CC1=C(N)N(Cc2ccccc2)C(NCc2ccccc2)=C([N+](=O)[O-])C12C(=O)Nc1ccccc12', 'Cc1ccc2c(c1)C1(C(=O)N2)C(C#N)=C(N)N2CCNC2=C1[N+](=O)[O-]', 'Cc1ccc2c(c1)C1(C(=O)N2)C(C#N)=C(N)N2CCCNC2=C1[N+](=O)[O-]', 'Cc1ccc2c(c1)C1(C(=O)N2)C(C#N)=C(N)N2CC(C)(C)CNC2=C1[N+](=O)[O-]', 'Cc1ccc2c(c1)C1(C(=O)N2)C(C#N)=C(N)N(Cc2ccccc2)C(NCc2ccccc2)=C1[N+](=O)[O-]', 'N#CC1=C(N)N2CCNC2=C([N+](=O)[O-])C12C(=O)Nc1ccc([N+](=O)[O-])cc12', 'N#CC1=C(N)N2CCCNC2=C([N+](=O)[O-])C12C(=O)Nc1ccc([N+](=O)[O-])cc12', 'CC1(C)CNC2=C([N+](=O)[O-])C3(C(=O)Nc4ccc([N+](=O)[O-])cc43)C(C#N)=C(N)N2C1', 'N#CC1=C(N)N(Cc2ccccc2)C(NCc2ccccc2)=C([N+](=O)[O-])C12C(=O)Nc1ccc([N+](=O)[O-])cc12', 'N#CC1=C(N)N2CCNC2=C([N+](=O)[O-])C12C(=O)Nc1ccc(F)cc12', 'N#CC1=C(N)N2CCCNC2=C([N+](=O)[O-])C12C(=O)Nc1ccc(F)cc12', 'CC1(C)CNC2=C([N+](=O)[O-])C3(C(=O)Nc4ccc(F)cc43)C(C#N)=C(N)N2C1', 'N#CC1=C(N)N(Cc2ccccc2)C(NCc2ccccc2)=C([N+](=O)[O-])C12C(=O)Nc1ccc(F)cc12', 'N#CC1=C(N)N2CCNC2=C([N+](=O)[O-])C12C(=O)c1cccc3cccc2c13', 'N#CC1=C(N)N2CCCNC2=C([N+](=O)[O-])C12C(=O)c1cccc3cccc2c13', 'CC1(C)CNC2=C([N+](=O)[O-])C3(C(=O)c4cccc5cccc3c45)C(C#N)=C(N)N2C1', 'N#CC1=C(N)N(Cc2ccccc2)C(NCc2ccccc2)=C([N+](=O)[O-])C12C(=O)c1cccc3cccc2c13', 'N#CC1=C(N)N2CCNC2=C([N+](=O)[O-])C12C(=O)c1ccc(Br)c3c(Br)ccc2c13', 'N#CC1=C(N)N2CCCNC2=C([N+](=O)[O-])C12C(=O)c1ccc(Br)c3c(Br)ccc2c13', 'CC1(C)CNC2=C([N+](=O)[O-])C3(C(=O)c4ccc(Br)c5c(Br)ccc3c45)C(C#N)=C(N)N2C1', 'N#CC1=C(N)N(Cc2ccccc2)C(NCc2ccccc2)=C([N+](=O)[O-])C12C(=O)c1ccc(Br)c3c(Br)ccc2c13', 'O=c1cc(Cl)c2ccc(OCCNC3CCN(Cc4ccccc4)CC3)cc2o1', 'Cc1c(C)c2ccc(OCCNC3CCN(Cc4ccccc4)CC3)cc2oc1=O', 'Cc1c(Cl)c(=O)oc2cc(OCCNC3CCN(Cc4ccccc4)CC3)ccc12', 'O=c1oc2cc(OCCNC3CCN(Cc4ccccc4)CC3)ccc2c2c1CCCC2', 'Cc1cc(=O)oc2cc(CNCCC3CCN(Cc4ccccc4)CC3)ccc12', 'COc1ccc(C(=O)N2c3ccccc3Sc3ccccc32)cc1OC', 'O=C(Cc1ccccc1)N1c2ccccc2Sc2ccc(Cl)cc21', 'O=C(CCc1ccccc1)N1c2ccccc2Sc2ccc(Cl)cc21', 'COc1cccc(C(=O)N2c3ccccc3Sc3ccc(Cl)cc32)c1', 'COc1ccc(C(=O)N2c3ccccc3Sc3ccc(Cl)cc32)cc1OC', 'c1ccc2c(c1)Nc1ccccc1[Se]2', 'Clc1ccc2c(c1)Nc1ccccc1[Se]2', 'O=C(c1ccccc1)N1c2ccccc2[Se]c2ccccc21', 'O=C(Cc1ccccc1)N1c2ccccc2[Se]c2ccccc21', 'O=C(CCc1ccccc1)N1c2ccccc2[Se]c2ccccc21', 'COc1ccc(C(=O)N2c3ccccc3[Se]c3ccccc32)cc1', 'COc1cccc(C(=O)N2c3ccccc3[Se]c3ccccc32)c1', 'COc1ccc(C(=O)N2c3ccccc3[Se]c3ccccc32)cc1OC', 'O=C(c1ccccc1)N1c2ccccc2[Se]c2ccc(Cl)cc21', 'O=C(Cc1ccccc1)N1c2ccccc2[Se]c2ccc(Cl)cc21', 'O=C(CCc1ccccc1)N1c2ccccc2[Se]c2ccc(Cl)cc21', 'COc1ccc(C(=O)N2c3ccccc3[Se]c3ccc(Cl)cc32)cc1', 'COc1cccc(C(=O)N2c3ccccc3[Se]c3ccc(Cl)cc32)c1', 'COc1ccc(C(=O)N2c3ccccc3[Se]c3ccc(Cl)cc32)cc1OC', 'CC(COC(=O)c1ccc(Oc2nc(Oc3ccc(C(=O)OCC(C)N(C)C)cc3)nc(Oc3ccc(C(=O)OCC(C)N(C)C)cc3)n2)cc1)N(C)C', 'C[N+](C)(C)CCOC(=O)c1ccc(Oc2nc(Oc3ccc(C(=O)OCC[N+](C)(C)C)cc3)nc(Oc3ccc(C(=O)OCC[N+](C)(C)C)cc3)n2)cc1', 'CCCCCCCNC(=O)Oc1ccc2c(c1)CN(C)C(c1ccc(F)cc1)N2C', 'CCCCCCCNC(=O)Oc1ccc2c(c1)CN(C)C(c1cc[nH]c1)N2C', 'CN1Cc2cc(O)ccc2N(C)C1c1c(Cl)cccc1Cl', 'COc1cccc2c1CC[C@H](NC(=O)N(C)C)C2', 'COc1cccc2c1CC[C@H](NC(=O)N(C)C)C2', 'COc1ccc2c(c1)CCC(NC(=O)N(C)C)C2', 'COc1ccc2c(c1)CCC(NC(=O)N(C)C)C2', 'COc1ccc2c(c1)C[C@@H](NC(=O)N(C)C)CC2', 'COc1ccc2c(c1)C[C@@H](NC(=O)N(C)C)CC2', 'COc1cccc2c1CCC(NS(=O)(=O)N(C)C)C2', 'COc1cccc2c1CCC(NS(=O)(=O)N(C)C)C2', 'COc1ccc2c(c1)CCC(NS(=O)(=O)N(C)C)C2', 'COc1ccc2c(c1)CCC(NS(=O)(=O)N(C)C)C2', 'COc1ccc2c(c1)CC(NS(=O)(=O)N(C)C)CC2', 'COc1ccc2c(c1)CC(NS(=O)(=O)N(C)C)CC2', 'CN(C)C(=O)N[C@H]1CCc2c(O)cccc2C1', 'CN(C)C(=O)N[C@H]1CCc2c(O)cccc2C1', 'CN(C)C(=O)NC1CCc2cc(O)ccc2C1', 'CN(C)C(=O)NC1CCc2cc(O)ccc2C1', 'CN(C)C(=O)N[C@H]1CCc2ccc(O)cc2C1', 'CN(C)C(=O)N[C@H]1CCc2ccc(O)cc2C1', 'CN(C)S(=O)(=O)NC1CCc2c(O)cccc2C1', 'CN(C)S(=O)(=O)NC1CCc2c(O)cccc2C1', 'CN(C)S(=O)(=O)N[C@H]1CCc2cc(O)ccc2C1', 'CN(C)S(=O)(=O)N[C@H]1CCc2cc(O)ccc2C1', 'CN(C)S(=O)(=O)NC1CCc2ccc(O)cc2C1', 'CN(C)S(=O)(=O)NC1CCc2ccc(O)cc2C1', 'COc1cc2occ(-c3ccc(O)cc3O)c(=O)c2c(O)c1CC=C(C)C', 'COc1cc(/C=C/C(=O)NCCC2CCN(Cc3ccccc3)CC2)ccc1O', 'COc1cc(/C=C/C(=O)NCCC2CCN(Cc3ccccc3)CC2)ccc1O', 'COc1ccc(/C=C/C(=O)NCCC2CCN(Cc3ccccc3)CC2)cc1O', 'COc1cc(/C=C/C(=O)NCCC2CCN(Cc3ccccc3)CC2)cc(OC)c1O', 'O=C(/C=C/c1ccc(O)cc1)NCCC1CCN(Cc2ccccc2)CC1', 'O=C(/C=C/c1ccc(O)cc1)NCCC1CCN(Cc2ccccc2)CC1', 'O=C(/C=C/c1ccc(O)cc1)NCCC1CCN(Cc2ccccc2)CC1', 'O=C(/C=C/c1ccc(O)c(O)c1)NCCC1CCN(Cc2ccccc2)CC1', 'O=C(/C=C/c1ccc(O)c(O)c1)NCCC1CCN(Cc2ccccc2)CC1', 'O=C(/C=C/c1ccccc1O)NCCC1CCN(Cc2ccccc2)CC1', 'O=C(/C=C/c1ccccc1)NCCC1CCN(Cc2ccccc2)CC1', 'O=C(/C=C/c1ccccc1)NCCC1CCN(Cc2ccccc2)CC1', 'COc1cc(/C=C/C(=O)NCCC2CCN(Cc3ccccc3)CC2)ccc1OC(C)=O', 'COc1ccc(/C=C/C(=O)NCCC2CCN(Cc3ccccc3)CC2)cc1OC', 'COc1ccc(/C=C/C(=O)NCCC2CCN(Cc3ccccc3)CC2)cc1OC', 'COc1cccc(/C=C/C(=O)NCCC2CCN(Cc3ccccc3)CC2)c1', 'COc1cccc(/C=C/C(=O)NCCC2CCN(Cc3ccccc3)CC2)c1', 'COc1cc(/C=C/C(=O)NCCC2CCN(Cc3ccccc3)CC2)cc(OC)c1OC', 'O=C(/C=C/c1ccc(F)cc1)NCCC1CCN(Cc2ccccc2)CC1', 'O=C(/C=C/c1ccc(Cl)cc1)NCCC1CCN(Cc2ccccc2)CC1', 'O=C(/C=C/c1ccc([N+](=O)[O-])cc1)NCCC1CCN(Cc2ccccc2)CC1', 'COc1cc(CCC(=O)NCCC2CCN(Cc3ccccc3)CC2)ccc1O', 'COc1cc2c(cc1O)C(=O)/C(=C/C1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1O)C(=O)/C(=C/C1CCN(Cc3ccccc3)CC1)C2', 'COc1cc2c(cc1O)C/C(=C\\\\C1CCN(Cc3ccccc3)CC1)C2=O', 'COc1cc2c(cc1O)C/C(=C\\\\C1CCN(Cc3ccccc3)CC1)C2=O', 'O=C1/C(=C/C2CCN(Cc3ccccc3)CC2)Cc2ccc(O)cc21', 'O=C1/C(=C/C2CCN(Cc3ccccc3)CC2)Cc2ccc(O)cc21', 'O=C1/C(=C/C2CCN(Cc3ccccc3)CC2)Cc2cccc(O)c21', 'O=C1/C(=C/C2CCN(Cc3ccccc3)CC2)Cc2cccc(O)c21', 'O=C1/C(=C/C2CCN(Cc3ccccc3)CC2)Cc2cc(O)ccc21', 'O=C1/C(=C/C2CCN(Cc3ccccc3)CC2)Cc2cc(O)ccc21', 'COc1ccc2c(c1)C(=O)/C(=C/C1CCN(Cc3ccccc3)CC1)C2', 'COc1ccc2c(c1)C(=O)/C(=C/C1CCN(Cc3ccccc3)CC1)C2', 'COc1cccc2c1C(=O)/C(=C/C1CCN(Cc3ccccc3)CC1)C2', 'COc1cccc2c1C(=O)/C(=C/C1CCN(Cc3ccccc3)CC1)C2', 'COc1ccc2c(c1)C/C(=C\\\\C1CCN(Cc3ccccc3)CC1)C2=O', 'COc1ccc2c(c1)C/C(=C\\\\C1CCN(Cc3ccccc3)CC1)C2=O', 'O=C1/C(=C/C2CCN(Cc3ccccc3)CC2)Cc2cc3c(cc21)OCO3', 'O=C1/C(=C/C2CCN(Cc3ccccc3)CC2)Cc2cc3c(cc21)OCO3', 'COc1cccc(CN2CCC(/C=C3\\\\Cc4cc(OC)ccc4C3=O)CC2)c1', 'COc1cccc(CN2CCC(/C=C3\\\\Cc4cc(OC)ccc4C3=O)CC2)c1', 'COc1cccc(CN2CCC(/C=C3\\\\Cc4ccc(OC)cc4C3=O)CC2)c1', 'COc1cccc(CN2CCC(/C=C3\\\\Cc4cccc(OC)c4C3=O)CC2)c1', 'COc1cccc(CN2CCC(/C=C3\\\\Cc4cccc(OC)c4C3=O)CC2)c1', 'COc1ccc2c(c1)C(=O)/C(=C/C1CCN(Cc3ccc4c(c3)OCO4)CC1)C2', 'COc1ccc2c(c1)C(=O)/C(=C/C1CCN(Cc3ccc4c(c3)OCO4)CC1)C2', 'COc1cccc2c1C(=O)/C(=C/C1CCN(Cc3ccc4c(c3)OCO4)CC1)C2', 'COc1cccc2c1C(=O)/C(=C/C1CCN(Cc3ccc4c(c3)OCO4)CC1)C2', 'O=C(CCCCCCCCc1ccc(O)cc1)c1c(O)cc(O)cc1O', 'O=C(CCCCCCCCc1ccc(O)c(O)c1)c1c(O)ccc(C(CCCCCCCCc2ccc(O)c(O)c2)c2c(O)cccc2O)c1O', 'O=C(CCCCCCCCc1ccc(O)c(O)c1)c1c(O)ccc(C(CCCCCCCCc2ccc(O)cc2)c2c(O)cccc2O)c1O', 'O=C(CC1CCN(Cc2ccccc2)CC1)NCCc1c[nH]c2ccccc12', 'Cc1ccccc1CN1CCC(CC(=O)NCCc2c[nH]c3ccccc23)CC1', 'COc1ccc2[nH]cc(CCNC(=O)CC3CCN(Cc4ccccc4C)CC3)c2c1', 'Cc1cccc(CN2CCC(CC(=O)NCCc3c[nH]c4ccccc34)CC2)c1', 'COc1ccc2[nH]cc(CCNC(=O)CC3CCN(Cc4cccc(C)c4)CC3)c2c1', 'Cc1ccc(CN2CCC(CC(=O)NCCc3c[nH]c4ccccc34)CC2)cc1', 'COc1ccc2[nH]cc(CCNC(=O)CC3CCN(Cc4ccc(C)cc4)CC3)c2c1', 'O=C(NCCc1c[nH]c2ccccc12)C1CCN(Cc2ccccc2)CC1', 'COc1ccc2[nH]cc(CCNC(=O)C3CCN(Cc4ccccc4)CC3)c2c1', 'Cc1ccccc1CN1CCC(C(=O)NCCc2c[nH]c3ccccc23)CC1', 'COc1ccc2[nH]cc(CCNC(=O)C3CCN(Cc4ccccc4C)CC3)c2c1', 'O=C(CCc1c[nH]c2ccccc12)NC1CCN(Cc2ccccc2)CC1', 'O=C(CCc1c[nH]c2ccccc12)NCCC1CCN(Cc2ccccc2)CC1', 'O=C(CCc1c[nH]c2ccccc12)NCCC1CCN(Cc2ccccc2)CC1', 'CCCCCCCC1OCc2c[n+](C)c(C)c(OC(=O)N(C)C)c2CO1.[Br-]', 'CCCCCCCCC1OCc2c[n+](C)c(C)c(OC(=O)N(C)C)c2CO1.[Br-]', 'CCCCCCCCCC(C)C1OCc2c[n+](C)c(C)c(OC(=O)N(C)C)c2CO1.[Br-]', 'NC(=O)c1cc[n+](CC[n+]2cccc(NC(=O)/C=N\\\\O)c2)cc1.[Br-].[Br-]', 'NC(=O)c1cc[n+](CCC[n+]2cccc(NC(=O)/C=N\\\\O)c2)cc1.[Br-].[Br-]', 'NC(=O)c1cc[n+](CCC[n+]2cccc(NC(=O)/C=N\\\\O)c2)cc1.[Br-].[Br-]', 'NC(=O)c1cc[n+](CCCC[n+]2cccc(NC(=O)/C=N\\\\O)c2)cc1.[Br-].[Br-]', 'NC(=O)c1cc[n+](CCCC[n+]2cccc(NC(=O)/C=N\\\\O)c2)cc1.[Br-].[Br-]', 'NC(=O)c1cc[n+](CCCCC[n+]2cccc(NC(=O)/C=N\\\\O)c2)cc1.[Br-].[Br-]', 'NC(=O)c1cc[n+](CCCCC[n+]2cccc(NC(=O)/C=N\\\\O)c2)cc1.[Br-].[Br-]', 'CN(CCCOc1ccc2c3c(c(=O)oc2c1)CCCC3)Cc1cccc(OC(=O)NCCCCCc2ccccc2)c1', 'Cc1cc(=O)oc2cc(OCCCN(C)Cc3cccc(OC(=O)NCCCCCc4ccccc4)c3)ccc12', 'CN(CCCOc1ccc2c(c1)oc(=O)c1ccccc12)Cc1cccc(OC(=O)NCCCCCc2ccccc2)c1', 'CN(CCCOc1ccc2cc(-c3ccccc3)c(=O)oc2c1)Cc1cccc(OC(=O)NCCCCCc2ccccc2)c1', 'COc1ccc(-c2cc3ccc(OCCCN(C)Cc4cccc(OC(=O)NCCCCCc5ccccc5)c4)cc3oc2=O)cc1', 'COc1ccc(-c2cc3cc(OCCCN(C)Cc4cccc(OC(=O)NCCCCCc5ccccc5)c4)ccc3oc2=O)cc1', 'CN(CCCOc1ccc2cc(-c3ccc(Cl)cc3)c(=O)oc2c1)Cc1cccc(OC(=O)NCCCCCc2ccccc2)c1', 'CCCCCCCNC(=O)Oc1cccc(CN(C)CCCOc2ccc3c4c(c(=O)oc3c2)CCCC4)c1', 'CCCCCCc1ccc(NC(=O)Oc2cccc(CN(C)CCCOc3ccc4ccc(=O)oc4c3)c2)cc1', 'CN(CCCOc1ccc2ccc(=O)oc2c1)Cc1cccc(OC(=O)NCCCCCCc2ccccc2)c1', 'CN(CCCCCOc1ccc2ccc(=O)oc2c1)Cc1cccc(OC(=O)NCCCCCc2ccccc2)c1', 'CCCCCCCNC(=O)Oc1cccc(CN(C)CCCCCOc2ccc3ccc(=O)oc3c2)c1', 'CCCCCCCNC(=O)Oc1cccc(CN(C)CCCCCOc2ccc3c4c(c(=O)oc3c2)CCCC4)c1', 'CCCCCCCNC(=O)Oc1cccc(CN(C)CCCCCOc2ccc3c(c2)Oc2ncccc2C3)c1', 'O=C(NCCCCCc1ccccc1)Oc1ccc(Cn2cc(COc3ccc4ccc(=O)oc4c3)nn2)cc1', 'O=C(NCCCCCc1ccccc1)Oc1cccc(Cn2cc(COc3ccc4ccc(=O)oc4c3)nn2)c1', 'CCCCCCCNC(=O)Oc1ccc(Cn2cc(COc3ccc4ccc(=O)oc4c3)nn2)cc1', 'CCCCCCCNC(=O)Oc1cccc(Cn2cc(COc3ccc4ccc(=O)oc4c3)nn2)c1', 'O=C(NCCCCCc1ccccc1)Oc1ccc(-n2cc(COc3ccc4ccc(=O)oc4c3)nn2)cc1', 'O=C(NCCCCCc1ccccc1)Oc1cccc(-n2cc(COc3ccc4ccc(=O)oc4c3)nn2)c1', 'CCCCCCCNC(=O)Oc1cccc(-n2cc(COc3ccc4ccc(=O)oc4c3)nn2)c1', 'O=S(=O)(c1ccccc1)n1ccc2c(N3CCN(CCCCCCCCNc4c5c(nc6ccccc46)CCCC5)CC3)cccc21', 'O=S(=O)(c1ccccc1)n1ccc2c(N3CCN(CCCNc4c5c(nc6ccccc46)CCCC5)CC3)cccc21', 'O=S(=O)(c1ccccc1)n1ccc2c(N3CCN(CCCCCCCNc4c5c(nc6ccccc46)CCCC5)CC3)cccc21', 'O=S(=O)(c1ccccc1)n1ccc2c(N3CCN(CCCCCNc4c5c(nc6ccccc46)CCCC5)CC3)cccc21', 'O=S(=O)(c1ccccc1)n1ccc2c(N3CCN(CCNc4c5c(nc6ccccc46)CCCC5)CC3)cccc21', 'O=S(=O)(c1ccccc1)n1ccc2c(N3CCN(CCCCCCNc4c5c(nc6ccccc46)CCCC5)CC3)cccc21', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccc4ccccc4n3)CC1)C2', 'COC(=O)c1cccc(CN2CCC(CC3Cc4cc(OC)c(OC)cc4C3=O)CC2)n1', 'COc1cccc2c1C=[N+](c1ccccc1Br)CC2.[Br-]', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3C(F)(F)F)CC1)C2', 'COc1cc(/C=C/C(=O)Nc2ccc(CN(C)Cc3ccccc3)cc2)ccc1O', 'CC1=C(C(=O)OCCN(C)C)C(c2ccccc2)c2c(nc3c(c2N)CC(F)(F)CC3)N1', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ncccc3C)CC1)C2', 'O=C(/C=C/c1cccc(O)c1)NCCC1CCN(Cc2ccccc2)CC1', 'C#CCN(CCC1CCN(Cc2ccccc2)CC1)Cc1ccc2cccc(O)c2n1', 'COc1ccc2nc(NCCc3cc[n+](Cc4ccccc4)cc3)sc2c1', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccc(C(F)(F)F)cc3)CC1)C2', 'COc1cccc2c1C=[N+](c1ccc(F)cc1)CC2.[Br-]', 'CCOC(=O)C1=C(C)Nc2nc3c(c(N)c2C1c1ccccc1OC)CC(C)CC3', 'C=CCOC(=O)C1=C(C)Nc2nc3c(c(N)c2C1c1cccc(F)c1)CC(C)(C)CC3', 'COc1cccc2c1C=[N+](c1ccccc1C)CC2.[Br-]', 'COc1cccc2c1C=[N+](c1ccc(I)cc1F)CC2.[Br-]', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ncc(C)cc3C)CC1)C2', 'O=[N+]([O-])c1ccc2nc(NCCc3cc[n+](Cc4ccc(F)cc4)cc3)sc2c1', 'CC1=C(C(=O)OC(C)C)C(c2cncnc2)c2c(nc3c(c2N)CC(C)(C)CC3)N1', 'C#CCN(Cc1ccc2cccc(O)c2n1)C(C#N)C1CCN(Cc2ccccc2)CC1', 'Cc1ccc(/C=C2/CNCC3=C2N=C2SC=C(c4ccc(C)cc4)N2C3c2ccc(C)cc2)cc1', 'COc1cccc([N+]2=Cc3c(cccc3OC)CC2)c1.[Br-]', 'COc1ccc(/C=C/C(=O)NCCC2CCN(Cc3ccccc3)CC2)cc1', 'COc1ccc2nc(NCCc3cc[n+](Cc4c(F)cccc4F)cc3)sc2c1', 'CCOC(=O)C1=C(C(F)(F)F)Nc2nc3c(c(N)c2C1c1cccc([N+](=O)[O-])c1)CC(C)(C)CC3', 'C#CCN(Cc1ccc2cccc(O)c2n1)C(C#N)CCC1CCN(Cc2ccccc2)CC1', 'C#CCN(Cc1ccc2cccc(O)c2n1)C(C#N)CCC1CCN(Cc2ccccc2)CC1', 'C#CCN(Cc1ccc2cccc(O)c2n1)C(C#N)CCC1CCN(Cc2ccccc2)CC1', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccn3)CC1)C2', 'Cc1ccc(/C=C2/CNCC3=C2N=C2SC=C(c4ccc5ccccc5c4)N2C3c2ccc(C)cc2)cc1', 'CCOC(=O)C1=C(C)N(C)c2nc3c(c(N)c2C1c1ccccc1Cl)CC(C)(C)CC3', 'CC(=O)/C(=N\\\\O)C(=O)Nc1cnc2c(c1)CC(N(C)CCc1ccccc1)CC2', 'COc1cccc2c1C=[N+](c1ccc(Cl)cc1)CC2.[Br-]', 'O=C(/C=N\\\\O)c1ccc(OCC2CCN(Cc3ccccc3)CC2)nc1', 'COc1cccc2c1C=[N+](c1ccc(C(F)(F)F)cc1)CC2.[Br-]', 'COc1ccc(/C=C/C(=O)NCCC2CCN(Cc3ccccc3)CC2)c(OC)c1', 'COc1ccc(/C=C/C(=O)Nc2ccc(CN(C)Cc3ccccc3)cc2)cc1OC', 'COc1ccc(/C=C/C(=O)Nc2ccc(CN(C)Cc3ccccc3)cc2)cc1OC', 'COc1cccc(/C=C/C(=O)Nc2ccc(CN(C)Cc3ccccc3)cc2)c1', 'O=C1NCCCc2c1c1ccccc1n2CCc1ccc(F)cc1', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3cccc(C)n3)CC1)C2', 'CC1=C(C(=O)OC(C)C)C(c2ccccc2Cl)c2c(nc3c(c2N)CC(C)(C)CC3)N1', 'COc1cccc2c1C=[N+](c1cccc(C#N)c1)CC2.[Br-]', 'C#CCOC(=O)C1=C(C)Nc2nc3c(c(N)c2C1c1cccc(F)c1)CC(C)(C)CC3', 'CN(C)C(=O)Oc1cccc(C(=O)/C=C/c2ccc(O)cc2)c1', 'CN(C)C(=O)Oc1cccc(C(=O)/C=C/c2ccc(O)cc2)c1', 'Cc1ccc(C2=CSC3=NC4=C(CNC/C4=C/c4ccc(Br)cc4)C(c4ccc(Br)cc4)N23)cc1', 'O=C1c2ccccc2S(=O)(=O)N1CCCCCNCc1ccccc1', 'COC(=O)C1=C(C)Nc2nc3c(c(N)c2C1c1cccc([N+](=O)[O-])c1)CCC(C)C3', 'COc1cccc2c1C=[N+](c1ccc(Cl)cc1Cl)CC2.[Br-]', 'COc1ccc([N+]2=Cc3c(cccc3OC)CC2)cc1.[Br-]', 'COc1cccc2c1C=[N+](c1ccccc1I)CC2.[Br-]', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccc(Cl)cc3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3cccc(F)c3)CC1)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3cccc(F)n3)CC1)C2', 'COC(=O)C1=C(C)Nc2nc3c(c(N)c2C1c1cccc([N+](=O)[O-])c1)CSC3', 'Cc1ccc(/C=C2\\\\CN(Cc3ccc4ccccc4c3)C/C(=C\\\\c3ccc(C)cc3)C2=O)cc1', 'Clc1ccc(/C=C2/CNCC3=C2N=C2SC=C(c4ccc5ccccc5c4)N2C3c2ccc(Cl)cc2)cc1', 'O=C(COc1ccccc1)N1CCN(C2CCN(Cc3ccccc3)CC2)CC1', 'C#CCN(Cc1ccc2cccc(O)c2n1)CC1CCN(Cc2ccccc2)CC1', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3Cl)CC1)C2', 'CCOC(=O)C1=C(C)Nc2nc3c(c(N)c2C1c1cccc(Cl)c1)CC(C)(C)CC3', 'COc1cccc2c1C=[N+](c1ccc(I)cc1)CC2.[Br-]', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccc4cccc(O)c4n3)CC1)C2', 'COc1ccc(/C=C/C(=O)Nc2ccc(CN(C)Cc3ccccc3)cc2)c(OC)c1', 'COc1ccc2nc(NCCc3cc[n+](Cc4ccc(F)cc4)cc3)sc2c1', 'COC(=O)C1=C(C)Nc2nc3c(c(N)c2C1c1ccccc1)CSCC3', 'CC1=C(C(=O)OC(C)C)C(c2cccc(Cl)c2)c2c(nc3c(c2N)CC(C)(C)CC3)N1', 'CC1=C(C(=O)OC(C)C)C(c2ccccc2F)c2c(nc3c(c2N)CC(C)(C)CC3)N1', 'COC(=O)C1=C(C)Nc2nc3c(c(N)c2C1c1cccc([N+](=O)[O-])c1)CCCC3Cl', 'COc1cccc2c1C=[N+](c1ccccc1F)CC2.[Br-]', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccccc3F)CC1)C2', 'CCOC(=O)C1=C(C)Nc2nc3c(c(N)c2C1c1cccc([N+](=O)[O-])c1)CC(C)(C)CC3', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3cccc(Cl)n3)CC1)C2', 'Cc1ccc(C2=CSC3=NC4=C(CNC/C4=C/c4ccc(Cl)cc4)C(c4ccc(Cl)cc4)N23)cc1', 'COc1cc(/C=C/C(=O)Nc2cccc(CN(C)Cc3ccccc3)c2)ccc1O', 'CCOC(=O)C1=C(C)Nc2nc3c(c(N)c2C1c1ccc(C(F)(F)F)cc1)CC(C)CC3', 'COc1ccc(/C=C/C(=O)c2cccc(OC(=O)N(C)C)c2)cc1', 'Brc1ccc(/C=C2/CNCC3=C2N=C2SC=C(c4ccc5ccccc5c4)N2C3c2ccc(Br)cc2)cc1', 'CN(Cc1ccccc1)Cc1ccc(NC(=O)/C=C/c2cccc(O)c2)cc1', 'CCOC(=O)C1=C(C)Nc2nc3c(c(N)c2C1c1cccc([N+](=O)[O-])c1)CC(Cl)(Cl)CC3', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccc(O)c4ncccc34)CC1)C2', 'CC(C)Cc1ccc(/C=C2\\\\Oc3ccccc3C2=O)cc1', 'Fc1ccc(C[n+]2ccc(CCNc3nc4ccc(F)cc4s3)cc2)cc1', 'O=C1/C(=C/c2ccccc2)CN(Cc2ccc3ccccc3c2)C/C1=C\\\\c1ccccc1', 'S=C1/C(=C/c2ccccc2)Oc2ccccc21', 'COc1cccc2c1C=[N+](c1ccc(C)cc1)CC2.[Br-]', 'Brc1ccc(/C=C2/CNCC3=C2N=C2SC=C(c4ccccc4)N2C3c2ccc(Br)cc2)cc1', 'CCOC(=O)C1=C(C)Nc2nc3c(c(N)c2C1c1cccc(C(F)(F)F)c1)CC(C)(C)CC3', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3cccc(Cl)c3)CC1)C2', 'C=CCOC(=O)C1=C(C)Nc2nc3c(c(N)c2C1c1cccc([N+](=O)[O-])c1)CC(C)(C)CC3', 'C#CCN(CCCC1CCN(Cc2ccccc2)CC1)Cc1ccc2cccc(O)c2n1', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3cccc(C(F)(F)F)c3)CC1)C2', 'CCN1CCN(C2CCN(C(=O)COc3ccc(-c4ccccc4)cc3)CC2)CC1', 'CCN1CCN(C2CCN(C(=O)COc3ccc(-c4ccccc4)cc3)CC2)CC1', 'CC1=C(C(=O)OC2CCC2)C(c2ccccc2F)c2c(nc3c(c2N)CC(C)(C)CC3)N1', 'O=C(/C=C/c1ccc(O)cc1O)NCCC1CCN(Cc2ccccc2)CC1', 'CCOC(=O)C1=C(C)Nc2nc3c(c(N)c2C1c1cccc(F)c1)CC(C)(C)CC3', 'COc1cccc2c1C=[N+](c1ccccc1)CC2.[Br-]', 'O=C1NCCCc2c1c1ccccc1n2CCc1ccccc1', 'C#CCN(Cc1ccc2cccc(O)c2n1)C(C#N)CC1CCN(Cc2ccccc2)CC1', 'CCOC(=O)C1=C(C)Nc2nc3c(c(N)c2C1c1cccc([N+](=O)[O-])c1)CC(F)(F)CC3', 'Cc1ccc(/C=C2/CNCC3=C2N=C2SC=C(c4ccc(Br)cc4)N2C3c2ccc(C)cc2)cc1', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3cccc(Br)n3)CC1)C2', 'COc1cccc2c1C=[N+](c1cccc(C)c1)CC2.[Br-]', 'Cc1cccc(CN2C/C(=C\\\\c3ccccc3)C(=O)/C(=C/c3ccccc3)C2)c1', 'COc1ccc(/C=C/C(=O)Nc2ccc(CN(C)Cc3ccccc3)cc2)cc1', 'COc1ccc(/C=C/C(=O)Nc2ccc(CN(C)Cc3ccccc3)cc2)cc1', 'COc1cccc2c1C=[N+](c1ccc(Br)cc1F)CC2.[Br-]', 'COc1ccc(CN2CCCCC2COc2ccc(C(=O)/C=N\\\\O)cn2)cc1OC', 'COc1cccc2c1C=[N+](c1c(F)cccc1F)CC2.[Br-]', 'C#CCOC(=O)C1=C(C)Nc2nc3c(c(N)c2C1c1cccc([N+](=O)[O-])c1)CC(C)(C)CC3', 'COCCOC(=O)C1=C(C)Nc2nc3c(c(N)c2C1c1ccccc1Cl)CC(C)(C)CC3', 'COc1cccc2c1C=[N+](c1ccc(Br)cc1Br)CC2.[Br-]', 'O=C1/C(=C/c2ccc(Br)cc2)CN(Cc2ccc3ccccc3c2)C/C1=C\\\\c1ccc(Br)cc1', 'CC1=C(C(=O)OCC2CC2)C(c2ccccc2Cl)c2c(nc3c(c2N)CC(C)(C)CC3)N1', 'Cc1ccc(/C=C2\\\\CN(Cc3cccc(C)c3)C/C(=C\\\\c3ccc(C)cc3)C2=O)cc1', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3ccc(F)cc3)CC1)C2', 'CC1=C(C(=O)OC(C)C)C(c2cccc(F)c2)c2c(nc3c(c2N)CC(C)(C)CC3)N1', 'COC(=O)C1=C(C)Nc2nc3c(c(N)c2C1c1ccccc1)CC(C)(C)CC3', 'COc1cccc2c1C=[N+](c1ccc(Br)cc1)CC2.[Br-]', 'COC(=O)C1=C(C)Nc2nc3c(c(N)c2C1c1cccc([N+](=O)[O-])c1)CC(C)(C)CC3', 'COc1ccc(CN(CC(=O)NCc2ccccc2)C(=O)CCCCCn2cc[n+](C)c2/C=N\\\\O)cc1.[I-]', 'COc1ccc(CN(CC(=O)NCc2ccccc2)C(=O)CCCCCn2cc[n+](C)c2/C=N\\\\O)cc1.[I-]', 'COc1ccc(CN(CC(=O)NCc2ccccc2)C(=O)CCCCCn2cc[n+](C)c2/C=N\\\\O)cc1.[I-]', 'COc1ccc(CN(CC(=O)NCc2ccccc2)C(=O)CCCCCn2cc[n+](C)c2/C=N\\\\O)cc1.[I-]', 'CCN(CC)CCCCCCCCOc1ccc(/C=C/C(=O)O)cc1OC', 'CCOC(=O)[C@@H](CCC(=O)NCCC1CCN(Cc2ccccc2)CC1)NC(=O)c1ccccc1', 'COc1cc2c(cc1OC)C(=O)/C(=C/c1ccc(CN3CCOCC3)c(O)c1)O2', 'COc1cc2c(cc1OC)C(=O)C(Cc1cc[n+](Cc3ccccc3)cc1C(C)=O)C2.[Br-]', 'COc1ccc(CCNc2nc(NC(C)=O)nc3ccccc23)cc1OC', 'O=C(CCCC1CCSS1)NCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'COc1ccc(CNc2nc(NC(N)=O)nc3ccccc23)cc1OC', 'N#CC1=C(N)N(Cc2ccccc2)C(NCc2ccccc2)=C([N+](=O)[O-])C12c1ccccc1-c1nc3ccc([N+](=O)[O-])cc3nc12', 'CN1CC2C(=O)N(Cc3ccccc3)C(=O)C2C12C(=O)c1ccccc1C2=O', 'CCN(CC)c1ccc(/C=C/c2ccc3ccccc3[n+]2C)c(O)c1.[I-]', 'COc1cc2c(cc1OC)C(=O)C(CC1C=CN(Cc3ccccc3C)C=C1C(C)=O)C2', 'CC(=O)Nc1nc(NCc2ccccc2)c2ccccc2n1', 'CCNc1nc(NCCc2ccccc2)c2ccccc2n1', 'Cc1cc2nc3c(nc2cc1C)C1(C(C#N)=C(N)N2CCNC2=C1[N+](=O)[O-])c1ccccc1-3', 'CCOC(=O)/C=C/c1ccc(OCCCCCCN2CCCC2)c(OC)c1', 'COc1ccc(NCc2ccc3c(c2)C(=O)C(=O)N3C(=O)c2ccccc2)cc1', 'COc1cc(/C=C/C(=O)Nc2ccccc2)ccc1OCCCCCCN(C)C', 'COc1cc2c(cc1OC)C(=O)/C(=C/c1cc[n+](Cc3ccccc3Br)cc1)C2.[Br-]', 'C[n+]1c2ccccc2c(N)c2ccccc21.F[B-](F)(F)F', 'COc1cc(/C=C/C(=O)Nc2ccccc2)ccc1OCCCCN1CCCC1', 'CN1CCN(Cc2ccc3c(c2)C(=O)C(=O)N3C(=O)c2ccccc2)CC1', 'COc1cc2c(cc1OC)CN(CC1CCN(Cc3cc(F)cc(/C=N/O)c3O)CC1)CC2', 'O=C(CC[C@@H](NC(=O)c1ccccc1)C(=O)O)NCCC1CCN(Cc2ccccc2)CC1', 'CNc1nc(NCCc2ccccc2)c2ccccc2n1', 'CCN(CC)CCOc1ccc(/C=C/C(=O)Nc2ccccc2)cc1OC', 'CC1(C)CNC2=C([N+](=O)[O-])C3(C(C#N)=C(N)N2C1)c1ccccc1-c1nc2ccccc2nc13', 'CN1c2ccccc2C(N2CCSCC2)c2ccccc21', 'CN1c2ccccc2C(N2CCSCC2)c2ccccc21', 'COc1cc(/C=C/C(=O)Nc2ccccc2)ccc1OCCCN(C)C', 'Oc1cc(O)cc(CCc2ccc(Nc3c4c(nc5cc(Cl)ccc35)CCCC4)cc2)c1', 'CCO[P@](=O)(SCC)c1ccccc1', 'CCO[P@](=O)(SCC)c1ccccc1', 'CCN(CC)c1ccc(/C=C/c2ccc3ccccc3[n+]2C)cc1.[I-]', 'COc1cc2c(cc1OC)C(=O)C(Cc1cc[n+](Cc3ccccc3Cl)cc1C(C)=O)C2.[Br-]', 'COc1ccccc1N1C(=O)C2CN(C)C3(C(=O)c4ccccc4C3=O)C2C1=O', 'CCN(CCCN1C(=O)c2ccccc2C1=O)Cc1ccccc1OC', 'CCOC(=O)CC[C@H](NC(=O)OCc1ccccc1)C(=O)NCCC1CCN(Cc2ccccc2)CC1', 'c1ccc(CNc2nc(NC3CC3)nc3ccccc23)cc1', 'Nc1c2c(nc3c1C(c1ccccc1)c1ccc4cccnc4c1O3)CCCC2', 'CCN(CC)CCCCCOc1ccc(/C=C/C(=O)Nc2ccccc2)cc1OC', 'C[n+]1c(/C=C/c2cc3ccccc3[nH]2)cc(N2CCOCC2)c2ccccc21.[I-]', 'COC(=O)c1c[n+](Cc2ccccc2)ccc1CC1Cc2cc(OC)c(OC)cc2C1=O.[Br-]', 'COc1cc(/C=C/C(=O)Nc2ccccc2)ccc1OCCCN1CCCCC1', 'CC(C)c1ccc(NC(=O)Oc2ccc3c(c2)[C@]2(C)CCC(C)[C@@H]2C3C)cc1', 'COc1ccc(CN(CC(=O)NC(C)C)C(=O)CCCCCn2cc[n+](C)c2/C=N\\\\O)cc1.[I-]', 'COc1ccc(CN(CC(=O)NC(C)C)C(=O)CCCCCn2cc[n+](C)c2/C=N\\\\O)cc1.[I-]', 'COc1ccc(CN(CC(=O)NC(C)C)C(=O)CCCCCn2cc[n+](C)c2/C=N\\\\O)cc1.[I-]', 'CCN(CC)Cc1ccc(NC(=O)c2ccccc2)c(C(=O)C(=O)N(CC)CC)c1', 'CCN(CCCCCCNC(=O)COc1ccc(-c2cc(=O)c3c(OC)c(OC)c(OC)cc3o2)cc1)Cc1ccccc1OC', 'CCc1ccc(N2C(=O)C3CN(C)C4(C(=O)c5ccccc5C4=O)C3C2=O)cc1', 'COc1cc2c(cc1OC)C(=O)/C(=C/c1ccc(O)c(CN(C)C)c1)O2', 'COc1cc(/C=C/C(=O)Nc2ccccc2)ccc1OCCCCN1CCCCC1', 'NC(=O)Cc1nc(NCCc2ccccc2)c2ccccc2n1', 'Cc1ccc(-c2c3ccccc3[n+](C)c3ccccc23)cc1.F[B-](F)(F)F', 'CCN(CCCCN1C(=O)c2ccccc2C1=O)Cc1ccccc1OC', 'CC(=O)Nc1ccc(-c2c3ccccc3[n+](C)c3ccccc23)cc1.F[B-](F)(F)F', 'C[n+]1c2ccccc2c(-c2cccs2)c2ccccc21.F[B-](F)(F)F', 'CN1CCN(c2ccc(/C=C/c3ccc4ccccc4[n+]3C)cc2)CC1.[I-]', 'COc1ccc(CNc2c3c(nc4cc(Cl)ccc24)CCCC3)cc1OC', 'NC(=O)Nc1nc(NCCc2ccccc2)c2ccccc2n1', 'CC(C)Nc1nc(NCCc2ccccc2)c2ccccc2n1', 'COc1cc2c(cc1OC)C(=O)/C(=C/c1cc[n+](Cc3ccc([N+](=O)[O-])cc3)cc1)C2.[Br-]', 'N#CC1=C(N)N2CCCNC2=C([N+](=O)[O-])C12c1ccccc1-c1nc3ccccc3nc12', 'Cc1cc(-c2c3ccccc3[n+](C)c3ccccc23)cc(C)c1C.F[B-](F)(F)F', 'COc1cc2c(cc1OC)C(=O)C(Cc1cc[n+](Cc3ccccc3)cc1C#N)C2.[Br-]', 'CN1CC2C(=O)N(c3ccc(F)cc3)C(=O)C2C12C(=O)c1ccccc1C2=O', 'COc1cc(/C=C/C(=O)Nc2ccccc2)ccc1OCCCCCCN1CCCC1', 'CCOC(=O)/C=C/c1ccc(OCCCCCCN(CC)CC)c(OC)c1', 'CSP(C)(=O)OC1CCCCC1', 'COc1ccc2nc3c(c(NCCCCCCCNC(=S)NC45CC6CC(CC(C6)C4)C5)c2c1)CCCC3', 'COc1ccc(N2C(=O)C3CN(C)C4(C(=O)c5ccccc5C4=O)C3C2=O)cc1', 'CCN(Cc1ccc(/C=C2\\\\Oc3cc(OC)c(OC)cc3C2=O)cc1O)Cc1ccccc1N(C)C', 'CC(=O)c1c[n+](Cc2ccccc2C)ccc1CC1Cc2cc(C)ccc2C1=O.[Br-]', 'NC(=O)Cc1nc(NCc2ccccc2)c2ccccc2n1', 'COc1ccc2cc(C(=O)N[C@@H](CCC(=O)NCCC3CCN(Cc4ccccc4)CC3)C(=O)O)ccc2c1', 'COc1cc2c(cc1OC)C(=O)/C(=C/c1cc[n+](Cc3ccc(F)cc3)cc1)C2.[Br-]', 'COc1ccccc1NC(=S)NCCN1CCCCC1.Cl', 'CC1(C)CNC2=C([N+](=O)[O-])C3(C(C#N)=C(N)N2C1)c1ccccc1-c1nc2ccc([N+](=O)[O-])cc2nc13', 'CC(=O)c1c[n+](Cc2ccccc2C)ccc1CC1Cc2cc(C)c(C)cc2C1=O.[Br-]', 'COc1cc(/C=C/C(=O)Nc2ccccc2)ccc1OCCCCCCCCCCN1CCCCC1', 'N#CC1=C(N)N(Cc2ccccc2)C(NCc2ccccc2)=C([N+](=O)[O-])C12c1ccccc1-c1nc3ccccc3nc12', 'Cc1ccc2c(c1)C(=O)C(=O)N2Cc1ccccc1[N+](=O)[O-]', 'COc1cc(/C=C/C(=O)O)ccc1OCCCCCCN1CCCCC1', 'Clc1ccc2c(NCc3ccccn3)c3c(nc2c1)CCCC3', 'COc1ccc(NC(=S)NCCN(C)C)cc1Cl', 'CCN(CC)Cc1ccc(/C=C2\\\\Oc3cc(OC)c(OC)cc3C2=O)cc1O', 'CN1c2ccccc2C(n2cnc([N+](=O)[O-])n2)c2ccccc21', 'C#CCN(CCCN1C(=O)c2ccccc2C1=O)Cc1ccccc1', 'CN1c2ccccc2C(n2cncn2)c2ccccc21', 'CN1c2ccccc2C(n2cncn2)c2ccccc21', 'COc1ccc(CNc2c3c(nc4ccccc24)CCCC3)cc1OC', 'CCCCCCOC(=O)[C@H](CCC(=O)NCCC1CCN(Cc2ccccc2)CC1)NC(=O)c1c[nH]c2ccccc12', 'COc1cc2c(cc1OC)C(=O)/C(=C/c1cc[n+](Cc3ccccc3F)cc1)C2.[Br-]', 'COc1cc2c(cc1OC)C(=O)C(Cc1cc[n+](Cc3ccccc3C)cc1C(N)=O)C2.[Br-]', 'COc1cc2c(cc1OC)C(=O)/C(=C/c1cc[n+](Cc3ccc(C)cc3)cc1)C2.[Br-]', 'CCNc1nc(NCc2ccc(OC)c(OC)c2)c2ccccc2n1', 'O=C(Nc1ccc(CN2CCOCC2)cc1C(=O)C(=O)N1C(=O)CCC1=O)c1ccccc1', 'CN1c2ccccc2C(N2CCOCC2)c2ccccc21', 'CN1c2ccccc2C(N2CCOCC2)c2ccccc21', 'COc1cc2c(cc1OC)CN(CC1CCN(Cc3cc(Br)cc(/C=N/O)c3O)CC1)CC2', 'COC(=O)c1cc2c(OC(=O)N(C)C)cccc2[n+](C)c1', 'C[n+]1c2ccccc2c(-c2ccc(F)cc2)c2ccccc21.F[B-](F)(F)F', 'O=C(CC[C@H](NC(=O)c1ccccc1)C(=O)O)NCCC1CCN(Cc2ccccc2)CC1', 'CCNc1nc(NCCc2ccc(OC)c(OC)c2)c2ccccc2n1', 'CCN(CC)CCCOc1ccc(/C=C/C(=O)Nc2ccccc2)cc1OC', 'NC(=O)c1cc[n+](COC[n+]2ccc(/C=N/O)cc2)cc1.[Cl-].[Cl-]', 'NC(=O)c1cc[n+](COC[n+]2ccc(/C=N/O)cc2)cc1.[Cl-].[Cl-]', 'NC(=O)c1cc[n+](COC[n+]2ccc(/C=N/O)cc2)cc1.[Cl-].[Cl-]', 'CCNc1nc(NCc2ccccc2)c2ccccc2n1', 'CCCCCCOC(=O)[C@@H](CCC(=O)NCCC1CCN(Cc2ccccc2)CC1)NC(=O)c1ccccc1', 'CN1CC2C(=O)N(c3ccccc3)C(=O)C2C12C(=O)c1ccccc1C2=O', 'NS(=O)(=O)c1ccc(NC(=S)NCCN2CCCCC2)cc1', 'COc1cc(/C=C/C(=O)Nc2ccccc2)ccc1OCCCCCCN1CCCCC1', 'COc1cc(/C=C/C(=O)Nc2ccccc2)ccc1OCCCCCCN1CCCCC1', 'COc1cc(/C=C/C(=O)Nc2ccccc2)ccc1OCCCCCCN1CCCCC1', 'CN1CC2C(=O)N(c3cccc(F)c3)C(=O)C2C12C(=O)c1ccccc1C2=O', 'CCN(CC)c1ccc(/C=C/c2ccc3ccccc3[n+]2C)c(Cl)c1.[I-]', 'CCOC(=O)[C@H](CCC(=O)NCCC1CCN(Cc2ccccc2)CC1)NC(=O)c1ccc2cc(OC)ccc2c1', 'CCN(CC)c1ccc(-c2c3ccccc3[n+](C)c3ccccc23)cc1.F[B-](F)(F)F', 'CCN(CC)c1ccc(-c2c3ccccc3[n+](C)c3ccccc23)cc1.F[B-](F)(F)F', 'NC(=O)Nc1nc(NCc2ccccc2)c2ccccc2n1', 'CCCCN(CC(=O)NCc1ccccc1)C(=O)CCCCCn1cc[n+](C)c1/C=N\\\\O.[I-]', 'CCCCN(CC(=O)NCc1ccccc1)C(=O)CCCCCn1cc[n+](C)c1/C=N\\\\O.[I-]', 'CCOC(=O)[C@H](CCC(=O)NCCC1CCN(Cc2ccccc2)CC1)NC(=O)c1c[nH]c2ccccc12', 'Oc1cc(O)cc(/C=C/c2ccc(Nc3c4c(nc5cc(Cl)ccc35)CCCC4)cc2)c1', 'COc1cc2c(cc1OC)C(=O)/C(=C/c1ccc(CN3CCN(C)CC3)c(O)c1)O2', 'COc1cc2c(cc1OC)C(=O)C(Cc1cc[n+](Cc3ccccc3C)cc1C(C)=O)C2.[Br-]', 'COc1cc2c(cc1OC)C(=O)/C(=C/c1cc[n+](Cc3cccc(Br)c3)cc1)C2.[Br-]', 'COc1cc(/C=C/C(=O)Nc2ccccc2)ccc1OCCCCCCCCCCN1CCCC1', 'CCOc1ccc(Cc2nc3cc(C(=O)N(CC)CC)ccc3n2CCCCCCN2CCCCC2)cc1', 'CCOc1ccc(Cc2nc3cc(C(=O)N(CC)CC)ccc3n2CCCCCCN2CCCCC2)cc1', 'O=C1C(=O)N(Cc2ccccc2[N+](=O)[O-])c2ccc(Br)cc21', 'COc1cc2c(cc1OC)C(=O)/C(=C/c1cc[n+](Cc3ccc(Br)cc3)cc1)C2.[Br-]', 'COc1cc(CCc2ccc(Nc3c4c(nc5cc(Cl)ccc35)CCCC4)cc2)cc(OC)c1', 'CCCNc1nc(NCc2ccc(OC)c(OC)c2)c2ccccc2n1', 'CCCNc1nc(NCCc2ccccc2)c2ccccc2n1', 'N#CC1=C(N)N2CCNC2=C([N+](=O)[O-])C12c1ccccc1-c1nc3ccc([N+](=O)[O-])cc3nc12', 'CC(=O)c1c[n+](Cc2ccccc2C)ccc1CC1Cc2cc3c(cc2C1=O)OCO3.[Br-]', 'COc1cc(/C=C/C(=O)Nc2ccccc2)ccc1OCCCCCCCCN(C)C', 'COc1cc2c(cc1OC)C(=O)/C(=C/c1cc[n+](Cc3cccc(C)c3)cc1)C2.[Br-]', 'CC(=O)Nc1nc(NCCc2ccccc2)c2ccccc2n1', 'COc1cc(/C=C/C(=O)N2CCC(Cc3ccccc3)CC2)ccc1OCCCCN1CCc2ccccc2C1', 'COc1cc(/C=C/C(=O)Nc2ccccc2)ccc1OCCCN1CCCC1', 'O=C1C(=O)N(C(=O)c2ccccc2)c2ccc(CN3CCCCC3)cc21', 'CCOc1ccc(Cc2nc3cc(C(=O)N(CC)CC)ccc3n2CCCCN2CCCCC2)cc1', 'CCOc1ccc(Cc2nc3cc(C(=O)N(CC)CC)ccc3n2CCCCN2CCCCC2)cc1', 'COc1cc(/C=N/O)c(O)c(CN2CCC(CN3CCc4cc(OC)c(OC)cc4C3)CC2)c1', 'COc1ccc(C2c3ccc4cccnc4c3Oc3nc4c(c(N)c32)CCCC4)cc1', 'O=C(CC[C@H](NC(=O)c1c[nH]c2ccccc12)C(=O)O)NCCC1CCN(Cc2ccccc2)CC1', 'COc1ccc(CCNc2nc(NC3CC3)nc3ccccc23)cc1OC', 'COc1cc(/C=C/C(=O)Nc2ccccc2)ccc1OCCCCCCCCCCN(C)C', 'COc1cc(/C=C/c2cc(N3CCN(C)CC3)c3ccccc3[n+]2C)ccc1N1CCN(C)CC1.[I-]', 'CCN(CC)CCCCCCCCCCOc1ccc(/C=C/C(=O)Nc2ccccc2)cc1OC', 'CCOC(=O)/C=C/c1ccc(OCCCCCCCCN(CC)CC)c(OC)c1', 'CN1C(=O)C2CN(C)C3(C(=O)c4ccccc4C3=O)C2C1=O', 'Cc1cc(-c2c3ccccc3[n+](C)c3ccccc23)cc(C)c1O.F[B-](F)(F)F', 'CN1c2ccccc2C(n2nnc3ccccc32)c2ccccc21', 'CN1c2ccccc2C(n2nnc3ccccc32)c2ccccc21', 'CN1CC2C(=O)N(C3CCCCC3)C(=O)C2C12C(=O)c1ccccc1C2=O', 'CC(C)c1ccc(NC(=O)Oc2ccc3c(c2)[C@]2(C)CCN[C@@H]2N3)cc1', 'CC(C)c1ccc(NC(=O)Oc2ccc3c(c2)[C@]2(C)CCN[C@@H]2N3)cc1', 'CCN(CCCCCCN1C(=O)c2ccccc2C1=O)Cc1ccccc1OC', 'COc1cc2c(cc1OC)CN(CC1CCN(Cc3cc(C)cc(/C=N/O)c3O)CC1)CC2', 'COc1cc2c(cc1OC)CN(CC1CCN(Cc3cc(C)cc(/C=N/O)c3O)CC1)CC2', 'COc1cc2c(cc1OC)CN(CC1CCN(Cc3cc(C)cc(/C=N/O)c3O)CC1)CC2', 'Cc1ccc(N2C(=O)C3CN(C)C4(C(=O)c5ccccc5C4=O)C3C2=O)cc1', 'COc1cc(/C=C/C(=O)Nc2ccccc2)ccc1OCCCCCN1CCCCC1', 'C[n+]1c2ccccc2c(-c2ccccc2)c2ccccc21.F[B-](F)(F)F', 'COc1cc(/C=C/C(=O)O)ccc1OCCCCCCN1CCCC1', 'COc1cc2c(cc1OC)C(=O)/C(=C/c1ccc(CN(C)C)c(O)c1)O2', 'O=C1C(=O)N(C(=O)c2ccccc2)c2ccc(CNc3ccc(Br)cc3)cc21', 'Clc1ccc(CNC2CCN(Cc3ccccc3)CC2)c(Cl)c1', 'COc1ccc(CNc2nc(NC(C)=O)nc3ccccc23)cc1OC', 'c1ccc(CCNc2nc(NC3CC3)nc3ccccc23)cc1', 'Cc1cc2nc3c(nc2cc1C)C1(C(C#N)=C(N)N2CCCNC2=C1[N+](=O)[O-])c1ccccc1-3', 'CCN(CCCCN1C(=O)c2ccccc2C1=O)Cc1ccccc1', 'COc1ccc(CCNc2c3c(nc4cc(Cl)ccc24)CCCC3)cc1OC', 'COc1cc2c(cc1OC)C(=O)C(Cc1cc[n+](Cc3cccc(Cl)c3)cc1C(N)=O)C2.[Br-]', 'COc1ccc(NC(=S)NCCN2CCOCC2)cc1Cl', 'CCN(CCCCCCNC(=O)COc1ccc(-c2cc(=O)c3c(O)c(OC)c(OC)cc3o2)cc1)Cc1ccccc1OC', 'N#CC1=C(N)N2CCCNC2=C([N+](=O)[O-])C12c1ccccc1-c1nc3ccc([N+](=O)[O-])cc3nc12', 'COc1cc(/C=C/C(=O)Nc2ccccc2)ccc1OCCCCCN1CCCC1', 'COc1cc(/C=C/C(=O)Nc2ccccc2)ccc1OCCN(C)C', 'COc1cc(CCc2ccc(Nc3c4c(nc5ccccc35)CCCC4)cc2)cc(OC)c1', 'CN1CCN(c2ccc(/C=C/c3cc(N4CCN(C)CC4)c4ccccc4[n+]3C)cc2)CC1.[I-]', 'CC(C)c1ccc(N2C(=O)C3CN(C)C4(C(=O)c5ccccc5C4=O)C3C2=O)cc1', 'COc1cc(/C=C/c2ccc3ccccc3[n+]2C)ccc1N1CCN(C)CC1.[I-]', 'CCOC(=O)[C@H](CCC(=O)NCCC1CCN(Cc2ccccc2)CC1)NC(=O)c1ccccc1', 'COc1cc2c(cc1OC)C(=O)C(Cc1cc[n+](Cc3cccc(C)c3)cc1C(C)=O)C2.[Br-]', 'COc1ccc2c(c1)CC(Cc1cc[n+](Cc3ccccc3C)cc1C(C)=O)C2=O.[Br-]', 'CCOC(=O)/C=C/c1ccc(OCCCCCCN2CCCCC2)c(OC)c1', 'COc1cc2c(cc1OC)C(=O)/C(=C/c1ccc(CN3CCCC3)c(O)c1)O2', 'CNc1nc(NCCc2ccc(OC)c(OC)c2)c2ccccc2n1', 'CCN(CC)CCCCCCOc1ccc(/C=C/C(=O)Nc2ccccc2)cc1OC', 'Cc1cc2nc3c(nc2cc1C)C1(C(C#N)=C(N)N(Cc2ccccc2)C(NCc2ccccc2)=C1[N+](=O)[O-])c1ccccc1-3', 'COc1cc2c(cc1OC)C(=O)/C(=C/c1cc[n+](Cc3cccc(F)c3)cc1)C2.[Br-]', 'CCn1c2ccccc2c2cc(/C=C/c3cc(N4CCOCC4)c4ccccc4[n+]3C)ccc21.[I-]', 'COc1ccc(CCNc2nc(NC(C)C)nc3ccccc23)cc1OC', 'COC(=O)c1c[n+](Cc2ccccc2C)ccc1CC1Cc2cc(OC)c(OC)cc2C1=O.[Br-]', 'COc1cc(/C=C/C(=O)Nc2ccccc2)ccc1OCCN1CCCCC1', 'CC1CC[C@@]2(C)c3cc(OC(=O)Nc4ccccc4)ccc3C(C)[C@@H]12', 'COc1cccc(C2c3ccc4cccnc4c3Oc3nc4c(c(N)c32)CCCC4)c1', 'COc1cccc(C2c3ccc4cccnc4c3Oc3nc4c(c(N)c32)CCCC4)c1', 'COc1ccc(-c2c3ccccc3[n+](C)c3ccccc23)cc1.F[B-](F)(F)F', 'COc1ccc(CCNc2nc(CC(N)=O)nc3ccccc23)cc1OC', 'CCN(CC)c1ccc(/C=C/c2ccc3ccccc3[n+]2C)c(OC)n1.[I-]', 'CCN(CCCCCCN1C(=O)c2ccccc2C1=O)Cc1ccccc1', 'C[n+]1c2ccccc2c(-c2ccc(NC(=O)C(F)(F)F)cc2)c2ccccc21.F[B-](F)(F)F', 'CCN(CC)c1ccc(/C=C/c2ccc3ccccc3[n+]2C)c(OC)c1.[I-]', 'COc1ccc(CNc2nc(NC3CC3)nc3ccccc23)cc1OC', 'CN1CC2C(=O)N(c3ccc(Br)cc3)C(=O)C2C12C(=O)c1ccccc1C2=O', 'COc1cc(/C=C/C(=O)Nc2ccccc2)ccc1OCCCCCCCCN1CCCCC1', 'CCN1CCN(Cc2ccc(/C=C3\\\\Oc4cc(OC)c(OC)cc4C3=O)cc2O)CC1', 'COc1cc2c(cc1OC)C(=O)C(Cc1cc[n+](Cc3ccccc3)cc1)C2.[Br-]', 'CNc1nc(NCc2ccc(OC)c(OC)c2)c2ccccc2n1', 'CCN(CCCCNC(=O)COc1ccc(-c2cc(=O)c3c(OC)c(OC)c(OC)cc3o2)cc1)Cc1ccccc1OC', 'COc1cc2c(cc1OC)C(=O)/C(=C/c1cc[n+](Cc3ccccc3)cc1)C2.[Br-]', 'CN1CC2C(=O)N(c3ccc(Cl)cc3)C(=O)C2C12C(=O)c1ccccc1C2=O', 'COc1ccc(CCNc2nc(NC(N)=O)nc3ccccc23)cc1OC', 'CCN(CC)CCCCCCOc1ccc(/C=C/C(=O)O)cc1OC', 'COc1cc2c(cc1OC)C(=O)/C(=C/c1cc[n+](Cc3ccccc3C)cc1)C2.[Br-]', 'N#CC1=C(N)N2CCNC2=C([N+](=O)[O-])C12c1ccccc1-c1nc3ccccc3nc12', 'COc1ccc(CNc2nc(NC(C)C)nc3ccccc23)cc1OC', 'CC(=O)c1c[n+](Cc2ccccc2C)ccc1CC1Cc2cc(Cl)ccc2C1=O.[Br-]', 'COc1ccc(CNc2nc(CC(N)=O)nc3ccccc23)cc1OC', 'CCN(CCCCNC(=O)COc1ccc(-c2cc(=O)c3c(O)c(OC)c(OC)cc3o2)cc1)Cc1ccccc1OC', 'Cc1cc2nc3c(nc2cc1C)C1(C(C#N)=C(N)N2CC(C)(C)CNC2=C1[N+](=O)[O-])c1ccccc1-3', 'Cc1ccc2c(c1)C(=O)C(=O)N2C(=O)N(C)C', 'COc1cc(/C=C/C(=O)Nc2ccccc2)ccc1OCCCCCCCCN1CCCC1', 'COc1cc2c(cc1OC)C(=O)/C(=C/c1ccc(CN3CCCCC3)c(O)c1)O2', 'O=C1C(=O)N(Cc2ccc(Br)cc2)c2ccc(Br)cc21', 'COc1cc2c(cc1OC)C(=O)/C(=C/c1cc[n+](Cc3cccc([N+](=O)[O-])c3)cc1)C2.[Br-]', 'COc1cc2c(cc1OC)C(=O)C(CC1C=CN(Cc3cccc(Cl)c3)C=C1C(N)=O)C2', 'COc1cc2c(cc1OC)C(=O)C(CC1C=CN(Cc3cccc(Cl)c3)C=C1C(N)=O)C2', 'COc1cc(/C=C/C(=O)Nc2ccccc2)ccc1OCCN1CCCC1', 'c1ccc(CNc2c3c(nc4ccccc24)CCCC3)nc1', 'COc1cc2c(cc1OC)CN(CC1CCN(Cc3cc(Cl)cc(/C=N/O)c3O)CC1)CC2', 'COc1cc2c(cc1OC)C(=O)C(Cc1cc[n+](Cc3cccc(Cl)c3)cc1C(C)=O)C2.[Br-]', 'COc1cc2c(cc1OC)C(=O)/C(=C/c1ccc(CN(C)Cc3ccccc3)c(O)c1)O2', 'CCOC(=O)CC[C@@H](NC(=O)OCc1ccccc1)C(=O)NCCC1CCN(Cc2ccccc2)CC1', 'CCCNc1nc(NCCc2ccc(OC)c(OC)c2)c2ccccc2n1', 'CCN(CC)CCCCOc1ccc(/C=C/C(=O)Nc2ccccc2)cc1OC', 'COc1cc(/C=C/C(=O)Nc2ccccc2)ccc1OCCCCCN(C)C', 'Cc1ccc(C2c3ccc4cccnc4c3Oc3nc4c(c(N)c32)CCCC4)cc1', 'CN1CC2C(=O)N(c3ccc([N+](=O)[O-])cc3)C(=O)C2C12C(=O)c1ccccc1C2=O', 'Nc1c2c(nc3c1C(c1cccc(F)c1)c1ccc4cccnc4c1O3)CCCC2', 'C[n+]1c(/C=C/c2ccc(Cl)cc2)ccc2ccccc21.[I-]', 'C[n+]1c2ccccc2c(-c2ccc(N)cc2)c2ccccc21.F[B-](F)(F)F', 'C[n+]1c2ccccc2c(-c2ccc(N)cc2)c2ccccc21.F[B-](F)(F)F', 'CC(=O)C1=CN(Cc2ccccc2C)C=CC1CC1Cc2cc(C)c(C)cc2C1=O', 'CCCNc1nc(NCc2ccccc2)c2ccccc2n1', 'CCN(CC)CCCCCCCCOc1ccc(/C=C/C(=O)Nc2ccccc2)cc1OC', 'CC1=C[C@H]2Cc3nc4cc(Cl)ccc4c(NCCCCCCCCCNC(=O)c4cc(O)c5c(c4)C(=O)c4cccc(O)c4C5=O)c3[C@@H](C1)C2', 'CC1=C[C@H]2Cc3nc4cc(Cl)ccc4c(N)c3[C@@H](C1)C2', 'CC1=C[C@@H]2Cc3nc4cc(Cl)ccc4c(NCCCCCCCCCNC(=O)c4cc(O)c5c(c4)C(=O)c4cccc(O)c4C5=O)c3[C@H](C1)C2', 'C=C(C)[C@H](O)CC[C@]1(C)[C@@H](CC=C(C)C)C[C@@]2(CC=C(C)C)C(=O)[C@]1(C(=O)C(C)C)C(=O)C1=C2O[C@H](C(C)(C)O)C1', 'COC(C)(C)/C=C/C[C@]1(C)[C@@H](CC=C(C)C)C[C@]2(CC=C(C)C)C(=O)C3=C(O[C@@H](C(C)(C)O)C3)[C@@]1(C(=O)C(C)C)C2=O', 'CC(C)=CCC[C@]1(C)[C@@H](CC=C(C)C)C[C@@]2(CC=C(C)C)C(=O)[C@]1(C(=O)C(C)C)C(=O)C1=C2O[C@H](C(C)(C)O)[C@H]1O', 'C=C(C)[C@@H](O)CC[C@]1(C)[C@@H](CC=C(C)C)C[C@]23C[C@@H](C(C)(C)O)OC2=C(CC=C(C)C)C(=O)[C@@]1(C(=O)C(C)C)C3=O', 'CC(C)=CC[C@H]1C[C@@]2(CC=C(C)C)C(=O)[C@](C(=O)C(C)C)(C(=O)C3=C2O[C@H](C(C)(C)O)C3)[C@]1(C)CCC(=O)C(C)C', 'C=C(C)[C@H](O)CC[C@]1(C)[C@@H](CC=C(C)C)C[C@]2(CC=C(C)C)C(=O)C3=C(O[C@H](C(C)(C)O)C3)[C@@]1(C(=O)C(C)C)C2=O', 'O=C(Cc1cc(=O)oc2cc(O)ccc12)NCCCCCCCNC(=O)c1cccc2c(=O)c3ccccc3[nH]c12', 'C=C(C)[C@@H](O)CC[C@]1(C)[C@@H](CC=C(C)C)C[C@]2(CC=C(C)C)C(=O)C3=C(O[C@H](C(C)(C)O)C3)[C@@]1(C(=O)C(C)C)C2=O', 'CC(=O)[C@@]12C(=O)C(CC=C(C)C)=C3O[C@H](C(C)(C)O)C[C@]3(C[C@H](CC=C(C)C)[C@@]1(C)CCC=C(C)C)C2=O', 'C=C(C)[C@H](O)CC[C@]1(C)[C@@H](CC=C(C)C)C[C@@]2(CC=C(C)C)C(=O)[C@]1(C(=O)C(C)C)C(=O)C1=C2O[C@@H](C(C)(C)O)C1', 'CC(C)=CCC[C@]1(C)[C@@H](CC=C(C)C)C[C@]2(CC=C(C)C)C(=O)C3=C(O[C@@H](C(C)(C)O)[C@@H]3O)[C@@]1(C(=O)C(C)C)C2=O', 'CC(C)=CCC1=C2O[C@H](C(C)(C)O)C[C@@]23C[C@H](CC=C(C)C)[C@@](C)(CCC(=O)C(C)C)[C@@](C(=O)C(C)C)(C1=O)C3=O', 'CC(C)=CCC[C@]1(C)[C@@H](CC=C(C)C)C[C@]2(CC=C(C)C)C(=O)C3=C(O[C@H](C(C)(C)O)[C@H]3O)[C@@]1(C(=O)C(C)C)C2=O', 'CC(C)=CCC[C@]1(C)[C@@H](CC=C(C)C)C[C@@]2(CC=C(C)C)C(=O)[C@]1(C(=O)C(C)C)C(=O)C1=C2O[C@@H](C(C)(C)O)[C@@H]1O', 'COC(C)(C)/C=C/C[C@]1(C)[C@@H](CC=C(C)C)C[C@]2(CC=C(C)C)C(=O)C3=C(O[C@H](C(C)(C)O)C3)[C@@]1(C(=O)C(C)C)C2=O', 'Oc1ccc(-c2oc3cc(O)c4c5c3c2-c2cc(O)cc(O)c2[C@H](c2ccc(O)cc2)[C@@H]5[C@H](c2ccc(O)cc2)[C@@H]4c2cc(O)cc(O)c2)cc1', 'COC(=O)c1ccccc1C[n+]1ccc(CC2Cc3cc(OC)c(OC)cc3C2=O)c(C(=O)Oc2c(Cl)cc(Cl)cc2Cl)c1.[Br-]', 'Cc1cc(=O)oc2cc(OCCCSC(=S)N3CCCCC3)ccc12', 'Cc1cc(=O)oc2cc(OCCSC(=S)N3CCC(N4CCCCC4)CC3)ccc12', 'COc1cc2c(cc1O)C(=O)C(Cc1cc[n+](Cc3cccc(Cl)c3)cc1C(C)=O)C2', 'Nc1c2c(nc3c1C(c1ccc(F)cc1)NC(=S)N3)CCCC2', 'COc1ccc(C(=O)CCc2cc[n+](Cc3cccc(Cl)c3)cc2C#N)cc1OC.[Br-]', 'COc1ccc2c(c1)CCC(Cc1cc[n+](Cc3cccc(F)c3)cc1C(C)=O)C2=O.[Br-]', 'CN(C)C(=O)Oc1cccc2c1cc(C(=O)NC1CCCCC1)c[n+]2C.[I-]', 'COc1ccc(C(=O)CCC2C=CN(Cc3cccc(Cl)c3)C=C2C#N)cc1OC', 'O=C(O)C(F)(F)F.O=C1C2=C(C3=NCCc4c[nH]c1c43)C1(C=CN2)C=C(Br)C(O)C(Br)=C1', 'COc1cc2c(cc1OC)C(=O)C(CC1C=CN(Cc3ccccc3)C=C1C(C)=O)CC2', 'COc1cc2c(cc1OC)C(=O)C(CC1C=CN(Cc3ccccc3)C=C1C(C)=O)CC2', 'COc1cc2c(cc1OC)C(=O)C(CC1C=CN(Cc3ccccc3)C=C1C(C)=O)CC2', 'COc1cc2c(cc1OC)C(=O)C(CC1C=CN(Cc3ccccc3)C=C1C(C)=O)CC2', 'O=C(Nc1cc(Cl)nc(Cl)c1)OCCCCCCNCc1ccccc1', 'COc1ccccc1C1NC(=S)Nc2nc3c(c(N)c21)CCCC3', 'COc1ccc2c(c1)CCC(Cc1cc[n+](Cc3ccccc3C)cc1C(C)=O)C2=O.[Br-]', 'O=C(NCCCCCCNCc1ccccc1)c1cc(Cl)nc(Cl)c1', 'COc1cc2c(cc1OC)C(=O)C(Cc1cc[n+](Cc3ccccc3)cc1C(C)=O)CC2.[Br-]', 'O=C1SCc2ccccc21', 'COc1cc2c(cc1OC)C(=O)C(Cc1cc[n+](Cc3nc4ccccc4o3)cc1C(N)=O)C2.[Br-]', 'Cc1ccc(C2NC(=S)Nc3nc4c(c(N)c32)CCCC4)cc1', 'COc1ccc(C(=O)CCc2cc[n+](Cc3cccc(F)c3)cc2C#N)cc1OC.[Br-]', 'CC1(c2nccc3cc4c(cc23)OCO4)OC(O)c2c1ccc1c2OCO1', 'CC1(c2nccc3cc4c(cc23)OCO4)OC(O)c2c1ccc1c2OCO1', 'O=C(NCCCCCCNCc1ccc2ccccc2c1)c1cc(Cl)nc(Cl)c1', 'Cc1cc(=O)oc2cc(OCCCCCCSC(=S)N3CCCCC3)ccc12', 'O=C(Nc1cc(Cl)nc(Cl)c1)OCCCCCNCc1c[nH]c2ccccc12', 'Nc1c2c(nc3c1C(c1cccc([N+](=O)[O-])c1)NC(=S)N3)CCCC2', 'O=C(Nc1cc(Cl)nc(Cl)c1)OCCCCCNCc1ccccc1', 'Cc1cc(=O)oc2cc(OCCSC(=S)N3CCCC3)ccc12', 'CNC(=O)c1cc2c(OC(=O)N(C)C)cccc2[n+](C)c1.[I-]', 'COc1ccc2c(c1)CCC(Cc1cc[n+](Cc3ccccc3C)cc1C(F)(F)F)C2=O', 'CN(C)C(=O)Oc1cccc2c1cc(C(=O)NCCOCCO)c[n+]2C.COS(=O)(=O)[O-]', 'O=C(NCCCCCCNCc1c[nH]c2ccccc12)c1cc(Cl)nc(Cl)c1', 'COc1cc2c(cc1OC)C(=O)C(Cc1cc[n+](Cc3ccccc3)cc1Br)C2.[Br-]', 'c1cc2cc3c(cc2c([C@H]2Oc4ccc5c(c4O2)OCO5)n1)OCO3', 'COc1ccc(C(=O)CCc2cc[n+](Cc3cccc(Cl)c3)cc2C(C)=O)cc1OC.[Br-]', 'COc1ccc(C(=O)CCc2cc[n+](Cc3cccc(Cl)c3)cc2C(=O)O)cc1OC.[Br-]', 'Cc1cccc(C2NC(=S)Nc3nc4c(c(N)c32)CCCC4)c1', 'CNC(=O)c1cc2c(OC(=O)N(C)C)cccc2[n+](Cc2ccccc2)c1.[Br-]', 'COc1cc2c(cc1OC)C(=O)/C(=C/C1CCN(Cc3cc(N)c4ccccc4n3)CC1)C2', 'COc1ccc2c(c1)CCC(Cc1cc[n+](Cc3ccccc3Cl)cc1C(N)=O)C2=O.[Br-]', 'COc1ccc2c(c1)CCC(Cc1cc[n+](Cc3cccc(Cl)c3)cc1C(C)=O)C2=O.[Br-]', 'O=C1SCc2cccc([N+](=O)[O-])c21', 'Cc1cc(=O)oc2cc(OCCCCSC(=S)N3CCCCC3)ccc12', 'Cc1cc(=O)oc2cc(OCCCCSC(=S)N3CCCCC3)ccc12', 'Nc1c2c(nc3c1C(c1ccc(Cl)cc1)NC(=S)N3)CCCC2', 'COc1ccc2c3c1O[C@H]1C[C@H](O)CC[C@@]31CCN(C)C2', 'Cc1cc(=O)oc2cc(OCCSC(=S)N3CCN(C(C)C)CC3)ccc12', 'COc1ccc2c(c1)CCC(Cc1cc[n+](Cc3ccccc3F)cc1C(C)=O)C2=O.[Br-]', 'Nc1c2c(nc3c1C(c1ccc4c(c1)OCO4)NC(=S)N3)CCCC2', 'COC(=O)CNC(=O)c1cc2c(OC(=O)N(C)C)cccc2[n+](C)c1.[I-]', 'CO[C@H]1O[C@@](C)(c2nccc3cc4c(cc23)OCO4)c2ccc3c(c21)OCO3', 'CN(C)C(=O)Oc1cccc2c1cc(C(=O)NCCOCCOCCN1C(=O)c3ccccc3C1=O)c[n+]2C.O=S(=O)([O-])C(F)(F)F', 'CN(C)C(=O)Oc1cccc2c1cc(C(=O)Nc1ccccc1)c[n+]2C.[I-]', 'O=C(O)C(F)(F)F.O=C1CC[C@@]2(C=CNC3=C2C2=NCCc4c[nH]c(c42)C3=O)C=C1Br', 'COc1ccccc1CNCCCCCOC(=O)Nc1cc(Cl)nc(Cl)c1', 'COc1ccc2c(c1)CCC(Cc1cc[n+](Cc3cccc(C)c3)cc1C(C)=O)C2=O.[Br-]', 'Cc1cc(=O)oc2cc(OCCSC(=S)N(C)C)ccc12', 'COc1cc2c(cc1OC)C(=O)C(Cc1cc[n+](Cc3cccc(Cl)c3)cc1C(C)=O)CC2.[Br-]', 'CC(=O)c1c[n+](Cc2cccc(Cl)c2)ccc1CC1Cc2cc(O)ccc2C1=O.[Br-]', 'COc1cc2c(cc1OC)C(=O)C(Cc1cc[n+](Cc3cccc(C)n3)cc1C(N)=O)C2.[Br-]', 'Nc1c2c(nc3c1C(c1ccccc1)NC(=S)N3)CCCC2', 'COc1cccc(C2NC(=S)Nc3nc4c(c(N)c32)CCCC4)c1', 'COc1cccc(C2NC(=S)Nc3nc4c(c(N)c32)CCCC4)c1', 'COC(=O)c1c[n+](Cc2cccc(Cl)c2)ccc1CCC(=O)c1ccc(OC)c(OC)c1.[Br-]', 'COC1c2c(ccc3c2OCO3)-c2ccc3cc4c(cc3c2N1C)OCO4', 'CC(C)NC(=O)c1cc2c(OC(=O)N(C)C)cccc2[n+](C)c1.[I-]', 'COc1cc2c3c(c1)c1cc(=O)c(OC)cc-1cn3CC2', 'COc1ccc2c(c1)CCC(Cc1cc[n+](Cc3ccc(Cl)cc3)cc1C(C)=O)C2=O.[Br-]', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN[C@@H]1N2.O=C(O)c1ccccc1O', 'CNC(=O)Oc1ccc2c(c1)[C@]1(C)CCN[C@@H]1N2.O=C(O)c1ccccc1O', 'O=C(Nc1ccncc1Br)OCCCCCNCc1ccccc1', 'COc1cc2c(cc1OC)C(=O)/C(=C/C1CCN(Cc3cc(N=[N+]=[N-])c4ccccc4n3)CC1)C2', 'COc1ccc2c(c1)CCC(Cc1cc[n+](Cc3ccc(C)cc3)cc1C(C)=O)C2=O.[Br-]', 'COc1ccc2c(c1)CCC(Cc1cc[n+](Cc3cccc(C)c3)cc1Br)C2=O.[Br-]', 'C#CCN(C)Cc1cc2cc(OCCCN3CCCCC3)ccc2n1C', 'C#CCN(C)Cc1cc2cc(OCCCN3CCCCC3)ccc2n1C', 'C#CCN(C)Cc1cc2cc(OCCCN3CCCCC3)ccc2n1C', 'C#CCN(C)Cc1cc2cc(OCCCN3CCCCC3)ccc2n1C', 'COc1cc2c(cc1OC)C(=O)C(Cc1cc[n+](CCc3ccccc3)cc1C(N)=O)C2.[Br-]', 'COc1ccc2c(c1)CCC(Cc1cc[n+](Cc3cccc(C(F)(F)F)c3)cc1C(C)=O)C2=O.[Br-]', 'CC(=O)c1c[n+](Cc2ccccc2C)ccc1CC1Cc2cc(OCC(F)(F)F)ccc2C1=O.[Br-]', 'COc1cc2c(cc1OC)C(=O)C(CC1CCN(Cc3cc(N)c4ccccc4n3)CC1)C2', 'c1ccc2c(c1)CN[C@@H](CN(CC[C@H]1CCCNC1)[C@H]1CCCc3cccnc31)C2', 'COc1ccc2c(c1)CCC(Cc1cc[n+](Cc3ccccc3C)cc1C(N)=O)C2=O.[Br-]', 'Cc1cc(=O)oc2cc(OCCCCCSC(=S)N3CCCCC3)ccc12', 'Nc1c2c(nc3c1C(c1cccc(Br)c1)NC(=S)N3)CCCC2', 'Nc1c2c(nc3c1C(c1cccc(Br)c1)NC(=S)N3)CCCC2', 'COc1ccc(C(=O)CCc2cc[n+](Cc3ccccc3C(F)(F)F)cc2C#N)cc1OC.[Br-]', 'Cc1cc(=O)oc2cc(OCCSC(=S)N3CCCCC3)ccc12', 'CC[n+]1cc(C(=O)NC)cc2c(OC(=O)N(C)C)cccc21.[I-]', 'COc1ccccc1CNCCCCCCNC(=O)c1cc(Cl)nc(Cl)c1', 'CN(C)c1ccc(C2NC(=S)Nc3nc4c(c(N)c32)CCCC4)cc1', 'COc1ccc2c(c1)CCC(Cc1cc[n+](CC3CCCCC3)cc1C(C)=O)C2=O.[I-]', 'COCCNC(=O)c1cc2c(OC(=O)N(C)C)cccc2[n+](C)c1.[I-]', 'COc1ccc(C2NC(=S)Nc3nc4c(c(N)c32)CCCC4)cc1', 'COC(=O)c1cc2c(OC(=O)N(C)C)cccc2[n+](C)c1.[I-]', 'CN(C)C(=O)Oc1cccc2c1cc(C(=O)N(C)C)c[n+]2C.[I-]', 'COc1ccc2c(c1)CCC(Cc1cc[n+](Cc3ccccc3Cl)cc1C(C)=O)C2=O.[Br-]', 'CCN(CC)C(=S)SCCOc1ccc2c(C)cc(=O)oc2c1', 'N#Cc1ccccc1CNCC(=O)Nc1ccc2nc3n(c(=O)c2c1)CCC3', 'COc1ccc(Cn2cc(C(=O)NCCCCCNc3c4c(nc5ccccc35)CCCC4)c(=O)c3ccccc32)cc1', 'COc1ccc(CC(=O)Nc2ccc(CN(C)Cc3ccccc3)cc2)cc1OC', 'CCN(Cc1ccccc1)Cc1ccc(NC(=O)Cc2ccc(OC)c(OC)c2)cc1', 'COc1ccc(Cn2cc(C(=O)NCCCCCCCCNc3c4c(nc5cc(Cl)ccc35)CCCC4)c(=O)c3ccccc32)cc1', 'CCCCCCCCNCC(=O)Nc1ccc2nc3n(c(=O)c2c1)CCC3', 'c1ccc2c(NCCCCC[Se][Se]CCCCCNc3c4c(nc5ccccc35)CCCC4)c3c(nc2c1)CCCC3', 'COc1ccc(Cn2cc(C(=O)NCCCCCCCCNc3c4c(nc5ccccc35)CCCC4)c(=O)c3ccccc32)cc1', 'COc1ccc(Cn2cc(C(=O)NCCCCCNc3c4c(nc5ccc(OC)cc35)CCCC4)c(=O)c3ccccc32)cc1', 'Cc1cc(=O)oc2cc(OCc3cc[n+](Cc4cccc([N+](=O)[O-])c4)cc3)ccc12.[Br-]', 'COc1ccccc1C(=O)Nc1ccc2c(c1)CN(C(=O)c1cccc(C)c1)C(=O)C2', 'COc1ccc(Cn2cc(C(=O)NCCNc3c4c(nc5ccccc35)CCCC4)c(=O)c3ccccc32)cc1', 'COc1ccccc1C(=O)N1Cc2cc(NC(=O)c3cccc(Cl)c3)ccc2CC1=O', 'CCCCCCCCCCCCCCCCNCC(=O)Nc1ccc2nc3n(c(=O)c2c1)CCC3', 'Cc1cccc(C[n+]2ccc(COc3ccc4c(C)cc(=O)oc4c3)cc2)c1.[Br-]', 'O=C(CNCc1ccccc1F)Nc1ccc2nc3n(c(=O)c2c1)CCC3', 'Cc1cc(=O)oc2cc(OCc3cc[n+](Cc4ccccc4F)cc3)ccc12.[Br-]', 'COc1ccc(Cn2cc(C(=O)NCCCCCCNc3c4c(nc5ccc(OC)cc35)CCCC4)c(=O)c3ccccc32)cc1', 'O=C(Nc1ccc2c(c1)CN(C(=O)c1ccccc1)C(=O)C2)c1cccc(Cl)c1', 'Cc1cc(=O)oc2cc(OCc3cc[n+](Cc4cccc(F)c4)cc3)ccc12.[Br-]', 'COc1ccc(Cn2cc(C(=O)NCCCCCCNc3c4c(nc5ccccc35)CCCC4)c(=O)c3ccccc32)cc1', 'O=C(CNCc1cc(F)cc(F)c1)Nc1ccc2nc3n(c(=O)c2c1)CCC3', 'O=C(CNCc1cc(F)cc(F)c1)Nc1ccc2nc3n(c(=O)c2c1)CCC3', 'O=C(CNCc1cc(F)cc(F)c1)Nc1ccc2nc3n(c(=O)c2c1)CCC3', 'CC(C)=CCNCC(=O)Nc1ccc2nc3n(c(=O)c2c1)CCC3', 'CCN(Cc1ccccc1)Cc1ccc(NC(=O)Cc2ccc(O)cc2)cc1', 'CCCCNCC(=O)Nc1ccc2nc3n(c(=O)c2c1)CCC3', 'CN(Cc1ccccc1)Cc1ccc(NC(=O)Cc2ccc(O)cc2)cc1', 'c1ccc2c(NCCCCCSSCCCCCNc3c4c(nc5ccccc35)CCCC4)c3c(nc2c1)CCCC3', 'O=C(Nc1ccc2c(c1)CN(C(=O)c1cccc(Cl)c1)C(=O)C2)c1ccccc1', 'CCCCCCCCCCNCC(=O)Nc1ccc2nc3n(c(=O)c2c1)CCC3', 'Cc1cc(=O)oc2cc(OCc3cc[n+](Cc4ccccc4Br)cc3)ccc12.[Br-]', 'CCNCC(=O)Nc1ccc2nc3n(c(=O)c2c1)CCC3', 'COc1ccccc1C(=O)Nc1ccc2c(c1)CN(C(=O)c1ccccc1)C(=O)C2', 'COc1ccc(Cn2cc(C(=O)NCCCCNc3c4c(nc5ccccc35)CCCC4)c(=O)c3ccccc32)cc1', 'COc1cc(/C=C/C(=O)NCCCCCCNc2c3c(nc4ccccc24)CCCC3)cc(OC)c1OCc1nc(C)c(C)nc1C', 'Cc1cccc(C(=O)Nc2ccc3c(c2)CN(C(=O)c2cccc(C)c2)C(=O)C3)c1', 'O=C(CNCCCc1ccccc1)Nc1ccc2nc3n(c(=O)c2c1)CCC3', 'COc1ccccc1C(=O)Nc1ccc2c(c1)CN(C(=O)c1ccccc1OC)C(=O)C2', 'COc1ccc(Cn2cc(C(=O)NCCCCCCCCNc3c4c(nc5ccc(OC)cc35)CCCC4)c(=O)c3ccccc32)cc1', 'Cc1cccc(C(=O)N2Cc3cc(NC(=O)c4cccc(Cl)c4)ccc3CC2=O)c1', 'Cc1ccccc1C[n+]1ccc(COc2ccc3c(C)cc(=O)oc3c2)cc1.[Br-]', 'Cc1ccccc1CNCC(=O)Nc1ccc2nc3n(c(=O)c2c1)CCC3', 'COc1ccc(Cn2cc(C(=O)NCCCNc3c4c(nc5cc(Cl)ccc35)CCCC4)c(=O)c3ccccc32)cc1', 'COc1ccc(Cn2cc(C(=O)NCCCNc3c4c(nc5cc(Cl)ccc35)CCCC4)c(=O)c3ccccc32)cc1', 'COc1ccc(Cn2cc(C(=O)NCCCNc3c4c(nc5cc(Cl)ccc35)CCCC4)c(=O)c3ccccc32)cc1', 'CC(=O)OC(C)(C)/C=C/C(=O)[C@](C)(O)[C@H]1[C@H](O)C[C@@]2(C)[C@@H]3CC=C(C(C)(C)C(=O)O)/C(=C\\\\C(=O)O)[C@]3(C)C(=O)C[C@]12C', 'COc1ccc(Cn2cc(C(=O)NCCNc3c4c(nc5ccc(OC)cc35)CCCC4)c(=O)c3ccccc32)cc1', 'CCN(Cc1ccccc1)Cc1ccc(NC(=O)Cc2ccc(O)c(O)c2)cc1', 'C#CCNCC(=O)Nc1ccc2nc3n(c(=O)c2c1)CCC3', 'C=CCNCC(=O)Nc1ccc2nc3n(c(=O)c2c1)CCC3', 'c1ccc2c(NCCCCC[Se]CCCCCNc3c4c(nc5ccccc35)CCCC4)c3c(nc2c1)CCCC3', 'CCCNCC(=O)Nc1ccc2nc3n(c(=O)c2c1)CCC3', 'COc1ccccc1C(=O)N1Cc2cc(NC(=O)c3ccccc3)ccc2CC1=O', 'Cc1cc(=O)oc2cc(OCc3cc[n+](Cc4ccc(Br)cc4)cc3)ccc12.[Br-]', 'COc1ccc(Cn2cc(C(=O)NCCCCCCCNc3c4c(nc5cc(Cl)ccc35)CCCC4)c(=O)c3ccccc32)cc1', 'O=C(Nc1ccc2c(c1)CN(C(=O)c1ccccc1)C(=O)C2)c1ccccc1', 'Cc1ccc(C[n+]2ccc(COc3ccc4c(C)cc(=O)oc4c3)cc2)cc1.[Br-]', 'CC(=O)OC(C)(C)/C=C/C(=O)[C@](C)(O)[C@H]1[C@H](O)C[C@@]2(C)[C@@H]3CC=C(C(C)(C)C(=O)O)C4=CC(=O)O[C@](O)(C[C@]12C)[C@@]43C', 'COc1ccccc1C(=O)Nc1ccc2c(c1)CN(C(=O)c1cccc(Cl)c1)C(=O)C2', 'COc1ccc(Cn2cc(C(=O)NCCCNc3c4c(nc5ccccc35)CCCC4)c(=O)c3ccccc32)cc1', 'Cc1cccc(C(=O)Nc2ccc3c(c2)CN(C(=O)c2cccc(Cl)c2)C(=O)C3)c1', 'CCN(Cc1ccccc1)Cc1ccc(NC(=O)Cc2ccc(OC)c(O)c2)cc1', 'COc1ccc(Cn2cc(C(=O)NCCCCCCCNc3c4c(nc5ccccc35)CCCC4)c(=O)c3ccccc32)cc1', 'O=C(CNCc1ccccc1)Nc1ccc2nc3n(c(=O)c2c1)CCC3', 'CN(Cc1ccccc1)Cc1ccc(NC(=O)Cc2ccc(O)c(O)c2)cc1', 'COc1ccc(Cn2cc(C(=O)NCCCCNc3c4c(nc5cc(Cl)ccc35)CCCC4)c(=O)c3ccccc32)cc1', 'COc1ccc(Cn2cc(C(=O)NCCNc3c4c(nc5cc(Cl)ccc35)CCCC4)c(=O)c3ccccc32)cc1', 'COc1cc(/C=C/C(=O)NCCCCCCNc2c3c(nc4ccccc24)CCCC3)cc(OC)c1O', 'COc1ccc(Cn2cc(C(=O)NCCCCNc3c4c(nc5ccc(OC)cc35)CCCC4)c(=O)c3ccccc32)cc1', 'O/N=C/c1nc(CCCCNc2c3c(nc4ccc(Cl)cc24)CCCC3)ccc1O', 'O/N=C/c1nc(CCCCNc2c3c(nc4ccc(Cl)cc24)CCCC3)ccc1O', 'O/N=C/c1nc(CCCCNc2c3c(nc4ccc(Cl)cc24)CCCC3)ccc1O', 'O/N=C/c1nc(CCCCNc2c3c(nc4ccc(Cl)cc24)CCCC3)ccc1O', 'O/N=C/c1nc(CCCCNc2c3c(nc4ccc(Cl)cc24)CCCC3)ccc1O', 'CN(Cc1ccccc1)Cc1ccc(NC(=O)/C=C/c2ccc(O)c(O)c2)cc1', 'Cc1cc(=O)oc2cc(OCc3cc[n+](Cc4ccc([N+](=O)[O-])cc4)cc3)ccc12.[Br-]', 'COc1ccc(Cn2cc(C(=O)NCCCNc3c4c(nc5ccc(OC)cc35)CCCC4)c(=O)c3ccccc32)cc1', 'CCCCCCCCCCCCNCC(=O)Nc1ccc2nc3n(c(=O)c2c1)CCC3', 'COc1ccc(CC(=O)Nc2ccc(CN(C)Cc3ccccc3)cc2)cc1O', 'COc1ccc(Cn2cc(C(=O)NCCCCCCNc3c4c(nc5cc(Cl)ccc35)CCCC4)c(=O)c3ccccc32)cc1', 'Cc1cc(=O)oc2cc(OCc3cc[n+](Cc4ccccc4)cc3)ccc12.[Br-]', 'COc1ccc(Cn2cc(C(=O)NCCCCCCCNc3c4c(nc5ccc(OC)cc35)CCCC4)c(=O)c3ccccc32)cc1', 'COc1ccc(Cn2cc(C(=O)NCCCCCNc3c4c(nc5cc(Cl)ccc35)CCCC4)c(=O)c3ccccc32)cc1', 'O=C(Nc1ccc2c(c1)CN(C(=O)c1cccc(Cl)c1)C(=O)C2)c1cccc(Cl)c1', 'C=CCCNCC(=O)Nc1ccc2nc3n(c(=O)c2c1)CCC3', 'CCCCCCNCC(=O)Nc1ccc2nc3n(c(=O)c2c1)CCC3', 'Cc1cc(=O)oc2cc(OCc3cc[n+](Cc4ccc(F)cc4)cc3)ccc12.[Br-]', 'Cc1cccc(C(=O)N2Cc3cc(NC(=O)c4ccccc4)ccc3CC2=O)c1', 'Cc1cc(=O)oc2cc(OCc3cc[n+](Cc4cccc(Br)c4)cc3)ccc12.[Br-]', 'O=C(CNCc1ccccc1[N+](=O)[O-])Nc1ccc2nc3n(c(=O)c2c1)CCC3', 'CN(Cc1ccccc1)Cc1ccc(NC(=O)Cc2ccccc2)cc1', 'C#CCNc1nc(NCCCCC2CCN(Cc3ccccc3)CC2)c(C#N)cc1C#N', 'COc1ccc2c(c1)C/C(=C/c1ccccc1-c1ccc3nc(N)ccc3c1)C2=O', 'COc1ccc2c(c1)C/C(=C/C1CCN(Cc3ccccc3)CC1)C2=O', 'COc1ccc2c(c1)C/C(=C/c1ccccc1-c1ccc3ccccc3c1)C2=O', 'COc1ccc2c(c1)C/C(=C/c1ccccc1-c1ccccc1)C2=O', 'COc1ccc(-c2ccccc2/C=C2/Cc3cc(OC)ccc3C2=O)cc1', 'CN(CCCCCN1C(=O)c2ccccc2S1(=O)=O)Cc1ccccc1', 'CCN1CCN(C2CCN(C(=O)COc3ccc(-c4ccccc4F)cc3)CC2)CC1', 'CCN(CC)CCOc1ccc(/C=C2\\\\COc3ccccc3C2=O)cc1', 'O=C(NCCC1CCN(Cc2ccccc2)CC1)c1cc(=O)c2c(O)cc(O)cc2o1', 'O=C(COc1ccc(-c2ccccc2)cc1)NCCCN1CCCCC1', 'O=C(NCCC1CCN(Cc2ccccc2)CC1)c1cc(=O)c2cc([N+](=O)[O-])ccc2o1', 'O=C(NCCC1CCN(Cc2ccccc2)CC1)c1cc(=O)c2cc([N+](=O)[O-])ccc2o1', 'Cc1ccccc1CN1CCC(CCNC(=O)/C=C/c2cc(C(C)(C)C)c(O)c(C(C)(C)C)c2)CC1', 'Cc1[nH]c2ccccc2c1CC(=O)NCCC1CCN(Cc2ccccc2)CC1', 'NC(=O)c1cc[n+](C/C=C/C[n+]2cc(Cl)c(/C=N/O)c(Cl)c2)cc1.[Br-].[Br-]', 'O=C(COc1ccc(-c2ccccc2)cc1)N1CCC(N2CCCCC2)CC1', 'COC(=O)c1sc(-c2ccnc(NC(=O)C3CC3)c2)nc1OCCNc1c2c(nc3ccccc13)CCCC2', 'CC(C)(C)c1cc(/C=C/C(=O)NCCC2CCN(Cc3ccc(C#N)cc3)CC2)cc(C(C)(C)C)c1O', 'COc1ccc2nc3c(c(NCCCNC(=O)c4sc(-c5ccnc(NC(=O)C6CC6)c5)nc4OC)c2c1)CCCC3', 'CCN(CC)CCOc1cccc(/C=C2\\\\COc3ccccc3C2=O)c1', 'COc1nc(-c2ccnc(NC(=O)C3CC3)c2)sc1C(=O)NCCCNc1c2c(nc3ccccc13)CCCC2', 'CCN(CC)CCOC(=O)/C=C/c1ccc2occ(C(=O)Nc3ccc(C)cc3)c(=O)c2c1', 'O=C(O)/C=C/c1ccc2oc(C(=O)Nc3ccccc3)cc(=O)c2c1', 'Cc1ccc(NC(=O)c2cc(=O)c3cc(/C=C/C(=O)OCCN(C)C)ccc3o2)cc1C', 'CC(C)(C)c1cc(C(=O)CNCCC2CCN(Cc3ccccc3)CC2)cc(C(C)(C)C)c1O', 'CCN(CC)Cc1cc(N)ccc1O.Cl.Cl', 'CCN(CC)Cc1cc(N)ccc1O.Cl.Cl', 'CCN(CC)Cc1cc(N)ccc1O.Cl.Cl', 'CCN(CC)Cc1cc(N)ccc1O.Cl.Cl', 'CCN(CC)Cc1cc(N)ccc1O.Cl.Cl', 'CCN(CC)Cc1cc(N)ccc1O.Cl.Cl', 'Fc1ccc2c(C3CCN(CCN4CCCC4)CC3)noc2c1', 'Nc1c2c(nc3cc(Cl)ccc13)C[C@H]1C=C(CCCCn3cc(CO)nn3)C[C@H]2C1', 'O=C(NCCC1CCN(Cc2ccccc2)CC1)c1cc(=O)c2cc(O)c(O)cc2o1', 'CCN1CCN(CCCNC(=O)COc2ccc(I)cc2)CC1', 'CCN(CC)CCCCCCOc1ccc(/C=C2\\\\COc3ccccc3C2=O)cc1', 'CC(C)(C)c1cc(/C=C/C(=O)NCCC2CCN(Cc3ccc(F)c(F)c3)CC2)cc(C(C)(C)C)c1O', 'NC(=O)c1cc[n+](CCC[n+]2cc(Cl)c(/C=N/O)c(Cl)c2)cc1.[Br-].[Br-]', 'C[N+](C)(CC#CCOC1=NOCC1)CCCCCCCCCC[N+](C)(C)CCCN1C(=O)c2ccccc2C1=O.[Br-].[Br-]', 'Cn1c2nc3ccccc3c-2c(NCCCCNc2c3c(nc4ccccc24)CCCC3)c2ccccc21', 'CC(C)(C)c1cc(/C=C/C(=O)NCCC2CCN(Cc3ccc(Br)cc3)CC2)cc(C(C)(C)C)c1O', 'CN(C)CCOc1cccc(/C=C2\\\\COc3ccccc3C2=O)c1', 'CN(C)CCOC(=O)/C=C/c1ccc2oc(C(=O)Nc3ccc(Cl)cc3)cc(=O)c2c1', 'COc1nc(-c2ccnc(NC(=O)C3CC3)c2)sc1C(=O)NCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'Cl.Cl.Nc1ccc(O)c(CN2CCCC2)c1', 'Cl.Cl.Nc1ccc(O)c(CN2CCCC2)c1', 'Cl.Cl.Nc1ccc(O)c(CN2CCCC2)c1', 'Cn1cc(C(=O)NCCC2CCN(Cc3ccccc3)CC2)c2ccccc21', 'COc1ccc2c(=O)cc(C(=O)NCCC3CCN(Cc4ccccc4)CC3)[nH]c2c1', 'CC(C)(C)c1cc(/C=C/C(=O)NCCC2CCN(Cc3cccc(Cl)c3)CC2)cc(C(C)(C)C)c1O', 'CCN(CC)CCOC(=O)/C=C/c1ccc2oc(C(=O)Nc3ccc(C)cc3)cc(=O)c2c1', 'O=C(NC1CCN(Cc2ccccc2)CC1)c1cc(=O)c2cc(O)ccc2o1', 'CCN(CC)CCOC(=O)/C=C/c1ccc2oc(C(=O)Nc3cccc(Cl)c3)cc(=O)c2c1', 'C[N+](C)(CC#CCOC1=NOCC1)CCCCCCCNc1c2c(nc3ccccc13)CCCC2.[Br-]', 'CC(C)(C)c1cc(/C=C/C(=O)NCCC2CCN(Cc3ccccc3)CC2)cc(C(C)(C)C)c1O', 'CC(C)(C)c1cc(/C=C/C(=O)NCCC2CCN(Cc3ccccc3)CC2)cc(C(C)(C)C)c1O', 'COc1ccc2oc(C(=O)NCCC3CCN(Cc4ccccc4)CC3)cc(=O)c2c1', 'CCN(CC)CCOC(=O)/C=C/c1ccc2occ(C(=O)Nc3cccc(Cl)c3)c(=O)c2c1', 'O=C(Cc1c[nH]c2ccccc12)NCCC1CCN(Cc2ccccc2)CC1', 'CCN(CCOc1ccc(/C=C2\\\\COc3ccccc3C2=O)cc1)Cc1ccccc1', 'CN(C)CCOc1ccc(/C=C2\\\\COc3ccccc3C2=O)cc1', 'Cc1ccc(NC(=O)c2cc(=O)c3cc(/C=C/C(=O)O)ccc3o2)cc1', 'Cn1c2nc3ccccc3c-2c(NCCCCCCNc2c3c(nc4ccccc24)CCCC3)c2ccccc21', 'O=C(NCCCC1CCN(Cc2ccccc2)CC1)c1cc(=O)c2cc(O)ccc2o1', 'O=C(NCCCC1CCN(Cc2ccccc2)CC1)c1cc(=O)c2cc(O)ccc2o1', 'Cc1ccc(NC(=O)c2coc3ccc(/C=C/C(=O)OCCN(C)C)cc3c2=O)cc1', 'CC(C)(C)c1cc(/C=C/C(=O)NCCC2CCN(Cc3ccc(F)cc3)CC2)cc(C(C)(C)C)c1O', 'COc1cc2oc(C(=O)OCCC3CCN(Cc4ccccc4)CC3)cc(=O)c2cc1OC', 'COc1cc2oc(C(=O)OCCC3CCN(Cc4ccccc4)CC3)cc(=O)c2cc1OC', 'O=C(COc1ccc(-c2ccccc2)cc1)N1CCC(N2CCOCC2)CC1', 'O=C(O)/C=C/c1ccc2occ(C(=O)Nc3ccccc3)c(=O)c2c1', 'COc1cc(OC)c2c(=O)cc(C(=O)NCCC3CCN(Cc4ccccc4)CC3)oc2c1', 'CCN1CCN(C2CCN(C(=O)COc3ccc(-c4ccc(OC)cc4)cc3)CC2)CC1', 'NC(=O)c1cc[n+](CCCC[n+]2ccc(/C=N/O)c(Cl)c2)cc1.[Br-].[Br-]', 'Cc1ccc(CN2CCC(CCNC(=O)/C=C/c3cc(C(C)(C)C)c(O)c(C(C)(C)C)c3)CC2)cc1', 'CCN(CC)CCCCOc1ccc(/C=C2\\\\COc3ccccc3C2=O)cc1', 'CCOC(=O)c1sc(-c2ccnc(NC(=O)C3CC3)c2)nc1OCCNc1c2c(nc3ccccc13)CCCC2', 'COc1ccc2nc3c(c(NCCNC(=O)c4sc(-c5ccnc(NC(=O)C6CC6)c5)nc4OC)c2c1)CCCC3', 'COc1cc2oc(C(=O)OCC3CCN(Cc4ccccc4)CC3)cc(=O)c2cc1OC', 'CN(C)CCOC(=O)/C=C/c1ccc2oc(C(=O)Nc3ccccc3)cc(=O)c2c1', 'CN(C)CCOC(=O)/C=C/c1ccc2occ(C(=O)Nc3ccc(Cl)cc3)c(=O)c2c1', 'Cc1cccc2c1ccc1c3c(c(=O)oc(=O)c12)[C@@H](C)CO3', 'COc1ccc2c(=O)cc(C(=O)NCCC3CCN(Cc4ccccc4)CC3)oc2c1', 'O=C(Cc1c[nH]c2ccc(Br)cc12)NCCC1CCN(Cc2ccccc2)CC1', 'NC(=O)c1cc[n+](CCCC[n+]2cc(Cl)c(/C=N/O)c(Cl)c2)cc1.[Br-].[Br-]', 'O=C(NCCC1CCN(Cc2ccccc2)CC1)c1cc(=O)c2cccc(O)c2[nH]1', 'CN1CCN(C2CCN(C(=O)COc3ccc(-c4ccccc4)cc3)CC2)CC1', 'CN(C)CCOC(=O)/C=C/c1ccc2occ(C(=O)Nc3ccccc3)c(=O)c2c1', 'COc1nc(-c2ccnc(NC(=O)C3CC3)c2)sc1C(=O)NCCNc1c2c(nc3ccccc13)CCCC2', 'COc1ccc2oc(C(=O)OCC3CCN(Cc4ccccc4)CC3)cc(=O)c2c1', 'CC(C)(C)c1cc(C(=O)CNCC2CCN(Cc3ccccc3)CC2)cc(C(C)(C)C)c1O', 'O=C(NCCC1CCN(Cc2ccccc2)CC1)c1cc(=O)c2ccccc2o1', 'O=C(NCCC1CCN(Cc2ccccc2)CC1)c1cc(=O)c2ccccc2o1', 'CCN(CC)CCOC(=O)/C=C/c1ccc2occ(C(=O)Nc3ccc(OC)cc3)c(=O)c2c1', 'CCN1CCN(C2CCN(C(=O)COc3ccc4c(c3)CCC4=O)CC2)CC1', 'COc1ccc2[nH]c(C(=O)NCCC3CCN(Cc4ccccc4)CC3)cc(=O)c2c1', 'COc1ccc(NC(=O)c2cc(=O)c3cc(/C=C/C(=O)OCCN(C)C)ccc3o2)cc1', 'C[N+](C)(CC#CCOC1=NOCC1)CCCCCCCCCCNc1c2c(nc3ccccc13)CCCC2.[Br-]', 'CC(C)(C)c1cc(CCC(=O)NCCC2CCN(Cc3ccccc3)CC2)cc(C(C)(C)C)c1O', 'COc1ccc2oc(C(=O)NCC3CCN(Cc4ccccc4)CC3)cc(=O)c2c1', 'COc1ccc(NC(=O)c2coc3ccc(/C=C/C(=O)O)cc3c2=O)cc1', 'COc1cc2oc(C(=O)NCCC3CCN(Cc4ccccc4)CC3)cc(=O)c2cc1OC', 'COc1cc2oc(C(=O)NCCC3CCN(Cc4ccccc4)CC3)cc(=O)c2cc1OC', 'COc1ccc(CN2CCC(CCNC(=O)/C=C/c3cc(C(C)(C)C)c(O)c(C(C)(C)C)c3)CC2)cc1', 'O=C1/C(=C/c2ccc(OCCCN3CCN(Cc4ccccc4)CC3)cc2)COc2ccccc21', 'NC(=O)c1sc(-c2ccnc(NC(=O)C3CC3)c2)nc1OCCNc1c2c(nc3ccccc13)CCCC2', 'O=C(COc1ccc(I)cc1)NCCCN1CCCCC1', 'CN(C)CCCOc1cccc(/C=C2\\\\COc3ccccc3C2=O)c1', 'NC(=O)c1cc[n+](C/C=C/C[n+]2ccc(/C=N/O)c(Cl)c2)cc1.[Br-].[Br-]', 'COc1cc2nc(C(=O)NCCC3CCN(Cc4ccccc4)CC3)cc(OC)c2cc1OC', 'C[C@@H]1C[C@H]2CC(=O)[C@H]3CCC[N+]4([O-])CCC[C@]2(O)[C@]34C1', 'CN(C)CCOC(=O)/C=C/c1ccc2oc(C(=O)Nc3cccc(Cl)c3)cc(=O)c2c1', 'CCN(CC)CCOC(=O)/C=C/c1ccc2oc(C(=O)Nc3ccccc3)cc(=O)c2c1', 'COc1nc(-c2ccnc(NC(=O)C3CC3)c2)sc1C(=O)NCCCCCCNc1c2c(nc3ccccc13)CCCC2', 'Cc1coc2c1c(=O)oc(=O)c1c3c(ccc12)C(C)(C)CCC3', 'COc1cccc2c(=O)cc(C(=O)NCCC3CCN(Cc4ccccc4)CC3)[nH]c12', 'Fc1ccc2c(C3CCN(CCN4CCCCC4)CC3)noc2c1', 'COc1ccc2oc(C(=O)NC3CCN(Cc4ccccc4)CC3)cc(=O)c2c1', 'COc1ccc(-c2ccc(OCC(=O)NCCCN3CCCCC3)cc2)cc1', 'CCN(CC)CCOC(=O)/C=C/c1ccc2oc(C(=O)Nc3ccc(Cl)cc3)cc(=O)c2c1', 'O=C(NCCC1CCN(Cc2ccccc2)CC1)c1cc(=O)c2cc(O)ccc2o1', 'COc1ccc2oc(C(=O)NCCCC3CCN(Cc4ccccc4)CC3)cc(=O)c2c1', 'CCN1CCN(C2CCN(C(=O)COc3ccc(I)cc3)CC2)CC1', 'CN(CCCCCCOc1ccc(/C=C2\\\\COc3ccccc3C2=O)cc1)Cc1ccccc1', 'CC(C)(C)c1cc(/C=C/C(=O)NCCC2CCN(Cc3ccc(F)cc3F)CC2)cc(C(C)(C)C)c1O', 'CCN1CCN(C2CCN(C(=O)COc3ccc(-c4ccc([N+](=O)[O-])cc4)cc3)CC2)CC1', 'CCN(CC)c1ccc(/C=C/c2cc(N3CCCCC3)c3ccccc3n2)cc1', 'Cc1ccc(NC(=O)c2cc(=O)c3cc(/C=C/C(=O)OCCN(C)C)ccc3o2)cc1', 'Cc1ccc(NC(=O)c2cc(=O)c3cc(/C=C/C(=O)OCCN(C)C)ccc3o2)cc1', 'CC(C)(C)c1cc(/C=C/C(=O)NCCC2CCN(Cc3cccc([N+](=O)[O-])c3)CC2)cc(C(C)(C)C)c1O', 'COc1cc2oc(C(=O)NC3CCN(Cc4ccccc4)CC3)cc(=O)c2cc1OC', 'Nc1ccc2oc(C(=O)NCCC3CCN(Cc4ccccc4)CC3)cc(=O)c2c1', 'Nc1ccc2oc(C(=O)NCCC3CCN(Cc4ccccc4)CC3)cc(=O)c2c1', 'NC(=O)c1cc[n+](CCC[n+]2ccc(/C=N/O)c(Cl)c2)cc1.[Br-].[Br-]', 'CC(C)(C)c1cc(/C=C/C(=O)NCCC2CCN(Cc3ccccc3F)CC2)cc(C(C)(C)C)c1O', 'CC(C)(C)c1cc(/C=C/C(=O)NCCC2CCN(Cc3ccccc3F)CC2)cc(C(C)(C)C)c1O', 'Cn1cc(CC(=O)NCCC2CCN(Cc3ccccc3)CC2)c2ccccc21', 'CC(C)(CN1C(=O)c2cccc3cccc(c23)C1=O)C[N+](C)(C)CCCCCCCCCC[N+](C)(C)CC#CCOC1=NOCC1.[Br-].[Br-]', 'CC(C)(C)c1cc(/C=C/C(=O)NCCC2CCN(Cc3ccccc3Cl)CC2)cc(C(C)(C)C)c1O', 'O=C(O)c1sc(-c2ccnc(NC(=O)C3CC3)c2)nc1OCCNc1c2c(nc3ccccc13)CCCC2', 'CCN(CC)CCOC(=O)/C=C/c1ccc2oc(C(=O)Nc3ccc(OC)cc3)cc(=O)c2c1', 'COc1nc(-c2ccnc(NC(=O)C3CC3)c2)sc1C(=O)NCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'C[C@H]1COc2c1c(=O)oc(=O)c1c3c(ccc21)C(C)(C)CCC3', 'COc1cc2[nH]c(C(=O)NCCC3CCN(Cc4ccccc4)CC3)cc(=O)c2cc1OC', 'COc1cc2[nH]c(C(=O)NCCC3CCN(Cc4ccccc4)CC3)cc(=O)c2cc1OC', 'CCN(CC)CCOC(=O)/C=C/c1ccc2occ(C(=O)Nc3ccc(Cl)cc3)c(=O)c2c1', 'O=C(CCCc1c[nH]c2ccccc12)NCCC1CCN(Cc2ccccc2)CC1', 'COc1ccc(NC(=O)c2cc(=O)c3cc(/C=C/C(=O)O)ccc3o2)cc1', 'CCN(CC)CCOC(=O)/C=C/c1ccc2oc(C(=O)Nc3ccc(C)c(C)c3)cc(=O)c2c1', 'O=C(NCCC1CCN(Cc2ccccc2)CC1)c1cc(=O)c2cc(O)ccc2[nH]1', 'Cn1c2nc3ccccc3c-2c(NCCCCCCCCNc2c3c(nc4ccccc24)CCCC3)c2ccccc21', 'COc1cccc2oc(C(=O)NCCC3CCN(Cc4ccccc4)CC3)cc(=O)c12', 'COc1cc2oc(C(=O)NCCCC3CCN(Cc4ccccc4)CC3)cc(=O)c2cc1OC', 'COc1cc2oc(C(=O)NCCCC3CCN(Cc4ccccc4)CC3)cc(=O)c2cc1OC', 'COc1ccc(NC(=O)c2coc3ccc(/C=C/C(=O)OCCN(C)C)cc3c2=O)cc1', 'CC(C)(C)c1cc(/C=C/C(=O)NCCC2CCN(Cc3cccc(F)c3)CC2)cc(C(C)(C)C)c1O', 'COc1cc2oc(C(=O)NCC3CCN(Cc4ccccc4)CC3)cc(=O)c2cc1OC', 'S=C(NNc1c2c(nc3ccccc13)CCCC2)Nc1ccc(Cl)cc1', 'S=C(NNc1c2c(nc3ccccc13)CCCC2)Nc1ccc(Br)cc1', 'COc1cccc(CNC2CCN(Cc3ccccc3)CC2)c1OC', 'COc1ccc(C(=O)CNc2ccc3oc(=O)ccc3c2)cc1', 'CSc1ccc(/C=N/c2ccc3oc(=O)ccc3c2)cc1', 'Cl.Cl.N[C@@H](Cc1c[nH]c2ccccc12)C(=O)NCCCNc1c2c(nc3ccccc13)CCCC2', 'O=C(CCCNc1c2c(nc3cc(Cl)ccc13)CCCC2)NC12CC3CC(F)(CC(C1)c1ccccc13)C2', 'COc1cc2c(cc1OC)C(=O)C(Cc1cn(CC3CCN(Cc4ccccc4)CC3)nn1)C2', 'COc1ccc(-c2cc(=O)c3cc(OC)c(O)c([C@H]4CCC(=O)N4)c3o2)cc1', 'Oc1ccc(/C=N/c2c3c(nc4ccccc24)CCCC3)cc1', 'c1ccc(CN2CCC(Cn3cc(CNc4ncnc5ccccc45)nn3)CC2)cc1', 'COc1cc(C(=O)n2nc(OCCN3CCCC3)c3ccccc32)cc(OC)c1OC', 'Cl.O=[N+]([O-])c1ccc(-n2cc(COc3ccc(/C=N/Nc4c5c(nc6ccccc46)CCCC5)cc3)nn2)cc1', 'CN(C)c1ccc(/C=N/c2ccc3oc(=O)ccc3c2)cc1', 'CCOc1ccc(Cc2nc3cc(C(=O)NCCCNc4c5c(nc6ccccc46)CCCC5)ccc3n2CCC(C)C)cc1', 'CCOc1ccc(Cc2nc3cc(C(=O)NCCCNc4c5c(nc6ccccc46)CCCC5)ccc3n2CCC(C)C)cc1', 'CCOc1ccc(Cc2nc3cc(C(=O)NCCCNc4c5c(nc6ccccc46)CCCC5)ccc3n2CCC(C)C)cc1', 'COc1ccc2[nH]c3nc4c(c(N)c3c2c1)CCCC4', 'O=[N+]([O-])c1ccc(CNC2CCN(Cc3ccccc3)CC2)cc1', 'Oc1ccc(CNC2CCN(Cc3ccccc3)CC2)c(O)c1', 'O=C(Nc1cc(-c2cn(CCNc3c4c(nc5ccccc35)CCCC4)nn2)ccn1)Nc1cccc2c1[C@@H]1CCCCN1C2=O', 'Fc1ccc(CNC2CCN(Cc3ccccc3)CC2)c(F)c1', 'Cl.Clc1ccc(-n2cc(COc3ccc(/C=N/Nc4c5c(nc6ccccc46)CCCC5)cc3)nn2)cc1', 'O=C(Nc1cc(-c2cn(CCNc3c4c(nc5ccccc35)CCCC4)nn2)ccn1)Nc1cccc2c1[C@H]1CCCCN1C2=O', 'Cl.NS(=O)(=O)c1ccc(-n2cc(COc3ccc(/C=N/Nc4c5c(nc6ccccc46)CCCC5)cc3)nn2)cc1', 'COc1cc(NCc2ccc(Oc3c(N)cccc3Cl)cc2)cc(OC)c1OC', 'COc1cc(NCc2ccc(Oc3c(N)cccc3Cl)cc2)cc(OC)c1OC', 'O=C1CSC(c2ccc(F)cc2)N1c1ccc2oc(=O)ccc2c1', 'NS(=O)(=O)c1ccc(C(=O)n2[nH]c(=O)c3cc(F)ccc3c2=O)cc1', 'Cl.Cl.N[C@@H](Cc1c[nH]c2ccccc12)C(=O)NCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'O=C(CCC1CCN(CC2CCCCC2)CC1)c1cc(Cl)c2[nH]ccc2c1', 'Cc1ccc(CNC2CCN(Cc3ccccc3)CC2)cc1', 'C(=N/Nc1c2c(nc3ccccc13)CCCC2)\\\\c1ccc(OCc2cn(-c3ccccc3)nn2)cc1.Cl', 'OC(CNCc1cccc(OCc2ccccc2)c1)Cn1cc(Br)c2cc(Br)ccc21', 'Cc1cc(=O)oc2ccc(OC/C=C/CCn3cnc4c(N5CCCCC5)ncnc43)cc12', 'COc1ccc(C2=NN(C(C)=O)C(c3ccc(N4CCC(C)CC4)cc3)C2)cc1OC', 'O=C(c1cccc(Cl)c1Cl)n1nc(OCCN2CCCCC2)c2ccccc21', 'O=C(CNc1ccc2oc(=O)ccc2c1)c1ccccc1', 'COc1ccc(NCC(=O)Nc2ccc3oc(=O)ccc3c2)cc1', 'CN(Cc1ccnc(NC(=O)Nc2cccc3c2C2CCCCN2C3=O)c1)Cc1cn(CCNc2c3c(nc4ccccc24)CCCC3)nn1', 'c1ccc(CN2CCC(Cn3cc(CSc4nc5ccccc5[nH]4)nn3)CC2)cc1', 'CCOc1ccc(Cc2nc3cc(C(=O)NCCSSCCNc4c5c(nc6ccccc46)CCCC5)ccc3n2CCC(C)C)cc1', 'CCOc1ccc(Cc2nc3cc(C(=O)NCCSSCCNc4c5c(nc6ccccc46)CCCC5)ccc3n2CCC(C)C)cc1', 'CCOc1ccc(Cc2nc3cc(C(=O)NCCSSCCNc4c5c(nc6ccccc46)CCCC5)ccc3n2CCC(C)C)cc1', 'Cl.O=[N+]([O-])c1cccc(-n2cc(COc3ccc(/C=N/Nc4c5c(nc6ccccc46)CCCC5)cc3)nn2)c1', 'Oc1ccccc1CNC1CCN(Cc2ccccc2)CC1', 'O=C(CCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2)NCCc1cc2ccccc2[nH]1', 'Cl.Cl.N[C@H](Cc1c[nH]c2ccccc12)C(=O)NCCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'O=c1ccc2cc(/N=C/c3ccc(Cl)cc3)ccc2o1', 'FC(F)(F)Oc1ccc(/C=N/C2CCN(Cc3ccccc3)CC2)cc1', 'CSc1ccc(/C=C2/S/C(=N/c3ccc4oc(=O)ccc4c3)NC2=O)cc1', 'Cc1c(C)c2ccc(OCC3CCN(Cc4cccc(CO)c4)CC3)cc2oc1=O', 'COc1cc2oc(-c3ccc(NCCNc4c5c(nc6cc(Cl)ccc46)CCCC5)cc3)cc(=O)c2c(OC)c1OC', 'O=C1N/C(=N\\\\c2ccc3oc(=O)ccc3c2)S/C1=C/c1ccccc1', 'O=[N+]([O-])c1ccc(/C=N/C2CCN(Cc3ccccc3)CC2)cc1', 'c1ccc(CNC2CCN(Cc3ccccc3)CC2)cc1', 'COc1ccc(NCc2ccc(Oc3c(N)cccc3Cl)cc2)cc1', 'NS(=O)(=O)c1ccc(C(=O)n2[nH]c(=O)c3cc([N+](=O)[O-])ccc3c2=O)cc1', 'Cc1c(C)c2ccc(OCC3CCCN(CCCO)C3)cc2oc1=O', 'CCOc1ccc(Cc2nc3cc(C(=O)NCCCCCNc4c5c(nc6ccccc46)CCCC5)ccc3n2CCC(C)C)cc1', 'Cc1cc(C)c(S(=O)(=O)Nc2ccc(C3C4=C(CC(C)(C)CC4=O)N(c4ccc(Br)cc4)C4=C3C(=O)CC(C)(C)C4)cc2)c(C)c1', 'Cc1cc(C)c(S(=O)(=O)Nc2ccc(C3C4=C(CC(C)(C)CC4=O)N(c4ccc(Br)cc4)C4=C3C(=O)CC(C)(C)C4)cc2)c(C)c1', 'Oc1ccc(/C=N/C2CCN(Cc3ccccc3)CC2)cc1', 'COc1c(C(=O)CCC2CCN(CC3CCCCC3)CC2)ccc2[nH]ccc12', 'COc1ccc(CNC(=O)C2CCN(C(=O)c3ccccc3)CC2)cc1OC', 'Cc1ccc2oc(-c3ccc(OCCCCCCN4CCCCCC4)cc3)cc(=O)c2c1', 'CCOc1ccc(Cc2nc3cc(C(=O)N(CC)CC)ccc3n2CCCCCCNc2c3c(nc4ccccc24)CCCC3)cc1', 'CCOc1ccc(Cc2nc3cc(C(=O)N(CC)CC)ccc3n2CCCCCCNc2c3c(nc4ccccc24)CCCC3)cc1', 'CCOc1ccc(Cc2nc3cc(C(=O)N(CC)CC)ccc3n2CCCCCCNc2c3c(nc4ccccc24)CCCC3)cc1', 'O=C(O)CC1(CC(=O)c2cc(O)ccc2O)C=C(CO)CCC1', 'CCOc1ccc(Cc2nc3cc(C(=O)N(CC)CC)ccc3n2CCOCCOCCNc2c3c(nc4ccccc24)CCCC3)cc1', 'Cl.Cl.N[C@@H](Cc1c[nH]c2ccccc12)C(=O)NCCCCCCCCNc1c2c(nc3ccccc13)CCCC2', 'Cc1c(C)c2ccc(OCC3CCCN(Cc4ccccc4)C3)cc2oc1=O.Cl', 'c1ccc2c(NCc3ccc(-c4ccc(CNc5c6c(nc7ccccc57)CCCC6)cc4)cc3)c3c(nc2c1)CCCC3', 'CCOc1ccc(Cc2nc3cc(C(=O)N(CC)CC)ccc3n2CCNc2c3c(nc4ccccc24)CCCC3)cc1', 'S=C(NCc1ccccc1)NNc1c2c(nc3ccccc13)CCCC2', 'S=C(NCc1ccccc1)NNc1c2c(nc3ccccc13)CCCC2', 'S=C(NCc1ccccc1)NNc1c2c(nc3ccccc13)CCCC2', 'Cc1cccc(CNC2CCN(Cc3ccccc3)CC2)c1', 'CCOc1ccc(Cc2nc3cc(C(=O)N(CC)CC)ccc3n2CCCNc2c3c(nc4ccccc24)CCCC3)cc1', 'NS(=O)(=O)c1ccc(NC(=S)NNc2c3c(nc4ccccc24)CCCC3)cc1', 'Cl.Cl.N[C@@H](Cc1c[nH]c2ccccc12)C(=O)NCCCCNc1c2c(nc3ccccc13)CCCC2', 'Cc1c(C)c2ccc(OCC3CCN(Cc4cccc(CO[N+](=O)[O-])c4)CC3)cc2oc1=O', 'Cl.Cl.N[C@@H](Cc1c[nH]c2ccccc12)C(=O)NCCNc1c2c(nc3ccccc13)CCCC2', 'COc1ccc(-c2cc3c(c(=O)o2)C[C@]2(O)[C@@]4(C)CC[C@@H](O)C(C)(C)[C@]4(O)CC[C@@]2(C)O3)cc1', 'O=C(CCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2)NC12CC3CC(F)(CC(C1)c1ccccc13)C2', 'Cc1c(C)c2ccc(OCC3CCN(CCCO)CC3)cc2oc1=O', 'Cc1c(C)c2ccc(OCC3CCN(CCCO)CC3)cc2oc1=O', 'CCOc1ccc(Cc2nc3cc(C(=O)NCCCCNc4c5c(nc6ccccc46)CCCC5)ccc3n2CCC(C)C)cc1', 'O=C1N/C(=N\\\\c2ccc3oc(=O)ccc3c2)S/C1=C/c1ccc(Cl)cc1', 'COc1ccc(C2=NN(C(C)=O)C(c3ccc(N4CCN(Cc5ccccc5)CC4)cc3)C2)cc1OC', 'COc1ccc(/C=C2/S/C(=N/c3ccc4oc(=O)ccc4c3)NC2=O)cc1', 'Cl.Cl.N[C@@H](Cc1c[nH]c2ccccc12)C(=O)NCCCCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'COc1cc2oc(-c3ccc(NCCCNc4c5c(nc6cc(Cl)ccc46)CCCC5)cc3)cc(=O)c2c(OC)c1OC', 'C(=N/Nc1c2c(nc3ccccc13)CCCC2)\\\\c1ccc(OCc2cn(Cc3ccccc3)nn2)cc1.Cl', 'COC(=O)/C(=C\\\\C(=O)c1cc(O)ccc1O)CC/C=C(\\\\C)CCC=C(C)C', 'COc1cc(NCc2ccc(Oc3c(N)cccc3Cl)cc2)cc(OC)c1', 'O=C(c1c(F)ccc(F)c1F)n1nc(OCCN2CCCCC2)c2ccccc21', 'O=C(CNc1ccc2oc(=O)ccc2c1)N1CCN(c2ccccc2)CC1', 'COc1ccc2nc3c(c(NCCCCCCNC(=O)[C@@H](N)Cc4c[nH]c5ccccc45)c2c1)CCCC3.Cl.Cl', 'Cc1ccc2[nH]c3c(c2c1)CN(CCCCCN1CCc2[nH]c4ccc(C)cc4c2C1)CC3', 'Oc1ccccc1/C=N/C1CCN(Cc2ccccc2)CC1', 'COc1ccc2nc3c(c(NCCCCCNC(=S)NC45CC6CC(CC(C6)C4)C5)c2c1)CCCC3', 'FC12CC3CC(NCCCCNc4c5c(nc6cc(Cl)ccc46)CCCC5)(CC(C1)c1ccccc13)C2', 'Cc1c(C)c2ccc(OCC3CCN(Cc4cccc(OCCCO)c4)CC3)cc2oc1=O', 'NC12CC3CC(F)(CC(C1)c1cc(NC(=O)CCCNc4c5c(nc6cc(Cl)ccc46)CCCC5)ccc13)C2', 'COc1ccc2nc3c(c(NCCCCCNC(=O)[C@@H](N)Cc4c[nH]c5ccccc45)c2c1)CCCC3.Cl.Cl', 'Fc1ccc2[nH]c3c(c2c1)C[PH](Cc1cccc2ccccc12)(c1ccccc1)CC3', 'Cc1cc(C)c(C(=O)n2nc(OCCN3CCCCC3)c3ccccc32)c(C)c1', 'C#CCNC1CCc2cc(Cl)c(OC(=O)N(C)CCC)cc21', 'CCOc1ccc(Cc2nc3cc(C(=O)N(CC)CC)ccc3n2CCCCNc2c3c(nc4ccccc24)CCCC3)cc1', 'O=C(CNc1ccc2oc(=O)ccc2c1)N1CCOCC1', 'Cc1ccc2oc(-c3ccc(OCCCCCCN4CCCCC4)cc3)cc(=O)c2c1', 'Cc1ccc2oc(-c3ccc(OCCCCCCN4CCCCC4)cc3)cc(=O)c2c1', 'Cc1ccc2oc(-c3ccc(OCCCCCCN4CCCCC4)cc3)cc(=O)c2c1', 'COc1ccc(CCOCCCCCNc2c3c(nc4ccccc24)CCCC3)cc1', 'COc1ccc2nc3c(c(NCCCCNC(=O)[C@@H](N)Cc4c[nH]c5ccccc45)c2c1)CCCC3.Cl.Cl', 'O=C(/C=C/c1ccccc1)c1ccc(OCCCCCCN2CCCC2)cc1O', 'O=C(NNC(=S)Nc1ccc(Cl)c(Cl)c1)c1ccccc1O', 'COc1ccc(-c2nc(NC(=O)C3CCN(Cc4cc(F)cc(F)c4)CC3)sc2-c2ccc(OC)cc2)cc1', 'O=C(Cc1cc(=O)oc2cc(O)ccc12)NCCCNCCNCCCNc1c2c(nc3ccccc13)CCCC2', 'Nc1cccc(Cl)c1Oc1ccc(CNc2ccc(O)cc2)cc1', 'O=C(CNc1ccc(F)cc1)Nc1ccc2oc(=O)ccc2c1', 'O=c1ccc2cc(/N=C/c3ccc(Br)cc3)ccc2o1', 'O=C(Nc1cc(COCc2cn(CCNc3c4c(nc5ccccc35)CCCC4)nn2)ccn1)Nc1cccc2c1C1CCCCN1C2=O', 'Fc1ccc(CN2CCC(Nc3nc(-c4ccc(Cl)cc4)c(-c4ccc(Cl)cc4)s3)CC2)c(Cl)c1', 'Fc1ccc(/C=N/C2CCN(Cc3ccccc3)CC2)cc1', 'Cc1ccc(-c2nc(NC3CCN(Cc4ccccc4)CC3)sc2-c2ccc(C)cc2)cc1', 'O=C1N/C(=N\\\\c2ccc3oc(=O)ccc3c2)S/C1=C/c1ccc(Br)cc1', 'CSc1ccc(C2SCC(=O)N2c2ccc3oc(=O)ccc3c2)cc1', 'Brc1ccc(-c2nnn3c2C2c4ccccc4CCN2Cc2ccccc2-3)cc1', 'COc1ccc(-c2nc(NC(=O)C3CCN(Cc4ccc(F)cc4)CC3)sc2-c2ccc(OC)cc2)cc1', 'COc1ccc(/C=N/c2ccc3oc(=O)ccc3c2)cc1', 'Oc1cc(/C=N/c2c3c(nc4ccccc24)CCCC3)cc(O)c1O', 'O=C(/C=C/c1ccc(OCc2ccccc2)cc1)NCCNc1c2c(nc3ccccc13)CCCC2', 'CC1=C[C@@H]2Cc3nc4cc(F)ccc4c(N)c3[C@H](C1)C2', 'NS(=O)(=O)c1ccc(C(=O)n2[nH]c(=O)c3c([N+](=O)[O-])cccc3c2=O)cc1', 'COc1ccc(NC(=S)NNc2c3c(nc4ccccc24)CCCC3)cc1', 'COc1cc(N)c(Cl)cc1C(=O)CCC1CCN(Cc2ccc(O)c(O)c2)CC1', 'COc1c(C(=O)CCC2CCN(Cc3ccccc3)CC2)cc(Cl)c2[nH]ccc12', 'Brc1ccc(-n2cc(COc3ccc(/C=N/Nc4c5c(nc6ccccc46)CCCC5)cc3)nn2)cc1.Cl', 'Clc1ccc(/C=N/C2CCN(Cc3ccccc3)CC2)cc1', 'COc1ccc(-c2nc(NC(=O)C3CCN(Cc4ccccc4C(F)(F)F)CC3)sc2-c2ccc(OC)cc2)cc1', 'COc1cc(CN2CCC(CCC(=O)c3cc(Cl)c(N)cc3OC)CC2)ccc1O', 'COc1ccc(-c2nc(NCC3CCN(Cc4ccccc4C(F)(F)F)CC3)sc2-c2ccc(OC)cc2)cc1', 'O=C(CCC1CCN(CC2CCCCC2)CC1)c1ccc2[nH]ccc2c1', 'Fc1cc(F)cc(CN2CCC(CNc3nc(-c4ccc(Cl)cc4)c(-c4ccc(Cl)cc4)s3)CC2)c1', 'O=C(Nc1nc(-c2ccc(Cl)cc2)c(-c2ccc(Cl)cc2)s1)C1CCN(Cc2ccc(F)cc2Cl)CC1', 'Cc1ccccc1CN1CCC(CNc2nc(-c3ccc(Cl)cc3)c(-c3ccc(Cl)cc3)s2)CC1', 'Cc1c(C)c2ccc(OCC3CCN(CCCO[N+](=O)[O-])CC3)cc2oc1=O', 'Oc1ccc(CCOCCCCCNc2c3c(nc4ccccc24)CCCC3)cc1', 'O=C(Nc1nc(-c2ccc(Cl)cc2)c(-c2ccc(Cl)cc2)s1)C1CCN(Cc2cc(F)cc(F)c2)CC1', 'Cc1ccc(-c2nc(NCC3CCN(Cc4ccccc4C(F)(F)F)CC3)sc2-c2ccc(C)cc2)cc1', 'COc1ccc(-c2cc(=O)c3cc(OC)c(O)c([C@@H]4CCC(=O)N4)c3o2)cc1', 'Cc1ccc(-c2nc(NCC3CCN(Cc4cc(F)cc(F)c4)CC3)sc2-c2ccc(C)cc2)cc1', 'O=C(/C=C/c1ccc([N+](=O)[O-])cc1)NCCCCCCNc1c2c(nc3ccccc13)CCCC2', 'Fc1ccc(CN2CCC(CNc3nc(-c4ccc(Cl)cc4)c(-c4ccc(Cl)cc4)s3)CC2)c(C(F)(F)F)c1', 'Cc1ccc(-c2nc(NC(=O)C3CCN(Cc4ccccc4C(F)(F)F)CC3)sc2-c2ccc(C)cc2)cc1', 'COc1cc2ncnc(NCc3cn(CC4CCN(Cc5ccccc5)CC4)nn3)c2cc1OC', 'COc1cc(/C=C/C(=O)NCCNc2c3c(nc4ccccc24)CCCC3)ccc1OCc1ccccc1', 'Cc1ccc(-c2nc(NC(=O)C3CCN(Cc4cc(F)cc(F)c4)CC3)sc2-c2ccc(C)cc2)cc1', 'Oc1ccc(CNc2c3c(nc4ccccc24)CCCC3)cc1O', 'Cc1ccc(-c2nc(NC(=O)C3CCN(Cc4ccc(C#N)cc4)CC3)sc2-c2ccc(C)cc2)cc1', 'Oc1ccc(/C=N/c2c3c(nc4ccccc24)CCCC3)cc1O', 'COc1ccc2[nH]cc(CCNC(=O)CN(CCC3CCN(Cc4ccccc4)CC3)C(=O)/C=C/c3ccc(O)c(OC)c3)c2c1', 'O=C(Nc1cccc(-c2cn(CCNc3c4c(nc5ccccc35)CCCC4)nn2)n1)Nc1cccc2c1C1CCCCN1C2=O', 'COc1c(C(=O)CCC2CCN(CC3CCCCC3)CC2)cc(Cl)c2[nH]ccc12', 'O=C(/C=C/c1ccc(OCCCCCCN2CCCC2)cc1)c1ccc(OCCCCCCN2CCCC2)cc1O', 'C(=N/C1CCN(Cc2ccccc2)CC1)\\\\c1ccccc1', 'O=c1ccc2cc(/N=C/c3ccccc3)ccc2o1', 'COc1ccc2nc3c(c(NCCNC(=O)[C@@H](N)Cc4c[nH]c5ccccc45)c2c1)CCCC3.Cl.Cl', 'Cl.c1ccc(CCCCN2CCCc3[nH]c4ccccc4c3C2)cc1', 'O=C(c1ccccc1Cl)n1nc(OCCCN2CCCCC2)c2ccccc21', 'COc1c(C(=O)CCC2CCN(Cc3ccccc3)CC2)cc(Cl)c2[nH]c([Si](C)(C)C)cc12', 'Cl.Cl.N[C@@H](Cc1c[nH]c2ccccc12)C(=O)NCCCCCCNc1c2c(nc3ccccc13)CCCC2', 'CN(C)c1ccc(/C=C2/S/C(=N/c3ccc4oc(=O)ccc4c3)NC2=O)cc1', 'Cc1ccc(CN2CCC(Nc3nc(-c4ccc(C)cc4)c(-c4ccc(C)cc4)s3)CC2)cc1', 'O=C(c1ccccc1Cl)n1nc(OCCN2CCCC2)c2ccccc21', 'COc1ccc2[nH]cc(CCNC(=O)CN(CCCC3CCN(Cc4ccccc4)CC3)C(=O)/C=C/c3ccc(O)c(OC)c3)c2c1', 'COc1c(C(=O)CCC2CCN(CC3CCCCC3)CC2)cc(Cl)c2c1ccn2Cc1ccccc1', 'Cl.Cl.N[C@@H](Cc1c[nH]c2ccccc12)C(=O)NCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'NS(=O)(=O)c1ccc(C(=O)n2[nH]c(=O)c3ccc(C(=O)O)cc3c2=O)cc1', 'C#CCOc1ccc(/C=N/Nc2c3c(nc4ccccc24)CCCC3)cc1.Cl', 'O=C1N/C(=N\\\\c2ccc3oc(=O)ccc3c2)S/C1=C/c1ccc(F)cc1', 'COc1ccc(-c2nc(NC3CCN(Cc4ccc(C(F)(F)F)cc4)CC3)sc2-c2ccc(OC)cc2)cc1', 'COc1cc2c(cc1OC)-c1cc(OCCN3CCCCC3)nc(=O)n1CC2', 'CCOc1ccc(Cc2nc3cc(C(=O)N(CC)CCCCNc4c5c(nc6ccccc46)CCCC5)ccc3n2CCC(C)C)cc1', 'c1ccc(COc2ccc(CCOCCCCCNc3c4c(nc5ccccc35)CCCC4)cc2OCc2ccccc2)cc1', 'N#Cc1ccccc1CN1CCC(C(=O)Nc2nc(-c3ccc(Cl)cc3)c(-c3ccc(Cl)cc3)s2)CC1', 'COc1cc2c(cc1O)C(Cc1ccc(O)c(Oc3cc(CC4c5cc(O)c(OC)cc5CCN4C)ccc3OC)c1)N(C)CC2', 'O=C(Nc1nc(-c2ccc(Cl)cc2)c(-c2ccc(Cl)cc2)s1)C1CCN(Cc2ccc(OC(F)(F)F)cc2)CC1', 'Cc1ccc(-c2nc(NCC3CCN(Cc4ccc(F)cc4)CC3)sc2-c2ccc(C)cc2)cc1', 'COc1ccc(-c2nc(NC(=O)C3CCN(Cc4ccc(F)cc4C(F)(F)F)CC3)sc2-c2ccc(OC)cc2)cc1', 'COc1ccc(CN2CCC(Nc3nc(-c4ccc(Cl)cc4)c(-c4ccc(Cl)cc4)s3)CC2)cc1', 'Cl.Cl.N[C@@H](Cc1c[nH]c2ccccc12)C(=O)NCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'COc1ccc2nc3c(c(NCCCCCCCCN(CC(=O)Nc4ccc5ccccc5c4)C(=O)/C=C/c4ccc(O)c(OC)c4)c2c1)CCCC3', 'COc1ccc(-n2cc(COc3ccc(/C=N/Nc4c5c(nc6ccccc46)CCCC5)cc3)nn2)cc1.Cl', 'CN1c2ccc(OC(=O)NCCCCCCN3CCCCC3)cc2CN2CCc3ccccc3C21', 'CN1c2ccc(OC(=O)NCCCCCCN3CCCCC3)cc2CN2CCc3ccccc3C21', 'Fc1ccc(CN2CCC(CNc3nc(-c4ccc(Cl)cc4)c(-c4ccc(Cl)cc4)s3)CC2)c(Cl)c1', 'COc1ccc(CCOCCCCCNc2c3c(nc4ccccc24)CCCC3)cc1OC', 'COc1ccc(-c2nc(NC3CCN(Cc4ccc(C)cc4)CC3)sc2-c2ccc(OC)cc2)cc1', 'Cl.Cl.N[C@@H](Cc1c[nH]c2ccccc12)C(=O)NCCCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'CCOc1ccc(Cc2nc3cc(C(=O)NCCOCCOCCNc4c5c(nc6ccccc46)CCCC5)ccc3n2CCC(C)C)cc1', 'Nc1cccc(Cl)c1Oc1ccc(CNc2cccc(O)c2)cc1', 'Cl.Cl.N[C@@H](Cc1c[nH]c2ccccc12)C(=O)NCCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'Cl.Cl.N[C@@H](Cc1c[nH]c2ccccc12)C(=O)NCCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'COc1ccc2nc3c(c(NCCCNC(=O)[C@@H](N)Cc4c[nH]c5ccccc45)c2c1)CCCC3.Cl.Cl', 'Cl.Cl.N[C@@H](Cc1c[nH]c2ccccc12)C(=O)NCCCCCNc1c2c(nc3ccccc13)CCCC2', 'C=CCNC(=S)NNc1c2c(nc3ccccc13)CCCC2', 'COc1cc(O)c(C(C)=O)c(-c2c(C)cc(O)c3oc4c(O)cc(C)c(-c5cc(OC)cc(O)c5C(=O)O)c4c23)c1', 'Oc1ccc(/C=N/C2CCN(Cc3ccccc3)CC2)c(O)c1', 'Cl.O=C(O)c1ccc(-n2cc(COc3ccc(/C=N/Nc4c5c(nc6ccccc46)CCCC5)cc3)nn2)cc1', 'CCOc1ccc2[nH]c(SCc3cn(CC4CCN(Cc5ccccc5)CC4)nn3)nc2c1', 'CCOc1ccc(Cc2nc3cc(C(=O)NCCCCCCNc4c5c(nc6ccccc46)CCCC5)ccc3n2CCC(C)C)cc1', 'FC12CC3CC(NCCCCCNc4c5c(nc6cc(Cl)ccc46)CCCC5)(CC(C1)c1ccccc13)C2', 'Cl.Cl.N[C@@H](Cc1c[nH]c2ccccc12)C(=O)NCCCCCCCNc1c2c(nc3ccccc13)CCCC2', 'Cl.Cl.NC(Cc1c[nH]c2ccccc12)C(=O)NCCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'COc1ccc(-c2nc(NCC3CCN(Cc4c(F)cccc4Cl)CC3)sc2-c2ccc(OC)cc2)cc1', 'COc1c(C(=O)CCC2CCN(CC3CCCCC3)CC2)cc(Cl)c2c1ccn2C', 'O=C(Nc1cc(-c2cn(CCNc3c4c(nc5ccccc35)CCCC4)nn2)ccn1)Nc1cccc2c1C1CCCCN1C2=O', 'Cc1ccc(-c2nc(NCC3CCN(Cc4ccccc4C)CC3)sc2-c2ccc(C)cc2)cc1', 'C/C(=C/CC[C@H](CO)c1cc2cc(O)c(O)cc2o1)CO', 'Oc1ccc(CNC2CCN(Cc3ccccc3)CC2)cc1', 'O=C(CCC1CCN(CC2CCCC2)CC1)c1ccc2[nH]ccc2c1', 'COc1ccc(CN2CCC(Nc3nc(-c4ccc(OC)cc4)c(-c4ccc(OC)cc4)s3)CC2)cc1', 'Cl.Cl.N[C@@H](Cc1c[nH]c2ccccc12)C(=O)NCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'O=C(c1cccc(F)c1F)n1nc(OCCN2CCCC2)c2ccccc21', 'COc1ccc(C2SCC(=O)N2c2ccc3oc(=O)ccc3c2)cc1', 'Cc1ccc(/C=N/C2CCN(Cc3ccccc3)CC2)cc1', 'Cc1ccccc1CN1CCC(C(=O)Nc2nc(-c3ccc(Cl)cc3)c(-c3ccc(Cl)cc3)s2)CC1', 'COc1ccc(-c2nc(NCC3CCN(Cc4ccccc4C)CC3)sc2-c2ccc(OC)cc2)cc1', 'COc1ccc2nc3c(c(NCCCCCCCCNC(=S)NC45CC6CC(CC(C6)C4)C5)c2c1)CCCC3', 'CCCCN1CCC(CCC(=O)c2ccc3[nH]ccc3c2)CC1', 'COc1cccc(NCc2ccc(Oc3c(N)cccc3Cl)cc2)c1', 'Clc1ccc(/C=N/C2CCN(Cc3ccccc3)CC2)c(Cl)c1', 'Fc1ccc(/C=N/C2CCN(Cc3ccccc3)CC2)c(F)c1', 'CC[C@@H](CN1CCCC1=O)C(=O)NCCCCCCCNc1c2c(nc3cc(Cl)ccc13)C[C@H]1C=C(C)C[C@@H]2C1', 'COc1cc2oc(-c3ccc(NCCCCNc4c5c(nc6cc(Cl)ccc46)CCCC5)cc3)cc(=O)c2c(OC)c1OC', 'COc1ccc(-c2nc(NC(=O)C3CCN(Cc4c(F)cccc4Cl)CC3)sc2-c2ccc(OC)cc2)cc1', 'O=c1ccc2cc(/N=C/c3ccc(F)cc3)ccc2o1', 'COc1cc(O)c2c(c1)C1=C(c3c(O)c(O)cc(C)c3-c3cc(OC)cc(O)c3C(=O)O)C(=O)C(O)=CC1(C)OC2=O', 'COc1ccc(-c2nc(NC(=O)C3CCN(Cc4cccc(F)c4)CC3)sc2-c2ccc(OC)cc2)cc1', 'Cc1c(C)c2ccc(OCC3CCCN(Cc4ccccc4)C3)cc2oc1=O', 'Cc1c(C)c2ccc(OCC3CCCN(Cc4ccccc4)C3)cc2oc1=O', 'Cc1c(C)c2ccc(OCC3CCCN(Cc4ccccc4)C3)cc2oc1=O', 'Cc1ccc(-c2nc(NC(=O)C3CCN(Cc4ccc([N+](=O)[O-])cc4)CC3)sc2-c2ccc(C)cc2)cc1', 'Oc1ccc(CNCCCCCCNc2c3c(nc4ccccc24)CCCC3)cc1O', 'Cc1ccc(-c2nc(NC(=O)C3CCN(Cc4c(F)cccc4Cl)CC3)sc2-c2ccc(C)cc2)cc1', 'O=C1c2ccccc2C(=O)N1Cc1cn(CC2CCN(Cc3ccccc3)CC2)nn1', 'FC(F)(F)c1ccc(/C=N/C2CCN(Cc3ccccc3)CC2)cc1', 'Clc1ccc(-c2nc(NC3CCN(Cc4ccccc4)CC3)sc2-c2ccc(Cl)cc2)cc1', 'COc1ccc(C2=NN(C(C)=O)C(c3ccc(N4CCC(Cc5ccccc5)CC4)cc3)C2)cc1OC', 'COc1ccc(C2CC(=O)c3ccc4c(c3O2)C=CC(C)(C)O4)cc1', 'Cc1c(C)c2ccc(OCC3CCN(Cc4cccc(OCCCO[N+](=O)[O-])c4)CC3)cc2oc1=O', 'O=C(CCC1CCN(CC2CCCCC2)CC1)c1ccc2c(ccn2Cc2ccccc2)c1', 'NS(=O)(=O)c1ccc(C(=O)n2[nH]c(=O)c3c(F)cccc3c2=O)cc1', 'Oc1ccc2[nH]c3c(c2c1)C[PH](Cc1cccc2ccccc12)(c1ccccc1)CC3', 'C#CCNC1CCCc2ccc(OC(=O)N(C)CC)cc21', 'S=C(NNc1c2c(nc3ccccc13)CCCC2)Nc1ccccc1', 'COc1ccc2nc3c(c(NCCCCCCCCNC(=O)[C@@H](N)Cc4c[nH]c5ccccc45)c2c1)CCCC3.Cl.Cl', 'COc1ccc(C2=NN(C(C)=O)C(c3ccc(N4CCN(C)CC4)cc3)C2)cc1OC', 'COc1ccc(C2=NN(C(C)=O)C(c3ccc(N4CCN(C)CC4)cc3)C2)cc1OC', 'CN1c2ccc(OC(=O)NCCCCCCN3CCCC3)cc2CN2CCc3ccccc3C21', 'CN1c2ccc(OC(=O)NCCCCCCN3CCCC3)cc2CN2CCc3ccccc3C21', 'FC(F)(F)c1ccc(CNC2CCN(Cc3ccccc3)CC2)cc1', 'FC(F)(F)c1ccc(CNC2CCN(Cc3ccccc3)CC2)cc1', 'O=C(Nc1ccc(-c2cn(CCNc3c4c(nc5ccccc35)CCCC4)nn2)cn1)Nc1cccc2c1C1CCCCN1C2=O', 'CCOc1ccc(Cc2nc3cc(C(=O)N(CC)CC)ccc3n2CCCCCNc2c3c(nc4ccccc24)CCCC3)cc1', 'COc1c(C(=O)CCC2CCN(CC3CCCCC3)CC2)cc(Cl)c2c1ccn2S(=O)(=O)c1ccccc1.O=C(O)/C=C/C(=O)O', 'O=C(CCC1CCN(Cc2ccccc2)CC1)c1ccc2[nH]ccc2c1', 'COc1ccc2nc3c(c(NCCCCCCCNC(=O)[C@@H](N)Cc4c[nH]c5ccccc45)c2c1)CCCC3.Cl.Cl', 'COc1ccc(-c2nc(NC(=O)C3CCN(Cc4ccccc4C#N)CC3)sc2-c2ccc(OC)cc2)cc1', 'FC(F)(F)Oc1ccc(CNC2CCN(Cc3ccccc3)CC2)cc1', 'Cc1ccc(CN2CCC(Nc3nc(-c4ccc(Cl)cc4)c(-c4ccc(Cl)cc4)s3)CC2)cc1', 'c1ccc(COc2ccc(CCOCCCCCNc3c4c(nc5ccccc35)CCCC4)cc2)cc1', 'CCOc1ccc(Cc2nc3cc(C(=O)NCCNc4c5c(nc6ccccc46)CCCC5)ccc3n2CCC(C)C)cc1', 'O=C(c1cccc(Cl)c1Cl)n1nc(OCCCN2CCCCC2)c2ccccc21', 'Cc1c(OCc2ccccc2)cccc1N1CCN(CCCCCCNc2c3c(nc4c2CCCC4)CCCC3)CC1', 'Oc1ccc(CCOCCCCCNc2c3c(nc4ccccc24)CCCC3)cc1O', 'CCN(CC)Cc1cc2cc(c1O)Oc1ccc(cc1)C[C@H]1c3cc(c(OC)cc3CCN1C)Oc1c(OC)c(OC)cc3c1[C@@H](C2)N(C)CC3', 'NC12CC3CC(F)(CC(C1)c1cc(NC(=O)CCCCNc4c5c(nc6cc(Cl)ccc46)CCCC5)ccc13)C2', 'COc1cc(CNC2CCN(Cc3ccccc3)CC2)cc(OC)c1OC', 'Cc1cc(Nc2nccc(-c3sc(C4CCNCC4)nc3-c3ccc(F)cc3)n2)ccn1', 'COc1ccccc1CN1CCN(CCCCCOc2cccc3[nH]c4ccccc4c23)CC1', 'O=C(Nc1nc(-c2ccc(Cl)cc2)c(-c2ccc(Cl)cc2)s1)C1CCN(Cc2cccc(F)c2)CC1', 'Cc1ccc(-n2cc(COc3ccc(/C=N/Nc4c5c(nc6ccccc46)CCCC5)cc3)nn2)cc1.Cl', 'O=C(Nc1nc(-c2ccc(Cl)cc2)c(-c2ccc(Cl)cc2)s1)C1CCN(Cc2ccccc2C(F)(F)F)CC1', 'O=C(Nc1cc(CCc2cn(CCNc3c4c(nc5ccccc35)CCCC4)nn2)ccn1)Nc1cccc2c1C1CCCCN1C2=O', 'COc1ccc(-c2nc(NC(=O)C3CCN(Cc4ccccc4C)CC3)sc2-c2ccc(OC)cc2)cc1', 'N#Cc1ccc(CN2CCC(Nc3nc(-c4ccc(Cl)cc4)c(-c4ccc(Cl)cc4)s3)CC2)cc1', 'CCN1CCN(c2ccc(C3CC(c4ccc(OC)c(OC)c4)=NN3C(C)=O)cc2)CC1', 'Cc1c(C)c2ccc(OCC3CCN(Cc4ccccc4)CC3)cc2oc1=O', 'COc1ccc([C@H]2OC[C@H]3[C@@H]2C(=O)O[C@@H]3c2ccc3c(c2)OCO3)cc1OC', 'O=C1CN(/N=C/c2ccc(-c3cccc([N+](=O)[O-])c3)o2)C(=O)N1CCC1CCN(Cc2ccccc2)CC1', 'O=[N+]([O-])C1C(Cc2c[nH]cn2)NC2(c3ccccc3-c3nc4ccccc4nc32)C1c1ccccc1', 'C#CCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'O=[N+]([O-])C1C(Cc2c[nH]cn2)NC2(c3ccccc3-c3nc4ccccc4nc32)C1c1ccco1', 'COc1cccc(-c2ccc(/C=N/N3CC(=O)N(CCC4CCN(Cc5ccccc5)CC4)C3=O)o2)c1', 'COc1ccc([C@H]2O[C@@H](O)[C@H]3[C@@H]2C(=O)O[C@@H]3c2ccc(OC)c(OC)c2)cc1OC', 'C#CCNc1c2c(nc3ccccc13)CCCC2', 'COc1ccc([C@H]2OC(=O)[C@H]3[C@@H]2C(=O)O[C@@H]3c2ccc3c(c2)OCO3)cc1OC', 'Cc1cccc(C2C([N+](=O)[O-])C(Cc3c[nH]cn3)NC23c2ccccc2-c2nc4ccccc4nc23)c1', 'COc1c2c(cc3c1OCO3)[C@]13C=C[C@H](OC)C[C@@H]1[N@](C2)C[C@H]3OC(=O)c1ccccc1[N+](=O)[O-]', 'COc1ccc([C@H]2O[C@@H](O)[C@H]3[C@@H]2C(=O)O[C@@H]3c2cc(OC)c3c(c2)OCO3)cc1OC', 'O=C1CN(/N=C/c2ccc(-c3ccc([N+](=O)[O-])cc3)o2)C(=O)N1CCC1CCN(Cc2ccccc2)CC1', 'O=[N+]([O-])C1C(Cc2c[nH]cn2)NC2(c3ccccc3-c3nc4ccccc4nc32)C1c1ccccn1', 'CC(C)=CC[C@H]1C[C@]2(CC=C(C)C)C(=O)[C@]3(CC=C(C)C)O[C@@]1(C(=O)C(C)C)[C@@]2(O)C(C)(C)C3=O', 'COc1cc2cc(NC(=O)CCCNCc3ccccc3)c(=O)oc2cc1OC', 'COc1ccc(-c2ccc(/C=N/N3CC(=O)N(CCC4CCN(Cc5ccccc5)CC4)C3=O)o2)cc1', 'COc1cccc(C2C([N+](=O)[O-])C(Cc3c[nH]cn3)NC23c2ccccc2-c2nc4ccccc4nc23)c1', 'Cc1ccc(C2C([N+](=O)[O-])C(Cc3c[nH]cn3)NC23c2ccccc2-c2nc4ccccc4nc23)cc1', 'O=C1CN(/N=C/c2ccc(-c3ccc([N+](=O)[O-])cc3)o2)C(=O)N1CCN1CCN(Cc2ccccc2)CC1', 'COc1c2c(cc3c1OCO3)[C@]13C=C[C@H](OC)C[C@@H]1[N@](C2)C[C@H]3OC(=O)c1ccccc1C', 'COc1ccccc1-c1ccc(/C=N/N2CC(=O)N(CCC3CCN(Cc4ccccc4)CC3)C2=O)o1', 'COc1ccc(C2C([N+](=O)[O-])C(Cc3c[nH]cn3)NC23c2ccccc2-c2nc4ccccc4nc23)cc1', 'COc1ccccc1C1C([N+](=O)[O-])C(Cc2c[nH]cn2)NC12c1ccccc1-c1nc3ccccc3nc12', 'O=C1CN(/N=C/c2ccc(-c3ccccc3[N+](=O)[O-])o2)C(=O)N1CCC1CCN(Cc2ccccc2)CC1', 'Cc1ccccc1C1C([N+](=O)[O-])C(Cc2c[nH]cn2)NC12c1ccccc1-c1nc3ccccc3nc12', 'COc1ccc(CCC(=O)Nc2nc(-c3cc4ccccc4oc3=O)cs2)cc1OC', 'COc1cc2cc(NC(=O)C3CCN(Cc4ccccc4)CC3)c(=O)oc2cc1OC', 'O=[N+]([O-])C1C(Cc2c[nH]cn2)NC2(c3ccccc3-c3nc4ccccc4nc32)C1c1ccc(Cl)cc1', 'COc1c2c(cc3c1OCO3)[C@]13C=C[C@H](OC)C[C@@H]1[N@](C2)C[C@H]3OC(=O)c1cccc([N+](=O)[O-])c1', 'COc1ccc([C@H](O)[C@H](N)C(=O)O)cc1OC', 'O=[N+]([O-])C1C(Cc2c[nH]cn2)NC2(c3ccccc3-c3nc4ccccc4nc32)C1c1ccc(Br)cc1', 'COc1cc2cc(NC(=O)[C@@H]3CCC[C@H](NCc4ccccc4)C3)c(=O)oc2cc1OC', 'COc1cc2cc(NC(=O)[C@@H]3CCC[C@H](NCc4ccccc4)C3)c(=O)oc2cc1OC', 'CN1C[C@@H](c2cccc(Br)c2)[C@@]2(CSc3ccccc3C2=O)C12C(=O)c1ccccc1C2=O', 'CCN(CC)C(=O)Oc1ccc(/C=C/C(=O)N2CCN(Cc3ccccc3)CC2)cc1OC', 'O=C(N/N=C/c1ccc(Cl)cc1)N1CCN(c2ccccn2)CC1', 'CN1C[C@@H](c2ccc(Br)cc2)[C@@]2(CSc3ccccc3C2=O)C12C(=O)c1ccccc1C2=O', 'COc1cc(/C=C/C(=O)N2CCc3ccccc3C2)ccc1OC(=O)N(C)OC', 'Cc1cc(S(=O)(=O)Nc2cnccn2)c(C(C)C)cc1O', 'COc1cc(CNC(=O)CCCC/C=C/CNc2c3c(nc4cc(Cl)ccc24)CC2C=C(C)CC3C2)ccc1O', 'CNC(=O)c1sc(-c2ccnc(NC(=O)C3CC3)c2)nc1OCCc1cn(CCNc2c3c(nc4cc(Cl)ccc24)CCCC3)nn1', 'Brc1ccc(CNC2CCN(Cc3ccccc3)C2)cc1', 'CNC(=O)c1sc(-c2ccnc(NC(=O)C3CC3)c2)nc1OCC1CCN(Cc2ccc(F)c(F)c2)CC1', 'NC(=O)c1sc(-c2ccnc(NC(=O)C3CC3)c2)nc1OCCC1CCN(Cc2ccccc2Cl)CC1', 'O=C(CCCN1CCC2c3ccccc3NC2C1)Oc1ccc(/C=C2\\\\CCn3c2nc2ccccc2c3=O)cc1', 'CCOC(=O)c1c(C)nc(N2CCN(S(=O)(=O)c3ccc(NC(C)=O)cc3)CC2)nc1-c1ccc(OC)cc1', 'O=[N+]([O-])c1ccccc1-c1nnc(Nc2ncccn2)o1', 'COc1cc(CNC(=O)CCCCNc2c3c(nc4cc(Cl)ccc24)CC2C=C(C)CC3C2)ccc1O', 'Cc1ccc(-c2nnc(N3CCN(c4ccccn4)CC3)o2)cc1', 'COc1ccc2cc3[n+](cc2c1OCc1cccc(Br)c1)CCc1cc2c(cc1-3)OCO2.[Br-]', 'O=C(N/N=C/c1ccccc1)N1CCN(c2ccccn2)CC1', 'CCOC(=O)c1c(C)nc(N2CCN(S(=O)(=O)c3ccc(N)c(Cl)c3)CC2)nc1-c1ccc(OC)cc1', 'O=C1c2ccccc2C(=O)C12N1CSC[C@@H]1[C@@H](c1ccc(Cl)cc1)[C@@]21CSc2ccccc2C1=O', 'COc1cccc(-c2nnc(N3CCN(c4ccccn4)CC3)o2)c1OC', 'O=C(N/N=C/c1ccc([N+](=O)[O-])cc1)N1CCN(c2ccccn2)CC1', 'CN1C[C@@H](c2ccc(Cl)cc2)[C@@]2(CSc3ccccc3C2=O)C12C(=O)c1ccccc1C2=O', 'Fc1ccc(/C=N\\\\C2CCN(Cc3ccccc3)C2)c(F)c1', 'CCN(C)C(=O)Oc1cccc(CNCCc2c[nH]c3cc(F)ccc23)c1', 'COc1cc(CNC(=O)Cc2cn(CCCCC3=CC4Cc5nc6cc(Cl)ccc6c(N)c5C(C3)C4)nn2)ccc1O', 'COc1cc(/C=C/C(=O)N2CCc3ccccc3C2)ccc1OC(=O)N(c1ccccc1)c1ccccc1', 'COc1ccc(-c2nnc(Nc3ncccn3)o2)cc1', 'COc1ccc2cc3[n+](cc2c1OCc1ccc([N+](=O)[O-])cc1)CCc1cc2c(cc1-3)OCO2.[Br-]', 'COc1cc(/C=N\\\\C2CCN(Cc3ccccc3)C2)cc(OC)c1OC', 'COc1cc(-c2nnc(N3CCN(c4ccccn4)CC3)o2)cc(OC)c1OC', 'CCCCN[C@@H](Cc1c[nH]c2ccccc12)C(=O)NCCC1CCN(CC2CCN(C)CC2)CC1', 'COc1ccc2cc3[n+](cc2c1OCc1ccccc1Br)CCc1cc2c(cc1-3)OCO2.[Br-]', 'COc1ccc2cc3[n+](cc2c1OCc1ccc(C)cc1)CCc1cc2c(cc1-3)OCO2.[Br-]', 'Oc1ccc(-c2nnc(N3CCN(c4ccccn4)CC3)o2)cc1', 'CS[C@@H](Cn1nnc2cc(C#Cc3ccc(CN4CCOCC4)cc3)ccc21)N(O)C=O', 'CCCNC(=O)c1sc(-c2ccnc(NC(=O)CNCCNc3c4c(nc5ccccc35)CCCC4)c2)nc1OCC1CC1', 'CNC(=O)c1sc(-c2ccnc(NC(=O)C3CC3)c2)nc1OCC1CCN(Cc2ccc(Cl)c(Cl)c2)CC1', 'c1ccc(-c2nnc(N3CCN(c4ccccn4)CC3)o2)cc1', 'O=C(N/N=C/c1ccc(Br)cc1)N1CCN(c2ccccn2)CC1', 'CCOC(=O)c1c(C)nc(N2CCN(S(=O)(=O)c3ccc(N)c(OC)c3)CC2)nc1-c1ccc(OC)c(OC)c1', 'COc1cc2c(cc1OCc1ccccc1)CCC(C)(CC(=O)NCCCCCCCNc1c3c(nc4cc(Cl)ccc14)CCCC3)O2', 'Brc1cccc(-c2nnc(Nc3ncccn3)o2)c1', 'COc1ccc2cc3[n+](cc2c1OCc1ccc(Cl)c(Cl)c1)CCc1cc2c(cc1-3)OCO2.[Br-]', 'COc1ccc([C@@H]2CN(C)C3(C(=O)c4ccccc4C3=O)[C@]23CSc2ccccc2C3=O)cc1', 'COc1cccc(CNC2CCN(Cc3ccccc3)C2)c1OC', 'COc1ccc2cc3[n+](cc2c1OCc1ccc2ccccc2c1)CCc1cc2c(cc1-3)OCO2.[Br-]', 'CCN(C)C(=O)Oc1ccc(/C=C/C(=O)N2CCCCC2)cc1OC', 'COc1cc2c(cc1OCc1ccccc1)CCC(C)(CC(=O)NCCCCCCCCNc1c3c(nc4cc(Cl)ccc14)CCCC3)O2', 'NC(=O)c1sc(-c2ccnc(NC(=O)C3CC3)c2)nc1OCCCC1CCN(Cc2ccc(F)cc2)CC1', 'O=C(N/N=C/c1ccc(C(F)(F)F)cc1)N1CCN(c2ccccn2)CC1', 'COc1cc(CNC(=O)CCCCCCCNc2c3c(nc4cc(Cl)ccc24)CC2C=C(C)CC3C2)ccc1O', 'O=C1c2ccccc2C(=O)C12N1CSC[C@@H]1[C@@H](c1ccccc1Cl)[C@@]21CSc2ccccc2C1=O', 'CNC(=O)c1sc(-c2ccnc(NC(=O)C3CC3)c2)nc1OCC1CCN(Cc2ccccc2)CC1', 'COC(=O)c1ccc(COc2c(OC)ccc3cc4[n+](cc23)CCc2cc3c(cc2-4)OCO3)cc1.[Br-]', 'COc1cc(/C=C/C(=O)N2CCCCC2)ccc1OC(=O)N(C)C', 'NC(=O)c1sc(-c2ccnc(NC(=O)C3CC3)c2)nc1OCCCC1CCN(Cc2ccccc2F)CC1', 'COc1cc2c(cc1O)CCC(C)(CC(=O)NCCCCCCNc1c3c(nc4ccccc14)CCCC3)O2', 'Cc1cc(/C=N/O)c(O)c(CN2CCN(c3ccncc3)CC2)c1', 'Cc1cc(/C=N/O)c(O)c(CN2CCN(c3ccncc3)CC2)c1', 'CNC(=O)c1sc(-c2ccnc(NC(=O)CNCCNc3c4c(nc5ccccc35)CCCC4)c2)nc1OC', 'COc1ccc2cc3[n+](cc2c1OCc1ccc(Cl)cc1)CCc1cc2c(cc1-3)OCO2.[Br-]', 'NC(=O)c1sc(-c2ccnc(NC(=O)C3CC3)c2)nc1OCCC1CCN(Cc2ccccn2)CC1', 'CNC(=O)c1sc(-c2ccnc(NC(=O)CNCCNc3c4c(nc5ccccc35)CCCC4)c2)nc1OCC1CCC1', 'Fc1ccc(CNC2CCN(Cc3ccccc3)C2)cc1', 'CCOC(=O)c1c(C)nc(N2CCN(S(=O)(=O)c3ccc(NC(C)=O)c(Cl)c3)CC2)nc1-c1ccccc1', 'COCCn1cnc2cc(NC(=O)c3ccccc3)cc(C(=O)NCc3cc(F)cc(F)c3)c21', 'CCOC(=O)c1c(C)nc(N2CCN(S(=O)(=O)c3ccc(N)cc3)CC2)nc1-c1ccc(OC)c(OC)c1', 'CNC(=O)c1sc(-c2ccnc(NC(=O)CNCCNc3c4c(nc5ccccc35)CCCC4)c2)nc1OCC(C)C', 'CCN(C)C(=O)Oc1ccc(/C=C/C(=O)N2CCN(Cc3ccccc3)CC2)cc1', 'O=C(CCCCCN1CCC2c3ccccc3NC2C1)Oc1ccc(/C=C2\\\\CCn3c2nc2ccccc2c3=O)cc1', 'CCCCN[C@@H](Cc1c[nH]c2ccccc12)C(=O)NCCC1CCCN(Cc2ccccc2)CC1', 'COc1ccc2nc3cc(Cl)ccc3c(Nc3ccc(C(=O)NO)cc3)c2n1', 'O=C(NO)c1ccc(Nc2c3ccccc3nc3ccc(OC(F)(F)F)cc23)cc1', 'COc1cc2c(cc1O)CCC(C)(CCNCCCCCCCCNc1c3c(nc4cc(Cl)ccc14)CCCC3)O2', 'COc1cc2c(cc1O)CCC(C)(CCNCCCCCCCCNc1c3c(nc4cc(Cl)ccc14)CCCC3)O2', 'COc1cc2c(cc1O)CCC(C)(CCNCCCCCCCCNc1c3c(nc4cc(Cl)ccc14)CCCC3)O2', 'C[C@@H]1CC[C@H]2[C@H](C(=O)c3c(O)c([C@@]4(O)CC[C@@H](O)[C@H]5O[C@H]54)cn(O)c3=O)[C@H](C)C=C[C@@H]2C1', 'COc1ccc2cc3[n+](cc2c1OCc1ccc(C(F)(F)F)cc1)CCc1cc2c(cc1-3)OCO2.[Br-]', 'COc1ccc2cc3[n+](cc2c1OCc1ccc(C(F)(F)F)cc1)CCc1cc2c(cc1-3)OCO2.[Br-]', 'CCOC(=O)c1c(C)nc(N2CCN(S(=O)(=O)c3ccc(NC(C)=O)c(F)c3)CC2)nc1-c1ccc(OC)c(OC)c1', 'CNC(=O)c1sc(-c2ccnc(NC(=O)C3CC3)c2)nc1OC1CCN(Cc2ccccc2)CC1', 'COc1ccc([C@@H]2[C@H]3CSCN3C3(C(=O)c4ccccc4C3=O)[C@]23CSc2ccccc2C3=O)cc1', 'Cc1cccc(-c2nnc(N3CCN(c4ccccn4)CC3)o2)c1', 'CCOC(=O)c1c(C)nc(N2CCN(S(=O)(=O)c3ccc(NC(C)=O)c(F)c3)CC2)nc1-c1ccccc1', 'O=C(NO)c1ccc(Nc2ccnc3ccccc23)cc1', 'CO[C@]1(c2cn(O)c(=O)c(C(=O)[C@H]3[C@@H]4CC[C@@H](C)C[C@H]4C=C[C@H]3C)c2O)CC[C@@H](O)[C@H]2O[C@H]21', 'Fc1ccc(CNC2CCN(Cc3ccccc3)C2)c(F)c1', 'COc1ccc2cc3[n+](cc2c1OC(C)c1ccccc1)CCc1cc2c(cc1-3)OCO2.[Br-]', 'Cc1cc(/C=N/O)c(O)c(CNc2ccc(Cn3cncn3)cc2)c1', 'Cc1cc(/C=N/O)c(O)c(CNc2ccc(Cn3cncn3)cc2)c1', 'Cc1cc(/C=N/O)c(O)c(CNc2ccc(Cn3cncn3)cc2)c1', 'Cc1cc(/C=N/O)c(O)c(CNc2ccc(Cn3cncn3)cc2)c1', 'CNC(=O)c1sc(-c2ccnc(NC(=O)C3CC3)c2)nc1OCC1CCN(Cc2ccccc2F)CC1', 'NC(=O)c1sc(-c2ccnc(NC(=O)CNCCNc3c4c(nc5ccccc35)CCCC4)c2)nc1OCC1CC1', 'NC(=O)c1sc(-c2ccnc(NC(=O)C3CC3)c2)nc1OCC1CCN(Cc2ccccc2)CC1', 'COc1ccc2cc3[n+](cc2c1OCc1cccc(Cl)c1)CCc1cc2c(cc1-3)OCO2.[Br-]', 'COc1cc2nc3ccccc3c(Nc3ccc(C(=O)NO)cc3)c2c(OC)c1OC', 'O=C1c2ccccc2C(=O)C12N1CSC[C@@H]1[C@@H](c1ccccc1)[C@@]21CSc2ccccc2C1=O', 'O=c1ccoc2ccc(OCCCN3CCCCCC3)cc12', 'O=c1ccoc2ccc(OCCCN3CCCCCC3)cc12', 'O=C(NCCCNc1c2c(nc3ccccc13)CCCC2)c1sc(-c2ccnc(NC(=O)C3CCC3)c2)nc1OCC1CC1', 'O=[N+]([O-])c1ccc(-c2nnc(N3CCN(c4ccccn4)CC3)o2)cc1', 'COc1cc(CNC(=O)CCCCCCNc2c3c(nc4cc(Cl)ccc24)CC2C=C(C)CC3C2)ccc1O', 'COc1cc(CNC(=O)CCCCCCNc2c3c(nc4cc(Cl)ccc24)CC2C=C(C)CC3C2)ccc1O', 'COc1cc(CNC(=O)CCCCCCNc2c3c(nc4cc(Cl)ccc24)CC2C=C(C)CC3C2)ccc1O', 'COc1cc(CNC(=O)CCCCCCNc2c3c(nc4cc(Cl)ccc24)CC2C=C(C)CC3C2)ccc1O', 'CN1C[C@@H](c2ccccc2Cl)[C@@]2(CSc3ccccc3C2=O)C12C(=O)c1ccccc1C2=O', 'Oc1ccc(/C=N\\\\C2CCN(Cc3ccccc3)C2)cc1', 'FC(F)(F)Oc1ccc(/C=N\\\\C2CCN(Cc3ccccc3)C2)cc1', 'NC(=O)c1sc(-c2ccnc(NC(=O)C3CC3)c2)nc1OCCC1CCN(Cc2c(F)cccc2F)CC1', 'Fc1ccc(-c2nnc(Nc3ncccn3)o2)cc1', 'CN1C[C@@H](c2ccccc2Br)[C@@]2(CSc3ccccc3C2=O)C12C(=O)c1ccccc1C2=O', 'O=C(CCN1CCC2c3ccccc3NC2C1)Oc1ccc(/C=C2\\\\CCn3c2nc2ccccc2c3=O)cc1', 'COc1cc(/C=C/C(=O)N2CCCCC2)ccc1OC(=O)N(c1ccccc1)c1ccccc1', 'COc1cc(/C=C/C(=O)N2CCN(Cc3ccccc3)CC2)ccc1OC(=O)N(C)C', 'CCOC(=O)c1c(C)nc(N2CCN(S(=O)(=O)c3ccc(NC(C)=O)c(OC)c3)CC2)nc1-c1ccc(OC)cc1', 'CNC(=O)c1sc(-c2ccnc(NC(=O)C3CC3)c2)nc1OCCOCc1cn(CCNc2c3c(nc4cc(Cl)ccc24)CCCC3)nn1', 'NC(=O)c1sc(-c2ccnc(NC(=O)C3CC3)c2)nc1OCCC1CCN(Cc2ccc(F)c(F)c2)CC1', 'COc1ccc2cc3[n+](cc2c1OCc1ccccc1C)CCc1cc2c(cc1-3)OCO2.[Br-]', 'Clc1ccc(-c2nnc(N3CCN(c4ccccn4)CC3)o2)cc1', 'CC(C)c1ccc([C@@H]2[C@H]3CSCN3C3(C(=O)c4ccccc4C3=O)[C@]23CSc2ccccc2C3=O)cc1', 'O=C(N/N=C/c1ccc(O)cc1O)N1CCN(c2ccccn2)CC1', 'Oc1ccc(CNC2CCN(Cc3ccccc3)C2)c(O)c1', 'CNC(=O)c1sc(-c2ccnc(NC(=O)CNCCCCNc3c4c(nc5ccccc35)CCCC4)c2)nc1OCC1CC1', 'O=C(NO)c1ccc(Nc2c3ccccc3nc3ccc(F)cc23)cc1', 'COc1cc(CNC2CCN(Cc3ccccc3)C2)cc(OC)c1OC', 'O=[N+]([O-])c1ccc(/C=N\\\\C2CCN(Cc3ccccc3)C2)cc1', 'O=C(CCN1CCC2c3ccccc3NC2C1)Nc1ccc(/C=C2\\\\CCn3c2nc2ccccc2c3=O)cc1', 'COc1cc2c(cc1O)CCC(C)(CC(=O)NCCCCCCCCCNc1c3c(nc4ccccc14)CCCC3)O2', 'O=C1c2ccccc2C(=O)C12N1CSC[C@@H]1[C@@H](c1cccc3ccccc13)[C@@]21CSc2ccccc2C1=O', 'COc1ccc2cc3[n+](cc2c1OCc1ccc(C(C)C)cc1)CCc1cc2c(cc1-3)OCO2.[Br-]', 'O/N=C/c1cc(Cl)cc(CN2CCN(c3ccncc3)CC2)c1O', 'O/N=C/c1cc(Cl)cc(CN2CCN(c3ccncc3)CC2)c1O', 'COc1ccc2cc3[n+](cc2c1OCc1cccc(C)c1)CCc1cc2c(cc1-3)OCO2.[Br-]', 'CC(=O)Nc1cc(-c2nc(OCC3CC3)c(C(=O)NCCCNc3c4c(nc5ccccc35)CCCC4)s2)ccn1', 'COc1cc2c(cc1O)CCC(C)(CC(=O)NCCOCCOCCNc1c3c(nc4cc(Cl)ccc14)CCCC3)O2', 'c1ccc(CNC2CCN(Cc3ccccc3)C2)cc1', 'CS[C@@H](Cn1nnc2cc(C#Cc3ccc(N4CC5(COC5)C4)cc3)ccc21)N(O)C=O', 'C/C=C1\\\\C2C=C(C)CC1(NCC(=O)OC)c1ccc(=O)[nH]c1C2', 'Fc1ccc(-c2nnc(N3CCN(c4ccccn4)CC3)o2)c(F)c1', 'Fc1ccc(-c2nnc(N3CCN(c4ccccn4)CC3)o2)c(F)c1', 'COc1ccc2cc3[n+](cc2c1OCc1cccc([N+](=O)[O-])c1)CCc1cc2c(cc1-3)OCO2.[Br-]', 'CNC(=O)c1sc(-c2ccnc(NC(=O)CNCCNc3c4c(nc5ccccc35)CCCC4)c2)nc1OCC(C)(C)C', 'NC(=O)c1sc(-c2ccnc(NC(=O)C3CC3)c2)nc1OCCC1CCN(Cc2ccccc2F)CC1', 'COc1cc(/C=C/C(=O)N2CCC(Cc3ccccc3)CC2)ccc1OC(=O)N(c1ccccc1)c1ccccc1', 'CCOC(=O)c1c(C)nc(N2CCN(S(=O)(=O)c3ccc(NC(C)=O)cc3)CC2)nc1-c1ccccc1', 'COc1ccc2[nH]cc(CCNC(=O)CN(CCCCCCCCNc3c4c(nc5ccccc35)CCCC4)C(=O)/C=C/c3ccc(O)c(OC)c3)c2c1', 'COc1cc(/C=C/C(=O)N2CCc3ccccc3C2)ccc1OC(=O)N(C)C', 'CNC(=O)c1sc(-c2ccnc(NC(=O)C3CC3)c2)nc1OCCCc1cn(CCNc2c3c(nc4ccccc24)CCCC3)nn1', 'Cc1ccc([C@@H]2[C@H]3CSCN3C3(C(=O)c4ccccc4C3=O)[C@]23CSc2ccccc2C3=O)cc1', 'CC1=C[C@@H]2Cc3[nH]c(=O)ccc3[C@]3(C1)NCCC[C@H]23', 'Clc1ccc(CNC2CCN(Cc3ccccc3)C2)cc1', 'c1cnc(Nc2nnc(-c3cccc4ccccc34)o2)nc1', 'c1cnc(Nc2nnc(-c3cccc4ccccc34)o2)nc1', 'CCN(CC)C(=O)Oc1ccc(/C=C/C(=O)N2CCC(Cc3ccccc3)CC2)cc1OC', 'CCN(C)C(=O)Oc1cccc(CNCCc2c[nH]c3cc(F)ccc23)c1.O=C(O)/C=C/C(=O)O', 'CCNC(=O)c1sc(-c2ccnc(NC(=O)CNCCNc3c4c(nc5ccccc35)CCCC4)c2)nc1OCC1CC1', 'FC(F)(F)c1ccc(CNC2CCN(Cc3ccccc3)C2)cc1', 'Oc1ccc(-c2nnc(N3CCN(c4ccccn4)CC3)o2)c(O)c1', 'O=C1c2ccccc2C(=O)C12N1CSC[C@@H]1[C@@H](c1cccc(F)c1)[C@@]21CSc2ccccc2C1=O', 'COc1ccc2cc3[n+](cc2c1OCc1ccc(Br)cc1)CCc1cc2c(cc1-3)OCO2.[Br-]', 'O=C(NO)c1ccc(Nc2c3ccccc3nc3ccc(OCc4ccccc4)cc23)cc1', 'CCN(CC)c1cc(/C=C2\\\\OC(=O)c3cc(OC)c(OC)cc32)ccc1O', 'Fc1ccc(-c2nnc(N3CCN(c4ccccn4)CC3)o2)cc1', 'CCN(C)C(=O)Oc1ccc(-c2cc(=O)c3c(O)cc(OC(=O)N(C)CC)cc3o2)cc1', 'CCN(C)C(=O)Oc1ccc(-c2cc(=O)c3c(O)cc(OC(=O)N(C)CC)cc3o2)cc1', 'COc1ccc2[nH]cc(CCNC(=O)CN(CCCCCCCCNc3c4c(nc5ccccc35)CCCC4)C(=O)CCCC[C@@H]3CCSS3)c2c1', 'O=C1c2ccccc2C(=O)C12N1CSC[C@@H]1[C@@H](c1ccc(Br)cc1)[C@@]21CSc2ccccc2C1=O', 'COc1cc2c(cc1O)CCC(C)(CCC(=O)NCCCCCCNc1c3c(nc4cc(Cl)ccc14)CCCC3)O2', 'Cc1cc(S(=O)(=O)NN)c(C(C)C)cc1O', 'COc1ccc(COc2c(OC)ccc3cc4[n+](cc23)CCc2cc3c(cc2-4)OCO3)cc1.[Br-]', 'CCN(Cc1ccccc1)C(=O)/C=C/c1ccc(OC(=O)N(c2ccccc2)c2ccccc2)c(OC)c1', 'COc1cc(/C=C/C(=O)N2CCN(Cc3ccccc3)CC2)ccc1OC(=O)N(c1ccccc1)c1ccccc1', 'c1ccc(-c2nnc(Nc3ncccn3)o2)cc1', 'CCOC(=O)c1c(C)nc(N2CCN(S(=O)(=O)c3ccc(N)cc3)CC2)nc1-c1ccc(OC)cc1', 'O=C(NO)c1ccc(Nc2c3ccccc3nc3ccccc23)cc1', 'COc1cccc(COc2c(OC)ccc3cc4[n+](cc23)CCc2cc3c(cc2-4)OCO3)c1.[Br-]', 'O=C(N/N=C/c1ccc(F)cc1F)N1CCN(c2ccccn2)CC1', 'CN1C[C@@H](c2cccs2)[C@@]2(CSc3ccccc3C2=O)C12C(=O)c1ccccc1C2=O', 'Cc1ccc(CNC2CCN(Cc3ccccc3)C2)cc1', 'O=C(CCCCCN1CCC2c3ccccc3NC2C1)Nc1ccc(/C=C2\\\\CCn3c2nc2ccccc2c3=O)cc1', 'CCOC(=O)c1c(C)nc(N2CCN(S(=O)(=O)c3ccc(N)c(OC)c3)CC2)nc1-c1ccccc1', 'CCOC(=O)c1c(C)nc(N2CCN(S(=O)(=O)c3ccc(NC(C)=O)cc3)CC2)nc1-c1ccc(OC)c(OC)c1', 'Brc1ccc(-c2nnc(Nc3ncccn3)o2)cc1', 'Oc1ccc(CNC2CCN(Cc3ccccc3)C2)cc1', 'NC(=O)c1sc(-c2ccnc(NC(=O)C3CC3)c2)nc1OCCC1CCN(Cc2ccc(F)cc2)CC1', 'FC(F)(F)c1ccc(-c2nnc(N3CCN(c4ccccn4)CC3)o2)cc1', 'C[C@@H]1CC[C@H]2[C@H](C(=O)c3c4c(cn(O)c3=O)[C@@]3(O)CC[C@H](O)[C@H](O4)[C@@H]3O)[C@H](C)C=C[C@@H]2C1', 'CCn1cc(CNCc2c[nH]nc2-c2ccc(-c3ccccc3)cc2)cn1', 'CCn1cc(CNCc2c[nH]nc2-c2ccc(-c3ccccc3)cc2)cn1', 'CC(C)c1ccc(NC(=O)OC2CCN(C3Cc4ccccc4C3)CC2)cc1', 'COc1cccc(C(=O)N2CCN(CC(=O)N3CCN(CCCc4c[nH]c5ccc(F)cc45)CC3)CC2)c1', 'CS[C@@H](Cn1nnc2cc(C#Cc3ccc(-n4ccnc4CO)cc3)ccc21)N(O)C=O', 'O=c1ccoc2ccc(OCCCCN3CCCCC3)cc12', 'O=c1ccoc2ccc(OCCCCN3CCCCC3)cc12', 'COc1cccc2cc[n+](-c3ccccc3F)cc12.[Br-]', 'COc1cccc2cc[n+](-c3ccc(Br)cc3F)cc12.[Br-]', 'NC(=O)c1sc(-c2ccnc(NC(=O)C3CC3)c2)nc1OCCCC1CCN(Cc2cccc(F)c2)CC1', 'O=C(CN1CCC2c3ccccc3NC2C1)Oc1ccc(/C=C2\\\\CCn3c2nc2ccccc2c3=O)cc1', 'CCN(C)C(=O)Oc1ccc(/C=C/C(=O)N2CCC(Cc3ccccc3)CC2)cc1', 'CCCC[N+]1(C)CCN(c2ccc(/C=C3\\\\Cc4cc(OC)c(OC)cc4C3=O)cc2)CC1.[Br-]', 'CCOC(=O)c1c(C)nc(N2CCN(S(=O)(=O)c3ccc(NC(C)=O)c(OC)c3)CC2)nc1-c1ccccc1', 'COc1cc(/C=C/C(=O)NCC(=O)Nc2cccc(Br)c2)ccc1O', 'CCN(C)C(=O)Oc1ccc(/C=C/C(=O)N2CCc3ccccc3C2)cc1', 'COc1ccc(-c2nnc(Nc3ncccn3)o2)cc1OC', 'O=C(CN1CCN(C(=O)c2ccccc2Br)CC1)N1CCN(CCCc2c[nH]c3ccc(F)cc23)CC1', 'CNC(=O)c1sc(-c2ccnc(NC(=O)CNCCNc3c4c(nc5cc(Cl)ccc35)CCCC4)c2)nc1OCC1CC1', 'O=c1cc(-c2ccc(OCCCCN3CCN(Cc4ccccc4)CC3)cc2)oc2cc(OCCCCN3CCN(Cc4ccccc4)CC3)cc(O)c12', 'O=C(/C=C/c1ccc(OCCCCN2CCCCC2)cc1)c1c(O)cc(OCCCCN2CCCCC2)cc1O', 'CCN(CC)c1cc(/C=C2/OC(=O)c3cc(OC)c(OC)cc32)ccc1O', 'Oc1ccccc1CNC1CCN(Cc2ccccc2)C1', 'COc1cc2c(cc1OC)/C(=C\\\\c1ccc(N3CCCCC3)c(O)c1)OC2=O', 'COc1cc(/C=C/C(=O)NCC(=O)Nc2ccc(Cl)cc2)ccc1O', 'COc1cc2c(cc1OC)C(=O)/C(=C/c1ccc(N3CC[N+](C)(Cc4cccc(Br)c4)CC3)cc1)C2.[Br-]', 'O=c1ccoc2ccc(OCCCN3CCCCC3)cc12', 'COc1cccc2cc[n+](-c3ccccc3I)cc12.[Br-]', 'CCc1ccc(NC(=O)COc2c(Cl)cc(Cl)cc2S(=O)(=O)N2CCN(C(=O)c3ccco3)CC2)cc1', 'O=c1ccoc2ccc(OCCCCCN3CCCC3)cc12', 'O=c1cc(-c2ccc(OCCCCN3CCC(Cc4ccccc4)CC3)cc2)oc2cc(OCCCCN3CCC(Cc4ccccc4)CC3)cc(O)c12', 'COc1cc(/C=C/C(=O)N2CCN(c3ccc(F)cc3)CC2)ccc1O', 'CCOC(=O)c1c(C)nc(N2CCN(S(=O)(=O)c3ccc(N)c(F)c3)CC2)nc1-c1ccc(OC)cc1', 'Brc1ccc([N+]2=Cc3ccccc3CC2)cc1.[Br-]', 'CNC(=O)c1sc(-c2ccnc(NC(=O)C3CC3)c2)nc1OCCOCc1cn(CCNc2c3c(nc4ccccc24)CCCC3)nn1', 'CCN(CC)C(=O)Oc1ccc(/C=C/C(=O)N2CCc3ccccc3C2)cc1OC', 'Cc1cc(/C=N/O)c(O)c(CNc2ncccc2OCc2ccccc2)c1', 'Oc1ccc(-c2nnc(Nc3ncccn3)o2)cc1', 'Brc1ccc(-c2nnc(N3CCN(c4ccccn4)CC3)o2)cc1', 'COc1cc2c(cc1OC)/C(=C/c1ccc(N3CCCCC3)c(O)c1)OC2=O', 'CN1C[C@@H](c2ccc(Cl)cc2Cl)[C@@]2(CSc3ccccc3C2=O)C12C(=O)c1ccccc1C2=O', 'CS[C@@H](Cn1nnc2cc(C#Cc3ccc(N4C[C@H](O)[C@@H](O)C4)cc3)ccc21)N(O)C=O', 'Oc1ccc(/C=N\\\\C2CCN(Cc3ccccc3)C2)c(O)c1', 'COc1cc2c(cc1OC)C(=O)/C(=C/c1ccc(N3CC[N+](C)(Cc4ccc(Br)cc4)CC3)cc1)C2.[Br-]', 'O=c1ccoc2ccc(OCCCCN3CCCC3)cc12', 'O=C(Nc1ccccc1)OCC1CCN(Cc2ccccc2)CC1', 'O=C(NCCCNc1c2c(nc3ccccc13)CCCC2)c1sc(-c2ccnc(NC(=O)C3CC3)c2)nc1OCC1CC1', 'O=C(CCCCN1CCC2c3ccccc3NC2C1)Nc1ccc(/C=C2\\\\CCn3c2nc2ccccc2c3=O)cc1', 'O=C(CN1CCN(C(=O)c2cccc(Cl)c2)CC1)N1CCN(CCCc2c[nH]c3ccc(F)cc23)CC1', 'COc1cc(/C=C/C(=O)N2CCN(c3ccc(C)cc3)CC2)ccc1O', 'O=c1ccoc2ccc(OCCCCCN3CCOCC3)cc12', 'COc1cccc2cc[n+](-c3ccc(Cl)cc3)cc12.[Br-]', 'Cc1ccc(C(=O)N2CCN(CC(=O)N3CCN(CCCc4c[nH]c5ccc(F)cc45)CC3)CC2)cc1', 'O=C(N/N=C/c1ccc(OC(F)(F)F)cc1)N1CCN(c2ccccn2)CC1', 'Oc1ccccc1-c1nnc(N2CCN(c3ccccn3)CC2)o1', 'Cc1ccc(C(=O)N2CCN(CC(=O)N3CCN(CCCc4c[nH]c5ccccc45)CC3)CC2)cc1', 'COc1cc(CNC(=O)c2ccc(CNc3c4c(nc5cc(Cl)ccc35)CC3C=C(C)CC4C3)cc2)ccc1O', 'CCOC(=O)c1c(C)nc(N2CCN(S(=O)(=O)c3ccc(NC(C)=O)c(Cl)c3)CC2)nc1-c1ccc(OC)cc1', 'CCN(CCCCOc1ccc(/C=C/C(=O)c2c(O)cc(OCCCCN(CC)Cc3ccccc3OC)cc2O)cc1)Cc1ccccc1OC', 'COc1ccc(C(=O)N2CCN(CC(=O)N3CCN(CCCc4c[nH]c5ccccc45)CC3)CC2)cc1', 'COc1cc(/C=C/C(=O)NCC(=O)Nc2ccc(Br)cc2)ccc1O', 'CCN(CC)CCCCOc1ccc(/C=C/C(=O)c2c(O)cc(OCCCCN(CC)CC)cc2O)cc1', 'COc1cc(CNC(=O)CCCCCCCCNc2c3c(nc4cc(Cl)ccc24)CC2C=C(C)CC3C2)ccc1O', 'COc1cc(/C=C/C(=O)NCC(=O)Nc2ccccc2Cl)ccc1O', 'COc1ccc2[nH]cc(CCCN3CCN(C(=O)CN4CCN(C(=O)c5cccc(F)c5)CC4)CC3)c2c1', 'CCN(CCCCOc1ccc(-c2cc(=O)c3c(O)cc(OCCCCN(CC)Cc4ccccc4)cc3o2)cc1)Cc1ccccc1', 'CCN(CCCCOc1ccc(-c2cc(=O)c3c(O)cc(OCCCCN(CC)Cc4ccccc4)cc3o2)cc1)Cc1ccccc1', 'O=c1c2cc(Cl)ccc2oc2ccc(OCCCCCN3CCCCCC3)cc12', 'COc1cc2c(cc1OC)C(=O)/C(=C/c1ccc(N3CC[N+](C)(Cc4ccccn4)CC3)cc1)C2.[Cl-]', 'O=C(CN1CCN(C(=O)c2ccc(F)cc2)CC1)N1CCN(CCCc2c[nH]c3ccccc23)CC1', 'COc1cc(/C=C/C(=O)NCC(=O)Nc2ccccc2OC)ccc1O', 'COc1cc(-c2nnc(Nc3ncccn3)o2)cc(OC)c1OC', 'COc1cc(/C=C/C(=O)NCC(=O)Nc2ccc(C#N)cc2)ccc1O', 'COc1cccc2cc[n+](-c3cccc(C)c3)cc12.[Br-]', 'COc1cccc(-[n+]2ccc3cccc(OC)c3c2)c1.[Br-]', 'COc1cc(/C=C/C(=O)NCC(=O)Nc2ccc(C)cc2)ccc1O', 'COc1ccc2nc3c(c(NCCCCCCCN(CC(=O)NCCc4c[nH]c5ccc(OC)cc45)C(=O)/C=C/c4ccc(O)c(OC)c4)c2c1)CCCC3', 'COc1cccc2cc[n+](-c3cccc(C#N)c3)cc12.[Br-]', 'CNC(=O)c1sc(-c2ccnc(NC(=O)CNCCNc3c4c(nc5ccc(OC)cc35)CCCC4)c2)nc1OCC1CC1', 'CCOC(=O)c1c(C)nc(N2CCN(S(=O)(=O)c3ccc(NC(C)=O)c(OC)c3)CC2)nc1-c1ccc(OC)c(OC)c1', 'COc1cc2c(cc1O)CCC(C)(CCNCCCCCCCCCNc1c3c(nc4cc(Cl)ccc14)CCCC3)O2', 'COc1cc(/C=C/C(=O)NCC(=O)Nc2cccc(C(F)(F)F)c2)ccc1O', 'COc1cccc(N2CCN(C(=O)/C=C/c3ccc(O)c(OC)c3)CC2)c1', 'COc1cccc(N2CCN(C(=O)/C=C/c3ccc(O)c(OC)c3)CC2)c1', 'COc1cccc2cc[n+](-c3ccccc3C#N)cc12.[Br-]', 'CC(C)c1ccc(NC(=O)OCC2CCCN(C3Cc4ccccc4C3)C2)cc1', 'COc1cc(/C=C/C(=O)N2CCN(c3cccc([N+](=O)[O-])c3)CC2)ccc1O', 'Cc1cc(S(=O)(=O)N2CCOCC2)c(C(C)C)cc1O', 'Clc1ccc(/C=N\\\\C2CCN(Cc3ccccc3)C2)cc1', 'O=C(CN1CCN(C(=O)c2ccc(F)cc2)CC1)N1CCN(CCCc2c[nH]c3ccc(F)cc23)CC1', 'COc1cccc2cc[n+](-c3ccc(Cl)cc3Cl)cc12.[Br-]', 'O=C(CN1CCN(C(=O)c2cccc(Br)c2)CC1)N1CCN(CCCc2c[nH]c3ccc(F)cc23)CC1', 'COc1cccc2cc[n+](-c3ccccc3Cl)cc12.[Br-]', 'O=C(CN1CCN(C(=O)c2cccc(Cl)c2)CC1)N1CCN(CCCc2c[nH]c3ccccc23)CC1', 'COc1cc2c(cc1OC)C(=O)/C(=C/c1ccc(N3CCN(C)CC3)cc1)C2', 'COc1cc(/C=C/C(=O)N2CCN(c3ccccc3)CC2)ccc1O', 'COc1cc(/C=C/C(=O)NCC(=O)Nc2cccc(Cl)c2)ccc1O', 'CC(C)c1ccc(NC(=O)OCC2CCN(C3Cc4ccccc4C3)CC2)cc1', 'CCN(C)C(=O)Oc1ccc(/C=C/C(=O)N2CCC(Cc3ccccc3)CC2)cc1OC', 'CNC(=O)c1sc(-c2ccnc(NC(=O)CNCCNc3c4c(nc5ccccc35)CCCC4)c2)nc1OC(C)C', 'COc1cc2c(cc1O)CCC(C)(CCNCCOCCOCCNc1c3c(nc4cc(Cl)ccc14)CCCC3)O2', 'CCCCN[C@@H](Cc1c[nH]c2ccccc12)C(=O)NCCC1CCN(Cc2ccccc2)CC1', 'CCN(C)C(=O)Oc1ccc(-c2cc(=O)c3c(OC(=O)N(C)CC)cc(OC(=O)N(C)CC)cc3o2)cc1', 'CCN(C)C(=O)Oc1ccc(-c2cc(=O)c3c(OC(=O)N(C)CC)cc(OC(=O)N(C)CC)cc3o2)cc1', 'COc1cc(/C=C/C(=O)NCC(=O)Nc2ccccc2C(F)(F)F)ccc1O', 'COc1cc2c(cc1O)CCC(C)(CC(=O)NCCCCCCCCNc1c3c(nc4cc(Cl)ccc14)CCCC3)O2', 'O=c1c(-c2ccc(OCCCCN3CCCCC3)cc2)coc2cc(OCCCCN3CCCCC3)cc(O)c12', 'COc1cc(/C=C/C(=O)NCC(=O)Nc2ccc(F)cc2)ccc1O', 'COc1cc2c(cc1OC)C(=O)/C(=C/c1ccc(N3CC[N+](C)(Cc4ccccc4Cl)CC3)cc1)C2.[Cl-]', 'COc1cc(/C=C/C(=O)N2CCN(c3ccc(Cl)cc3)CC2)ccc1O', 'O=C(N/N=C/c1ccc(F)cc1)N1CCN(c2ccccn2)CC1', 'O=C1c2ccccc2C(=O)C12N1CSC[C@@H]1[C@@H](c1ccc(F)cc1)[C@@]21CSc2ccccc2C1=O', 'COc1cc(CNC(=O)CCCCCNc2c3c(nc4cc(Cl)ccc24)CC2C=C(C)CC3C2)ccc1O', 'COc1cc(/C=C/C(=O)NCC(=O)Nc2ccccc2)ccc1O', 'COc1cc(/C=C/C(=O)NCC(=O)Nc2ccccc2)ccc1O', 'COc1cccc2cc[n+](-c3c(F)cccc3F)cc12.[Br-]', 'O=C(Nc1ccccc1)OCC1CCCN(Cc2ccccc2)C1', 'COc1cccc2cc[n+](-c3cccc(Cl)c3)cc12.[Br-]', 'COc1cccc2cc[n+](-c3ccc(Br)cc3)cc12.[Br-]', 'COc1ccc2cc3[n+](cc2c1OCc1cc(C)cc(C)c1)CCc1cc2c(cc1-3)OCO2.[Br-]', 'CON(C)C(=O)Oc1ccc(-c2cc(=O)c3c(O)cc(OC(=O)N(C)OC)cc3o2)cc1', 'CNC(=O)c1sc(-c2ccnc(NC(=O)CNCCNc3c4c(nc5ccccc35)CCCC4)c2)nc1OCC1CC1', 'COc1cccc2cc[n+](-c3ccccc3)cc12.[Br-]', 'COc1cc2c(cc1OCc1ccccc1)CCC(C)(CC(=O)NCCCCCCNc1c3c(nc4cc(Cl)ccc14)CCCC3)O2', 'COc1cccc2cc[n+](-c3ccc(Br)cc3Br)cc12.[Br-]', 'CC(C)c1ccc(NC(=O)OC2CCCN(C3Cc4ccccc4C3)C2)cc1', 'COc1ccc(NC(=O)CNC(=O)/C=C/c2ccc(O)c(OC)c2)cc1', 'O=C(CN1CCN(C(=O)c2ccc(Cl)cc2)CC1)N1CCN(CCCc2c[nH]c3ccccc23)CC1', 'COc1cc2c(cc1OCc1ccccc1)CCC(C)(CC(=O)NCCCCCCCCCNc1c3c(nc4cc(Cl)ccc14)CCCC3)O2', 'COc1cc(/C=C/C(=O)NCC(=O)Nc2ccc3ncccc3c2)ccc1O', 'O=C1c2ccccc2C(=O)C12N1CSC[C@@H]1[C@@H](c1cccs1)[C@@]21CSc2ccccc2C1=O', 'CCN(CC)C(=O)/C=C/c1ccc(OC(=O)N(C)C)c(OC)c1', 'C#CCOc1ccc(-c2cc(-c3ccc(OCCN4CCOCC4)cc3)nc(N)n2)cc1', 'O=C(CN1CCN(C(=O)c2ccccc2F)CC1)N1CCN(CCCc2c[nH]c3ccccc23)CC1', 'COc1ccc2cc(C(=O)NCCC3CCN(Cc4ccccc4)CC3)ccc2c1', 'COc1ccc2cc(C(=O)NCCC3CCN(Cc4ccccc4)CC3)ccc2c1', 'COc1cc2c(cc1OC)C(=O)/C(=C/c1ccc(N3CC[N+](C)(CCO)CC3)cc1)C2.[Cl-]', 'COc1ccc2cc3[n+](cc2c1OCc1ccc(SC)cc1)CCc1cc2c(cc1-3)OCO2.[Br-]', 'CCOC(=O)c1c(C)nc(N2CCN(S(=O)(=O)c3ccc(NC(C)=O)c(Cl)c3)CC2)nc1-c1ccc(OC)c(OC)c1', 'CCOC(=O)c1c(C)nc(N2CCN(S(=O)(=O)c3ccc(NC(C)=O)c(Cl)c3)CC2)nc1-c1ccc(OC)c(OC)c1', 'COc1cccc2cc[n+](-c3ccc(I)cc3F)cc12.[Br-]', 'COc1cc2c(cc1OC)C(=O)/C(=C/c1ccc(N3CC[N+](C)(Cc4cccc(Cl)c4)CC3)cc1)C2.[Br-]', 'COc1cc2c(cc1OC)C(=O)/C(=C/c1ccc(N3CC[N+](C)(Cc4cccc(Cl)c4)CC3)cc1)C2.[Br-]', 'CC(C)c1ccc([C@@H]2CN(C)C3(C(=O)c4ccccc4C3=O)[C@]23CSc2ccccc2C3=O)cc1', 'CNC(=O)c1sc(-c2ccnc(NC(=O)C3CC3)c2)nc1OCC1CCN(Cc2ccc(Cl)cc2)CC1', 'CN1C[C@@H](c2ccc(F)cc2)[C@@]2(CSc3ccccc3C2=O)C12C(=O)c1ccccc1C2=O', 'O=c1c(-c2ccc(OCCCCN3CCc4ccccc4C3)cc2)coc2cc(OCCCCN3CCc4ccccc4C3)cc(O)c12', 'O=C(CCCCN1CCC2c3ccccc3NC2C1)Oc1ccc(/C=C2\\\\CCn3c2nc2ccccc2c3=O)cc1', 'COc1ccc(N2CCN(C(=O)/C=C/c3ccc(O)c(OC)c3)CC2)cc1', 'Clc1ccc(-c2nnc(Nc3ncccn3)o2)cc1', 'COc1cc(/C=C/C(=O)N2CCC(Cc3ccccc3)CC2)ccc1OC(=O)N(C)C', 'CC(C)c1ccc(NC(=O)OCC2CCCN(Cc3ccccc3)C2)cc1', 'O=c1cc(-c2ccc(OCCCCN3CCc4ccccc4C3)cc2)oc2cc(OCCCCN3CCc4ccccc4C3)cc(O)c12', 'CC1c2ccccc2CCN1CCCCOc1ccc(-c2coc3cc(OCCCCN4CCc5ccccc5C4C)cc(O)c3c2=O)cc1', 'CCOC(=O)c1c(C)nc(N2CCN(S(=O)(=O)c3ccc(N)c(F)c3)CC2)nc1-c1ccc(OC)c(OC)c1', 'CN1CCCC[C@H]1c1ccc(-c2cccnc2)nc1', 'COc1cc2c(cc1O)CCC(C)(CC(=O)NCCCCCCCCNc1c3c(nc4ccccc14)CCCC3)O2', 'CCN(C)C(=O)OCC1CCCN(Cc2ccccc2)C1', 'CNC(=O)c1sc(-c2ccnc(NC(=O)C3CC3)c2)nc1OCC1CCN(Cc2cccc([N+](=O)[O-])c2)CC1', 'FC(F)(F)c1ccc(/C=N\\\\C2CCN(Cc3ccccc3)C2)cc1', 'O=C(N/N=C/c1ccc(O)cc1)N1CCN(c2ccccn2)CC1', 'CCN(C)C(=O)Oc1ccc(/C=C/C(=O)N2CCc3ccccc3C2)cc1OC', 'O=C(/C=C/c1ccc(OCCCCN2CCC(Cc3ccccc3)CC2)cc1)c1c(O)cc(OCCCCN2CCC(Cc3ccccc3)CC2)cc1O', 'CS(=O)(=O)[O-].CS(=O)(=O)[O-].NC(=O)c1cc[n+](COC[n+]2ccccc2/C=N/O)cc1', 'CS(=O)(=O)[O-].CS(=O)(=O)[O-].NC(=O)c1cc[n+](COC[n+]2ccccc2/C=N/O)cc1', 'FC(F)(F)Oc1ccc(CNC2CCN(Cc3ccccc3)C2)cc1', 'FC(F)(F)Oc1ccc(CNC2CCN(Cc3ccccc3)C2)cc1', 'FC(F)(F)Oc1ccc(-c2nnc(N3CCN(c4ccccn4)CC3)o2)cc1', 'COc1cccc2cc[n+](-c3ccc(I)cc3)cc12.[Br-]', 'COc1cc(/C=C/C(=O)NCC(=O)Nc2cccc(C#N)c2)ccc1O', 'COc1cccc2cc[n+](-c3cccc(F)c3)cc12.[Br-]', 'Brc1ccc(/C=N\\\\C2CCN(Cc3ccccc3)C2)cc1', 'O=C1CC(c2ccc(OCCCCN3CCc4ccccc4C3)cc2)Oc2cc(OCCCCN3CCc4ccccc4C3)cc(O)c21', 'COc1cc2c(cc1OC)C(=O)/C(=C/c1ccc(N3CC[N+](C)(Cc4ccccc4Br)CC3)cc1)C2.[Br-]', 'COc1cc(/C=C/C(=O)NCC(=O)Nc2ccc(C(F)(F)F)cc2)ccc1O', 'COc1cc2c(cc1OC)C(=O)/C(=C/c1ccc(OCCN[N+]3(C)CCN(c4ccc(/C=C5\\\\Cc6cc(OC)c(OC)cc6C5=O)cc4)CC3)cc1)C2.[Br-]', 'CCCCCC[N+]1(C)CCN(c2ccc(/C=C3\\\\Cc4cc(OC)c(OC)cc4C3=O)cc2)CC1.[Br-]', 'COc1cc2c(cc1O)CCC(C)(CC(=O)NCCCCCCCNc1c3c(nc4ccccc14)CCCC3)O2', 'COc1cc2c(cc1O)CCC(C)(CCC(=O)NCCCCCCCCNc1c3c(nc4cc(Cl)ccc14)CCCC3)O2', 'CCC[N+]1(C)CCN(c2ccc(/C=C3\\\\Cc4cc(OC)c(OC)cc4C3=O)cc2)CC1.[Br-]', 'COc1cc(CNC(=O)CCCC/C=C/CCCNc2c3c(nc4cc(Cl)ccc24)CC2C=C(C)CC3C2)ccc1O', 'CN1C[C@@H](c2cccc3ccccc23)[C@@]2(CSc3ccccc3C2=O)C12C(=O)c1ccccc1C2=O', 'NC(=O)c1sc(-c2ccnc(NC(=O)C3CC3)c2)nc1OCCCC1CCN(Cc2ccccc2)CC1', 'O=C1CC(c2ccc(OCCCCN3CCN(Cc4ccccc4)CC3)cc2)Oc2cc(OCCCCN3CCN(Cc4ccccc4)CC3)cc(O)c21', 'O=C(CN1CCN(C(=O)c2ccc(Br)cc2)CC1)N1CCN(CCCc2c[nH]c3ccc(F)cc23)CC1', 'CCN(CCCCOc1ccc(C2CC(=O)c3c(O)cc(OCCCCN(CC)Cc4ccccc4OC)cc3O2)cc1)Cc1ccccc1OC', 'CON(C)C(=O)Oc1ccc(-c2cc(=O)c3c(OC(=O)N(C)OC)cc(OC(=O)N(C)OC)cc3o2)cc1', 'CC(C)c1ccc(NC(=O)OCC2CCN(Cc3ccccc3)CC2)cc1', 'COc1ccc2cc3[n+](cc2c1OCc1ccc(C#N)cc1)CCc1cc2c(cc1-3)OCO2.[Br-]', 'NC(=O)c1sc(-c2ccnc(NC(=O)C3CC3)c2)nc1OCCC1CCN(Cc2cccc(F)c2)CC1', 'Cn1c(=O)sc2cc(C(=O)CCN3CCN(Cc4ccccc4)CC3)ccc21', 'O=C(NO)c1ccc(Nc2c3ccccc3nc3ccc(Br)cc23)cc1', 'COc1cccc2cc[n+](-c3ccccc3Br)cc12.[Br-]', 'C(=N\\\\C1CCN(Cc2ccccc2)C1)\\\\c1ccccc1', 'O=C(CN1CCN(C(=O)c2ccc(Cl)cc2)CC1)N1CCN(CCCc2c[nH]c3ccc(F)cc23)CC1', 'COc1cc(/C=C/C(=O)NCC(=O)Nc2ccccc2F)ccc1O', 'NC(=O)c1sc(-c2ccnc(NC(=O)C3CC3)c2)nc1OCCC1CCN(Cc2ccccc2)CC1', 'COc1cc2c(cc1O)CCC(C)(CCNCCCCCCCNc1c3c(nc4cc(Cl)ccc14)CCCC3)O2', 'Brc1ccc(-[n+]2ccc3ccccc3c2)cc1.[Br-]', 'COc1cccc2cc[n+](-c3ccc(F)cc3)cc12.[Br-]', 'O=c1c(-c2ccc(OCCCCN3CCC(Cc4ccccc4)CC3)cc2)coc2cc(OCCCCN3CCC(Cc4ccccc4)CC3)cc(O)c12', 'CNC(=O)c1sc(-c2ccnc(NC(=O)C3CC3)c2)nc1OCCc1cn(CCNc2c3c(nc4ccccc24)CCCC3)nn1', 'O=c1c(-c2ccc(OCCCCN3CCN(Cc4ccccc4)CC3)cc2)coc2cc(OCCCCN3CCN(Cc4ccccc4)CC3)cc(O)c12', 'O=[N+]([O-])c1ccc(CNC2CCN(Cc3ccccc3)C2)cc1', 'Cc1ccc([C@@H]2CN(C)C3(C(=O)c4ccccc4C3=O)[C@]23CSc2ccccc2C3=O)cc1', 'Fc1ccc(/C=N\\\\C2CCN(Cc3ccccc3)C2)cc1', 'COc1cc(/C=C/C(=O)NCC(=O)Nc2cccc(C)c2)ccc1O', 'COc1cc(/C=C/C(=O)NCC(=O)Nc2ccccc2C)ccc1O', 'COc1cc2c(cc1O)CCC(C)(CCC(=O)NCCCCCCCNc1c3c(nc4cc(Cl)ccc14)CCCC3)O2', 'CCOC(=O)c1c(C)nc(N2CCN(S(=O)(=O)c3ccc(N)c(OC)c3)CC2)nc1-c1ccc(OC)cc1', 'O=c1c2ccccc2oc2ccc(OCCCCCN3CCCCCC3)cc12', 'O=C1c2ccccc2C(=O)C12N1CSC[C@@H]1[C@@H](c1cccc(Br)c1)[C@@]21CSc2ccccc2C1=O', 'Cc1cc(S(=O)(=O)NCc2ccccn2)c(C(C)C)cc1O', 'COc1ccc(-[n+]2ccc3cccc(OC)c3c2)cc1.[Br-]', 'CCCCC[N+]1(C)CCN(c2ccc(/C=C3\\\\Cc4cc(OC)c(OC)cc4C3=O)cc2)CC1.[Br-]', 'COc1cc2c(cc1O)CCC(C)(CC(=O)NCCCCCCCCCNc1c3c(nc4cc(Cl)ccc14)CCCC3)O2', 'O=C1c2ccccc2C(=O)C12N1CSC[C@@H]1[C@@H](c1ccc(Cl)cc1Cl)[C@@]21CSc2ccccc2C1=O', 'Cc1ccc(-c2nnc(Nc3ncccn3)o2)cc1', 'CCOC(=O)c1c(C)nc(N2CCN(S(=O)(=O)c3ccc(NC(C)=O)c(F)c3)CC2)nc1-c1ccc(OC)cc1', 'C=CC[N+]1(C)CCN(c2ccc(/C=C3\\\\Cc4cc(OC)c(OC)cc4C3=O)cc2)CC1.[Cl-]', 'O=C(CN1CCN(C(=O)c2cccc(Br)c2)CC1)N1CCN(CCCc2c[nH]c3ccccc23)CC1', 'CNC(=O)c1sc(-c2ccnc(NC(=O)CNCCCCCCCCNc3c4c(nc5ccccc35)CCCC4)c2)nc1OCC1CC1', 'O=C(/C=C/c1ccc(OCCCCN2CCCC2)cc1)c1c(O)cc(OCCCCN2CCCC2)cc1O', 'O=C1CC(c2ccc(OCCCCN3CCC(Cc4ccccc4)CC3)cc2)Oc2cc(OCCCCN3CCC(Cc4ccccc4)CC3)cc(O)c21', 'COc1cc2c(cc1O)CCC(C)(CC(=O)NCCCCCCCNc1c3c(nc4cc(Cl)ccc14)CCCC3)O2', 'COc1cccc2cc[n+](-c3ccccc3C)cc12.[Br-]', 'Cc1ccc(/C=N/NC(=O)N2CCN(c3ccccn3)CC2)cc1', 'CCN(C)C(=O)OCC1CCN(Cc2ccccc2)CC1', 'COc1cc(/C=C/C(=O)NCC(=O)Nc2cccc(F)c2)ccc1O', 'CN1C[C@@H](c2cccc(F)c2)[C@@]2(CSc3ccccc3C2=O)C12C(=O)c1ccccc1C2=O', 'COc1cccc2cc[n+](-c3ccc(C(F)(F)F)cc3)cc12.[Br-]', 'O=C(Nc1ccccc1)OC1CCN(C2Cc3ccccc3C2)CC1', 'COc1cccc(NC(=O)CNC(=O)/C=C/c2ccc(O)c(OC)c2)c1', 'O=C(NO)c1ccc(Nc2c3c(nc4ccccc24)CCCC3)cc1', 'COc1cc(/C=C/C(=O)NCC(=O)Nc2ccc3[nH]ccc3c2)ccc1O', 'COc1cc(/C=C/C(=O)NCC(=O)Nc2ccc3[nH]ccc3c2)ccc1O', 'CCOC(=O)c1c(C)nc(N2CCN(S(=O)(=O)c3ccc(N)c(Cl)c3)CC2)nc1-c1ccc(OC)c(OC)c1', 'CN1C[C@@H](c2ccccc2)[C@@]2(CSc3ccccc3C2=O)C12C(=O)c1ccccc1C2=O', 'C[C@H]1CCCN1Cc1nc2cc(NC(=O)c3ccc4cnccc4c3)ccc2[nH]1', 'COc1ccc(C(=O)N2CCN(CC(=O)N3CCN(CCCc4c[nH]c5ccc(F)cc45)CC3)CC2)cc1', 'COc1cc(/C=N/NC(=O)N2CCN(c3ccccn3)CC2)cc(OC)c1OC', 'COc1cc2c(cc1OC)C(=O)/C(=C/c1ccc(N3CC[N+](C)(Cc4ccccc4)CC3)cc1)C2.[Cl-]', 'COc1cc2c(cc1OC)C(=O)/C(=C/c1ccc(N3CC[N+](C)(Cc4ccccc4)CC3)cc1)C2.[Cl-]', 'Cc1cc(S(=O)(=O)Nc2ccccc2O)c(C(C)C)cc1O', 'CCN(C)C(=O)Oc1ccc(/C=C/C(=O)N(CC)Cc2ccccc2)cc1OC', 'COc1cccc2cc[n+](-c3ccc(C)cc3)cc12.[Br-]', 'CNC(=O)c1sc(-c2ccnc(NC(=O)CNCCCCCCNc3c4c(nc5ccccc35)CCCC4)c2)nc1OCC1CC1', 'CCOC(=O)c1c(C)nc(N2CCN(S(=O)(=O)c3ccc(N)c(Cl)c3)CC2)nc1-c1ccccc1', 'O=C(CN1CCN(C(=O)c2ccc(Br)cc2)CC1)N1CCN(CCCc2c[nH]c3ccccc23)CC1', 'Cc1ccc2c(N)c3c(nc2c1)CCCCC3.Cl', 'Cc1ccc(S(=O)(=O)SCc2ccc(F)cc2)cc1', 'Cc1ccc(S(=O)(=O)SCc2ccc(F)cc2)cc1', 'COc1ccc2[nH]cc(CCNC(=O)CCCCn3cc(CN4CC[C@@]56C=C[C@H](O)C[C@@H]5Oc5c(OC)ccc(c56)C4)nn3)c2c1', 'COc1ccc(CN2CCC(c3oc4ccccc4c3C(=O)c3ccc(OC)cc3)CC2)cc1', 'COc1cc2c(cc1OC)C(=O)C(CC1(F)CCN(Cc3ccccc3)CC1)C2', 'O=C(CC1CCN(Cc2ccccc2F)CC1)Nc1n[nH]c2cc(-c3cccnc3)ccc12', 'COc1ccc2[nH]c3ccncc3c2c1', 'CCOC(=O)/C(=N\\\\Nc1ccccc1C(=O)OCC)C(=O)C(F)(F)F', 'COc1ccc(CN2CCC(c3oc4ccccc4c3C(=O)c3ccccc3)CC2)cc1OC', 'O=C(CCn1c2ccccc2c2cnccc21)N1c2ccccc2Sc2ccccc21', 'Cl.Nc1c2c(nc3ccc(F)cc13)CCCC2', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(NCCCCCCCCC(=O)NCc4cc[nH]c(=O)c4)c3C(C1)C2', 'COc1cccc(NC(=O)CCNC(=O)/C=C/c2ccc(O)c(OC)c2)c1', 'COc1cc(/C=C/C(=O)N2CCN(Cc3ccccc3)CC2)ccc1O', 'COc1ccc(OC)c(CN2CCC(c3oc4ccccc4c3C(=O)c3ccc(OC)c(OC)c3)CC2)c1', 'COc1ccc(C(=O)c2c(C3CCN(Cc4ccccc4)CC3)oc3ccccc23)cc1', 'C[n+]1ccc2[nH]c3ccc(F)cc3c2c1.[I-]', 'CCOC(=O)/C(=N\\\\Nc1ccc(C)cc1)C(=O)C(F)(F)F', 'COc1ccc2[nH]cc(CCNC(=O)CCCCn3cc(CCCCN4CC[C@@]56C=C[C@H](O)C[C@@H]5Oc5c(OC)ccc(c56)C4)nn3)c2c1', 'COC(=O)/C(=N\\\\Nc1ccccc1)C(=O)C(F)(F)F', 'COc1ccc2[nH]c3c(c2c1)CN(Cc1ccccc1)CC3', 'COc1ccc2[nH]cc(CCNC(=O)Cn3cc(CN4CCc5cc(OC)c(OC)cc5C4CCCN4C(=O)c5ccccc5C4=O)nn3)c2c1', 'O=C(NC1CCN(Cc2ccc(F)cc2)CC1)c1cncc(NC(=O)c2ccnc3[nH]ccc23)c1', 'c1ccc(CN2CCC(CCNc3cc4c(nn3)-c3ccccc3CCCC4)CC2)cc1', '[Br-].c1ccc(C[n+]2ccc3[nH]c4ccccc4c3c2)cc1', 'COc1ccc2c(c1)c1cnccc1n2CCC(=O)N1c2ccccc2Sc2ccccc21', 'COc1ccc2nc3c(c(N)c2c1)C1CC(C)=CC(C3)C1.Cl', 'O=C(CCn1c2ccccc2c2c[n+](Cc3ccccc3)ccc21)N1c2ccccc2Sc2ccccc21.[Br-]', 'COc1cccc(CN2CCN(C(=O)/C=C/c3ccc(O)c(OC)c3)CC2)c1', 'Fc1ccccc1-c1ccc(N[C@H]2C[C@@H]3CN(CC4CCOCC4)C[C@@H]3C2)nn1', 'O=C(NCC1CCN(Cc2ccccc2)CC1)c1cncc(NC(=O)c2ccnc(NC(=O)C3CC3)c2)c1', 'COc1ccc2[nH]cc(CCNC(=O)Cn3cc(CCCCN4CC[C@@]56C=C[C@H](O)C[C@@H]5Oc5c(OC)ccc(c56)C4)nn3)c2c1', 'Cc1ccc(S(=O)(=O)SCc2ccc(C(C)(C)C)cc2)cc1', 'Cc1ccc(S(=O)(=O)SCc2ccc(C(C)(C)C)cc2)cc1', 'COc1ccc(CN2CCC(c3oc4ccccc4c3C(=O)c3ccccc3)CC2)cc1', 'CCOC(=O)/C(=N\\\\Nc1cccc(C)c1)C(=O)C(F)(F)F', 'O=C(NCCC1CCN(Cc2cccc(Cl)c2)CC1)c1cncc(NC(=O)c2cccc(NC(=O)C3CC3)c2)c1', 'COc1cc2c(cc1OC)C(=O)C(CC1(F)CCN(Cc3cccc(F)c3)CC1)C2', 'CCOC(=O)/C(=N\\\\Nc1ccccc1)C(=O)C(F)(F)F', 'O=C(Nc1cncc(C(=O)NC2CCN(Cc3cccc(Cl)c3)CC2)c1)c1ccnc(NC(=O)C2CC2)c1', 'CCOC(=O)/C(=N\\\\Nc1ccccc1[N+](=O)[O-])C(=O)C(F)(F)F', 'COc1cc(/C=C/C(=O)NCC(=O)NCCc2c[nH]c3ccccc23)ccc1O', 'COc1ccc2[nH]cc(CCNC(=O)Cn3cc(CN4CC[C@@]56C=C[C@H](O)C[C@@H]5Oc5c(OC)ccc(c56)C4)nn3)c2c1', 'Cl.Nc1c2c(nc3c(Cl)cc(Cl)cc13)CCCC2', 'O=C(NCC1CCN(Cc2ccccc2F)CC1)c1n[nH]c2ccc(-c3cccnc3)cc12', 'Cl.Nc1c2c(nc3ccc(F)cc13)CCC2', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(NCCCCCCCCC(=O)N4CCNC(=O)C4)c3C(C1)C2', 'Cc1ccc2c(c1)c1cnccc1n2CCC(=O)N1c2ccccc2Sc2ccccc21', 'CCc1ccc(CN2CCC(c3cc4ccccc4o3)CC2)cc1', 'O=C(Nc1cccc(OCC2CCN(Cc3ccccc3)CC2)c1)c1ccnc(NC(=O)C2CC2)c1', 'COc1ccc2nc3c(c(N)c2c1)CCC3.Cl', 'c1ccc(CN2CCC(c3cc4ccccc4o3)CC2)cc1', 'CCOC(=O)/C(=N\\\\Nc1ccc(OC)cc1)C(=O)C(F)(F)F', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(CCCCc1cn(CCCC(=O)NCCc3c[nH]c4ccccc34)nn1)C2', 'COC(=O)/C(=N\\\\Nc1ccccc1[N+](=O)[O-])C(=O)C(F)(F)F', 'Cc1cccc2nc3c(c(N)c12)CCCCC3.Cl', 'CCOC(=O)/C(=N\\\\Nc1ccc(C(=O)OCC)cc1)C(=O)C(F)(F)F', 'COc1cc(/C=C/C(=O)NCCC(=O)Nc2ccc(Cl)cc2)ccc1O', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(NCCCCCCNC(=O)[C@@H](N)Cc4c[nH]c5ccccc45)c3C(C1)C2.Cl.Cl', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(NCCCCCCNC(=O)[C@@H](N)Cc4c[nH]c5ccccc45)c3C(C1)C2.Cl.Cl', 'Cc1ccc2[nH]c3c(c2c1)CN(Cc1ccccc1)CC3', 'COc1ccc(CN2CCN(C(=O)/C=C/c3ccc(O)c(OC)c3)CC2)cc1', 'COc1cc2c(cc1OC)C(=O)C(CC1(F)CCN(Cc3cc(F)c(F)cc3F)CC1)C2', 'Cl.Nc1c2c(nc3ccc(Cl)cc13)CCC2', 'COc1ccc(C(=O)c2c(C3CCN(Cc4cc(OC)ccc4OC)CC3)oc3ccccc23)cc1', 'COc1cc2c(cc1OC)C(=O)C(CC1(F)CCN(Cc3ccc(F)cc3)CC1)C2', 'Cl.Nc1c2c(nc3c(Br)cc(Br)cc13)CCCC2', 'O=C(Nc1cncc(C(=O)NC2CCN(Cc3ccccc3)CC2)c1)c1ccnc(NC(=O)C2CC2)c1', 'Cc1ccc2c(N)c3c(nc2c1)CCC3.Cl', 'COc1ccc2[nH]c3cc[n+](C)cc3c2c1.[I-]', 'Cl.Nc1c2c(nc3ccc(Br)cc13)CCC2', 'Cc1ccc(S(=O)(=O)SCc2ccc(C#N)cc2)cc1', 'Cc1ccc(S(=O)(=O)SCc2ccc(C#N)cc2)cc1', 'CCOC(=O)/C(=N\\\\Nc1ccc(F)cc1)C(=O)C(F)(F)F', 'COc1ccc(OC)c(CN2CCC(c3oc4ccccc4c3C(=O)c3ccccc3)CC2)c1', 'Cc1ccc2c(N)c3c(nc2c1)CCCC3.Cl', 'O=C(CC1CCN(Cc2ccc(F)cc2)CC1)Nc1n[nH]c2cc(-c3cccnc3)ccc12', 'Fc1ccc2[nH]c3c(c2c1)CN(Cc1ccccc1)CC3', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(NCCCCCCCCCNC(=O)c4cc(O)cc(O)c4)c3C(C1)C2', 'Cc1cccc2nc3c(c(N)c12)CCC3.Cl', 'COc1cc2c(cc1OC)C(=O)C(CC1(F)CCN(Cc3ccccc3F)CC1)C2', 'COc1cc(/C=C/C(=O)NCCC(=O)Nc2ccccc2)ccc1O', 'CN1CCc2c(c3ccccc3n2CCC(=O)N2c3ccccc3Sc3ccccc32)C1', 'Cc1ccc(S(=O)(=O)SCc2ccc(OC(F)(F)F)cc2)cc1', 'Cc1ccc(S(=O)(=O)SCc2ccc(OC(F)(F)F)cc2)cc1', 'Cl.Nc1c2c(nc3ccc(Cl)cc13)CCCCC2', 'Cc1ccc2nc3c(c(N)c2c1)CCCCC3.Cl', 'Cl.Nc1c2c(nc3cccc(Cl)c13)CCCC2', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(NCCCCCCCCCNS(=O)(=O)c4cn[nH]c4)c3C(C1)C2', 'O=C(NC1CCN(Cc2ccccc2)CC1)c1cncc(NC(=O)c2ccnc3[nH]ccc23)c1', 'Fc1ccc2[nH]c3ccncc3c2c1', 'Cc1ccc(S(=O)(=O)SCc2ccc(Cl)cc2)cc1', 'Cc1ccc(S(=O)(=O)SCc2ccc(Cl)cc2)cc1', 'c1ccc2oc(C3CCNCC3)cc2c1', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(NCCCCCCCCC(=O)Nc4cn[nH]c4)c3C(C1)C2', 'COc1ccc(CN2CCC(c3cc4ccccc4o3)CC2)cc1OC', 'O=C(Nc1cncc(OCC2CCN(Cc3ccccc3)CC2)c1)c1ccnc(NC(=O)C2CC2)c1', 'O=C(NCC1CCN(Cc2cccc(Cl)c2)CC1)c1cncc(NC(=O)c2ccnc(NC(=O)C3CC3)c2)c1', 'O=C(CCn1c2ccncc2c2cc(F)ccc21)N1c2ccccc2Sc2ccccc21', 'COc1cc(/C=C/C(=O)N2CCN(Cc3ccc(F)cc3)CC2)ccc1O', 'Cl.Nc1c2c(nc3c(Cl)cc(Cl)cc13)CCC2', 'O=C(Nc1cncc(OCC2CCN(Cc3ccccc3F)CC2)c1)c1ccnc(NC(=O)C2CC2)c1', 'O=C(c1ccccc1)c1c(C2CCN(Cc3ccccc3)CC2)oc2ccccc12', 'O=C(NCC1CCN(Cc2ccc(F)c(F)c2)CC1)c1cncc(NC(=O)c2ccnc(NC(=O)C3CC3)c2)c1', 'Cl.Nc1c2c(nc3ccc(F)cc13)CCCCC2', 'Cc1ccc2[nH]c3cc[n+](C)cc3c2c1.[I-]', 'O=C(NCC1CCN(Cc2cccc(F)c2)CC1)c1cncc(NC(=O)c2ccnc(NC(=O)C3CC3)c2)c1', 'COc1cc(/C=C/C(=O)NCC(=O)NCCc2c[nH]c3ccc(Cl)cc23)ccc1O', 'COc1ccc2[nH]cc(CCNC(=O)Cn3cc(CCCCN(C)CCCC4c5cc(OC)c(OC)cc5CCN4C)nn3)c2c1', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(NCCCCCCCCCNC(=O)c4ccc[nH]c4=O)c3C(C1)C2', 'Cc1ccc(S(=O)(=O)SCc2ccc([N+](=O)[O-])cc2)cc1', 'Cc1ccc(S(=O)(=O)SCc2ccc([N+](=O)[O-])cc2)cc1', 'O=C(Nc1cncc(OCC2CCN(Cc3ccccc3Cl)CC2)c1)c1ccnc(NC(=O)C2CC2)c1', 'Cl.Nc1c2c(nc3ccc(Br)cc13)CCCCC2', 'CCOC(=O)/C(=N\\\\Nc1ccc(Br)cc1)C(=O)C(F)(F)F', 'Cl.Nc1c2c(nc3c(Br)cc(Br)cc13)CCC2', 'COc1cc(/C=C/C(=O)N2CCN(Cc3cccc(Cl)c3)CC2)ccc1O', 'COC(=O)/C(=N\\\\Nc1ccc(C)cc1)C(=O)C(F)(F)F', 'COC(=O)/C(=N\\\\Nc1ccc(C)cc1)C(=O)C(F)(F)F', 'Cc1ccc(S(=O)(=O)SCc2ccc(C(F)(F)F)cc2)cc1', 'Cc1ccc(S(=O)(=O)SCc2ccc(C(F)(F)F)cc2)cc1', 'O=C(NCC1CCN(Cc2ccc(F)cc2)CC1)c1cncc(NC(=O)c2ccnc(NC(=O)C3CC3)c2)c1', 'Cl.Nc1c2c(nc3c(Br)cc(Br)cc13)CCCCC2', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(CCCCc1cn(CCCCC(=O)NCCc3c[nH]c4ccccc34)nn1)C2', 'COc1ccc2[nH]cc(CCNC(=O)CNC(=O)/C=C/c3ccc(O)c(OC)c3)c2c1', 'O=C(NCC1CCN(Cc2cccc(Cl)c2)CC1)c1cncc(NC(=O)c2ccnc3[nH]ccc23)c1', 'C[n+]1ccc2c(c1)c1ccccc1n2CCC(=O)N1c2ccccc2Sc2ccccc21.[I-]', 'O=C(NCC1CCN(Cc2ccccc2F)CC1)c1cncc(NC(=O)c2ccnc(NC(=O)C3CC3)c2)c1', 'O=C(CC1CCN(Cc2ccccc2)CC1)Nc1n[nH]c2cc(-c3cccnc3)ccc12', 'COc1ccc(CN2CCC(c3cc4ccccc4o3)CC2)cc1', 'COc1ccc2c3c1O[C@H]1C[C@@H](O)C=C[C@@]31CCN(CCCCc1cn(CC(=O)NCCc3c[nH]c4ccccc34)nn1)C2', 'Cc1ccc(S(=O)(=O)SCc2ccc(C(C)C)cc2)cc1', 'Cc1ccc(S(=O)(=O)SCc2ccc(C(C)C)cc2)cc1', 'COc1cc(CNC(=O)CCCCCCCCNc2c3c(nc4cc(Cl)ccc24)CC2C=C(C)CC3C2)ccn1', 'Cc1ccccc1CN1CCC(CNC(=O)c2cncc(NC(=O)c3ccnc(NC(=O)C4CC4)c3)c2)CC1', 'COC(=O)/C(=N\\\\Nc1ccc(OC)cc1)C(=O)C(F)(F)F', 'COc1ccc2nc3c(c(N)c2c1)CCCC3.Cl', 'Cl.Nc1c2c(nc3c(Cl)cc(Cl)cc13)CCCCC2', 'Oc1ccc(CN2CCC(c3cc4ccccc4o3)CC2)cc1', 'O=C(NCC1CCN(Cc2ccccc2)CC1)c1n[nH]c2ccc(-c3cccnc3)cc12', 'COc1cc(/C=C/C(=O)N2CCN(Cc3cccc(F)c3)CC2)ccc1O', 'Cc1cccc2nc3c(c(N)c12)CCCC3.Cl', 'O=C(Nc1cncc(OCC2CCN(Cc3ccc(F)cc3)CC2)c1)c1ccnc(NC(=O)C2CC2)c1', 'Cc1ccc2c(c1)c1c[n+](C)ccc1n2CCC(=O)N1c2ccccc2Sc2ccccc21.[I-]', 'C[n+]1ccc2c(c1)c1cc(F)ccc1n2CCC(=O)N1c2ccccc2Sc2ccccc21.[I-]', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(NCCCCCNC(=O)[C@@H](N)Cc4c[nH]c5ccccc45)c3C(C1)C2.Cl.Cl', 'COc1ccc(CN2CCC(c3oc4ccccc4c3C(=O)c3ccc(OC)c(OC)c3)CC2)cc1OC', 'Cc1ccc2nc3c(c(N)c2c1)CCC3.Cl', 'COc1ccc2nc3c(c(N)c2c1)CCCCC3.Cl', 'Fc1ccc(CN2CCC(c3cc4ccccc4o3)CC2)cc1', 'COc1ccc(OC)c(CN2CCC(c3cc4ccccc4o3)CC2)c1', 'CC(=O)Nc1cc(C(=O)Nc2cncc(OCC3CCN(Cc4ccc(F)cc4)CC3)c2)ccn1', 'COc1ccc(CSS(=O)(=O)c2ccc(C)cc2)cc1', 'COc1ccc(CSS(=O)(=O)c2ccc(C)cc2)cc1', 'Cc1ccc2nc3c(c(N)c2c1)CCCC3.Cl', 'Cl.Nc1c2c(nc3ccc(Cl)cc13)CCCC2', 'O=C(Nc1cncc(OCC2CCN(Cc3ccccc3)CC2)c1)c1ccnc2[nH]ccc12', 'COc1cc2c(cc1OC)C(=O)C(CC1(F)CCN(Cc3ccc(F)cc3F)CC1)C2', 'CC1=CC2Cc3nc4cc(Cl)ccc4c(NCCCCCCCNC(=O)[C@@H](N)Cc4c[nH]c5ccccc45)c3C(C1)C2.Cl.Cl', 'Clc1ccc(CN2CCC(c3cc4ccccc4o3)CC2)cc1', 'Cl.Nc1c2c(nc3ccc(Br)cc13)CCCC2', 'COc1ccc2c(c1)c1c[n+](C)ccc1n2CCC(=O)N1c2ccccc2Sc2ccccc21.[I-]', 'Cc1c(C)c2ccc(OCC3CCCN(CCCC(F)F)C3)cc2oc1=O', 'Oc1cccc(CCCCCCCCNc2c3c(nc4cc(Cl)ccc24)CCCC3)c1', 'Oc1cccc(CCCCCCCCNc2c3c(nc4ccccc24)CCCC3)c1', 'O=C(O[C@H]1CN2Cc3cc4c(cc3[C@]13C=C[C@@H](O)C[C@H]23)OCO4)c1cccc([N+](=O)[O-])c1', 'CO[C@H]1C[C@H]2C(=C[C@@H]1OC(=O)c1ccc(C)c([N+](=O)[O-])c1)[C@H]1CN2Cc2cc3c(cc21)OCO3', 'COc1cc2c(c3c1OCOC3)C[C@H]1c3c(cc4c(c3OC)OCO4)CC[N+]1=C2.O=C([O-])C(F)(F)F', 'COc1cc2c(c3c1OCOC3)C[C@H]1c3c(cc4c(c3OC)OCO4)CC[N+]1=C2.O=C([O-])C(F)(F)F', 'COc1cc(CCCCCCCCNc2c3c(nc4cc(Cl)ccc24)CCCC3)cc(OC)c1', 'COC(=O)c1c(CCCCCCCCNc2c3c(nc4cc(Cl)ccc24)CCCC3)cccc1OC', 'Cc1c(C)c2ccc(OCc3ccc(CN(C)CCCC(F)F)cc3)cc2oc1=O', 'O=C(O)c1c(O)cccc1CCCCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'CN(CCCO)Cc1ccc(COc2ccc3c(CO)cc(=O)oc3c2)cc1', 'COc1cc2c[n+]3c(cc2c(CO)c1OC)-c1c(cc2c(c1OC)OCO2)CC3', 'COc1cc2c[n+]3c(cc2c(CO)c1OC)-c1c(cc2c(c1OC)OCO2)CC3', 'COC(=O)c1c(CCCCCCCCNc2c3c(nc4ccccc24)CCCC3)cccc1OC', 'Cc1c(C)c2ccc(OCC3CCN(CCCC(F)F)CC3)cc2oc1=O', 'CCN(CCCOc1ccc2c(C)c(C)c(=O)oc2c1)Cc1cccc(F)c1', 'N#Cc1ccc2[nH]cc(CCCCN3CCN(c4ccc(C(=O)CCC5CCN(Cc6ccccc6)CC5)cc4)CC3)c2c1', 'COC(=O)c1c(O)cccc1CCCCCCCCNc1c2c(nc3cc(Cl)ccc13)CCCC2', 'CN(CCCC(F)F)Cc1ccc(COc2ccc3c(CO)cc(=O)oc3c2)cc1', 'CN(CCCC(F)F)Cc1ccc(COc2ccc3c(CO)cc(=O)oc3c2)cc1', 'Cc1c(C)c2ccc(OCC3CCCN(Cc4cccc(F)c4)C3)cc2oc1=O', 'COc1c(-c2ccc(O)cc2)cc2oc3cc(O)c(O)cc3c2c1O', 'CN(Cc1ccccc1)Cc1ccc(COc2ccc3c(C(F)F)cc(=O)oc3c2)cc1', 'Cc1c(C)c2ccc(OCc3cccc(CN(C)CCCC(F)F)c3)cc2oc1=O', 'CO[C@H]1C[C@H]2C(=C[C@@H]1OC(=O)c1cc([N+](=O)[O-])cc([N+](=O)[O-])c1)[C@H]1CN2Cc2cc3c(cc21)OCO3', 'COC(=O)c1c(CCCCCCCCNc2c3c(nc4ccc(OC)cc24)CCCC3)cccc1OC', 'COc1cc2c(c3c1OCOC3)C[C@H]1c3c(cc4c(c3OC)OCO4)CCN1C2', 'COc1cc2c(c3c1OCOC3)C[C@H]1c3c(cc4c(c3OC)OCO4)CCN1C2', 'Cc1c(C)c2ccc(OCC3CCN(Cc4cccc(C(F)(F)F)c4)CC3)cc2oc1=O', 'O=C(O[C@@H]1C=C[C@]23CCN(Cc4cc5c(cc42)OCO5)[C@H]3C1)c1ccccc1[N+](=O)[O-]', 'CO[C@H]1C[C@H]2C(=C[C@@H]1OC(=O)c1ccc(Cl)c([N+](=O)[O-])c1)[C@H]1CN2Cc2cc3c(cc21)OCO3', 'O=C(O)c1c(O)cccc1CCCCCCCCNc1c2c(nc3ccccc13)CCCC2', 'COc1cc(CCCCCCCCNc2c3c(nc4ccccc24)CCCC3)cc(OC)c1', 'COc1cccc(CCCCCCCCNc2c3c(nc4cc(Cl)ccc24)CCCC3)c1', 'O=C(O[C@H]1CN2Cc3cc4c(cc3[C@]13C=C[C@@H](O)C[C@H]23)OCO4)c1ccccc1Cl', 'COc1cc2c(c(CO)c1OC)C[C@H]1c3c(cc4c(c3OC)OCO4)CC[N+]1=C2.O=C([O-])C(F)(F)F', 'COc1cc2c(c(CO)c1OC)C[C@H]1c3c(cc4c(c3OC)OCO4)CC[N+]1=C2.O=C([O-])C(F)(F)F', 'CN(Cc1ccc(COc2ccc3c(CO)cc(=O)oc3c2)cc1)Cc1cccc(F)c1', 'COc1ccccc1C(=O)O[C@H]1CN2Cc3cc4c(cc3[C@]13C=C[C@@H](O)C[C@H]23)OCO4', 'Cc1c(C)c2ccc(OCC3CCN(Cc4cccc(F)c4)CC3)cc2oc1=O', 'CCNC(=O)Oc1ccc2c(c1)[C@]1(C)CCOC1O2', 'COc1cccc(CCCCCCCCNc2c3c(nc4ccccc24)CCCC3)c1', 'CO[C@H]1C[C@H]2C(=C[C@@H]1OC(=O)c1cc([N+](=O)[O-])ccc1Cl)[C@H]1CN2Cc2cc3c(cc21)OCO3', 'COC(=O)c1c(O)cccc1CCCCCCCCNc1c2c(nc3ccccc13)CCCC2', 'Cc1c(C)c2ccc(OCCCN(Cc3cccc(F)c3)C(C)C)cc2oc1=O', 'CCCCN(CCOc1cccc2c(OC(=O)N(C)C)cccc12)CCC1CCCCCC1', 'c1ccc2c(NCCN3CCOCC3)c3c(nc2c1)CCCC3', 'COc1cc(/C=C/c2cc(=O)oc3c2ccc2oc(-c4ccc(C)cc4)cc23)cc(OC)c1', 'O=C(COc1ccc(Cl)cc1)NCCN1CCN(Cc2ccccc2)CC1', 'NS(=O)(=O)c1ccc(NCc2cccc(Cl)c2O)cc1', 'CCN(CC)C(=O)c1ccc2c(c1)nc(Cc1ccc(OC(=O)NCCCCCCN3CCc4ccccc4C3)cc1)n2CCC(C)C', 'CCN(CC)C(=O)c1ccc2c(c1)nc(Cc1ccc(OC(=O)NCCCCCCN3CCc4ccccc4C3)cc1)n2CCC(C)C', 'O=C(COc1ccc(-c2ccccc2)cc1)NCC1CCN(Cc2ccccc2)CC1', 'CCOc1ccc(C(=O)Cc2ncc(C(=O)N(C)CCCOc3ccc([N+](=O)[O-])cc3)cn2)cc1', 'NC(=O)c1cc[n+](CCC[n+]2cc(F)c(/C=N/O)c(F)c2)cc1.[Br-].[Br-]', 'COc1ccc(C(=O)Cc2ncc(C(=O)N(C)CCCOc3ccc(C(F)(F)F)cc3)cn2)cc1', 'COc1ccc(C(=O)Cc2ncc(C(=O)NCc3ccc(OC)c(OC)c3)cn2)cc1', 'Cc1cccc2sc(NC(=O)CCN3CCN(C(C)(C)C)CC3)nc12', 'COc1ccc(/C=C/C(=O)Nc2cc[n+](Cc3cccc(F)c3)cc2)cc1OC.[Br-]', 'Cc1cccc2sc(NC(=O)CCN3CCN(Cc4ccc(C(C)(C)C)cc4)CC3)nc12', 'COc1ccc(C(=O)Cc2ncc(C(=O)N(C)CCCOc3ccc([N+](=O)[O-])cc3)cn2)cc1', 'CCN(C)C(=O)Oc1ccc(C2CC(=O)c3c(O)cc(OC(=O)N(C)CC)cc3O2)cc1', 'COc1cc2nc3c(c(N4CCOCC4)c2cc1OC)CCCC3', 'NC(=O)c1cc[n+](CCCC[n+]2ccc(/C=N/O)c(F)c2)cc1.[Br-].[Br-]', 'Cc1cccc2sc(NC(=O)CCN3CCN(Cc4ccccc4F)CC3)nc12', 'O=C(CN1CCN(Cc2ccccc2)CC1)Nc1n[nH]c2ncccc12', 'O=[N+]([O-])c1ccc2nc3c(c(Nc4[nH]nc5ncccc45)c2c1)CCCC3', 'CCC(c1ccc(O)c(OC)c1)c1ccc(OC)cc1O', 'O=c1c2ccccc2nc2n1C(c1cncc3[nH]c4ccccc4c13)CC2O', 'COc1ccc(OCC(=O)NCCN2CCN(Cc3ccccc3)CC2)cc1', 'Cc1ccc2nc3c(c(NCCCl)c2c1)CCCC3', 'O=C(COc1ccc(Cl)cc1)NCC1CCN(Cc2ccccc2)CC1', 'CC(=O)c1ccc(N2CCN(CCC(=O)Nc3nc4c(C)cccc4s3)CC2)cc1', 'COc1cc(/C=C/c2cc(=O)oc3c2ccc2oc(-c4ccccc4)cc23)cc(OC)c1', 'CN1CCN(CCC(=O)Nc2n[nH]c3ncccc23)CC1', 'Cc1ccc2nc3c(c(NCCN4CCN(C)CC4)c2c1)CCCC3', 'Cc1cccc2sc(NC(=O)CCN3CCN(c4ccccn4)CC3)nc12', 'COc1ccc(OCC(=O)NCC2CCN(Cc3ccccc3)CC2)cc1', 'CC(=O)N1N=C(c2ccc(Br)cc2)CC1c1ccc(-c2ccccc2)cc1', 'NC(=O)c1cc[n+](CCC[n+]2ccc(/C=N/O)c(F)c2)cc1.[Br-].[Br-]', 'COc1cc(/C=C/C(=O)OCCCCCN(C)Cc2cccc(OC(=O)N(C)C)c2)ccc1O', 'C=C(C)[C@]1(O)CC[C@@]2(C)C3=Cc4c(cc(-c5cccnc5)oc4=O)O[C@]3(C)[C@@H](O)C[C@@H]2[C@@]12CCC(=O)OC2', 'Cc1cc(Br)cc(C)c1OCC(=O)NCC1CCN(Cc2ccccc2)CC1', 'CCCCC1OC(=O)c2cc(OCc3ccc(CN4CCCCC4)c(O)c3)ccc21', 'CCN(CC)Cc1ccc(C=C2Cc3ccccc3C2=O)cc1', 'CCCCN(CCCc1c[nH]c2ccccc12)CCC1CCN(Cc2ccccc2)CC1', 'O=C(Nc1ccc(OC(F)(F)F)cc1)NC1CCN(C(=O)CCCCNc2c3c(nc4cc(Cl)ccc24)CCCC3)CC1', 'CCCCCCCNC(=O)Oc1ccc(Cc2nc3cc(C(=O)N(CC)CC)ccc3n2CCC(C)C)cc1', 'CCCCCCCNC(=O)Oc1ccc(Cc2nc3cc(C(=O)N(CC)CC)ccc3n2CCC(C)C)cc1', 'CC(=O)N1N=C(c2ccc(-c3ccccc3)cc2)CC1c1ccccc1[N+](=O)[O-]', 'O=C(COc1ccc([N+](=O)[O-])cc1)NCC1CCN(Cc2ccccc2)CC1', 'C[C@H]1CN2C(=O)[C@]34Cc5c([nH]c6c7c(ccc56)OC(C)(C)CC7=O)C(C)(C)[C@@H]3C[C@@]2(C1)C(=O)N4', 'CCCCC1OC(=O)c2cc(OCc3ccc(CN4CCCC4)c(O)c3)ccc21', 'CN(CCC1CCCCCC1)Cc1c[nH]c2ccccc12', 'CCC1C/C(=C\\\\c2cc(OC)c(OC)c(OC)c2Br)C(=O)c2ccccc21', 'NS(=O)(=O)c1ccc(/N=C/c2cc(Br)cc(Cl)c2O)cc1', 'CCN(CC)Cc1ccc(/C=C2\\\\Cc3ccccc3C2=O)cc1', 'CCCCC1OC(=O)c2cc(OCc3ccc(CN4CCOCC4)c(O)c3)ccc21', 'c1ccc2c(c1)CCN1Cc3cc(OCCCN4CCCCC4)ccc3N=C21', 'COc1cc(/C=C/c2cc(=O)oc3c2ccc2oc(-c4cc(OC)cc(OC)c4)cc23)cc(OC)c1', 'CCn1c2ccccc2c2cc(/C=C/c3ccc(NC(=S)NCCN4CCCC4)cc3)ccc21', 'CCCCC1OC(=O)c2cc(OCc3ccc(CN(CC)CC)c(O)c3)ccc21', 'O=C(COc1ccc(CCc2ccccc2)cc1)NCC1CCN(Cc2ccccc2)CC1', 'Cc1ccc2nc3c(c(Nc4[nH]nc5ncccc45)c2c1)CCCC3', 'O=C(CCN1CCN(c2ccccc2)CC1)Nc1n[nH]c2ncccc12', 'Cc1cccc2sc(NC(=O)CCN3CCN(C(C)C)CC3)nc12', 'CCCCN(CCC1CCCCCC1)Cc1cc2ccccc2cc1O', 'CCCCC1OC(=O)c2cc(OCc3ccc(CN4CCN(C)CC4)c(O)c3)ccc21', 'OCCCCCCCCc1ccc(CN2CCCCC2)c(O)c1', 'CCN(CC)Cc1ccc(/C=C2\\\\Cc3ccc(OC)cc3C2=O)cc1', 'Oc1cc2c(cc1O)-c1cc3ccc(O)c(O)c3c[n+]1CC2.[Br-]', 'NC(=O)c1cc[n+](CCCC[n+]2cc(F)c(/C=N/O)c(F)c2)cc1.[Br-].[Br-]', 'CCCC[N+](C)(CCCc1c[nH]c2ccccc12)CCC1CCCCCC1.[I-]', 'CCN1CCN(c2ccc(-c3nc4ccccc4[nH]3)cc2)CC1', 'Cc1ccc2nc3c(c(N4CCN(c5c6c(nc7ccc(C)cc57)CCCC6)CC4)c2c1)CCCC3', 'CC(=O)N1N=C(c2ccc3c(c2)OCO3)CC1c1ccc(-c2ccccc2)cc1', 'COc1cccc(C(=O)Cc2ncc(C(=O)N(C)CCCOc3ccc([N+](=O)[O-])cc3)cn2)c1', 'CCN(CC)Cc1ccc(C=C2Cc3cc(OC)ccc3C2=O)cc1', 'O=C(COc1ccc(CCc2ccccc2)cc1)NCCN1CCN(Cc2ccccc2)CC1', 'COc1cc(/C=C/c2cc(=O)oc3c2ccc2oc(-c4ccc(Cl)cc4)cc23)cc(OC)c1', 'CC(=O)Nc1ccc2nc3c(c(N4CCCCC4)c2c1)CCCC3', 'O=C(CCN1CCCCC1)Nc1n[nH]c2ncccc12', 'CC(=O)Nc1ccc2nc3c(c(N4CCOCC4)c2c1)CCCC3', 'CCN1CCN(CCC(=O)Nc2nc3c(C)cccc3s2)CC1', 'COc1ccc(C(=O)Cc2ncc(C(=O)NC3CCN(Cc4ccccc4)CC3)cn2)cc1', 'O=C(COc1ccc(Cl)cc1[N+](=O)[O-])NCCN1CCN(Cc2ccccc2)CC1', 'COc1ccc(C(=O)Cc2ncc(C(=O)N(C)CCCOc3cccc(OC)c3)cn2)cc1', 'COc1ccc(C(=O)Cc2ncc(C(=O)N(C)CCCOc3c(F)c(F)c(F)c(F)c3F)cn2)cc1', 'O=c1c2ccccc2nc2n1CC[C@@H]2[C@@H]1CCCN1', 'c1ccc2c(c1)CCCN1Cc3cc(OCCCN4CCCCC4)ccc3N=C21', 'COc1ccc(C(=O)Cc2ncc(C(=O)N3CCN(Cc4ccccc4)CC3)cn2)cc1', 'CCCCN(CCc1c[nH]c2c(OC(=O)C(C)C)cccc12)CCC1CCCCCC1', 'CCN(C)C(=O)Oc1ccc(C2CC(=O)c3c(OC(=O)N(C)CC)cc(OC(=O)N(C)CC)cc3O2)cc1', 'CCN(CC)C(=O)c1ccc2c(c1)nc(Cc1ccc(OC(=O)N3CCC3)cc1)n2CCC(C)C', 'CCN(CC)C(=O)c1ccc2c(c1)nc(Cc1ccc(OC(=O)N3CCC3)cc1)n2CCC(C)C', 'C[N+](C)(C)CCNC(=O)/C=C/c1ccc(O)c(O)c1', 'CN(CCCOc1ccc([N+](=O)[O-])cc1)C(=O)c1cnc(CC(=O)c2cccs2)nc1', 'CC(=O)N1N=C(c2ccc3ccccc3c2)CC1c1ccc(-c2ccccc2)cc1', 'CN1c2ccccc2C(NCCCCCCC(=O)CCCCNc2c3c(nc4ccccc24)CCCC3)c2ccc(Cl)cc2S1(=O)=O', 'COc1cc2c(cc1OC)C(=O)/C(=C/c1cc[n+](Cc3ccc(F)cc3)cc1)OC2.[Br-]', 'CCCCCCCNC(=O)Oc1ccc(Cc2nc3cc(C(=O)N(CC)CC)ccc3n2CCCCN2CCCCC2)cc1', 'CCCCCCCNC(=O)Oc1ccc(Cc2nc3cc(C(=O)N(CC)CC)ccc3n2CCCCN2CCCCC2)cc1', 'CC1=C[C@H]2Cc3nc4cc(Cl)ccc4c(NCCCCC(=O)N4CCC(NC(=O)Nc5ccc(OC(F)(F)F)cc5)CC4)c3[C@@H](C1)C2', 'CC(=O)N1N=C(c2ccc(-c3ccccc3)cc2)CC1c1ccc2c(c1)OCO2', 'COc1ccc2cc3[n+](cc2c1OC)CCc1cc(O)c(O)cc1-3.[Br-]', 'Cc1ccc2nc3c(c(NCCN4CCCCC4)c2c1)CCCC3', 'CCCCCCCNC(=O)Oc1ccc(Cc2nc3cc(C(=O)N4CCCCC4)ccc3n2CCC(C)C)cc1', 'CCCCCCCNC(=O)Oc1ccc(Cc2nc3cc(C(=O)N4CCCCC4)ccc3n2CCC(C)C)cc1', 'CCCCN(CCc1c[nH]c2cc(O)ccc12)CCC1CCCCCC1', 'O=C(COc1cc(F)ccc1[N+](=O)[O-])NCCN1CCN(Cc2ccccc2)CC1', 'CC(=O)N1N=C(c2ccc(C)cc2)CC1c1ccc(-c2ccccc2)cc1', 'CN(C)C1CCC(CCN(CCCc2c[nH]c3ccccc23)CCC2CCCCCC2)CC1', 'CN(C)C1CCC(CCN(CCCc2c[nH]c3ccccc23)CCC2CCCCCC2)CC1', 'CCCCN(CCC1CCCCCC1)Cc1ccc(OC(=O)N(C)C)c2ccccc12', 'Cc1ccc2nc3c(c(NCCO)c2c1)CCCC3', 'COc1cc(/C=C/c2nnc(-c3ccc(C(F)(F)F)cc3)o2)ccc1O', 'Cc1cc(Br)cc(C)c1OCC(=O)NCCN1CCN(Cc2ccccc2)CC1', 'CO[C@@H]1C=C[C@@]23c4cc5c(cc4CN(C[C@@H]2OC(=O)c2ccc([N+](=O)[O-])cc2)C3C1)OCO5', 'O=c1c2ccccc2nc2n1C(C1CN=Cc3[nH]c4ccccc4c31)CC2O', 'CC(=O)N1N=C(c2ccccc2[N+](=O)[O-])CC1c1ccc(-c2ccccc2)cc1', 'COc1ccc2nc3c(c(N)c2c1)C1CC=CC(C3)C1', 'O=C(CN1CCN(c2ccccc2)CC1)Nc1n[nH]c2ncccc12', 'CCCCN(CCC1CCCCCC1)Cc1cn(OC(=O)N(C)C)c2ccccc12', 'OCCCCCCCCc1ccc(CN2CCCC2)c(O)c1', 'Cc1cccc2sc(NC(=O)CCN3CCN(Cc4cc(F)ccc4F)CC3)nc12', 'O=[N+]([O-])c1ccc2nc3c(c(N4CCOCC4)c2c1)CCCC3', 'COc1ccc(C(=O)Cc2ncc(C(=O)N(C)CCCOc3ccc(OC)c(OC)c3)cn2)cc1', 'CCCCC1OC(=O)c2cc(OCc3ccc(CN(C)C)c(O)c3)ccc21', 'O=C(COc1ccc([N+](=O)[O-])cc1)NCCN1CCN(Cc2ccccc2)CC1', 'Cc1cccc2sc(NC(=O)CCN3CCN(CCCN(C)C)CC3)nc12', 'O=C(Cn1nc2ncccc2c1NC(=O)Cn1nc2ncccc2c1NC(=O)CN1CCN(Cc2ccccc2)CC1)Nc1[nH]nc2ncccc12', 'O=C(CCN1CCOCC1)Nc1n[nH]c2ncccc12', 'CC(=O)O[C@@H]1C[C@@]2(C)Oc3cc(C)oc(=O)c3C[C@@H]2[C@@]2(C)C=CC(=O)C(C)(C)[C@H]12', 'CC(=O)O[C@@H]1C[C@@]2(C)Oc3cc(C)oc(=O)c3C[C@@H]2[C@@]2(C)C=CC(=O)C(C)(C)[C@H]12', 'NS(=O)(=O)c1ccc(N2N=C(c3cccs3)CC2c2ccc(Br)cc2)cc1', 'O=C(COc1cc(F)ccc1[N+](=O)[O-])NCC1CCN(Cc2ccccc2)CC1', 'O=C(CCN1CCN(Cc2ccccc2)CC1)Nc1ccc2nc3n(c(=O)c2c1)CCC3', 'COc1cc(/C=C/c2cc(=O)oc3c2ccc2oc(-c4ccc(F)cc4)cc23)cc(OC)c1', 'COc1ccc(OCCCN(C)C(=O)c2cnc(CC(=O)c3ccc(OC)cc3)nc2)cc1', 'NS(=O)(=O)c1ccc(NCc2cccc(Br)c2O)cc1', 'Cc1ccc2nc3c(c(N4CCCCC4)c2c1)CCCC3', 'COc1cc(/C=C/c2cc(=O)oc3c2ccc2oc(-c4cccc(Cl)c4)cc23)cc(OC)c1', 'COc1cc(/C=C/c2nnc(-c3ccc(OC(F)(F)F)cc3)o2)ccc1O', 'CC(=O)N1N=C(c2ccc(-c3ccccc3)cc2)CC1c1ccc2ccccc2c1', 'COC/C(C=O)=C\\\\CCC1=CC(c2cc(O)ccc2O)OC1=O', 'Cc1cccc2sc(NC(=O)CCN3CCN(Cc4cccc5ccccc45)CC3)nc12', 'Cc1ccc2nc3c(c(NCCN4CCN(Cc5ccccc5)CC4)c2c1)CCCC3', 'Cc1cccc2sc(NC(=O)CCN3CCN(C4CCN(C)CC4)CC3)nc12', 'COC(=O)/C=C/c1ccc(OCCCCCN2CCN(CC(=O)Nc3c4c(nc5ccccc35)CCCC4)CC2)c(OC)c1', 'Cc1ccc2nc3c(c(NCCN4CCOCC4)c2c1)CCCC3', 'CN1CCN(c2c3c(nc4ccc([N+](=O)[O-])cc24)CCCC3)CC1', 'COc1ccc(C(=O)Cc2ncc(C(=O)Nc3ccncc3)cn2)cc1', 'O=C(CCN1CCN(Cc2ccccc2)CC1)Nc1n[nH]c2ncccc12', 'C#CCOc1cccc(-c2cc(-c3ccc(OCCN4CCOCC4)cc3)nc(C)n2)c1', 'COc1ccc(-c2cc3c(ccc4c(/C=C/c5cc(OC)cc(OC)c5)cc(=O)oc43)o2)cc1', 'O=C(Nc1ccc(OC(F)(F)F)cc1)NC1CCN(C(=O)CCCNc2c3c(nc4cc(Cl)ccc24)CCCC3)CC1', 'O=c1cc(/N=N/N=P(CCP(=N/N=N/c2cc(=O)oc3ccccc23)(c2ccccc2)c2ccccc2)(c2ccccc2)c2ccccc2)c2ccccc2o1', 'CCOC1(c2cc(O)ccc2O)C=C(CC/C=C(\\\\C)CCC=C(C)C)C(=O)O1', 'c1cc2c(cc1OCCCN1CCCCC1)CN1CCCCCC1=N2', 'CCCCCCCNC(=O)Oc1ccc(Cc2nc3cc(C(=O)N(CC)CC)ccc3n2CCN2CCCCC2)cc1', 'CCCCCCCNC(=O)Oc1ccc(Cc2nc3cc(C(=O)N(CC)CC)ccc3n2CCN2CCCCC2)cc1', 'COc1cc2oc(C(=O)Nc3cccc(CN(C)Cc4ccccc4)c3)cc(=O)c2cc1OC', 'O=C(COc1ccccc1C(F)(F)F)NCC1CCN(Cc2ccccc2)CC1', 'COc1cc(/C=C2\\\\CCc3cc([N+](=O)[O-])ccc3C2=O)c(Br)c(OC)c1OC', 'COc1cc(/C=C/c2cc(=O)oc3c2ccc2oc(-c4cccc(F)c4)cc23)cc(OC)c1', 'O=[N+]([O-])c1ccc2nc3c(c(N4CCCCC4)c2c1)CCCC3', 'Cc1ccc2nc3c(c(N4CCN(C)CC4)c2c1)CCCC3', 'CCOCCN1CCN(CCC(=O)Nc2nc3c(C)cccc3s2)CC1', 'O=C(COc1ccc(Cc2ccccc2)cc1)NCC1CCN(Cc2ccccc2)CC1', 'Cc1cccc2sc(NC(=O)CCN3CCN(C4CCCCC4)CC3)nc12', 'COc1ccc(C(=O)Cc2ncc(C(=O)N(C)CCCOc3ccc([N+](=O)[O-])cc3)cn2)cc1OC', 'CCN(CC)Cc1ccc(C=C2Cc3ccc(OC)cc3C2=O)cc1', 'O=C(COc1ccc(-c2ccccc2)cc1)NCCN1CCN(Cc2ccccc2)CC1', 'CN(CCCOc1ccc([N+](=O)[O-])cc1)C(=O)c1cnc(CC(=O)c2ccccc2)nc1', 'O=C(Nc1ccc(OC(F)(F)F)cc1)NC1CCN(C(=O)CCNc2c3c(nc4cc(Cl)ccc24)CCCC3)CC1', 'Cc1cccc2sc(NC(=O)CCN3CCN(CC4CCCCC4)CC3)nc12', 'Cc1cccc2sc(NC(=O)CCN3CCN(CCN(C(C)C)C(C)C)CC3)nc12', 'COc1ccc(C(=O)Cc2ncc(C(=O)NCc3cccs3)cn2)cc1', 'Nc1nn(-c2c3c(nc4ccc([N+](=O)[O-])cc24)CCCC3)c2ncccc12', 'COc1ccc(/C=C2\\\\CCc3cc([N+](=O)[O-])ccc3C2=O)c(Cl)c1OC', 'CCN(CC)Cc1ccc(C=C2Cc3cc(OC)c(OC)cc3C2=O)cc1', 'O=C(COc1ccc(Cc2ccccc2)cc1)NCCN1CCN(Cc2ccccc2)CC1', 'Cc1cccc2sc(NC(=O)CCN3CCN(c4ccncc4)CC3)nc12', 'COc1ccc(/C=C/C(=O)Nc2cc[n+](Cc3ccc(F)cc3)cc2)cc1OC.[Br-]', 'NC(=O)c1cc[n+](C/C=C/C[n+]2cc(F)c(/C=N/O)c(F)c2)cc1.[Br-].[Br-]', 'Cc1cccc2sc(NC(=O)CCN3CCN(c4ncccn4)CC3)nc12', 'O=C(COc1ccc(Cl)cc1[N+](=O)[O-])NCC1CCN(Cc2ccccc2)CC1', 'CN(CCC1CCN(Cc2ccccc2)CC1)Cc1c[nH]c2ccccc12', 'CCN(CC)Cc1ccc(/C=C2\\\\Cc3cc(OC)ccc3C2=O)cc1', 'CC1=C[C@@H]2Cc3nc4cc(Cl)ccc4c(NCCCCC(=O)N4CCC(NC(=O)Nc5ccc(OC(F)(F)F)cc5)CC4)c3[C@H](C1)C2', 'Cc1cccc2sc(NC(=O)CCN3CCN(CC4CCCO4)CC3)nc12', 'Cc1cccc2sc(NC(=O)CCN3CCN(CCN(C)C)CC3)nc12', 'COc1ccccc1/C=C/C=C(\\\\Br)S(=O)(=O)F', 'CN(CCCOc1ccc([N+](=O)[O-])cc1)C(=O)c1cnc(CC(=O)c2ccc3c(c2)OCO3)nc1', 'c1ccc2c(c1)CN1Cc3cc(OCCCN4CCCCC4)ccc3N=C21', 'c1cc2c(cc1OCCCN1CCCCC1)CN1CCCCC1=N2', 'COc1cc2c(Nc3ccc(C(=O)/C=C/c4nc(C)c(C)nc4C)cc3)ncnc2c(OC)c1OC', 'O=C(COc1ccccc1C(F)(F)F)NCCN1CCN(Cc2ccccc2)CC1', 'Cc1ccc2nc3c(c(N4CCOCC4)c2c1)CCCC3', 'CCN(CC)Cc1ccc(/C=C2/Cc3cc(OC)ccc3C2=O)cc1', 'CN(CCCOc1ccc2ccc(=O)oc2c1)Cc1cccc(OC(=O)NC2CCCC2)c1', 'O=C(Oc1cc(O)c2c(=O)cc(-c3ccc(O)cc3)oc2c1)N1CCCCC1', 'CNC(=O)Oc1cccc(CN(C)CCCCCCCOc2ccc(-c3cc(=O)c4ccccc4o3)cc2)c1', 'COc1cccc2c1CCC(NC(=O)OCc1ccccc1)C2', 'CNC(=O)Oc1cccc(CN(C)CCCCCCOc2ccc(C(=O)/C=C/c3cc(OC)c(OC)c(OC)c3)c(O)c2)c1', 'CC(=O)N1CC[C@@]2(O)c3cc(OC(=O)Nc4ccccc4)ccc3N[C@@H]12', 'CC[C@@]1(c2cccc(OC(=O)Nc3ccccc3)c2)CCCCN(C)C1', 'O=c1c(NCCCCCCCc2c3c(nc4ccccc24)CCCC3)c(NCCCCCCCc2c3c(nc4ccccc24)CCCC3)c1=O', 'COc1cc2c(c(OC)c1)CC(NC(=O)OCc1ccccc1)C2', 'CC1CCCCN1CCCNC(=O)c1cc(NC(=O)OC(C)(C)C)ccc1O', 'CCN1/C(=C/C(C)=O)Sc2ccc(OC(=O)OCCOCCNC(=O)c3cc4c(OC(=O)N(C)C)cccc4[n+](C)c3)cc21.COS(=O)(=O)[O-]', 'CCOC(=O)c1cc2c(OC(=O)N(C)C)cccc2[n+](C)c1.O=C([O-])C(F)(F)F', 'CCN(CC)C(=O)OC1C[N+]2(C)CCC1CC2.[I-]', 'CNC(=O)Oc1cccc2c1CCC1C2CCN1CCC1CCCCC1', 'Cc1c(Cl)c(=O)oc2cc(OCCCCSC(=S)N3C(C)CCCC3C)ccc12', 'Cc1c(Cl)c(=O)oc2cc(OCCCCSC(=S)N3CCCCC3C)ccc12', 'O=c1[nH]c2ccc(OCc3ccc(F)cc3)cc2c(=O)o1', 'CNC(=O)Oc1cccc(CN(C)CCCCCCCOc2cccc(-c3cc(=O)c4ccccc4o3)c2)c1', 'COc1cccc2c1CCCC2NS(=O)(=O)NC(=O)OCc1ccccc1', 'CC(C)c1ccc(COc2ccc3[nH]c(=O)oc(=O)c3c2)cc1', 'CCN(C)C(=O)Oc1cccc(CN2CCC(CCC(=O)c3cc(Cl)c(N)cc3OC)CC2)c1', 'O=c1c(NCCCCc2c3c(nc4cc(Cl)ccc24)CCCC3)c(NCCCCc2c3c(nc4ccc(Cl)cc24)CCCC3)c1=O', 'CNC(=O)Oc1cccc(CN(C)CCCCCCOc2ccc3c(c2)O/C(=C\\\\c2cc(OC)c(OC)c(OC)c2)C3=O)c1', 'CN(CCCOc1ccc2ccc(=O)oc2c1)Cc1cccc(OC(=O)NC2CCCCC2)c1', 'CCC(C)(C)NCC(O)c1cc(O)cc(OC(=O)N(C)C)c1', 'CC(C)(C)OC(=O)Nc1ccc(O)c(C(=O)NCCCN2CCCCC2)c1', 'O=C1CCOc2cc(OCCCCCSC(=S)N3CCCCC3)ccc21', 'Cn1ccc2cc(-c3cnc4ccc(C(=O)N5CCCCC5)cc4n3)ccc2c1=O', 'COC(=O)c1cc2c(OC(=O)N(C)C)cccc2[n+]([11CH3])c1']\n\n\nAlso, manually checking for any “NaNs” in the canonical SMILES column (X variable), since AdaBoost classifier won’t accept missing values in the dataset, but if using HistGradientBoostingClassifier() instead, it should take care of the native NaNs.\n\nprint(f\"{df_ache.canonical_smiles.isna().sum()} out of {len(df_ache)} SMILES failed in conversion\")\n\n0 out of 7075 SMILES failed in conversion\n\n\nThere are other ways to deal with NaNs with a few examples provided by scikit-learn. However, with regards to drug discovery data, there are probably more caveats that need to be taken during data preprocessing (I’m also still exploring this too).\n\n\n\nSplit data\nRandomly splitting data this time.\n\n# Found a silly error when naming X, y train/test sets!\n# Remember to name them in this order: X_train, X_test, y_train, y_test\n# otherwise model fitting won't work...\nX_train, X_test, y_train, y_test = train_test_split(X_valid, y, test_size=0.2, random_state=3)\n\n\n\n\n\nCreate pipelines\nThe aim is to create pipeline(s) using scikit-learn.\n\n\nAdaBoost classifier\nThe original plan is to chain an AdaBoost classifier, XGBoost classifier, along with Scikit-mol transformers all at once. However, it turns out that I’m building two separate pipelines of AdaBoost classifier and XGBoost classifier so that I can compare the difference(s) between them, and this also serves better for the purpose of this post really.\nThis is also the time to think about generating molecular features for model training. Choosing data features such as fingerprints (e.g. Morgan fingerprints which is usually best for larger dataset) or RDKit 2D descriptors (which is useful for smaller datasets) or others. For RDKit 2D descriptors, Scikit-mol has integrated RDKit’s rdkit.Chem.Descriptors module and rdkit.ML.Descriptors.MoleculeDescriptors module within its MolecularDescriptorTransformer().\nSome useful links regarding building pipelines in scikit-learn and also another reference notebook on when to use parallel calculations for different molecular features:\n\nPipeline module\nmake_pipeline module (simpler pipeline construction, without naming estimators ourselves but rather naming them automatically)\nUseful notebook explaining when is the best to run parallel calculations to calculate molecular fingerprints and descriptors\n\nInitally, RDKit 2D descriptors are used and to see all the available descriptors, run the following code.\n\nrdkit2d = MolecularDescriptorTransformer()\navailable_descriptors = rdkit2d.available_descriptors\nprint(f\"First 10 descriptor names: {available_descriptors[:10]}\")\n\nFirst 10 descriptor names: ['MaxAbsEStateIndex', 'MaxEStateIndex', 'MinAbsEStateIndex', 'MinEStateIndex', 'qed', 'SPS', 'MolWt', 'HeavyAtomMolWt', 'ExactMolWt', 'NumValenceElectrons']\n\n\nFor the first sample pipeline I’m building below, I’ve noticed that not all of the 209 RDKit 2D descriptors can be used for AdaBoost classifier, as some of the descriptors will have values of “0” and AdaBoost classifier will not be able to take care of them. Therefore, I’m only using a small selection of descriptors only, but HistGradientBoostingClassifier() should be able to take into account of NaNs and can be chained to include all descriptors in a pipeline.\nThe following is an example of building a scikit_learn pipeline by using AdaBoost classifier model, along with Scikit-mol’s transformers for multi-class max_phase predictions with training set consisting of molecules with max_phase 0, 1, 2, 3 and 4. I’ve used Morgan fingerprints instead eventually so that’ll be shown in the following pipeline code, but I’ve also kept the RDKit 2D descriptor option on (just need to uncomment to run).\n\n# Set parameters for RDKit 2D descriptors\n# params_rdkit2d = {\n#     \"desc_list\": ['HeavyAtomCount', 'FractionCSP3', 'RingCount', 'MolLogP', 'MolWt']\n# }\n\n# Set parameters for adaboost model\nparams_adaboost = {\n    \"estimator\": DecisionTreeClassifier(max_depth = 3), \n    # default: n_estimators = 50, learning_rate = 1.0 (trade-off between them)\n    \"n_estimators\": 80, \n    \"learning_rate\": 0.2, \n    # SAMME (Stagewise Additive Modeling using a Multi-class Exponential loss function) algorithm \n    # for multi-class classification\n    \"algorithm\": \"SAMME\", \n    \"random_state\": 2,\n    }\n\n# Building AdaBoostClassifier pipeline\nmlpipe_adaboost = make_pipeline(\n    # Convert SMILES to RDKit molecules\n    SmilesToMolTransformer(), \n    # Molecule standardisations\n    Standardizer(),\n    ## A choice of using either Morgan fingerprints or RDKit 2D descriptors:\n    # Generate MorganFingerprintTransformer()\n    MorganFingerprintTransformer(useFeatures=True),\n    # Generate RDKit2D descriptors\n    #MolecularDescriptorTransformer(**params_rdkit2d),\n    # Scale variances in descriptor data\n    StandardScaler(),\n    # Apply adaptive boost classifier\n    AdaBoostClassifier(**params_adaboost)\n)\n\n\n# Check on pipeline\nmlpipe_adaboost\n\nPipeline(steps=[('smilestomoltransformer', SmilesToMolTransformer()),\n                ('standardizer', Standardizer()),\n                ('morganfingerprinttransformer',\n                 MorganFingerprintTransformer(useFeatures=True)),\n                ('standardscaler', StandardScaler()),\n                ('adaboostclassifier',\n                 AdaBoostClassifier(algorithm='SAMME',\n                                    estimator=DecisionTreeClassifier(max_depth=3),\n                                    learning_rate=0.2, n_estimators=80,\n                                    random_state=2))])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  Pipeline?Documentation for PipelineiNot fittedPipeline(steps=[('smilestomoltransformer', SmilesToMolTransformer()),\n                ('standardizer', Standardizer()),\n                ('morganfingerprinttransformer',\n                 MorganFingerprintTransformer(useFeatures=True)),\n                ('standardscaler', StandardScaler()),\n                ('adaboostclassifier',\n                 AdaBoostClassifier(algorithm='SAMME',\n                                    estimator=DecisionTreeClassifier(max_depth=3),\n                                    learning_rate=0.2, n_estimators=80,\n                                    random_state=2))]) SmilesToMolTransformerSmilesToMolTransformer() StandardizerStandardizer() MorganFingerprintTransformerMorganFingerprintTransformer(useFeatures=True)  StandardScaler?Documentation for StandardScalerStandardScaler()  adaboostclassifier: AdaBoostClassifier?Documentation for adaboostclassifier: AdaBoostClassifierAdaBoostClassifier(algorithm='SAMME',\n                   estimator=DecisionTreeClassifier(max_depth=3),\n                   learning_rate=0.2, n_estimators=80, random_state=2) estimator: DecisionTreeClassifierDecisionTreeClassifier(max_depth=3)  DecisionTreeClassifier?Documentation for DecisionTreeClassifierDecisionTreeClassifier(max_depth=3) \n\n\nAn interactive pipeline diagram should show with a status of “not fitted” if you hover the mouse over the “i” logo on top right. The pipeline is then fitted onto the training sets.\n\nmlpipe_adaboost.fit(X_train, y_train)\n\nPipeline(steps=[('smilestomoltransformer', SmilesToMolTransformer()),\n                ('standardizer', Standardizer()),\n                ('morganfingerprinttransformer',\n                 MorganFingerprintTransformer(useFeatures=True)),\n                ('standardscaler', StandardScaler()),\n                ('adaboostclassifier',\n                 AdaBoostClassifier(algorithm='SAMME',\n                                    estimator=DecisionTreeClassifier(max_depth=3),\n                                    learning_rate=0.2, n_estimators=80,\n                                    random_state=2))])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  Pipeline?Documentation for PipelineiFittedPipeline(steps=[('smilestomoltransformer', SmilesToMolTransformer()),\n                ('standardizer', Standardizer()),\n                ('morganfingerprinttransformer',\n                 MorganFingerprintTransformer(useFeatures=True)),\n                ('standardscaler', StandardScaler()),\n                ('adaboostclassifier',\n                 AdaBoostClassifier(algorithm='SAMME',\n                                    estimator=DecisionTreeClassifier(max_depth=3),\n                                    learning_rate=0.2, n_estimators=80,\n                                    random_state=2))]) SmilesToMolTransformerSmilesToMolTransformer() StandardizerStandardizer() MorganFingerprintTransformerMorganFingerprintTransformer(useFeatures=True)  StandardScaler?Documentation for StandardScalerStandardScaler()  adaboostclassifier: AdaBoostClassifier?Documentation for adaboostclassifier: AdaBoostClassifierAdaBoostClassifier(algorithm='SAMME',\n                   estimator=DecisionTreeClassifier(max_depth=3),\n                   learning_rate=0.2, n_estimators=80, random_state=2) estimator: DecisionTreeClassifierDecisionTreeClassifier(max_depth=3)  DecisionTreeClassifier?Documentation for DecisionTreeClassifierDecisionTreeClassifier(max_depth=3) \n\n\nThe pipeline status should now show a “fitted” message if hovering over the same “i” logo. Then the pipeline is used on the X_test (testing X set) to predict the target (max_phase) variable.\n\nmlpipe_adaboost.predict(X_test)\n\narray([0, 0, 0, ..., 0, 0, 0], shape=(1415,))\n\n\n\n\n\nXGBoost classfier\nThe following code snippet is an example of a scikit_learn pipeline using Scikit-mol’s transformers and XGBoost classifier. One nice thing about XGBoost is that is has scikit_learn interface so that it can be integrated into the scikit-learn pipeline and Scikit-mol’s transformers, which is what I’ve tried below.\n\n# Set parameters for xgboost model\nparams_xgboost = {\n    \"n_estimators\": 100,\n    \"max_depth\": 3,\n    # For multi-class classification, use softprob for loss function (learning task parameters)\n    # source: https://xgboost.readthedocs.io/en/latest/parameter.html#learning-task-parameters\n    \"objective\": 'multi:softprob', \n    \"learning_rate\": 0.1, \n    \"subsample\": 0.5, \n    \"random_state\": 2\n    }\n\n# Building XGBoostClassifier pipeline\nmlpipe_xgb = make_pipeline(\n    # Convert SMILES to RDKit molecules\n    SmilesToMolTransformer(), \n    # Molecule standardisations\n    Standardizer(),\n    ## A choice of using either Morgan fingerprints  or RDKit 2D descriptors:\n    # Generate MorganFingerprintTransformer()\n    MorganFingerprintTransformer(useFeatures=True),\n    # Generate RDKit2D descriptors\n    #MolecularDescriptorTransformer(**params_rdkit2d),\n    # Scale variances in descriptor data\n    StandardScaler(),\n    # XGBoost classifier\n    XGBClassifier(**params_xgboost)\n)\n\n\nmlpipe_xgb\n\nPipeline(steps=[('smilestomoltransformer', SmilesToMolTransformer()),\n                ('standardizer', Standardizer()),\n                ('morganfingerprinttransformer',\n                 MorganFingerprintTransformer(useFeatures=True)),\n                ('standardscaler', StandardScaler()),\n                ('xgbclassifier',\n                 XGBClassifier(base_score=None, booster=None, callbacks=None,\n                               colsample_bylevel=None, colsample_bynode=None,\n                               colsample_bytr...\n                               feature_types=None, gamma=None, grow_policy=None,\n                               importance_type=None,\n                               interaction_constraints=None, learning_rate=0.1,\n                               max_bin=None, max_cat_threshold=None,\n                               max_cat_to_onehot=None, max_delta_step=None,\n                               max_depth=3, max_leaves=None,\n                               min_child_weight=None, missing=nan,\n                               monotone_constraints=None, multi_strategy=None,\n                               n_estimators=100, n_jobs=None,\n                               num_parallel_tree=None,\n                               objective='multi:softprob', ...))])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  Pipeline?Documentation for PipelineiNot fittedPipeline(steps=[('smilestomoltransformer', SmilesToMolTransformer()),\n                ('standardizer', Standardizer()),\n                ('morganfingerprinttransformer',\n                 MorganFingerprintTransformer(useFeatures=True)),\n                ('standardscaler', StandardScaler()),\n                ('xgbclassifier',\n                 XGBClassifier(base_score=None, booster=None, callbacks=None,\n                               colsample_bylevel=None, colsample_bynode=None,\n                               colsample_bytr...\n                               feature_types=None, gamma=None, grow_policy=None,\n                               importance_type=None,\n                               interaction_constraints=None, learning_rate=0.1,\n                               max_bin=None, max_cat_threshold=None,\n                               max_cat_to_onehot=None, max_delta_step=None,\n                               max_depth=3, max_leaves=None,\n                               min_child_weight=None, missing=nan,\n                               monotone_constraints=None, multi_strategy=None,\n                               n_estimators=100, n_jobs=None,\n                               num_parallel_tree=None,\n                               objective='multi:softprob', ...))]) SmilesToMolTransformerSmilesToMolTransformer() StandardizerStandardizer() MorganFingerprintTransformerMorganFingerprintTransformer(useFeatures=True)  StandardScaler?Documentation for StandardScalerStandardScaler() XGBClassifierXGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=3, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=100, n_jobs=None,\n              num_parallel_tree=None, objective='multi:softprob', ...) \n\n\n\nmlpipe_xgb.fit(X_train, y_train)\n\nPipeline(steps=[('smilestomoltransformer', SmilesToMolTransformer()),\n                ('standardizer', Standardizer()),\n                ('morganfingerprinttransformer',\n                 MorganFingerprintTransformer(useFeatures=True)),\n                ('standardscaler', StandardScaler()),\n                ('xgbclassifier',\n                 XGBClassifier(base_score=None, booster=None, callbacks=None,\n                               colsample_bylevel=None, colsample_bynode=None,\n                               colsample_bytr...\n                               feature_types=None, gamma=None, grow_policy=None,\n                               importance_type=None,\n                               interaction_constraints=None, learning_rate=0.1,\n                               max_bin=None, max_cat_threshold=None,\n                               max_cat_to_onehot=None, max_delta_step=None,\n                               max_depth=3, max_leaves=None,\n                               min_child_weight=None, missing=nan,\n                               monotone_constraints=None, multi_strategy=None,\n                               n_estimators=100, n_jobs=None,\n                               num_parallel_tree=None,\n                               objective='multi:softprob', ...))])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  Pipeline?Documentation for PipelineiFittedPipeline(steps=[('smilestomoltransformer', SmilesToMolTransformer()),\n                ('standardizer', Standardizer()),\n                ('morganfingerprinttransformer',\n                 MorganFingerprintTransformer(useFeatures=True)),\n                ('standardscaler', StandardScaler()),\n                ('xgbclassifier',\n                 XGBClassifier(base_score=None, booster=None, callbacks=None,\n                               colsample_bylevel=None, colsample_bynode=None,\n                               colsample_bytr...\n                               feature_types=None, gamma=None, grow_policy=None,\n                               importance_type=None,\n                               interaction_constraints=None, learning_rate=0.1,\n                               max_bin=None, max_cat_threshold=None,\n                               max_cat_to_onehot=None, max_delta_step=None,\n                               max_depth=3, max_leaves=None,\n                               min_child_weight=None, missing=nan,\n                               monotone_constraints=None, multi_strategy=None,\n                               n_estimators=100, n_jobs=None,\n                               num_parallel_tree=None,\n                               objective='multi:softprob', ...))]) SmilesToMolTransformerSmilesToMolTransformer() StandardizerStandardizer() MorganFingerprintTransformerMorganFingerprintTransformer(useFeatures=True)  StandardScaler?Documentation for StandardScalerStandardScaler() XGBClassifierXGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=3, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=100, n_jobs=None,\n              num_parallel_tree=None, objective='multi:softprob', ...) \n\n\n\npred = mlpipe_xgb.predict(X_test)\npred\n\narray([0, 0, 0, ..., 0, 0, 0], shape=(1415,))\n\n\n\n\n\nModel metrics\nOne can never just leave the process of building a machine learning model without evaluating it. Although what I have done below is probably very minimal but it’s somewhat a starting point to think about how good the model is.\n\nfrom sklearn.metrics import accuracy_score\n\n# Following misclassification score function code borrowed and adapted from:\n# https://scikit-learn.org/stable/auto_examples/ensemble/plot_adaboost_multiclass.html#sphx-glr-auto-examples-ensemble-plot-adaboost-multiclass-py\n\ndef misclassification_error(y_true, y_pred):\n    return 1 - accuracy_score(y_true, y_pred)\n\nmlpipe_adaboost_misclassification_error = misclassification_error(\n    y_test, mlpipe_adaboost.fit(X_train, y_train).predict(X_test)\n)\n\nmlpipe_xgb_misclassifiaction_error = misclassification_error(\n    y_test, mlpipe_xgb.fit(X_train, y_train).predict(X_test)\n)\n\nprint(\"Training score for mlpipe_adaboost: \"f\"{mlpipe_adaboost.score(X_train, y_train):0.2f}\")\nprint(\"Testing score for mlpipe_adaboost: \"f\"{mlpipe_adaboost.score(X_test, y_test):0.2f}\")\nprint(\"AdaBoostClassifier's misclassification_error: \"f\"{mlpipe_adaboost_misclassification_error:0.3f}\")\n\nprint(\"Training score for mlpipe_xgb: \"f\"{mlpipe_xgb.score(X_train, y_train):0.2f}\")\nprint(\"Testing score for mlpipe_xgb: \"f\"{mlpipe_xgb.score(X_test, y_test):0.2f}\")\nprint(\"XGBClassifier's missclassification_error: \"f\"{mlpipe_xgb_misclassifiaction_error:0.3f}\")\n\nTraining score for mlpipe_adaboost: 0.97\n\n\nTesting score for mlpipe_adaboost: 0.97\nAdaBoostClassifier's misclassification_error: 0.028\n\n\nTraining score for mlpipe_xgb: 0.99\n\n\nTesting score for mlpipe_xgb: 0.99\nXGBClassifier's missclassification_error: 0.014\n\n\nIt appears that XGBoost model obtained a better prediction accuracy than the AdaBoost one (although the models are built in a very simple way, but it still shows the slight difference in performance). The training data being used here is also very imbalanced with a lot of them being max_phase of “0” than “4”, and with max_phase “4” being our ultimate aim, the dataset used above is really for demonstration only. Also, since this post is already quite long, I’d rather not make this post into a gigantic tl;dr, so for the imbalanced data discussion and exploration, my previous posts have tried to touch on this topic - “Random forest” and “Random forest classifier”.\n\n\n\nHyperparameter tuning for XGBoost classifier\nFor XGBoost, one of the main things is to minimise model overfitting where several parameters will play important roles to achieve this. For example, learning_rate and subsample are the first two mentioned previously, and another technique is based on regularisation which includes two other parameters, reg_alpha (L1 regularisation based on Manhattan distance) and reg_lamda (L2 regularisation based on Euclidean distance). Both of these regularisation parameters aim to penalise XGBoost’s model complexity to make it a bit more conservative in order to reduce overfitting (Bruce, Bruce, and Gedeck 2020).\nA full list of XGBoost classifier pipeline parameters and settings used can be retrieved as shown below. It contains a long list of parameters and one of the ways to find the optimal set of parameters is by using cross-validation (CV).\n\nmlpipe_xgb.get_params()\n\n{'memory': None,\n 'steps': [('smilestomoltransformer', SmilesToMolTransformer()),\n  ('standardizer', Standardizer()),\n  ('morganfingerprinttransformer',\n   MorganFingerprintTransformer(useFeatures=True)),\n  ('standardscaler', StandardScaler()),\n  ('xgbclassifier',\n   XGBClassifier(base_score=None, booster=None, callbacks=None,\n                 colsample_bylevel=None, colsample_bynode=None,\n                 colsample_bytree=None, device=None, early_stopping_rounds=None,\n                 enable_categorical=False, eval_metric=None, feature_types=None,\n                 gamma=None, grow_policy=None, importance_type=None,\n                 interaction_constraints=None, learning_rate=0.1, max_bin=None,\n                 max_cat_threshold=None, max_cat_to_onehot=None,\n                 max_delta_step=None, max_depth=3, max_leaves=None,\n                 min_child_weight=None, missing=nan, monotone_constraints=None,\n                 multi_strategy=None, n_estimators=100, n_jobs=None,\n                 num_parallel_tree=None, objective='multi:softprob', ...))],\n 'verbose': False,\n 'smilestomoltransformer': SmilesToMolTransformer(),\n 'standardizer': Standardizer(),\n 'morganfingerprinttransformer': MorganFingerprintTransformer(useFeatures=True),\n 'standardscaler': StandardScaler(),\n 'xgbclassifier': XGBClassifier(base_score=None, booster=None, callbacks=None,\n               colsample_bylevel=None, colsample_bynode=None,\n               colsample_bytree=None, device=None, early_stopping_rounds=None,\n               enable_categorical=False, eval_metric=None, feature_types=None,\n               gamma=None, grow_policy=None, importance_type=None,\n               interaction_constraints=None, learning_rate=0.1, max_bin=None,\n               max_cat_threshold=None, max_cat_to_onehot=None,\n               max_delta_step=None, max_depth=3, max_leaves=None,\n               min_child_weight=None, missing=nan, monotone_constraints=None,\n               multi_strategy=None, n_estimators=100, n_jobs=None,\n               num_parallel_tree=None, objective='multi:softprob', ...),\n 'smilestomoltransformer__parallel': False,\n 'smilestomoltransformer__safe_inference_mode': False,\n 'standardizer__neutralize': True,\n 'standardizer__parallel': False,\n 'standardizer__safe_inference_mode': False,\n 'morganfingerprinttransformer__fpSize': 2048,\n 'morganfingerprinttransformer__parallel': False,\n 'morganfingerprinttransformer__radius': 2,\n 'morganfingerprinttransformer__safe_inference_mode': False,\n 'morganfingerprinttransformer__useBondTypes': True,\n 'morganfingerprinttransformer__useChirality': False,\n 'morganfingerprinttransformer__useCounts': False,\n 'morganfingerprinttransformer__useFeatures': True,\n 'standardscaler__copy': True,\n 'standardscaler__with_mean': True,\n 'standardscaler__with_std': True,\n 'xgbclassifier__objective': 'multi:softprob',\n 'xgbclassifier__base_score': None,\n 'xgbclassifier__booster': None,\n 'xgbclassifier__callbacks': None,\n 'xgbclassifier__colsample_bylevel': None,\n 'xgbclassifier__colsample_bynode': None,\n 'xgbclassifier__colsample_bytree': None,\n 'xgbclassifier__device': None,\n 'xgbclassifier__early_stopping_rounds': None,\n 'xgbclassifier__enable_categorical': False,\n 'xgbclassifier__eval_metric': None,\n 'xgbclassifier__feature_types': None,\n 'xgbclassifier__gamma': None,\n 'xgbclassifier__grow_policy': None,\n 'xgbclassifier__importance_type': None,\n 'xgbclassifier__interaction_constraints': None,\n 'xgbclassifier__learning_rate': 0.1,\n 'xgbclassifier__max_bin': None,\n 'xgbclassifier__max_cat_threshold': None,\n 'xgbclassifier__max_cat_to_onehot': None,\n 'xgbclassifier__max_delta_step': None,\n 'xgbclassifier__max_depth': 3,\n 'xgbclassifier__max_leaves': None,\n 'xgbclassifier__min_child_weight': None,\n 'xgbclassifier__missing': nan,\n 'xgbclassifier__monotone_constraints': None,\n 'xgbclassifier__multi_strategy': None,\n 'xgbclassifier__n_estimators': 100,\n 'xgbclassifier__n_jobs': None,\n 'xgbclassifier__num_parallel_tree': None,\n 'xgbclassifier__random_state': 2,\n 'xgbclassifier__reg_alpha': None,\n 'xgbclassifier__reg_lambda': None,\n 'xgbclassifier__sampling_method': None,\n 'xgbclassifier__scale_pos_weight': None,\n 'xgbclassifier__subsample': 0.5,\n 'xgbclassifier__tree_method': None,\n 'xgbclassifier__validate_parameters': None,\n 'xgbclassifier__verbosity': None}\n\n\n\n\n\n\n\n\nNote\n\n\n\nTo see the default values or types of each XGBoost parameter, this XGBoost documentation link is useful (which can be cross-referenced with XGBoost’s Python API reference).\n\n\n\n# To obtain only the parameter names for the ease of reading\nmlpipe_xgb.get_params().keys()\n\ndict_keys(['memory', 'steps', 'verbose', 'smilestomoltransformer', 'standardizer', 'morganfingerprinttransformer', 'standardscaler', 'xgbclassifier', 'smilestomoltransformer__parallel', 'smilestomoltransformer__safe_inference_mode', 'standardizer__neutralize', 'standardizer__parallel', 'standardizer__safe_inference_mode', 'morganfingerprinttransformer__fpSize', 'morganfingerprinttransformer__parallel', 'morganfingerprinttransformer__radius', 'morganfingerprinttransformer__safe_inference_mode', 'morganfingerprinttransformer__useBondTypes', 'morganfingerprinttransformer__useChirality', 'morganfingerprinttransformer__useCounts', 'morganfingerprinttransformer__useFeatures', 'standardscaler__copy', 'standardscaler__with_mean', 'standardscaler__with_std', 'xgbclassifier__objective', 'xgbclassifier__base_score', 'xgbclassifier__booster', 'xgbclassifier__callbacks', 'xgbclassifier__colsample_bylevel', 'xgbclassifier__colsample_bynode', 'xgbclassifier__colsample_bytree', 'xgbclassifier__device', 'xgbclassifier__early_stopping_rounds', 'xgbclassifier__enable_categorical', 'xgbclassifier__eval_metric', 'xgbclassifier__feature_types', 'xgbclassifier__gamma', 'xgbclassifier__grow_policy', 'xgbclassifier__importance_type', 'xgbclassifier__interaction_constraints', 'xgbclassifier__learning_rate', 'xgbclassifier__max_bin', 'xgbclassifier__max_cat_threshold', 'xgbclassifier__max_cat_to_onehot', 'xgbclassifier__max_delta_step', 'xgbclassifier__max_depth', 'xgbclassifier__max_leaves', 'xgbclassifier__min_child_weight', 'xgbclassifier__missing', 'xgbclassifier__monotone_constraints', 'xgbclassifier__multi_strategy', 'xgbclassifier__n_estimators', 'xgbclassifier__n_jobs', 'xgbclassifier__num_parallel_tree', 'xgbclassifier__random_state', 'xgbclassifier__reg_alpha', 'xgbclassifier__reg_lambda', 'xgbclassifier__sampling_method', 'xgbclassifier__scale_pos_weight', 'xgbclassifier__subsample', 'xgbclassifier__tree_method', 'xgbclassifier__validate_parameters', 'xgbclassifier__verbosity'])\n\n\nSome of the main XGBoost parameters that can be tuned are n_estimators, max_depth, learning_rate, subsample and reg_lambda. Here, I’m going to try to look for the best combination of learning_rate and subsample for a XGBoost classifier model for now.\n\n# Specify parameters and distributions to be sampled\nparams_dist = {\n    # learning_rate usually between 0.01 - 0.1 as suggested by Raschka et al. \n    # default is between 0 and 1\n    \"xgbclassifier__learning_rate\": [0.05, 0.1, 0.3], \n    # subsample default is between 0 and 1\n    \"xgbclassifier__subsample\": [0.5, 0.7, 1.0]\n}\n\n\n\n\nRandomised search CV\nThe following chunk of code is an example of running randomised search CV. I’ve deliberately folded the code to minimise the reading length of the post and also because the result from it is very similar to the grid search CV used below (randomised search CV run time was 13 min 33.2 seconds due to having two pipelines containing two different machine learning models for the same set of data). It’s being kept as a code reference for anyone who’d like to try it and also as an alternative way to do hyperparameter tuning.\n\n\nCode\n## Uncomment code below to run\n# from sklearn.model_selection import RandomizedSearchCV\n# from time import time\n\n## Borrowing a utility function code from scikit_learn documentation to report best scores\n## Source: https://scikit-learn.org/stable/auto_examples/model_selection/plot_randomized_search.html#sphx-glr-auto-examples-model-selection-plot-randomized-search-py\n\n# def report(results, n_top=3):\n#     for i in range(1, n_top + 1):\n#         candidates = np.flatnonzero(results[\"rank_test_score\"] == i)\n#         for candidate in candidates:\n#             print(\"Model with rank: {0}\".format(i))\n#             print(\n#                 \"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n#                     results[\"mean_test_score\"][candidate],\n#                     results[\"std_test_score\"][candidate],\n#                 )\n#             )\n#             print(\"Parameters: {0}\".format(results[\"params\"][candidate]))\n#             print(\"\")\n\n## The following code has also referenced and adapted from this notebook \n## https://github.com/EBjerrum/scikit-mol/blob/main/notebooks/06_hyperparameter_tuning.ipynb\n\n# n_iter_search = 9\n\n# random_search = RandomizedSearchCV(\n#     mlpipe_xgb, \n#     param_distributions=params_dist,\n#     n_iter=n_iter_search,\n#     n_jobs=2\n# )\n\n# t_start = time()\n# random_search.fit(X_train, y_train)\n# t_finish = time()\n\n# print(f'Runtime: {t_finish-t_start:0.2F} seconds for {n_iter_search} iterations')\n\n## Run report function code\n# report(random_search.cv_results_)\n\n\n\n\n\nGrid search CV\n\ngrid_search = GridSearchCV(\n    mlpipe_xgb,\n    param_grid=params_dist,\n    verbose=1,\n    n_jobs=2\n)\n\ngrid_search.fit(X_train, y_train)\n\nprint(f\"The best cv score is: {grid_search.best_score_:0.2f}\")\nprint(f\"The best cv parameter settings are: {grid_search.best_params_}\")\n\n# This may take longer time to run depending on computer hardware specs (for me it's taken ~13min)\n\nFitting 5 folds for each of 9 candidates, totalling 45 fits\n\n\n/Users/jenniferlin/Data_in_life_blog/.venv/lib/python3.12/site-packages/joblib/externals/loky/backend/fork_exec.py:38: DeprecationWarning: This process (pid=1491) is multi-threaded, use of fork() may lead to deadlocks in the child.\n  pid = os.fork()\n\n\n/Users/jenniferlin/Data_in_life_blog/.venv/lib/python3.12/site-packages/joblib/externals/loky/backend/fork_exec.py:38: DeprecationWarning: This process (pid=1491) is multi-threaded, use of fork() may lead to deadlocks in the child.\n  pid = os.fork()\n\n\n/Users/jenniferlin/Data_in_life_blog/.venv/lib/python3.12/site-packages/joblib/externals/loky/backend/fork_exec.py:38: DeprecationWarning: This process (pid=1491) is multi-threaded, use of fork() may lead to deadlocks in the child.\n  pid = os.fork()\n\n\nThe best cv score is: 0.99\nThe best cv parameter settings are: {'xgbclassifier__learning_rate': 0.3, 'xgbclassifier__subsample': 0.7}\n\n\nFor tuning parameters of Morgan fingerprints, this Scikit-mol example notebook explains how to do it with code, so I won’t repeat them here, but have only shown how to tune some of the main XGBoost parameters.\n\n\n\nPickle model\nThe next step is to pickle the model or pipeline if wanting to save it for future use and to avoid re-training model from the ground up again.\nSome security tips regarding pickle module:\n\nPython documentation\nReference blog post 1 and blog post 2\n\nOne thing to remember is to avoid unpickling unknown files over insecure network, and add security key if needed.\n\n# Pickle to save (serialise) the model in working directory (specify path if needed)\n# \"wb\" - write binary\npickle.dump(mlpipe_xgb, open(\"xgb_pipeline.pkl\", \"wb\"))\n# Unpickle (de-serialise) the model\n# \"rb\" - read binary\nmlpipe_xgb_2 = pickle.load(open(\"xgb_pipeline.pkl\", \"rb\"))\n\n# Use the unpickled model object to make prediction\npred2 = mlpipe_xgb_2.predict(X_test)\n\n## Check unpickled model and original model are the same via Python's assertion method\n#assert np.sum(np.abs(pred2 - pred)) == 0\n## or alternatively use numpy's allclose()\nprint(np.allclose(pred, pred2))\n\nTrue\n\n\n\n\n\n\nAcknowledgement\nAgain, this grows into another really long post… Although this post has taken quite a long time to build up to completion, I still want to thank all the contributors or developers for all the packages used in this post.\n\n\n\n\n\nReferences\n\nBjerrum, EJ, RA Bachorz, A Bitton, O Choung, Y Chen, C Esposito, SV Ha, and A Poehlmann. 2023. “Scikit-Mol Brings Cheminformatics to Scikit-Learn.” https://chemrxiv.org/engage/chemrxiv/article-details/60ef0fc58825826143a82cc0.\n\n\nBruce, Peter, Andrew Bruce, and Peter Gedeck. 2020. Practical Statistics for Data Scientists. https://www.oreilly.com/library/view/practical-statistics-for/9781492072935/.\n\n\nChen, Tianqi, and Carlos Guestrin. 2016. “XGBoost: A Scalable Tree Boosting System.” CoRR abs/1603.02754. http://arxiv.org/abs/1603.02754.\n\n\nFreund, Yoav, and Robert E Schapire. 1997. “A Decision-Theoretic Generalization of On-Line Learning and an Application to Boosting.” Journal of Computer and System Sciences 55 (1): 119–39. https://doi.org/10.1006/jcss.1997.1504.\n\n\nRaschka, Sebastian, Yuxi (Hayden) Liu, and Vahid Mirjalili. 2022. Machine Learning with PyTorch and Scikit-Learn. Birmingham, UK: Packt Publishing.\n\n\nSchapire, Robert E. 1990. “The Strength of Weak Learnability.” Machine Learning 5 (2): 197–227. https://doi.org/10.1007/bf00116037."
  },
  {
    "objectID": "posts/06_Long_COVID_update/ExtractTableFromPDF.html",
    "href": "posts/06_Long_COVID_update/ExtractTableFromPDF.html",
    "title": "Table scraping from PDF",
    "section": "",
    "text": "Quick introduction\nRecently I had the idea of continuing the long COVID exploration and thought that I’ve never tried scraping a PDF before, so by combining these two ideas together, I ended up with this little piece of work as another post.\nA quick heads up: Java should be installed in order for tabula-py to work seamlessly, since tabula-py is actually a Python wrapper for tabula-java. In this case, I’ve relied on Homebrew to install Java, but there are several other different options available online and I’ll leave this open for people who’re interested to explore themselves. Once it’s installed, we can then check for the Java version to ensure it’s installed properly.\n\n# Check the version of Java\n!java -version\n\nopenjdk version \"17.0.4.1\" 2022-08-12\nOpenJDK Runtime Environment Temurin-17.0.4.1+1 (build 17.0.4.1+1)\nOpenJDK 64-Bit Server VM Temurin-17.0.4.1+1 (build 17.0.4.1+1, mixed mode, sharing)\n\n\n\n\nInstalling and importing libraries\nThen we would install any libraries needed for scraping table data from PDF, which in this case, I ended up using only one library.\n\n!pip install -q tabula-py\n\n\n[notice] A new release of pip available: 22.3.1 -> 23.0.1\n[notice] To update, run: pip install --upgrade pip\n\n\n\n# import read_pdf from the tabula library\nfrom tabula import read_pdf\n\n\n\nData source\nSource of the table was from this journal paper by Healey Q, Sheikh A, Daines L, Vasileiou E. Symptoms and signs of long COVID: A rapid review and meta-analysis. J Glob Health 2022;12:05014. Creative Commons Attribution 4.0 International Public License\n\n\n\nPhoto by Steve Richey on Unsplash\n\n\n\n\nTable scraping\nFirstly, I trialled scraping the table from page 4 of the journal paper, which only really scraped about half of the table. I then went on to add in another line of code to specify the scraping area1 on the PDF page in inches (this part could be deduced by using the in-built PDF tool).\nOne thing I wasn’t too sure about was that the tabula-py documentation did state that the default = full page, but in fact, it appeared to be not the case (only half of the table showed up). Also, the journal paper I was using had the tables printed in landscape layout (rather than the more common portrait style), so it wasn’t completely clear if landscape version was making this harder or the other way.\n\n#specify the scraping area (top, left, bottom, right)\ntest_area = \"10.05,6.60,10.05,6.60\" \ndf = read_pdf(\"Journal.pdf\", pages = \"4\", area = test_area, guess = False, stream = True, pandas_options={'header':None})\ndf\n\n[                                                    0\n 0   VREIESWEAPROCINHT TSHEME 1:  Healey et al. COV...\n 1    Table 1. Characteristics of the included studies\n 2                             Author Hospital (%) Age\n 3   (country) {ICU (%)} (years) Comorbiditiestime ...\n 4   41% hypertension, 15% diabetes, Generalised/MS...\n 5   11% obesity, 11% endocrine disease, Respirator...\n 6   10% malignancy, 9% IHD, 8% Neuropsychiatric 43...\n 7    Bellan (Italy) dyslipidaemia, 7% AF, 6% COPD, 6%\n 8   100 {12} 61 107 ENT 5% gustatory dysfunction, ...\n 9             [19] CKD, 6% haematological disease, 5%\n 10             anxiety/depression, 4% cerebrovascular\n 11  disease, 3% liver disease, 3% VTE, 2% Gastroin...\n 12                         IBD, 2% autoimmune disease\n 13  Generalised/MSK Fatigue, myalgia, arthralgia, ...\n 14  Respiratory Dyspnoea, cough, chest pain, sputu...\n 15       Bliddal 28% allergy, 17% osteoarthritis, 15%\n 16  Neuropsychiatric Memory issues, concentration ...\n 17  (Denmark) 0 50 hypertension, 9% thyroid diseas...\n 18  ENT Olfactory dysfunction, gustatory dysfuncti...\n 19                                        [20] asthma\n 20  Gastrointestinal Diarrhoea, anorexia, abdomina...\n 21                              Others Red runny eyes\n 22        Chiesa- 6% hypertension, 6% hypothyroidism,\n 23  Estomba Not stated 41 6% asthma, 4% autoimmune...\n 24          (Italy) [21] 3% diabetes, 2% IHD, 1% COPD\n 25                                             Cousyn\n 26  0 35 Not stated 60 ENT 16.8% olfactory dysfunc...\n 27                                      (France) [22]\n 28  Generalised/MSK 45% fatigue, 15% myalgia, 3% f...\n 29  33% dyspnoea, 33% cough. Normal spirometry, no...\n 30                                        Respiratory\n 31                                   distance on 6MWT\n 32  Neuropsychiatric 18% cognitive issues, 15% hea...\n 33          Daher 59% hypertension, 25% diabetes, 22%\n 34  ENT 12% olfactory dysfunction, 12% rhinorrhoea...\n 35   (Germany) 100 64 CKD, 19% IHD, 13% asthma, 9% 56\n 36  9% diarrhoea, 6% nausea, 3% abdominal pain, no...\n 37  18% angina, normal left ventricular function, ...\n 38                                     Cardiovascular\n 39                                         biomarkers\n 40  Normal FBC, normal coagulation screen, raised ...\n 41                                   Other biomarkers\n 42  U&Es, normal CRP, normal procalcitonin, normal...\n 43  26% hypertension, 12% diabetes, Generalised/MS...\n 44                                         Fernandez-\n 45                 12% IHD, 7% asthma, 5% obesity, 4%\n 46                        de-Las-Penas 100 {7} 61 340\n 47  COPD, 2% cerebrovascular disease, 2% Respirato...\n 48                                       (Spain) [23]\n 49                            rheumatological disease\n 50  47% hypertension, 42% dyslipidaemia, Generalis...\n 51                                           Froidure\n 52  28% obesity, 22% diabetes, 9% Abnormal chest C...\n 53                           (Belgium) 100 {22} 60 98\n 54  asthma, 4% COPD, 2% lung cancer, Respiratory t...\n 55                                               [24]\n 56  1% ILD cough, 4% chest tightness, normal spiro...\n 57  2022  •  Vol. 12  •  05014 4 www.jogh.org •  d...]\n\n\nOnce above worked, I moved onto scraping the whole table across pages 4 to 6 of the PDF, and then saved the scraped table into a .csv file, which appeared automatically in the working directory.\n\nimport tabula\ntest_area = \"10.05,6.60,10.05,6.60\"\n# Convert and save scraped data into specified file format\ntabula.convert_into(\"Journal.pdf\", \"Full_table_scraped.csv\", output_format = \"csv\", pages = \"4-6\", area = test_area, guess = False, stream = True)\n!cat Full_table_scraped.csv\n\nVREIESWEAPROCINHT TSHEME 1:  Healey et al. COVID-19 PANDEMIC\nTable 1. Characteristics of the included studies\nAuthor Hospital (%) Age\n(country) {ICU (%)} (years) Comorbiditiestime (days) Follow-up Body system Results\n\"41% hypertension, 15% diabetes, Generalised/MSK 5.9% myalgia, 5.9% arthralgia\"\n\"11% obesity, 11% endocrine disease, Respiratory 5.5% dyspnoea, 2.5% cough, 0.4% chest pain, 51.6% reduced DLCO, normal spirometry\"\n\"10% malignancy, 9% IHD, 8% Neuropsychiatric 43% PTSD symptoms\"\n\"Bellan (Italy) dyslipidaemia, 7% AF, 6% COPD, 6%\"\n\"100 {12} 61 107 ENT 5% gustatory dysfunction, 4.6% olfactory dysfunction\"\n\"[19] CKD, 6% haematological disease, 5%\"\n\"anxiety/depression, 4% cerebrovascular\"\n\"disease, 3% liver disease, 3% VTE, 2% Gastrointestinal 1.3% diarrhoea\"\n\"IBD, 2% autoimmune disease\"\n\"Generalised/MSK Fatigue, myalgia, arthralgia, chills, fever\"\n\"Respiratory Dyspnoea, cough, chest pain, sputum production\"\n\"Bliddal 28% allergy, 17% osteoarthritis, 15%\"\n\"Neuropsychiatric Memory issues, concentration issues, headache\"\n\"(Denmark) 0 50 hypertension, 9% thyroid disease, 8% 84\"\n\"ENT Olfactory dysfunction, gustatory dysfunction, sore throat, rhinorrhoea, sneezing\"\n[20] asthma\n\"Gastrointestinal Diarrhoea, anorexia, abdominal pain, nausea\"\nOthers Red runny eyes\n\"Chiesa- 6% hypertension, 6% hypothyroidism,\"\n\"Estomba Not stated 41 6% asthma, 4% autoimmune disease, 47 ENT 51% olfactory dysfunction\"\n\"(Italy) [21] 3% diabetes, 2% IHD, 1% COPD\"\nCousyn\n\"0 35 Not stated 60 ENT 16.8% olfactory dysfunction, 9.6% gustatory dysfunction\"\n(France) [22]\n\"Generalised/MSK 45% fatigue, 15% myalgia, 3% fever, slight pain/discomfort\"\n\"33% dyspnoea, 33% cough. Normal spirometry, normal ABG, reduced DLCO, reduced\"\nRespiratory\ndistance on 6MWT\n\"Neuropsychiatric 18% cognitive issues, 15% headache, mild depression, subthreshold anxiety\"\n\"Daher 59% hypertension, 25% diabetes, 22%\"\n\"ENT 12% olfactory dysfunction, 12% rhinorrhoea, 9% gustatory dysfunction, 9% sore throat\"\n\"(Germany) 100 64 CKD, 19% IHD, 13% asthma, 9% 56\"\n\"9% diarrhoea, 6% nausea, 3% abdominal pain, normal LFTs[17] COPD, 9% AF, 9% heart failureGastrointestinal\"\n\"18% angina, normal left ventricular function, normal right ventricular function, normal cardiac\"\nCardiovascular\nbiomarkers\n\"Normal FBC, normal coagulation screen, raised ferritin, potentially raised D-dimer, normal\"\nOther biomarkers\n\"U&Es, normal CRP, normal procalcitonin, normal TFTs, normal IL-6\"\n\"26% hypertension, 12% diabetes, Generalised/MSK 61.2% fatigue\"\nFernandez-\n\"12% IHD, 7% asthma, 5% obesity, 4%\"\nde-Las-Penas 100 {7} 61 340\n\"COPD, 2% cerebrovascular disease, 2% Respiratory 23.3% dyspnoea, 6.5% chest pain, 2.5% cough\"\n(Spain) [23]\nrheumatological disease\n\"47% hypertension, 42% dyslipidaemia, Generalised/MSK 25% fatigue\"\nFroidure\n\"28% obesity, 22% diabetes, 9% Abnormal chest CT: 67% ground glass opacities, 44% reticulations, 20% fibrotic lesions/\"\n(Belgium) 100 {22} 60 98\n\"asthma, 4% COPD, 2% lung cancer, Respiratory traction bronchiectasis, 7% consolidations. 46% reduced DLCO, 35% dyspnoea, 10% dry\"\n[24]\n\"1% ILD cough, 4% chest tightness, normal spirometry\"\n2022  •  Vol. 12  •  05014 4 www.jogh.org •  doi: 10.7189/jogh.12.05014\n\"\",,,,,,,Symptoms and signs of long COVID: A rapid review\nTable 1. continued,,,,,,,\nAuthor (country) Hospital (%) {ICU (%)},Age (years),,,Comorbidities,Follow-up time (days),,Body system Results\n\"\",,,,,,,Generalised/MSK 17% fatigue\nGerhards,,,,,,,\n\"\",,,,,,,\"Neuropsychiatric Depression, concentration issues\"\n(Germany) 10,46,,,Not stated,183,,\n\"\",,,,,,,ENT 27% olfactory/gustatory dysfunction\n[25],,,,,,,\n\"\",,,,,,,Others Alopecia\n\"\",,,,,,,\"Generalised/MSK Fatigue, arthralgia, myalgia\"\n\"\",,,,\"38% hypertension, 22% obesity, 19%\",,,\nGhosn,,,,,,,\"Respiratory Dyspnoea, cough\"\n100 {29},61,,,\"diabetes, 18% IHD, 10% COPD, 7%\",194,,\n(France) [26],,,,,,,Neuropsychiatric Headache\n\"\",,,,\"CKD, 7% malignancy, 1% liver disease\",,,\n\"\",,,,,,,\"ENT Rhinorrhoea, olfactory dysfunction, gustatory dysfunction, sore throat\"\n\"\",,,,,,,\"62% abnormal chest CT: 35% fibrotic-like changes, 27% ground glass opacities/interstitial\"\nHan (China),,,,\"28% hypertension, 14% respiratory\",,,\"thickening, nodules/masses, interlobar pleural traction, pulmonary atelectasis and\"\n100,54,,,,175,,Respiratory\n[27],,,,\"disease, 11% diabetes\",,,\"bronchiectasis. 26% reduced DLCO, 14% mild dyspnoea, 10% sputum production, 6.1% dry\"\n\"\",,,,,,,cough\n\"\",,,,,,,\"Generalised/MSK 50% fatigue, 35.7% arthralgia, 21.4% myalgia\"\nHolmes,,,,,,,\"Respiratory 28.6% cough, 25% dyspnoea, 3.6% chest pain\"\n(Australia) 0,57,,,Not stated,183,,Neuropsychiatric 10.7% headache\n[28],,,,,,,\"ENT 28.6% olfactory dysfunction, 14.3% rhinorrhoea\"\n\"\",,,,,,,Gastrointestinal No abdominal pain\n\"\",,,,\"49% obesity, 48% hypertension,\",,,\"Generalised/MSK 44.8% fatigue, 21.3% myalgia, 15.8% arthralgia, 1.1% fever, 1.1% ulcer\"\n\"\",,,,\"28% diabetes, 12% IHD, 11%\",,,\"Respiratory 31.7% dyspnoea, 25.1% cough, 14.8% sputum production\"\n\"\",,,,\"dyslipidaemia, 10% asthma, 10%\",,,\"Neuropsychiatric 12.6% headache, 8.7% cognitive issues\"\nJacobs (USA),,,,\"malignancy, 5% arrhythmia, 4%\",,,\n100,57,,,,35,,\"ENT 9.8% gustatory dysfunction, 9.3% olfactory dysfunction\"\n[29],,,,\"COPD, 4% hypothyroidism, 4%\",,,\n\"\",,,,,,,Gastrointestinal 3.8% diarrhoea\n\"\",,,,\"depression, anxiety or schizophrenia,\",,,\n\"\",,,,\"3% heart failure, 3% sleep apnoea, 2%\",,,\"Others 8.2% eye irritation, 1.1% ulcer\"\n\"\",,,,VTE,,,\n\"\",,,,\"36% obesity, 29% hypertension,\",,,\"Generalised/MSK 63% fatigue, 35% myalgia\"\nLeth,,,,\"12% malignancy, 10% IHD, 8%\",,,\"Respiratory 53% dyspnoea, 24% cough, 20% chest pain, 12% sputum production\"\n(Denmark) 100 {12},58,,,\"asthma, 8% COPD, 4% diabetes, 4%\",128,,\"Neuropsychiatric 45% concentration issues, 27% headache, 27% paraesthesia\"\n[30],,,,\"hyperthyroidism, 2% cerebrovascular\",,,\"ENT 31% gustatory dysfunction, 27% olfactory dysfunction, 10% sore throat\"\n\"\",,,,disease,,,\"Gastrointestinal 10% abdominal pain, 8% diarrhoea, 8% nausea, 4% anorexia\"\n\"\",,,,,,,\"Generalised/MSK 33% fatigue, 1.4% arthralgia, 0.6% myalgia\"\n\"\",,,,,,,\"Respiratory 8.5% cough, 7% dyspnoea, 0.8% chest pain\"\nMahmud,,,,,,,\n\"\",,,,,,,\"3.9% circadian rhythm disorders, 3.4% headache, 2.3% sleep disturbance, 1.4% adjustment\"\n(Bangladesh) Not stated,40,,,\"15% hypertension, 14% diabetes\",30,,Neuropsychiatric\n\"\",,,,,,,disorder\n[18],,,,,,,\n\"\",,,,,,,\"ENT 2.3% vertigo, 2% olfactory dysfunction\"\n\"\",,,,,,,Cardiovascular 1.4% palpitation\n\"\",,,,,,,RESEARCH THEME 1:\n\"\",,,,,,,VCOIEVWIDP-O1I9N PTASNDEMIC\nwww.jogh.org • doi: 10.7189/jogh.12.05014,,,,5,,,2022  •  Vol. 12  •  05014\nRVEIESWEAPROCINHT TSHEME 1:  Healey et al. COVID-19 PANDEMIC\nTable 1. continued\nAuthor Hospital (%) Age Follow-up\n(country) {ICU (%)} (years) Comorbidities time (days) Body system Results\nOtte\n\"42.3% subjective olfactory dysfunction, 26.9% objective olfactory dysfunction (discrimination\"\n(Germany) 0 45 Not stated 201 ENT\nand identification issues)\n[31]\n\"Generalised/MSK 13.1% fatigue, 8.2% rheumatological issues\"\n\"23% hypertension, 16% obesity, 6% Respiratory 6% dyspnoea, 2% cough, 0.8% chest pain\"\n\"Peghin (Italy) diabetes, 4% respiratory disease, 1% Neuropsychiatric 9.6% neurological disorders, 4.9% psychiatric disorders, 2.7% headache\"\n26 53 191\n\"[32] IHD, 2% liver disease, 1% depression/ ENT 10.4% olfactory/gustatory dysfunction,\"\n\"anxiety, 0% CKD Gastrointestinal 1.5% gastrointestinal disorders\"\n\"Others 3.7% alopecia, 3.4% cutaneous manifestations, 0.3% ocular symptoms\"\n\"Generalised/MSK 24% night sweats, 0% fever\"\n\"63% abnormal chest CT: ground-glass opacities, reticular lesions, consolidations, bronchial\"\n\"Respiratory dilation. 36% dyspnoea, abnormal spirometry: 22% reduced FVC, 22% reduced FEV1, normal\"\n\"40% cardiovascular disease, 30% FEV1/FVC. 21% reduced DLCO, 17% cough\"\n\"hypertension, 19% dyslipidaemia,\"\nSonnweber Neuropsychiatric 22% sleep disorders\n\"75 57 17% diabetes, 7% asthma, 7% CKD, 103\"\n(Austria) [16] ENT 19% olfactory dysfunction\n\"6% COPD, 6% liver disease, 6%\"\n\"malignancy, 1% ILD Gastrointestinal 9% diarrhoea/vomiting\"\n\"97% normal LVEF, 55% diastolic dysfunction on echo, 23% raised NT-proBNP, 10%\"\nCardiovascular\n\"pulmonary hypertension, 1% pericardial effusion\"\n\"Other biomarkers Raised D-dimer, potentially raised ferritin, normal CRP, normal procalcitonin, normal IL-6\"\n\"Generalised/MSK Fatigue, myalgia, fever\"\n\"Respiratory Dyspnoea, cough, chest pain\"\n\"Sudre (UK, 26% obesity, 14% respiratory disease, Neuropsychiatric Headache, paraesthesia, numbness, concentration/ memory issues\"\n\"USA, Sweden) 14 42 10% asthma, 3% diabetes, 2% IHD, 84\"\n\"[33] 1% CKD ENT Olfactory dysfunction, sore throat, hoarse voice, tinnitus, earache\"\n\"Gastrointestinal Diarrhoea, abdominal pain\"\nCardiovascular Palpitations/tachycardia\n\"Vaira (Italy) 29% obesity, 27% IHD, 15%\"\n\"23 51 60 ENT 21% olfactory dysfunction, 7.9% gustatory dysfunction\"\n\"[34] respiratory disease, 11% diabetes\"\n\"ICU – intensive care unit, IHD – ischaemic heart disease, AF – atrial fibrillation, COPD – chronic obstructive pulmonary disease, CKD – chronic kidney disease, VTE – venous thromboembolism, IBD – inflammatory bowel\"\n\"disease, NS – not stated, ILD – interstitial lung disease, MSK – musculoskeletal, ENT – ear, nose, and throat, OGD – olfactory-gustatory dysfunction, DLCO – diffusing capacity for carbon monoxide, PTSD – posttraumatic\"\n\"stress disorder, ABG – arterial blood gas, 6MWT – 6-min walk test, LFT – liver function test, FBC – full blood count, U&E – urea and electrolyte, CRP – c-reactive protein, TFT – thyroid function test, IL-6 – interleukin-6,\"\n\"FVC – forced vital capacity, FEV1 – forced expiratory volume in one second, NT-proBNP – N-terminal pro B-type natriuretic peptide\"\n2022  •  Vol. 12  •  05014 6 www.jogh.org •  doi: 10.7189/jogh.12.05014\n\n\n\n\nShort summary\nThe PDF scraping exercise only worked to a certain degree2, as the data did not arrive in a proper tabular format. I’ve also gone on to read several online resources and looked into tabula-py and tabula-java, it was clearly shown in their GitHub repo that there were existing issues for tables that have merged cells, empty cells or no column lines (which was what I had in this case). All of them tend to result in jumbled or merged rows or columns. It tends to work better if the tables in the PDFs are already in a proper table format i.e. columns and rows marked by lines. Nevertheless, the purpose of scraping the table data was achieved as full data were there after checking, but just not in a clean and tidy state so the next post named, “Long COVID - an update” would take us into the next stage to see what this tabular data would tell us about long COVID (all done in R).\n\n\n\n\n\nFootnotes\n\n\nThanks to Stack Overflow as I’ve managed to find this solution from several different scenarios and comments.↩︎\nor it could be my ignorance to other better methods - please leave a comment as I’d like to learn!↩︎"
  },
  {
    "objectID": "posts/06_Long_COVID_update/Long_COVID_update.html",
    "href": "posts/06_Long_COVID_update/Long_COVID_update.html",
    "title": "Long COVID - an update",
    "section": "",
    "text": "Background\nThis was another update on the current long COVID saga around the world that I thought to follow up from my earlier work (details in the SQL and Tableau projects). This time the dataset was obtained from another journal paper, which had data collected until July 2021 (the previous paper was only until March 2021). I’ve used Python to extract a table from the PDF of the paper and also Excel to assist with data cleaning. This was followed by using R to analyse and visualise all the data.\n\n\nSource of dataset\nJournal paper by Healey Q, Sheikh A, Daines L, Vasileiou E. Symptoms and signs of long COVID: A rapid review and meta-analysis. J Glob Health 2022;12:05014. Creative Commons Attribution 4.0 International Public License\n\n\nData scraping from PDF\nThe dataset was scraped from a PDF obtained via PubMed (journal paper source as shown above) by using tabula-py (for details please see this post, “Table scraping from PDF”). Unfortunately I had trouble installing a similar R package remotely after it was archived (tabulizer package with known issues in its GitHub repository) so I trialled tabula-py instead. It worked for scraping all the data from the target table, but the downside was that the scraped data did not inherit the original tabular format on PDF, with columns and rows all jumbled. I’ve discussed a little bit more on the likely reason for this in the blog post link above. So in short, the final scraped table was cleaned in Excel and saved as .csv file, which was then imported as shown below.\n\n\nData inspection and wrangling\n\n# Uncomment below if requiring installations of packages\n# install.packages(\"wordcloud\")\n# install.packages(\"RColorBrewer\")\n# install.packages(\"tidytext\")\n# install.packages(\"leaflet\")\n\nLoading all the required libraries below. Install libraries needed as shown in code above.\n\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(knitr)\nlibrary(leaflet)\nlibrary(tidytext)\nlibrary(wordcloud)\nlibrary(RColorBrewer)\n\n\ndf <- read_csv(\"Full_table.csv\")\n\nNew names:\nRows: 75 Columns: 9\n── Column specification\n──────────────────────────────────────────────────────── Delimiter: \",\" chr\n(5): Author (country), Hospital (%) {ICU (%)}, Comorbidities, Body syste... dbl\n(2): Age (years), Follow-up time (days) lgl (2): ...8, ...9\nℹ Use `spec()` to retrieve the full column specification for this data. ℹ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n• `` -> `...8`\n• `` -> `...9`\n\n\n\n\n\nHere’s a quick overview on the hospitalisation rates across all the studies from this paper.\n\ndf_hosp <- df %>% \n  select(`Author (country)`, `Hospital (%) {ICU (%)}`)\ndf_hosp\n\n# A tibble: 75 × 2\n   `Author (country)` `Hospital (%) {ICU (%)}`\n   <chr>              <chr>                   \n 1 Bellan (Italy)     100 {12}                \n 2 Bellan (Italy)     <NA>                    \n 3 Bellan (Italy)     <NA>                    \n 4 Bellan (Italy)     <NA>                    \n 5 Bellan (Italy)     <NA>                    \n 6 Bliddal (Denmark)  0                       \n 7 Bliddal (Denmark)  <NA>                    \n 8 Bliddal (Denmark)  <NA>                    \n 9 Bliddal (Denmark)  <NA>                    \n10 Bliddal (Denmark)  <NA>                    \n# … with 65 more rows\n# ℹ Use `print(n = ...)` to see more rows\n\n\n\nSeparating columns and change column type\nThe table column of Hospital (%) {ICU (%)} was separated into two separate columns to allow clearer differentiation between hospital and ICU rates within each study. The data type for Hospital (%) column was also changed from character to numeric so we can plot a bar graph later on (otherwise the x-axis may not be accurate or properly shown).\n\ndf_hosp_icu <- df_hosp %>% \n  # separate column into two columns\n  separate(`Hospital (%) {ICU (%)}`, c(\"Hospital (%)\", \"ICU (%)\"))%>% \n  # change column type\n  mutate(across(`Hospital (%)`, as.numeric))\n# show the first 10 rows as example\nc <- head(df_hosp_icu, 10)\nkable(c)\n\n\n\n\nAuthor (country)\nHospital (%)\nICU (%)\n\n\n\n\nBellan (Italy)\n100\n12\n\n\nBellan (Italy)\nNA\nNA\n\n\nBellan (Italy)\nNA\nNA\n\n\nBellan (Italy)\nNA\nNA\n\n\nBellan (Italy)\nNA\nNA\n\n\nBliddal (Denmark)\n0\nNA\n\n\nBliddal (Denmark)\nNA\nNA\n\n\nBliddal (Denmark)\nNA\nNA\n\n\nBliddal (Denmark)\nNA\nNA\n\n\nBliddal (Denmark)\nNA\nNA\n\n\n\n\n\n\n\nSeparating rows\nThe listed co-morbidities for each study were separated into separate rows, rather than into columns, to avoid adding too many columns all at once.\n\ndf_new <- df %>% \n  separate_rows(Comorbidities, sep = \", \")\n# Show the first 10 rows as example\ne <- head(df_new, 10)\nkable(e)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAuthor (country)\nHospital (%) {ICU (%)}\nAge (years)\nComorbidities\nFollow-up time (days)\nBody system\nResults\n…8\n…9\n\n\n\n\nBellan (Italy)\n100 {12}\n61\n41% hypertension\n107\nGeneralised/MSK\n5.9% myalgia, 5.9% arthralgia\nNA\nNA\n\n\nBellan (Italy)\n100 {12}\n61\n15% diabetes\n107\nGeneralised/MSK\n5.9% myalgia, 5.9% arthralgia\nNA\nNA\n\n\nBellan (Italy)\n100 {12}\n61\n11% obesity\n107\nGeneralised/MSK\n5.9% myalgia, 5.9% arthralgia\nNA\nNA\n\n\nBellan (Italy)\n100 {12}\n61\n11% endocrine disease\n107\nGeneralised/MSK\n5.9% myalgia, 5.9% arthralgia\nNA\nNA\n\n\nBellan (Italy)\n100 {12}\n61\n10% malignancy\n107\nGeneralised/MSK\n5.9% myalgia, 5.9% arthralgia\nNA\nNA\n\n\nBellan (Italy)\n100 {12}\n61\n9% IHD\n107\nGeneralised/MSK\n5.9% myalgia, 5.9% arthralgia\nNA\nNA\n\n\nBellan (Italy)\n100 {12}\n61\n8% dyslipidaemia\n107\nGeneralised/MSK\n5.9% myalgia, 5.9% arthralgia\nNA\nNA\n\n\nBellan (Italy)\n100 {12}\n61\n7% AF\n107\nGeneralised/MSK\n5.9% myalgia, 5.9% arthralgia\nNA\nNA\n\n\nBellan (Italy)\n100 {12}\n61\n6% COPD\n107\nGeneralised/MSK\n5.9% myalgia, 5.9% arthralgia\nNA\nNA\n\n\nBellan (Italy)\n100 {12}\n61\n6% CKD\n107\nGeneralised/MSK\n5.9% myalgia, 5.9% arthralgia\nNA\nNA\n\n\n\n\n\n\n\nA frequency count showing types of comorbidities in long COVID\nI then noticed how the comorbidities for each study were listed with different percentages and to gather a quick initial overall picture of the data, I started by removing these digits and percentage symbols. Obviously since I was still quite new to R (started using R in July), I soon ran into a problem as I kept on getting stuck with not having the count() function to actually count unique elements under the co-morbidities column.\nBy looking at the magnified circle on the right in the image below, you would notice a subtle difference in spacing, so yes the culprit was the space1 and once it was removed, count() worked nicely as how it should be. One small downside was that it would also remove the space between the co-morbidity terms e.g. “liver disease” became “liverdisease”, but since it achieved the aim intended to do unique counts on all the co-morbidities, I left it as it was.\n\n\n\nScreenshot of the extra space(s) in dataframe\n\n\n\ndf_new %>% \n  # Remove % symbol, numbers and don't forget to remove spaces as well in the column! \n  mutate(Comorbidities = str_remove_all(Comorbidities, \"[:digit:]|[%]|[ ]\")) %>%\n  # Add this line to filter out all the \"NA\"s\n  filter(!is.na(Comorbidities)) %>% \n  # Count the comorbidities in descending order\n  count(Comorbidities, sort = TRUE) \n\n# A tibble: 37 × 2\n   Comorbidities     n\n   <chr>         <int>\n 1 diabetes         14\n 2 hypertension     13\n 3 IHD              10\n 4 asthma            9\n 5 COPD              9\n 6 obesity           9\n 7 CKD               6\n 8 malignancy        5\n 9 dyslipidaemia     4\n10 liverdisease      4\n# … with 27 more rows\n# ℹ Use `print(n = ...)` to see more rows\n\n\nNow we could observe the top 3 frequency of all co-morbidities listed were: diabetes, hypertension and IHD2. These were followed by, unsurprisingly, common respiratory illnesses such as asthma, COPD3, then obesity, and also CKD4, malignancy, dyslipidaemia and so on. These would be considered as high risk factors of developing long COVID symptoms if someone had these co-morbidities present before being infected by the coronoviruses.\n\n\n\nData visualisations\n\nBar graph for hospitalisation rate\nThen a line of code to filter out the results of “NA” under the column of Hospital (%) was added. Most of the cells with “NA” were there to fill the multiple empty row entries for other variables and not for the Hospital (%) column, therefore these “NA”s were removed in this instance. The horizontal bar graph below showed the COVID-19 hospitalisation rate for studies in different countries, presenting a very diverse results between 0% and 100% hospitalisations across all 19 cohort studies.\n\ndf_hosp_icu %>% \n  # filter out all NAs\n  filter(!is.na(`Hospital (%)`)) %>% \n  # plot the bar graph\n  ggplot(aes(x = `Author (country)`, y = `Hospital (%)`)) + \n  geom_bar(stat = \"identity\") +\n  coord_flip()\n\n\n\n\nCOVID-19 hospitalisation rate across different countries\n\n\n\n\nNote: two of the studies were removed from above, these studies were by Chiesa-Estomba (Italy) and Mahmud (Bangladesh), which had “Not stated” recorded under Hospital (%) {ICU (%)} column. When the Hospital (%) column was converted from character to numeric, these two rows were converted to “NA” automatically.\n\n\nInteractive map for long COVID results\n\nPreparing dataframe for map\n\ndf_new_a <- df %>% \n  # separate Author (country) column into two columns \n  # note: rename country as region - needed for joining data later on\n  separate(`Author (country)`, c(\"Author\", \"region\")) %>% \n  # print only the columns as selected\n  select(`region`, Results)\n\n# The study author name, Fernandez-de-Las-Penas (Spain), got separated as above\n# so replace \"de\" under Country column with the actual country name of Spain\ndf_new_a[df_new_a == \"de\"] <- \"Spain\" \n# Show first 10 rows as example\nd <- head(df_new_a, 10)\nkable(d)\n\n\n\n\n\n\n\n\nregion\nResults\n\n\n\n\nItaly\n5.9% myalgia, 5.9% arthralgia\n\n\nItaly\n5.5% dyspnoea, 2.5% cough, 0.4% chest pain, 51.6% reduced DLCO, normal spirometry\n\n\nItaly\n43% PTSD symptoms\n\n\nItaly\n5% gustatory dysfunction, 4.6% olfactory dysfunction\n\n\nItaly\n1.3% diarrhoea\n\n\nDenmark\nfatigue, myalgia, arthralgia, chills, fever\n\n\nDenmark\ndyspnoea, cough, chest pain, sputum production\n\n\nDenmark\nmemory issues, concentration issues, headache\n\n\nDenmark\nolfactory dysfunction, gustatory dysfunction, sore throat, rhinorrhoea, sneezing\n\n\nDenmark\ndiarrhoea, anorexia, abdominal pain, nausea\n\n\n\n\n\n\ndf1 <- df_new_a %>% \n  # re-group dataframe based on region column\n  group_by(`region`) %>%\n  # merge all rows under Results column into one string\n  summarise(across(everything(), ~toString(.)))\ndf1\n\n# A tibble: 13 × 2\n   region     Results                                                           \n   <chr>      <chr>                                                             \n 1 Australia  50% fatigue, 35.7% arthralgia, 21.4% myalgia, 28.6% cough, 25% dy…\n 2 Austria    24% night sweats, 0% fever, 63% abnormal chest CT: ground-glass o…\n 3 Bangladesh 33% fatigue, 1.4% arthralgia, 0.6% myalgia, 8.5% cough, 7% dyspno…\n 4 Belgium    25% fatigue, abnormal chest CT: 67% ground glass opacities, 44% r…\n 5 China      62% abnormal chest CT: 35% fibrotic-like changes, 27% ground glas…\n 6 Denmark    fatigue, myalgia, arthralgia, chills, fever, dyspnoea, cough, che…\n 7 Estomba    51% olfactory dysfunction                                         \n 8 France     16.8% olfactory dysfunction, 9.6% gustatory dysfunction, fatigue,…\n 9 Germany    45% fatigue, 15% myalgia, 3% fever, slight pain/discomfort, 33% d…\n10 Italy      5.9% myalgia, 5.9% arthralgia, 5.5% dyspnoea, 2.5% cough, 0.4% ch…\n11 Spain      61.2% fatigue, 23.3% dyspnoea, 6.5% chest pain, 2.5% cough        \n12 UK         fatigue, myalgia, fever, dyspnoea, cough, chest pain, headache, p…\n13 USA        44.8% fatigue, 21.3% myalgia, 15.8% arthralgia, 1.1% fever, 1.1% …\n\n\n\n# grab the world map data from ggplot\nmapdata <- map_data(\"world\") \n# view full dataset in separate tab \nview(mapdata)\n\n\n# combine mapdata dataframe (contains longitudes & latitudes of each country) \n# with df_new_a dataframe (contains country info)\nmapdata <- left_join(mapdata, df1, by = \"region\")\nhead(mapdata)\n\n       long      lat group order region subregion Results\n1 -69.89912 12.45200     1     1  Aruba      <NA>    <NA>\n2 -69.89571 12.42300     1     2  Aruba      <NA>    <NA>\n3 -69.94219 12.43853     1     3  Aruba      <NA>    <NA>\n4 -70.00415 12.50049     1     4  Aruba      <NA>    <NA>\n5 -70.06612 12.54697     1     5  Aruba      <NA>    <NA>\n6 -70.05088 12.59707     1     6  Aruba      <NA>    <NA>\n\n\n\n# filter out all the empty or \"NA\" cells\nmapdata_new <- mapdata %>% filter(!is.na(mapdata$Results))\nhead(mapdata_new)\n\n      long       lat group order    region                   subregion\n1 123.5945 -12.42568   133  7115 Australia Ashmore and Cartier Islands\n2 123.5952 -12.43594   133  7116 Australia Ashmore and Cartier Islands\n3 123.5732 -12.43418   133  7117 Australia Ashmore and Cartier Islands\n4 123.5725 -12.42393   133  7118 Australia Ashmore and Cartier Islands\n5 123.5945 -12.42568   133  7119 Australia Ashmore and Cartier Islands\n6 158.8788 -54.70976   139  7267 Australia            Macquarie Island\n                                                                                                                                                                      Results\n1 50% fatigue, 35.7% arthralgia, 21.4% myalgia, 28.6% cough, 25% dyspnoea, 3.6% chest pain, 10.7% headache, 28.6% olfactory dysfunction, 14.3% rhinorrhoea, no abdominal pain\n2 50% fatigue, 35.7% arthralgia, 21.4% myalgia, 28.6% cough, 25% dyspnoea, 3.6% chest pain, 10.7% headache, 28.6% olfactory dysfunction, 14.3% rhinorrhoea, no abdominal pain\n3 50% fatigue, 35.7% arthralgia, 21.4% myalgia, 28.6% cough, 25% dyspnoea, 3.6% chest pain, 10.7% headache, 28.6% olfactory dysfunction, 14.3% rhinorrhoea, no abdominal pain\n4 50% fatigue, 35.7% arthralgia, 21.4% myalgia, 28.6% cough, 25% dyspnoea, 3.6% chest pain, 10.7% headache, 28.6% olfactory dysfunction, 14.3% rhinorrhoea, no abdominal pain\n5 50% fatigue, 35.7% arthralgia, 21.4% myalgia, 28.6% cough, 25% dyspnoea, 3.6% chest pain, 10.7% headache, 28.6% olfactory dysfunction, 14.3% rhinorrhoea, no abdominal pain\n6 50% fatigue, 35.7% arthralgia, 21.4% myalgia, 28.6% cough, 25% dyspnoea, 3.6% chest pain, 10.7% headache, 28.6% olfactory dysfunction, 14.3% rhinorrhoea, no abdominal pain\n\n\nI realised that map_data(“world”) showed all the longitudes and latitudes for subregions of each country, which might not be required for the map I wanted. So after trialling the map visualisation several times, I opted to use centroids of each country instead, to leave the map in a cleaner and easy-to-see state. Otherwise one of the maps I tested before ended up with countless blobs of circles marking the boundaries of each country, looking like a 5-year-old’s map drawing!\n\nmapdata_final <- mapdata_new %>% \n  group_by(region) %>% \n  # Using centroids of countries = means of longitudes and latitudes for each country\n  summarise(long = mean(long), lat = mean(lat))\nkable(mapdata_final)\n\n\n\n\nregion\nlong\nlat\n\n\n\n\nAustralia\n136.998543\n-25.18300\n\n\nAustria\n13.473366\n47.57973\n\n\nBangladesh\n90.506118\n23.50905\n\n\nBelgium\n4.732104\n50.59063\n\n\nChina\n106.847575\n35.08244\n\n\nDenmark\n10.731255\n55.70473\n\n\nFrance\n3.226979\n46.16686\n\n\nGermany\n10.401156\n51.20461\n\n\nItaly\n11.752853\n42.16598\n\n\nSpain\n-2.906821\n40.67995\n\n\nUK\n-4.098750\n55.55813\n\n\nUSA\n-121.625310\n48.74333\n\n\n\n\n\n\n# join above mapdata_final with the df1 which contains countries and long COVID results\ndf1_mapdata <- left_join(mapdata_final, df1, by = \"region\")\nkable(df1_mapdata)\n\n\n\n\n\n\n\n\n\n\nregion\nlong\nlat\nResults\n\n\n\n\nAustralia\n136.998543\n-25.18300\n50% fatigue, 35.7% arthralgia, 21.4% myalgia, 28.6% cough, 25% dyspnoea, 3.6% chest pain, 10.7% headache, 28.6% olfactory dysfunction, 14.3% rhinorrhoea, no abdominal pain\n\n\nAustria\n13.473366\n47.57973\n24% night sweats, 0% fever, 63% abnormal chest CT: ground-glass opacities, reticular lesions, consolidations, bronchial dilation. 36% dyspnoea, abnormal spirometry: 22% reduced FVC, 22% reduced FEV1, normal FEV1/FVC. 21% reduced DLCO, 17% cough, 22% sleep disorders, 19% olfactory dysfunction, 9% diarrhoea/vomiting, 97% normal LVEF, 55% diastolic dysfunction on echo, 23% raised NT-proBNP, 10% pulmonary hypertension, 1% pericardial effusion, raised D-dimer, potentially raised ferritin, normal CRP, normal procalcitonin, normal IL-6\n\n\nBangladesh\n90.506118\n23.50905\n33% fatigue, 1.4% arthralgia, 0.6% myalgia, 8.5% cough, 7% dyspnoea, 0.8% chest pain, 3.9% circadian rhythm disorders, 3.4% headache, 2.3% sleep disturbance, 1.4% adjustment disorder, 2.3% vertigo, 2% olfactory dysfunction, 1.4% palpitation\n\n\nBelgium\n4.732104\n50.59063\n25% fatigue, abnormal chest CT: 67% ground glass opacities, 44% reticulations, 20% fibrotic lesions/traction bronchiectasis, 7% consolidations. 46% reduced DLCO, 35% dyspnoea, 10% dry cough, 4% chest tightness, normal spirometry\n\n\nChina\n106.847575\n35.08244\n62% abnormal chest CT: 35% fibrotic-like changes, 27% ground glass opacities/interstitial thickening, nodules/masses, interlobar pleural traction, pulmonary atelectasis and bronchiectasis. 26% reduced DLCO, 14% mild dyspnoea, 10% sputum production, 6.1% dry cough\n\n\nDenmark\n10.731255\n55.70473\nfatigue, myalgia, arthralgia, chills, fever, dyspnoea, cough, chest pain, sputum production, memory issues, concentration issues, headache, olfactory dysfunction, gustatory dysfunction, sore throat, rhinorrhoea, sneezing, diarrhoea, anorexia, abdominal pain, nausea, red runny eyes, 63% fatigue, 35% myalgia, 53% dyspnoea, 24% cough, 20% chest pain, 12% sputum production, 45% concentration issues, 27% headache, 27% paraesthesia, 31% gustatory dysfunction, 27% olfactory dysfunction, 10% sore throat, 10% abdominal pain, 8% diarrhoea, 8% nausea, 4% anorexia\n\n\nFrance\n3.226979\n46.16686\n16.8% olfactory dysfunction, 9.6% gustatory dysfunction, fatigue, arthralgia, myalgia, dyspnoea, cough, headache, rhinorrhoea, olfactory dysfunction, gustatory dysfunction, sore throat\n\n\nGermany\n10.401156\n51.20461\n45% fatigue, 15% myalgia, 3% fever, slight pain/discomfort, 33% dyspnoea, 33% cough. Normal spirometry, normal ABG, reduced DLCO, reduced distance on 6MWT, 18% cognitive issues, 15% headache, mild depression, subthreshold anxiety, 12% olfactory dysfunction, 12% rhinorrhoea, 9% gustatory dysfunction, 9% sore throat, 9% diarrhoea, 6% nausea, 3% abdominal pain, normal LFTs, 18% angina, normal left ventricular function, normal right ventricular function, normal cardiac biomarkers, normal FBC, normal coagulation screen, raised ferritin, potentially raised D-dimer, normal U&Es, normal CRP, normal procalcitonin, normal TFTs, normal IL-6, 17% fatigue, depression, concentration issues, 27% olfactory/gustatory dysfunction, alopecia, 42.3% subjective olfactory dysfunction, 26.9% objective olfactory dysfunction (discrimination and identification issues)\n\n\nItaly\n11.752853\n42.16598\n5.9% myalgia, 5.9% arthralgia, 5.5% dyspnoea, 2.5% cough, 0.4% chest pain, 51.6% reduced DLCO, normal spirometry, 43% PTSD symptoms, 5% gustatory dysfunction, 4.6% olfactory dysfunction, 1.3% diarrhoea, 13.1% fatigue, 8.2% rheumatological issues, 6% dyspnoea, 2% cough, 0.8% chest pain, 9.6% neurological disorders, 4.9% psychiatric disorders, 2.7% headache, 10.4% olfactory/gustatory dysfunction, 1.5% gastrointestinal disorders, 3.7% alopecia, 3.4% cutaneous manifestations, 0.3% ocular symptoms, 21% olfactory dysfunction, 7.9% gustatory dysfunction\n\n\nSpain\n-2.906821\n40.67995\n61.2% fatigue, 23.3% dyspnoea, 6.5% chest pain, 2.5% cough\n\n\nUK\n-4.098750\n55.55813\nfatigue, myalgia, fever, dyspnoea, cough, chest pain, headache, paraesthesia, numbness, concentration/ memory issues, olfactory dysfunction, sore throat, hoarse voice, tinnitus, earache, diarrhoea, abdominal pain, palpitations/tachycardia\n\n\nUSA\n-121.625310\n48.74333\n44.8% fatigue, 21.3% myalgia, 15.8% arthralgia, 1.1% fever, 1.1% ulcer, 31.7% dyspnoea, 25.1% cough, 14.8% sputum production, 12.6% headache, 8.7% cognitive issues, 9.8% gustatory dysfunction, 9.3% olfactory dysfunction, 3.8% diarrhoea, 8.2% eye irritation, 1.1% ulcer\n\n\n\n\n\n\n# Prepare pop up information\ndf1_mapdata <- df1_mapdata %>% \n  # paste region and Results columns into popup_info and add it as a new column into dataset\n  # bold texts and add break lines by using html tags as shown\n  mutate(popup_info = paste(\"<b>\",region,\"</b>\",\"<br/>\",\"<b>\",\"Long COVID symptoms:\",\"</b>\",\"<br/>\", Results))\ndf1_mapdata\n\n# A tibble: 12 × 5\n   region        long   lat Results                                      popup…¹\n   <chr>        <dbl> <dbl> <chr>                                        <chr>  \n 1 Australia   137.   -25.2 50% fatigue, 35.7% arthralgia, 21.4% myalgi… <b> Au…\n 2 Austria      13.5   47.6 24% night sweats, 0% fever, 63% abnormal ch… <b> Au…\n 3 Bangladesh   90.5   23.5 33% fatigue, 1.4% arthralgia, 0.6% myalgia,… <b> Ba…\n 4 Belgium       4.73  50.6 25% fatigue, abnormal chest CT: 67% ground … <b> Be…\n 5 China       107.    35.1 62% abnormal chest CT: 35% fibrotic-like ch… <b> Ch…\n 6 Denmark      10.7   55.7 fatigue, myalgia, arthralgia, chills, fever… <b> De…\n 7 France        3.23  46.2 16.8% olfactory dysfunction, 9.6% gustatory… <b> Fr…\n 8 Germany      10.4   51.2 45% fatigue, 15% myalgia, 3% fever, slight … <b> Ge…\n 9 Italy        11.8   42.2 5.9% myalgia, 5.9% arthralgia, 5.5% dyspnoe… <b> It…\n10 Spain        -2.91  40.7 61.2% fatigue, 23.3% dyspnoea, 6.5% chest p… <b> Sp…\n11 UK           -4.10  55.6 fatigue, myalgia, fever, dyspnoea, cough, c… <b> UK…\n12 USA        -122.    48.7 44.8% fatigue, 21.3% myalgia, 15.8% arthral… <b> US…\n# … with abbreviated variable name ¹​popup_info\n\n\n\nleaflet() %>% \n  # initialising the graphics environment for map\n  addTiles() %>% \n  # add circle markers to map\n  # use the df1_mapdata dataset containing countries, longitudes, latitudes and long COVID results\n  # add data, latitudes, longitudes, radius of circles, pop up information\n  addCircleMarkers(data = df1_mapdata, lat = ~lat, lng = ~long, radius = ~3, popup = ~popup_info)\n\n\n\nInteractive map for long COVID symptoms\n\n\nABG = arterial blood gas, CT = computed tomography, CRP = c-reactive protein, DLCO = diffusing capacity for carbon monoxide, FBC = full blood count, FEV1 = forced expiratory volume in one second, FVC = forced vital capacity, IL-6 = interleukin-6, LFT = liver function test, LVEF = left ventricular ejection fraction, NT-proBNP = N-terminal pro B-type natriuretic peptide, PTSD = posttraumatic stress disorder, 6MWT = 6-min walk test, U&E = urea and electrolyte, TFT = thyroid function test\n\n\n\nText mining for word cloud\nWhen skimming through the Results column, it appeared some of the terms recorded were repetitive, so a wordcloud might be another interesting way to see if it could highlight any particular long COVID symptoms from this meta-analysis.\n\n# Select the results column\ntext <- df$Results\n# Remove numbers from the texts so that the digits won't appear in the wordcloud\ntext1 <- str_replace_all(text, \"[:digit:]\", \"\")\ntext1\n\n [1] \".% myalgia, .% arthralgia\"                                                                                                                                                                                                                                \n [2] \".% dyspnoea, .% cough, .% chest pain, .% reduced DLCO, normal spirometry\"                                                                                                                                                                                 \n [3] \"% PTSD symptoms\"                                                                                                                                                                                                                                          \n [4] \"% gustatory dysfunction, .% olfactory dysfunction\"                                                                                                                                                                                                        \n [5] \".% diarrhoea\"                                                                                                                                                                                                                                             \n [6] \"fatigue, myalgia, arthralgia, chills, fever\"                                                                                                                                                                                                              \n [7] \"dyspnoea, cough, chest pain, sputum production\"                                                                                                                                                                                                           \n [8] \"memory issues, concentration issues, headache\"                                                                                                                                                                                                            \n [9] \"olfactory dysfunction, gustatory dysfunction, sore throat, rhinorrhoea, sneezing\"                                                                                                                                                                         \n[10] \"diarrhoea, anorexia, abdominal pain, nausea\"                                                                                                                                                                                                              \n[11] \"red runny eyes\"                                                                                                                                                                                                                                           \n[12] \"% olfactory dysfunction\"                                                                                                                                                                                                                                  \n[13] \".% olfactory dysfunction, .% gustatory dysfunction\"                                                                                                                                                                                                       \n[14] \"% fatigue, % myalgia, % fever, slight pain/discomfort\"                                                                                                                                                                                                    \n[15] \"% dyspnoea, % cough. Normal spirometry, normal ABG, reduced DLCO, reduced distance on MWT\"                                                                                                                                                                \n[16] \"% cognitive issues, % headache, mild depression, subthreshold anxiety\"                                                                                                                                                                                    \n[17] \"% olfactory dysfunction, % rhinorrhoea, % gustatory dysfunction, % sore throat\"                                                                                                                                                                           \n[18] \"% diarrhoea, % nausea, % abdominal pain, normal LFTs\"                                                                                                                                                                                                     \n[19] \"% angina, normal left ventricular function, normal right ventricular function, normal cardiac biomarkers\"                                                                                                                                                 \n[20] \"normal FBC, normal coagulation screen, raised ferritin, potentially raised D-dimer, normal U&Es, normal CRP, normal procalcitonin, normal TFTs, normal IL-\"                                                                                               \n[21] \".% fatigue\"                                                                                                                                                                                                                                               \n[22] \".% dyspnoea, .% chest pain, .% cough\"                                                                                                                                                                                                                     \n[23] \"% fatigue\"                                                                                                                                                                                                                                                \n[24] \"abnormal chest CT: % ground glass opacities, % reticulations, % fibrotic lesions/traction bronchiectasis, % consolidations. % reduced DLCO, % dyspnoea, % dry cough, % chest tightness, normal spirometry\"                                                \n[25] \"% fatigue\"                                                                                                                                                                                                                                                \n[26] \"depression, concentration issues\"                                                                                                                                                                                                                         \n[27] \"% olfactory/gustatory dysfunction\"                                                                                                                                                                                                                        \n[28] \"alopecia\"                                                                                                                                                                                                                                                 \n[29] \"fatigue, arthralgia, myalgia\"                                                                                                                                                                                                                             \n[30] \"dyspnoea, cough\"                                                                                                                                                                                                                                          \n[31] \"headache\"                                                                                                                                                                                                                                                 \n[32] \"rhinorrhoea, olfactory dysfunction, gustatory dysfunction, sore throat\"                                                                                                                                                                                   \n[33] \"% abnormal chest CT: % fibrotic-like changes, % ground glass opacities/interstitial thickening, nodules/masses, interlobar pleural traction, pulmonary atelectasis and bronchiectasis. % reduced DLCO, % mild dyspnoea, % sputum production, .% dry cough\"\n[34] \"% fatigue, .% arthralgia, .% myalgia\"                                                                                                                                                                                                                     \n[35] \".% cough, % dyspnoea, .% chest pain\"                                                                                                                                                                                                                      \n[36] \".% headache\"                                                                                                                                                                                                                                              \n[37] \".% olfactory dysfunction, .% rhinorrhoea\"                                                                                                                                                                                                                 \n[38] \"no abdominal pain\"                                                                                                                                                                                                                                        \n[39] \".% fatigue, .% myalgia, .% arthralgia, .% fever, .% ulcer\"                                                                                                                                                                                                \n[40] \".% dyspnoea, .% cough, .% sputum production\"                                                                                                                                                                                                              \n[41] \".% headache, .% cognitive issues\"                                                                                                                                                                                                                         \n[42] \".% gustatory dysfunction, .% olfactory dysfunction\"                                                                                                                                                                                                       \n[43] \".% diarrhoea\"                                                                                                                                                                                                                                             \n[44] \".% eye irritation, .% ulcer\"                                                                                                                                                                                                                              \n[45] \"% fatigue, % myalgia\"                                                                                                                                                                                                                                     \n[46] \"% dyspnoea, % cough, % chest pain, % sputum production\"                                                                                                                                                                                                   \n[47] \"% concentration issues, % headache, % paraesthesia\"                                                                                                                                                                                                       \n[48] \"% gustatory dysfunction, % olfactory dysfunction, % sore throat\"                                                                                                                                                                                          \n[49] \"% abdominal pain, % diarrhoea, % nausea, % anorexia\"                                                                                                                                                                                                      \n[50] \"% fatigue, .% arthralgia, .% myalgia\"                                                                                                                                                                                                                     \n[51] \".% cough, % dyspnoea, .% chest pain\"                                                                                                                                                                                                                      \n[52] \".% circadian rhythm disorders, .% headache, .% sleep disturbance, .% adjustment disorder\"                                                                                                                                                                 \n[53] \".% vertigo, % olfactory dysfunction\"                                                                                                                                                                                                                      \n[54] \".% palpitation\"                                                                                                                                                                                                                                           \n[55] \".% subjective olfactory dysfunction, .% objective olfactory  dysfunction (discrimination and identification issues)\"                                                                                                                                      \n[56] \".% fatigue, .% rheumatological issues\"                                                                                                                                                                                                                    \n[57] \"% dyspnoea, % cough, .% chest pain\"                                                                                                                                                                                                                       \n[58] \".% neurological disorders, .% psychiatric disorders, .% headache\"                                                                                                                                                                                         \n[59] \".% olfactory/gustatory dysfunction\"                                                                                                                                                                                                                       \n[60] \".% gastrointestinal disorders\"                                                                                                                                                                                                                            \n[61] \".% alopecia, .% cutaneous manifestations, .% ocular symptoms\"                                                                                                                                                                                             \n[62] \"% night sweats, % fever\"                                                                                                                                                                                                                                  \n[63] \"% abnormal chest CT: ground-glass opacities, reticular lesions, consolidations, bronchial dilation. % dyspnoea, abnormal spirometry: % reduced FVC, % reduced FEV, normal FEV/FVC. % reduced DLCO, % cough\"                                               \n[64] \"% sleep disorders\"                                                                                                                                                                                                                                        \n[65] \"% olfactory dysfunction\"                                                                                                                                                                                                                                  \n[66] \"% diarrhoea/vomiting\"                                                                                                                                                                                                                                     \n[67] \"% normal LVEF, % diastolic dysfunction on echo, % raised NT-proBNP, % pulmonary hypertension, % pericardial effusion\"                                                                                                                                     \n[68] \"raised D-dimer, potentially raised ferritin, normal CRP, normal procalcitonin, normal IL-\"                                                                                                                                                                \n[69] \"fatigue, myalgia, fever\"                                                                                                                                                                                                                                  \n[70] \"dyspnoea, cough, chest pain\"                                                                                                                                                                                                                              \n[71] \"headache, paraesthesia, numbness, concentration/ memory issues\"                                                                                                                                                                                           \n[72] \"olfactory dysfunction, sore throat, hoarse voice, tinnitus, earache\"                                                                                                                                                                                      \n[73] \"diarrhoea, abdominal pain\"                                                                                                                                                                                                                                \n[74] \"palpitations/tachycardia\"                                                                                                                                                                                                                                 \n[75] \"% olfactory dysfunction, .% gustatory dysfunction\"                                                                                                                                                                                                        \n\n\n\n# Change the text into a tibble\ntext_df <- tibble(line = 1:75, text = text1)\ntext_df\n\n# A tibble: 75 × 2\n    line text                                                                   \n   <int> <chr>                                                                  \n 1     1 .% myalgia, .% arthralgia                                              \n 2     2 .% dyspnoea, .% cough, .% chest pain, .% reduced DLCO, normal spiromet…\n 3     3 % PTSD symptoms                                                        \n 4     4 % gustatory dysfunction, .% olfactory dysfunction                      \n 5     5 .% diarrhoea                                                           \n 6     6 fatigue, myalgia, arthralgia, chills, fever                            \n 7     7 dyspnoea, cough, chest pain, sputum production                         \n 8     8 memory issues, concentration issues, headache                          \n 9     9 olfactory dysfunction, gustatory dysfunction, sore throat, rhinorrhoea…\n10    10 diarrhoea, anorexia, abdominal pain, nausea                            \n# … with 65 more rows\n# ℹ Use `print(n = ...)` to see more rows\n\n\n\n# Tokenise the texts in the selected column\ntext_df1 <- text_df %>% \n  unnest_tokens(word, text)\ntext_df1\n\n# A tibble: 399 × 2\n    line word      \n   <int> <chr>     \n 1     1 myalgia   \n 2     1 arthralgia\n 3     2 dyspnoea  \n 4     2 cough     \n 5     2 chest     \n 6     2 pain      \n 7     2 reduced   \n 8     2 dlco      \n 9     2 normal    \n10     2 spirometry\n# … with 389 more rows\n# ℹ Use `print(n = ...)` to see more rows\n\n\n\ntext_df1 %>% \n  # Remove stop_words\n  anti_join(stop_words) %>% \n  # Count the frequency of appearance of each word\n  count(word) %>% \n  # Then create a wordcloud\n  with(wordcloud(word, n, colors = brewer.pal(8,\"Dark2\")))\n\n\n\n# display.brewer.all to display all colour palettes if wanting to use different colours\n\nA known drawback of wordcloud was that the length of a word might influence how big it might appear in the wordcloud, so it was not completely dependent on the word frequencies in a set of texts. Nevertheless, it was one of the ways to get a rough idea about the most common terms cropping up in collected texts. This last part was more like a small exercise for me and also for anyone who might want to try this but did not where to start.\n\n\n\nSummary\nLong COVID had shown a very versatile and diverse range of signs and symptoms, often resembling other known post-viral illnesses such as myalgic encephalomyelitis and chronic fatigue syndrome, the interactive map above would enable readers to see specific long COVID symptoms for selected countries. People with diabetes, hypertension and IHD might have higher risk of suffering from long COVID if they were infected with the coronoviruses. The types of co-morbidities were not limited to these three unfortunately and several other chronic illnesses mentioned above might also contribute to similar risk. The most affected body systems in long COVID were in respiratory tract, ear, nose and throat areas, musculoskeletal parts, gastrointestinal tract and last, but not the least, neuropsychiatric systems which could bring fatigue and memory/concentration issue, or more widely known as the “brain fog”. All of these outcomes also did not vary widely from earlier meta-analyses on long COVID, reiterating the wide health ramifications that COVID-19 could inflict upon global populations.\n\nAcknowledgement\nI have to thank several online resources when I was trying to build the interactive map. Most notably, I’ve adapted my code based on these two useful online resources:\n\nR tutorial: Creating Maps and mapping data with ggplot2 by Dr Paul Christiansen\nCreating interactive maps in R by A&G Statworks\n\nI also have to thank all the package creators for all the packages used here and all the authors of the journal paper (as mentioned under “Source of dataset”) which provided the long COVID data.\n\nsessionInfo()\n\nR version 4.2.0 (2022-04-22)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Catalina 10.15.7\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] wordcloud_2.6      RColorBrewer_1.1-3 tidytext_0.3.4     leaflet_2.1.1     \n [5] knitr_1.39         forcats_0.5.1      stringr_1.4.0      dplyr_1.0.9       \n [9] purrr_0.3.4        readr_2.1.2        tidyr_1.2.0        tibble_3.1.8      \n[13] ggplot2_3.3.6      tidyverse_1.3.2   \n\nloaded via a namespace (and not attached):\n [1] httr_1.4.3          maps_3.4.0          bit64_4.0.5        \n [4] vroom_1.6.1         jsonlite_1.8.0      modelr_0.1.8       \n [7] assertthat_0.2.1    highr_0.9           googlesheets4_1.0.0\n[10] cellranger_1.1.0    yaml_2.3.5          pillar_1.8.0       \n[13] backports_1.4.1     lattice_0.20-45     glue_1.6.2         \n[16] digest_0.6.29       rvest_1.0.2         colorspace_2.0-3   \n[19] htmltools_0.5.5     Matrix_1.4-1        pkgconfig_2.0.3    \n[22] broom_1.0.0         haven_2.5.0         scales_1.2.0       \n[25] tzdb_0.3.0          googledrive_2.0.0   farver_2.1.1       \n[28] generics_0.1.3      ellipsis_0.3.2      withr_2.5.0        \n[31] cli_3.4.1           magrittr_2.0.3      crayon_1.5.1       \n[34] readxl_1.4.0        evaluate_0.15       tokenizers_0.2.1   \n[37] janeaustenr_1.0.0   fs_1.5.2            fansi_1.0.3        \n[40] SnowballC_0.7.0     xml2_1.3.3          tools_4.2.0        \n[43] hms_1.1.1           gargle_1.2.0        lifecycle_1.0.3    \n[46] munsell_0.5.0       reprex_2.0.1        compiler_4.2.0     \n[49] rlang_1.1.0         grid_4.2.0          rstudioapi_0.13    \n[52] htmlwidgets_1.5.4   crosstalk_1.2.0     labeling_0.4.2     \n[55] rmarkdown_2.21      gtable_0.3.0        DBI_1.1.3          \n[58] R6_2.5.1            lubridate_1.8.0     fastmap_1.1.0      \n[61] bit_4.0.4           utf8_1.2.2          stringi_1.7.8      \n[64] parallel_4.2.0      Rcpp_1.0.9          vctrs_0.4.1        \n[67] dbplyr_2.2.1        tidyselect_1.1.2    xfun_0.38          \n\n\n\n\n\n\n\n\nFootnotes\n\n\nIt took probably at least half an hour to figure this out… eventually I thought to look at the column itself long enough to see if I’d missed anything… then voila!↩︎\nischaemic heart disease↩︎\nchronic obstructive pulmonary disease↩︎\nchronic kidney disease↩︎"
  },
  {
    "objectID": "posts/14_Scaffolds_in_small_molecules/chembl_anti-inf_data_prep_current.html",
    "href": "posts/14_Scaffolds_in_small_molecules/chembl_anti-inf_data_prep_current.html",
    "title": "Working with scaffolds in small molecules",
    "section": "",
    "text": "Features in post\nThis post will mainly be about the following:\n\nPre-process and standardise compounds (e.g. converting SMILES1 into SELFIES2 and other forms)\nObtain scaffolds for compounds\nAlign scaffolds of compounds\nQuery target scaffolds against a dataframe of compounds:\n\nFunction for saving multiple SMILES in .smi file\nFunction for converting .smi file into a list to query and match scaffolds of interests\nIdentify any similarities or differences in target compound of interest against other compounds in a dataframe\n\n\n\n\n\nQuick words\nI’ve always wanted to shorten my posts to a more readable length, but it was proven to be hard again, as this post was much longer than expected. Page content links are available on the right-hand side if needing to jump to sections for quick reads.\n\n\n\nKey question to answer\nWill the scaffold of compound 3 (compound of interest) be similar to the scaffolds of any approved anti-infectives in ChEMBL database?\n\n\n\nImport libraries\nThe following libraries were used in this post.\n\nimport polars as pl\nimport pandas as pd\nimport datamol as dm\nimport mols2grid\n\nfrom rdkit import Chem\nfrom rdkit.Chem import AllChem\nfrom rdkit.Chem.rdmolfiles import SmilesWriter, SmilesMolSupplier\n\n# Following library was modified & adapted from  \n# Patrick Walters' tutorial on \"Identifying Scaffolds\" \n# - links provided in \"scaffold_finder library\" section under\n# the subheading of \"Combining ChEMBL anti-infectives and FtsZ compounds\"\nfrom scaffold_finder_test import find_scaffolds, get_molecules_with_scaffold\n\n\n\n\nChEMBL anti-infectives\n\nData cleaning\nThe dataset used was extracted from ChEMBL database, with a focus on the anti-infectives.\n\ndf_ai = pl.read_csv(\"chembl_anti-inf.csv\", sep = \";\")\ndf_ai\n\n\n\n\nshape: (144, 29)\n\n\n\n\nParent Molecule\n\n\nName\n\n\nSynonyms\n\n\nResearch Codes\n\n\nPhase\n\n\nDrug Applicants\n\n\nUSAN Stem\n\n\nUSAN Year\n\n\nUSAN Definition\n\n\nUSAN Stem - Substem\n\n\nFirst Approval\n\n\nATC Codes\n\n\nLevel 4 ATC Codes\n\n\nLevel 3 ATC Codes\n\n\nLevel 2 ATC Codes\n\n\nLevel 1 ATC Codes\n\n\nIndication Class\n\n\nPatent\n\n\nDrug Type\n\n\nPasses Rule of Five\n\n\nFirst In Class\n\n\nChirality\n\n\nProdrug\n\n\nOral\n\n\nParenteral\n\n\nTopical\n\n\nBlack Box\n\n\nAvailability Type\n\n\nSmiles\n\n\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nf64\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\ni64\n\n\ni64\n\n\nstr\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\nstr\n\n\nstr\n\n\n\n\n\n\n\"CHEMBL374975\"\n\n\n\"FUSIDIC ACID\"\n\n\n\"ANHYDROUS FUSI...\n\n\n\"CEM-102|NSC-56...\n\n\n4.0\n\n\n\"\"\n\n\n\"\"\n\n\n\"1967\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"J01XC01 | S01A...\n\n\n\"J01XC - Steroi...\n\n\n\"J01X - OTHER A...\n\n\n\"J01 - ANTIBACT...\n\n\n\"J - ANTIINFECT...\n\n\n\"Antibacterial\"\n\n\n\"None\"\n\n\n\"1:Synthetic Sm...\n\n\n0\n\n\n0\n\n\n\"Single Stereoi...\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n\"Unknown\"\n\n\n\"CC(=O)O[C@H]1C...\n\n\n\n\n\"CHEMBL130\"\n\n\n\"CHLORAMPHENICO...\n\n\n\"9-HYDROXY-9-PH...\n\n\n\"NSC-16331|NSC-...\n\n\n4.0\n\n\n\"Ivax Pharmaceu...\n\n\n\"\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"\"\n\n\n\"1950\"\n\n\n\"S01AA01 | S03A...\n\n\n\"S01AA - Antibi...\n\n\n\"S01A - ANTIINF...\n\n\n\"S01 - OPHTHALM...\n\n\n\"S - SENSORY OR...\n\n\n\"Antibacterial;...\n\n\n\"None\"\n\n\n\"1:Synthetic Sm...\n\n\n1\n\n\n0\n\n\n\"Single Stereoi...\n\n\n0\n\n\n1\n\n\n1\n\n\n1\n\n\n0\n\n\n\"Unknown\"\n\n\n\"O=C(N[C@H](CO)...\n\n\n\n\n\"CHEMBL186\"\n\n\n\"CEFEPIME\"\n\n\n\"BMY-28142|CEFE...\n\n\n\"BMY-28142|J01D...\n\n\n4.0\n\n\n\"Samson Medical...\n\n\n\"'cef-'\"\n\n\n\"1987\"\n\n\n\"cephalosporins...\n\n\n\"'cef-(cef-)'\"\n\n\n\"1996\"\n\n\n\"J01DE01\"\n\n\n\"J01DE - Fourth...\n\n\n\"J01D - OTHER B...\n\n\n\"J01 - ANTIBACT...\n\n\n\"J - ANTIINFECT...\n\n\n\"Antibacterial\"\n\n\n\"None\"\n\n\n\"1:Synthetic Sm...\n\n\n1\n\n\n0\n\n\n\"Single Stereoi...\n\n\n0\n\n\n0\n\n\n1\n\n\n0\n\n\n0\n\n\n\"Prescription O...\n\n\n\"CO/N=C(\\C(=O)N...\n\n\n\n\n\"CHEMBL222645\"\n\n\n\"FLOXACILLIN\"\n\n\n\"ABBOFLOX|BRL 2...\n\n\n\"BRL 2039|BRL-2...\n\n\n4.0\n\n\n\"\"\n\n\n\"'-cillin'\"\n\n\n\"1972\"\n\n\n\"penicillins\"\n\n\n\"'-cillin(-cill...\n\n\n\"\"\n\n\n\"J01CF05\"\n\n\n\"J01CF - Beta-l...\n\n\n\"J01C - BETA-LA...\n\n\n\"J01 - ANTIBACT...\n\n\n\"J - ANTIINFECT...\n\n\n\"Antibacterial\"\n\n\n\"None\"\n\n\n\"1:Synthetic Sm...\n\n\n1\n\n\n0\n\n\n\"Single Stereoi...\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n\"Unknown\"\n\n\n\"Cc1onc(-c2c(F)...\n\n\n\n\n\"CHEMBL2364632\"\n\n\n\"SARECYCLINE\"\n\n\n\"P-005672|P0056...\n\n\n\"P-005672|P0056...\n\n\n4.0\n\n\n\"Almirall Llc\"\n\n\n\"'-cycline'\"\n\n\n\"2012\"\n\n\n\"antibiotics (t...\n\n\n\"'-cycline(-cyc...\n\n\n\"2018\"\n\n\n\"J01AA14\"\n\n\n\"J01AA - Tetrac...\n\n\n\"J01A - TETRACY...\n\n\n\"J01 - ANTIBACT...\n\n\n\"J - ANTIINFECT...\n\n\n\"\"\n\n\n\"US-8318706-B2\"\n\n\n\"1:Synthetic Sm...\n\n\n1\n\n\n0\n\n\n\"Single Stereoi...\n\n\n0\n\n\n1\n\n\n0\n\n\n0\n\n\n0\n\n\n\"Prescription O...\n\n\n\"CON(C)Cc1ccc(O...\n\n\n\n\n\"CHEMBL62193\"\n\n\n\"SULFADIMETHOXI...\n\n\n\"Madribon|NSC-6...\n\n\n\"NSC-683544|NSC...\n\n\n4.0\n\n\n\"\"\n\n\n\"'sulfa-'\"\n\n\n\"\"\n\n\n\"antimicrobials...\n\n\n\"'sulfa-(sulfa-...\n\n\n\"\"\n\n\n\"J01ED01\"\n\n\n\"J01ED - Long-a...\n\n\n\"J01E - SULFONA...\n\n\n\"J01 - ANTIBACT...\n\n\n\"J - ANTIINFECT...\n\n\n\"\"\n\n\n\"None\"\n\n\n\"1:Synthetic Sm...\n\n\n1\n\n\n0\n\n\n\"Achiral Molecu...\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n\"Withdrawn\"\n\n\n\"COc1cc(NS(=O)(...\n\n\n\n\n\"CHEMBL2303613\"\n\n\n\"CEFODIZIME\"\n\n\n\"CEFODIZIME|CEF...\n\n\n\"HR 221|HR 221 ...\n\n\n4.0\n\n\n\"\"\n\n\n\"'cef-'\"\n\n\n\"\"\n\n\n\"cephalosporins...\n\n\n\"'cef-(cef-)'\"\n\n\n\"\"\n\n\n\"J01DD09\"\n\n\n\"J01DD - Third-...\n\n\n\"J01D - OTHER B...\n\n\n\"J01 - ANTIBACT...\n\n\n\"J - ANTIINFECT...\n\n\n\"\"\n\n\n\"None\"\n\n\n\"1:Synthetic Sm...\n\n\n0\n\n\n0\n\n\n\"Single Stereoi...\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n\"Unknown\"\n\n\n\"CO/N=C(\\C(=O)N...\n\n\n\n\n\"CHEMBL31\"\n\n\n\"GATIFLOXACIN\"\n\n\n\"AM-1155|BMS-20...\n\n\n\"AM-1155|BMS-20...\n\n\n4.0\n\n\n\"Apotex Inc|Bri...\n\n\n\"'-oxacin'\"\n\n\n\"1997\"\n\n\n\"antibacterials...\n\n\n\"'-oxacin(-oxac...\n\n\n\"1999\"\n\n\n\"S01AE06 | J01M...\n\n\n\"S01AE - Fluoro...\n\n\n\"S01A - ANTIINF...\n\n\n\"S01 - OPHTHALM...\n\n\n\"S - SENSORY OR...\n\n\n\"Antibacterial\"\n\n\n\"None\"\n\n\n\"1:Synthetic Sm...\n\n\n1\n\n\n0\n\n\n\"Racemic Mixtur...\n\n\n0\n\n\n1\n\n\n1\n\n\n1\n\n\n0\n\n\n\"Prescription O...\n\n\n\"COc1c(N2CCNC(C...\n\n\n\n\n\"CHEMBL268869\"\n\n\n\"SULFAMETHOXYPY...\n\n\n\"CL-13494|DEPOV...\n\n\n\"CL-13494|NSC-7...\n\n\n4.0\n\n\n\"\"\n\n\n\"'sulfa-'\"\n\n\n\"\"\n\n\n\"antimicrobials...\n\n\n\"'sulfa-(sulfa-...\n\n\n\"\"\n\n\n\"J01ED05\"\n\n\n\"J01ED - Long-a...\n\n\n\"J01E - SULFONA...\n\n\n\"J01 - ANTIBACT...\n\n\n\"J - ANTIINFECT...\n\n\n\"\"\n\n\n\"None\"\n\n\n\"1:Synthetic Sm...\n\n\n1\n\n\n0\n\n\n\"Achiral Molecu...\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n\"Withdrawn\"\n\n\n\"COc1ccc(NS(=O)...\n\n\n\n\n\"CHEMBL3039597\"\n\n\n\"GENTAMICIN\"\n\n\n\"GENTAMICIN|GEN...\n\n\n\"SCH-9724\"\n\n\n4.0\n\n\n\"Schering Corp ...\n\n\n\"'-micin'\"\n\n\n\"1963\"\n\n\n\"antibiotics (M...\n\n\n\"'-micin(-micin...\n\n\n\"1970\"\n\n\n\"S01AA11 | S02A...\n\n\n\"S01AA - Antibi...\n\n\n\"S01A - ANTIINF...\n\n\n\"S01 - OPHTHALM...\n\n\n\"S - SENSORY OR...\n\n\n\"Antibacterial\"\n\n\n\"None\"\n\n\n\"1:Synthetic Sm...\n\n\n0\n\n\n0\n\n\n\"Unknown\"\n\n\n0\n\n\n0\n\n\n1\n\n\n1\n\n\n1\n\n\n\"Prescription O...\n\n\n\"CNC(C)[C@@H]1C...\n\n\n\n\n\"CHEMBL3182343\"\n\n\n\"PIVAMPICILLIN\"\n\n\n\"MK-191|PIVAMPI...\n\n\n\"MK-191\"\n\n\n4.0\n\n\n\"\"\n\n\n\"'-cillin'\"\n\n\n\"1970\"\n\n\n\"penicillins\"\n\n\n\"'-cillin(-cill...\n\n\n\"\"\n\n\n\"J01CA02\"\n\n\n\"J01CA - Penici...\n\n\n\"J01C - BETA-LA...\n\n\n\"J01 - ANTIBACT...\n\n\n\"J - ANTIINFECT...\n\n\n\"\"\n\n\n\"None\"\n\n\n\"1:Synthetic Sm...\n\n\n1\n\n\n0\n\n\n\"Single Stereoi...\n\n\n1\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n\"Unknown\"\n\n\n\"CC(C)(C)C(=O)O...\n\n\n\n\n\"CHEMBL2146161\"\n\n\n\"MIKAMYCIN\"\n\n\n\"MIKAMYCIN|PRIS...\n\n\n\"RP 7293|RP-729...\n\n\n4.0\n\n\n\"\"\n\n\n\"'-mycin'\"\n\n\n\"\"\n\n\n\"antibiotics (S...\n\n\n\"'-mycin(-mycin...\n\n\n\"\"\n\n\n\"J01FG01\"\n\n\n\"J01FG - Strept...\n\n\n\"J01F - MACROLI...\n\n\n\"J01 - ANTIBACT...\n\n\n\"J - ANTIINFECT...\n\n\n\"\"\n\n\n\"None\"\n\n\n\"1:Synthetic Sm...\n\n\n0\n\n\n0\n\n\n\"Unknown\"\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n\"Unknown\"\n\n\n\"CC1=C\\[C@@H](O...\n\n\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n\n\n\"CHEMBL572\"\n\n\n\"NITROFURANTOIN...\n\n\n\"BERKFURIN|CEDU...\n\n\n\"NSC-2107|NSC-4...\n\n\n4.0\n\n\n\"Sun Pharmaceut...\n\n\n\"'-toin'\"\n\n\n\"\"\n\n\n\"antiepileptics...\n\n\n\"'-toin(-toin)'...\n\n\n\"1953\"\n\n\n\"J01XE01 | J01X...\n\n\n\"J01XE - Nitrof...\n\n\n\"J01X - OTHER A...\n\n\n\"J01 - ANTIBACT...\n\n\n\"J - ANTIINFECT...\n\n\n\"Antibacterial ...\n\n\n\"None\"\n\n\n\"1:Synthetic Sm...\n\n\n1\n\n\n0\n\n\n\"Achiral Molecu...\n\n\n0\n\n\n1\n\n\n1\n\n\n0\n\n\n0\n\n\n\"Prescription O...\n\n\n\"O=C1CN(/N=C/c2...\n\n\n\n\n\"CHEMBL1596\"\n\n\n\"CARBENICILLIN ...\n\n\n\"CARBENICILLIN ...\n\n\n\"\"\n\n\n4.0\n\n\n\"Pfizer Laborat...\n\n\n\"'-cillin'\"\n\n\n\"1972\"\n\n\n\"penicillins\"\n\n\n\"'-cillin(-cill...\n\n\n\"1972\"\n\n\n\"J01CA05\"\n\n\n\"J01CA - Penici...\n\n\n\"J01C - BETA-LA...\n\n\n\"J01 - ANTIBACT...\n\n\n\"J - ANTIINFECT...\n\n\n\"Antibacterial\"\n\n\n\"None\"\n\n\n\"1:Synthetic Sm...\n\n\n1\n\n\n0\n\n\n\"Racemic Mixtur...\n\n\n1\n\n\n1\n\n\n0\n\n\n0\n\n\n0\n\n\n\"Discontinued\"\n\n\n\"CC1(C)S[C@@H]2...\n\n\n\n\n\"CHEMBL44354\"\n\n\n\"CEFTAZIDIME\"\n\n\n\"CEFTAZIDIME|CE...\n\n\n\"GR 20263|GR-20...\n\n\n4.0\n\n\n\"Glaxosmithklin...\n\n\n\"'cef-'\"\n\n\n\"1980\"\n\n\n\"cephalosporins...\n\n\n\"'cef-(cef-)'\"\n\n\n\"1985\"\n\n\n\"J01DD02\"\n\n\n\"J01DD - Third-...\n\n\n\"J01D - OTHER B...\n\n\n\"J01 - ANTIBACT...\n\n\n\"J - ANTIINFECT...\n\n\n\"Antibacterial\"\n\n\n\"US-7112592-B2\"\n\n\n\"1:Synthetic Sm...\n\n\n0\n\n\n0\n\n\n\"Single Stereoi...\n\n\n0\n\n\n0\n\n\n1\n\n\n0\n\n\n1\n\n\n\"Prescription O...\n\n\n\"CC(C)(O/N=C(\\C...\n\n\n\n\n\"CHEMBL29\"\n\n\n\"BENZYLPENICILL...\n\n\n\"BENZYL PENICIL...\n\n\n\"J01CE01|NSC-19...\n\n\n4.0\n\n\n\"Hq Specialty P...\n\n\n\"'-cillin'\"\n\n\n\"\"\n\n\n\"penicillins\"\n\n\n\"'-cillin(-cill...\n\n\n\"1947\"\n\n\n\"J01CE01 | S01A...\n\n\n\"J01CE - Beta-l...\n\n\n\"J01C - BETA-LA...\n\n\n\"J01 - ANTIBACT...\n\n\n\"J - ANTIINFECT...\n\n\n\"Antibacterial\"\n\n\n\"None\"\n\n\n\"1:Synthetic Sm...\n\n\n1\n\n\n0\n\n\n\"Single Stereoi...\n\n\n0\n\n\n1\n\n\n1\n\n\n0\n\n\n1\n\n\n\"Prescription O...\n\n\n\"CC1(C)S[C@@H]2...\n\n\n\n\n\"CHEMBL277100\"\n\n\n\"TEMAFLOXACIN\"\n\n\n\"Omniflox|TEMAF...\n\n\n\"\"\n\n\n4.0\n\n\n\"\"\n\n\n\"'-oxacin'\"\n\n\n\"1988\"\n\n\n\"antibacterials...\n\n\n\"'-oxacin(-oxac...\n\n\n\"1992\"\n\n\n\"J01MA05\"\n\n\n\"J01MA - Fluoro...\n\n\n\"J01M - QUINOLO...\n\n\n\"J01 - ANTIBACT...\n\n\n\"J - ANTIINFECT...\n\n\n\"Antibacterial ...\n\n\n\"None\"\n\n\n\"1:Synthetic Sm...\n\n\n1\n\n\n0\n\n\n\"Racemic Mixtur...\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n\"Withdrawn\"\n\n\n\"CC1CN(c2cc3c(c...\n\n\n\n\n\"CHEMBL1731\"\n\n\n\"MEZLOCILLIN\"\n\n\n\"BAY-F-1353|BAY...\n\n\n\"BAY-F-1353\"\n\n\n4.0\n\n\n\"Bayer Pharmace...\n\n\n\"'-cillin'\"\n\n\n\"1976\"\n\n\n\"penicillins\"\n\n\n\"'-cillin(-cill...\n\n\n\"1981\"\n\n\n\"J01CA10\"\n\n\n\"J01CA - Penici...\n\n\n\"J01C - BETA-LA...\n\n\n\"J01 - ANTIBACT...\n\n\n\"J - ANTIINFECT...\n\n\n\"Antibacterial\"\n\n\n\"None\"\n\n\n\"1:Synthetic Sm...\n\n\n0\n\n\n0\n\n\n\"Single Stereoi...\n\n\n0\n\n\n0\n\n\n1\n\n\n0\n\n\n0\n\n\n\"Discontinued\"\n\n\n\"CC1(C)S[C@@H]2...\n\n\n\n\n\"CHEMBL2105612\"\n\n\n\"PROPICILLIN\"\n\n\n\"(1-PHENOXYPROP...\n\n\n\"\"\n\n\n4.0\n\n\n\"\"\n\n\n\"'-cillin'\"\n\n\n\"\"\n\n\n\"penicillins\"\n\n\n\"'-cillin(-cill...\n\n\n\"\"\n\n\n\"J01CE03\"\n\n\n\"J01CE - Beta-l...\n\n\n\"J01C - BETA-LA...\n\n\n\"J01 - ANTIBACT...\n\n\n\"J - ANTIINFECT...\n\n\n\"\"\n\n\n\"None\"\n\n\n\"1:Synthetic Sm...\n\n\n1\n\n\n0\n\n\n\"Racemic Mixtur...\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n\"Unknown\"\n\n\n\"CCC(Oc1ccccc1)...\n\n\n\n\n\"CHEMBL8\"\n\n\n\"CIPROFLOXACIN\"\n\n\n\"BAY O 9867 FRE...\n\n\n\"BAY O 9867 FRE...\n\n\n4.0\n\n\n\"Inforlife Sa|A...\n\n\n\"'-oxacin'\"\n\n\n\"1987\"\n\n\n\"antibacterials...\n\n\n\"'-oxacin(-oxac...\n\n\n\"1987\"\n\n\n\"J01MA02 | S03A...\n\n\n\"J01MA - Fluoro...\n\n\n\"J01M - QUINOLO...\n\n\n\"J01 - ANTIBACT...\n\n\n\"J - ANTIINFECT...\n\n\n\"Antibacterial\"\n\n\n\"US-8318817-B2\"\n\n\n\"1:Synthetic Sm...\n\n\n1\n\n\n0\n\n\n\"Achiral Molecu...\n\n\n0\n\n\n1\n\n\n1\n\n\n1\n\n\n1\n\n\n\"Prescription O...\n\n\n\"O=C(O)c1cn(C2C...\n\n\n\n\n\"CHEMBL9\"\n\n\n\"NORFLOXACIN\"\n\n\n\"Baccidal|CHIBR...\n\n\n\"MK-366|NSC-757...\n\n\n4.0\n\n\n\"Merck Research...\n\n\n\"'-oxacin'\"\n\n\n\"1984\"\n\n\n\"antibacterials...\n\n\n\"'-oxacin(-oxac...\n\n\n\"1986\"\n\n\n\"J01MA06 | S01A...\n\n\n\"J01MA - Fluoro...\n\n\n\"J01M - QUINOLO...\n\n\n\"J01 - ANTIBACT...\n\n\n\"J - ANTIINFECT...\n\n\n\"Antibacterial\"\n\n\n\"None\"\n\n\n\"1:Synthetic Sm...\n\n\n1\n\n\n0\n\n\n\"Achiral Molecu...\n\n\n0\n\n\n1\n\n\n0\n\n\n1\n\n\n1\n\n\n\"Prescription O...\n\n\n\"CCn1cc(C(=O)O)...\n\n\n\n\n\"CHEMBL21\"\n\n\n\"SULFANILAMIDE\"\n\n\n\"ANILINE-P-SULF...\n\n\n\"NSC-7618\"\n\n\n4.0\n\n\n\"Mylan Specialt...\n\n\n\"'sulfa-'\"\n\n\n\"\"\n\n\n\"antimicrobials...\n\n\n\"'sulfa-(sulfa-...\n\n\n\"1985\"\n\n\n\"D06BA05 | J01E...\n\n\n\"D06BA - Sulfon...\n\n\n\"D06B - CHEMOTH...\n\n\n\"D06 - ANTIBIOT...\n\n\n\"D - DERMATOLOG...\n\n\n\"\"\n\n\n\"None\"\n\n\n\"1:Synthetic Sm...\n\n\n1\n\n\n0\n\n\n\"Achiral Molecu...\n\n\n0\n\n\n0\n\n\n0\n\n\n1\n\n\n0\n\n\n\"Prescription O...\n\n\n\"Nc1ccc(S(N)(=O...\n\n\n\n\n\"CHEMBL4\"\n\n\n\"OFLOXACIN\"\n\n\n\"DL-8280|EXOCIN...\n\n\n\"DL-8280|HOE 28...\n\n\n4.0\n\n\n\"Bausch And Lom...\n\n\n\"'-oxacin'\"\n\n\n\"1984\"\n\n\n\"antibacterials...\n\n\n\"'-oxacin(-oxac...\n\n\n\"1990\"\n\n\n\"J01MA01 | S02A...\n\n\n\"J01MA - Fluoro...\n\n\n\"J01M - QUINOLO...\n\n\n\"J01 - ANTIBACT...\n\n\n\"J - ANTIINFECT...\n\n\n\"Antibacterial\"\n\n\n\"None\"\n\n\n\"1:Synthetic Sm...\n\n\n1\n\n\n0\n\n\n\"Racemic Mixtur...\n\n\n0\n\n\n1\n\n\n1\n\n\n1\n\n\n1\n\n\n\"Prescription O...\n\n\n\"CC1COc2c(N3CCN...\n\n\n\n\n\"CHEMBL530\"\n\n\n\"AMDINOCILLIN\"\n\n\n\"AMDINOCILLIN|C...\n\n\n\"FL 1060|FL-106...\n\n\n4.0\n\n\n\"Hoffmann La Ro...\n\n\n\"'-cillin'\"\n\n\n\"1981\"\n\n\n\"penicillins\"\n\n\n\"'-cillin(-cill...\n\n\n\"1984\"\n\n\n\"J01CA11\"\n\n\n\"J01CA - Penici...\n\n\n\"J01C - BETA-LA...\n\n\n\"J01 - ANTIBACT...\n\n\n\"J - ANTIINFECT...\n\n\n\"Antibacterial\"\n\n\n\"None\"\n\n\n\"1:Synthetic Sm...\n\n\n1\n\n\n0\n\n\n\"Single Stereoi...\n\n\n0\n\n\n0\n\n\n1\n\n\n0\n\n\n0\n\n\n\"Discontinued\"\n\n\n\"CC1(C)S[C@@H]2...\n\n\n\n\n\n\n\n\n# Uncomment below if requiring a quick overview on all column names, \n# first ten variables in each column and each column data type\n#print(df_ai.glimpse())\n\nUnder the “Availability Type” column, there were a few different availabilities for each anti-bacterial such as, “Discontinued”, “Withdrawn”, “Unknown” and “Prescription Only”.\n\ndf_ai.groupby(\"Availability Type\").count()\n\n\n\n\nshape: (4, 2)\n\n\n\n\nAvailability Type\n\n\ncount\n\n\n\n\nstr\n\n\nu32\n\n\n\n\n\n\n\"Discontinued\"\n\n\n36\n\n\n\n\n\"Withdrawn\"\n\n\n7\n\n\n\n\n\"Unknown\"\n\n\n29\n\n\n\n\n\"Prescription O...\n\n\n72\n\n\n\n\n\n\n\nI only wanted to choose the “Prescription Only” ones, so the following filter condition was applied to the dataframe.\n\ndf_ai_rx = df_ai.filter(pl.col(\"Availability Type\") == \"Prescription Only\")\ndf_ai_rx.head()\n\n\n\n\nshape: (5, 29)\n\n\n\n\nParent Molecule\n\n\nName\n\n\nSynonyms\n\n\nResearch Codes\n\n\nPhase\n\n\nDrug Applicants\n\n\nUSAN Stem\n\n\nUSAN Year\n\n\nUSAN Definition\n\n\nUSAN Stem - Substem\n\n\nFirst Approval\n\n\nATC Codes\n\n\nLevel 4 ATC Codes\n\n\nLevel 3 ATC Codes\n\n\nLevel 2 ATC Codes\n\n\nLevel 1 ATC Codes\n\n\nIndication Class\n\n\nPatent\n\n\nDrug Type\n\n\nPasses Rule of Five\n\n\nFirst In Class\n\n\nChirality\n\n\nProdrug\n\n\nOral\n\n\nParenteral\n\n\nTopical\n\n\nBlack Box\n\n\nAvailability Type\n\n\nSmiles\n\n\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nf64\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\ni64\n\n\ni64\n\n\nstr\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\nstr\n\n\nstr\n\n\n\n\n\n\n\"CHEMBL186\"\n\n\n\"CEFEPIME\"\n\n\n\"BMY-28142|CEFE...\n\n\n\"BMY-28142|J01D...\n\n\n4.0\n\n\n\"Samson Medical...\n\n\n\"'cef-'\"\n\n\n\"1987\"\n\n\n\"cephalosporins...\n\n\n\"'cef-(cef-)'\"\n\n\n\"1996\"\n\n\n\"J01DE01\"\n\n\n\"J01DE - Fourth...\n\n\n\"J01D - OTHER B...\n\n\n\"J01 - ANTIBACT...\n\n\n\"J - ANTIINFECT...\n\n\n\"Antibacterial\"\n\n\n\"None\"\n\n\n\"1:Synthetic Sm...\n\n\n1\n\n\n0\n\n\n\"Single Stereoi...\n\n\n0\n\n\n0\n\n\n1\n\n\n0\n\n\n0\n\n\n\"Prescription O...\n\n\n\"CO/N=C(\\C(=O)N...\n\n\n\n\n\"CHEMBL2364632\"\n\n\n\"SARECYCLINE\"\n\n\n\"P-005672|P0056...\n\n\n\"P-005672|P0056...\n\n\n4.0\n\n\n\"Almirall Llc\"\n\n\n\"'-cycline'\"\n\n\n\"2012\"\n\n\n\"antibiotics (t...\n\n\n\"'-cycline(-cyc...\n\n\n\"2018\"\n\n\n\"J01AA14\"\n\n\n\"J01AA - Tetrac...\n\n\n\"J01A - TETRACY...\n\n\n\"J01 - ANTIBACT...\n\n\n\"J - ANTIINFECT...\n\n\n\"\"\n\n\n\"US-8318706-B2\"\n\n\n\"1:Synthetic Sm...\n\n\n1\n\n\n0\n\n\n\"Single Stereoi...\n\n\n0\n\n\n1\n\n\n0\n\n\n0\n\n\n0\n\n\n\"Prescription O...\n\n\n\"CON(C)Cc1ccc(O...\n\n\n\n\n\"CHEMBL31\"\n\n\n\"GATIFLOXACIN\"\n\n\n\"AM-1155|BMS-20...\n\n\n\"AM-1155|BMS-20...\n\n\n4.0\n\n\n\"Apotex Inc|Bri...\n\n\n\"'-oxacin'\"\n\n\n\"1997\"\n\n\n\"antibacterials...\n\n\n\"'-oxacin(-oxac...\n\n\n\"1999\"\n\n\n\"S01AE06 | J01M...\n\n\n\"S01AE - Fluoro...\n\n\n\"S01A - ANTIINF...\n\n\n\"S01 - OPHTHALM...\n\n\n\"S - SENSORY OR...\n\n\n\"Antibacterial\"\n\n\n\"None\"\n\n\n\"1:Synthetic Sm...\n\n\n1\n\n\n0\n\n\n\"Racemic Mixtur...\n\n\n0\n\n\n1\n\n\n1\n\n\n1\n\n\n0\n\n\n\"Prescription O...\n\n\n\"COc1c(N2CCNC(C...\n\n\n\n\n\"CHEMBL3039597\"\n\n\n\"GENTAMICIN\"\n\n\n\"GENTAMICIN|GEN...\n\n\n\"SCH-9724\"\n\n\n4.0\n\n\n\"Schering Corp ...\n\n\n\"'-micin'\"\n\n\n\"1963\"\n\n\n\"antibiotics (M...\n\n\n\"'-micin(-micin...\n\n\n\"1970\"\n\n\n\"S01AA11 | S02A...\n\n\n\"S01AA - Antibi...\n\n\n\"S01A - ANTIINF...\n\n\n\"S01 - OPHTHALM...\n\n\n\"S - SENSORY OR...\n\n\n\"Antibacterial\"\n\n\n\"None\"\n\n\n\"1:Synthetic Sm...\n\n\n0\n\n\n0\n\n\n\"Unknown\"\n\n\n0\n\n\n0\n\n\n1\n\n\n1\n\n\n1\n\n\n\"Prescription O...\n\n\n\"CNC(C)[C@@H]1C...\n\n\n\n\n\"CHEMBL893\"\n\n\n\"DICLOXACILLIN\"\n\n\n\"BRL-1702|DICLO...\n\n\n\"BRL-1702|R-134...\n\n\n4.0\n\n\n\"Teva Pharmaceu...\n\n\n\"'-cillin'\"\n\n\n\"1965\"\n\n\n\"penicillins\"\n\n\n\"'-cillin(-cill...\n\n\n\"1968\"\n\n\n\"J01CF01\"\n\n\n\"J01CF - Beta-l...\n\n\n\"J01C - BETA-LA...\n\n\n\"J01 - ANTIBACT...\n\n\n\"J - ANTIINFECT...\n\n\n\"Antibacterial\"\n\n\n\"None\"\n\n\n\"1:Synthetic Sm...\n\n\n1\n\n\n0\n\n\n\"Single Stereoi...\n\n\n0\n\n\n1\n\n\n0\n\n\n0\n\n\n0\n\n\n\"Prescription O...\n\n\n\"Cc1onc(-c2c(Cl...\n\n\n\n\n\n\n\nIn preparation for possible future work on building machine learning models on this line of work, I looked into Datamol’s function on pre-processing molecules (shown in the next section), as it involved converting SMILES strings into SELFIES, which were considered to be more robust than SMILES.\nHowever, I kept running into an error, with the error message showing the SMILES column was empty. After a few tries I realised that I’ve actually forgotten to check whether there were any missing SMILES in the column. So here I’ve filtered the SMILES column to look for any missing SMILES\n\ndf_ai_rx.filter(pl.col(\"Smiles\") == \"\")\n\n\n\n\nshape: (1, 29)\n\n\n\n\nParent Molecule\n\n\nName\n\n\nSynonyms\n\n\nResearch Codes\n\n\nPhase\n\n\nDrug Applicants\n\n\nUSAN Stem\n\n\nUSAN Year\n\n\nUSAN Definition\n\n\nUSAN Stem - Substem\n\n\nFirst Approval\n\n\nATC Codes\n\n\nLevel 4 ATC Codes\n\n\nLevel 3 ATC Codes\n\n\nLevel 2 ATC Codes\n\n\nLevel 1 ATC Codes\n\n\nIndication Class\n\n\nPatent\n\n\nDrug Type\n\n\nPasses Rule of Five\n\n\nFirst In Class\n\n\nChirality\n\n\nProdrug\n\n\nOral\n\n\nParenteral\n\n\nTopical\n\n\nBlack Box\n\n\nAvailability Type\n\n\nSmiles\n\n\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nf64\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\ni64\n\n\ni64\n\n\nstr\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\nstr\n\n\nstr\n\n\n\n\n\n\n\"CHEMBL3989751\"\n\n\n\"NEOMYCIN\"\n\n\n\"FRADIOMYCIN|KA...\n\n\n\"\"\n\n\n4.0\n\n\n\"Bayer Pharmace...\n\n\n\"'-mycin'\"\n\n\n\"1966\"\n\n\n\"antibiotics (S...\n\n\n\"'-mycin(-mycin...\n\n\n\"1957\"\n\n\n\"R02AB01 | S01A...\n\n\n\"R02AB - Antibi...\n\n\n\"R02A - THROAT ...\n\n\n\"R02 - THROAT P...\n\n\n\"R - RESPIRATOR...\n\n\n\"\"\n\n\n\"None\"\n\n\n\"1:Synthetic Sm...\n\n\n0\n\n\n0\n\n\n\"Single Stereoi...\n\n\n0\n\n\n1\n\n\n0\n\n\n1\n\n\n1\n\n\n\"Prescription O...\n\n\n\"\"\n\n\n\n\n\n\n\nNeomycin was the only compound found to have no SMILES recorded. To fix this error, I then used the “when-then-otherwise” expression in Polars again (used in previous post) to replace the empty string in the dataframe. A code example below was kindly adapted from StackOverflow from this link, and code example as shown below.\n```{python}\nonly_these = ['str1', 'str2']\ndf.with_columns([\n    pl.when(pl.col(only_these).str.lengths() == 0)\n    .then(None)\n    .otherwise(pl.col(only_these))\n    .keep_name()\n])\n```\nThis was what I’ve done to amend the issue.\n\n# Canonical SMILES for neomycin was extracted from PubChem \n# (https://pubchem.ncbi.nlm.nih.gov/compound/Neomycin)\n\ndf_ai_rx = df_ai_rx.with_columns([\n    pl.when(pl.col(\"Smiles\").str.lengths() == 0)\n    .then(\"C1C(C(C(C(C1N)OC2C(C(C(C(O2)CN)O)O)N)OC3C(C(C(O3)CO)OC4C(C(C(C(O4)CN)O)O)N)O)O)N\")\n    .otherwise(pl.col(\"Smiles\"))\n    .keep_name()\n])\n\ndf_ai_rx\n\n\n\n\nshape: (72, 29)\n\n\n\n\nParent Molecule\n\n\nName\n\n\nSynonyms\n\n\nResearch Codes\n\n\nPhase\n\n\nDrug Applicants\n\n\nUSAN Stem\n\n\nUSAN Year\n\n\nUSAN Definition\n\n\nUSAN Stem - Substem\n\n\nFirst Approval\n\n\nATC Codes\n\n\nLevel 4 ATC Codes\n\n\nLevel 3 ATC Codes\n\n\nLevel 2 ATC Codes\n\n\nLevel 1 ATC Codes\n\n\nIndication Class\n\n\nPatent\n\n\nDrug Type\n\n\nPasses Rule of Five\n\n\nFirst In Class\n\n\nChirality\n\n\nProdrug\n\n\nOral\n\n\nParenteral\n\n\nTopical\n\n\nBlack Box\n\n\nAvailability Type\n\n\nSmiles\n\n\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nf64\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\ni64\n\n\ni64\n\n\nstr\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\ni64\n\n\nstr\n\n\nstr\n\n\n\n\n\n\n\"CHEMBL186\"\n\n\n\"CEFEPIME\"\n\n\n\"BMY-28142|CEFE...\n\n\n\"BMY-28142|J01D...\n\n\n4.0\n\n\n\"Samson Medical...\n\n\n\"'cef-'\"\n\n\n\"1987\"\n\n\n\"cephalosporins...\n\n\n\"'cef-(cef-)'\"\n\n\n\"1996\"\n\n\n\"J01DE01\"\n\n\n\"J01DE - Fourth...\n\n\n\"J01D - OTHER B...\n\n\n\"J01 - ANTIBACT...\n\n\n\"J - ANTIINFECT...\n\n\n\"Antibacterial\"\n\n\n\"None\"\n\n\n\"1:Synthetic Sm...\n\n\n1\n\n\n0\n\n\n\"Single Stereoi...\n\n\n0\n\n\n0\n\n\n1\n\n\n0\n\n\n0\n\n\n\"Prescription O...\n\n\n\"CO/N=C(\\C(=O)N...\n\n\n\n\n\"CHEMBL2364632\"\n\n\n\"SARECYCLINE\"\n\n\n\"P-005672|P0056...\n\n\n\"P-005672|P0056...\n\n\n4.0\n\n\n\"Almirall Llc\"\n\n\n\"'-cycline'\"\n\n\n\"2012\"\n\n\n\"antibiotics (t...\n\n\n\"'-cycline(-cyc...\n\n\n\"2018\"\n\n\n\"J01AA14\"\n\n\n\"J01AA - Tetrac...\n\n\n\"J01A - TETRACY...\n\n\n\"J01 - ANTIBACT...\n\n\n\"J - ANTIINFECT...\n\n\n\"\"\n\n\n\"US-8318706-B2\"\n\n\n\"1:Synthetic Sm...\n\n\n1\n\n\n0\n\n\n\"Single Stereoi...\n\n\n0\n\n\n1\n\n\n0\n\n\n0\n\n\n0\n\n\n\"Prescription O...\n\n\n\"CON(C)Cc1ccc(O...\n\n\n\n\n\"CHEMBL31\"\n\n\n\"GATIFLOXACIN\"\n\n\n\"AM-1155|BMS-20...\n\n\n\"AM-1155|BMS-20...\n\n\n4.0\n\n\n\"Apotex Inc|Bri...\n\n\n\"'-oxacin'\"\n\n\n\"1997\"\n\n\n\"antibacterials...\n\n\n\"'-oxacin(-oxac...\n\n\n\"1999\"\n\n\n\"S01AE06 | J01M...\n\n\n\"S01AE - Fluoro...\n\n\n\"S01A - ANTIINF...\n\n\n\"S01 - OPHTHALM...\n\n\n\"S - SENSORY OR...\n\n\n\"Antibacterial\"\n\n\n\"None\"\n\n\n\"1:Synthetic Sm...\n\n\n1\n\n\n0\n\n\n\"Racemic Mixtur...\n\n\n0\n\n\n1\n\n\n1\n\n\n1\n\n\n0\n\n\n\"Prescription O...\n\n\n\"COc1c(N2CCNC(C...\n\n\n\n\n\"CHEMBL3039597\"\n\n\n\"GENTAMICIN\"\n\n\n\"GENTAMICIN|GEN...\n\n\n\"SCH-9724\"\n\n\n4.0\n\n\n\"Schering Corp ...\n\n\n\"'-micin'\"\n\n\n\"1963\"\n\n\n\"antibiotics (M...\n\n\n\"'-micin(-micin...\n\n\n\"1970\"\n\n\n\"S01AA11 | S02A...\n\n\n\"S01AA - Antibi...\n\n\n\"S01A - ANTIINF...\n\n\n\"S01 - OPHTHALM...\n\n\n\"S - SENSORY OR...\n\n\n\"Antibacterial\"\n\n\n\"None\"\n\n\n\"1:Synthetic Sm...\n\n\n0\n\n\n0\n\n\n\"Unknown\"\n\n\n0\n\n\n0\n\n\n1\n\n\n1\n\n\n1\n\n\n\"Prescription O...\n\n\n\"CNC(C)[C@@H]1C...\n\n\n\n\n\"CHEMBL893\"\n\n\n\"DICLOXACILLIN\"\n\n\n\"BRL-1702|DICLO...\n\n\n\"BRL-1702|R-134...\n\n\n4.0\n\n\n\"Teva Pharmaceu...\n\n\n\"'-cillin'\"\n\n\n\"1965\"\n\n\n\"penicillins\"\n\n\n\"'-cillin(-cill...\n\n\n\"1968\"\n\n\n\"J01CF01\"\n\n\n\"J01CF - Beta-l...\n\n\n\"J01C - BETA-LA...\n\n\n\"J01 - ANTIBACT...\n\n\n\"J - ANTIINFECT...\n\n\n\"Antibacterial\"\n\n\n\"None\"\n\n\n\"1:Synthetic Sm...\n\n\n1\n\n\n0\n\n\n\"Single Stereoi...\n\n\n0\n\n\n1\n\n\n0\n\n\n0\n\n\n0\n\n\n\"Prescription O...\n\n\n\"Cc1onc(-c2c(Cl...\n\n\n\n\n\"CHEMBL1449\"\n\n\n\"TICARCILLIN\"\n\n\n\"TICARCILLIN|Ti...\n\n\n\"\"\n\n\n4.0\n\n\n\"Glaxosmithklin...\n\n\n\"'-cillin'\"\n\n\n\"1973\"\n\n\n\"penicillins\"\n\n\n\"'-cillin(-cill...\n\n\n\"1976\"\n\n\n\"J01CA13\"\n\n\n\"J01CA - Penici...\n\n\n\"J01C - BETA-LA...\n\n\n\"J01 - ANTIBACT...\n\n\n\"J - ANTIINFECT...\n\n\n\"Antibacterial\"\n\n\n\"None\"\n\n\n\"1:Synthetic Sm...\n\n\n1\n\n\n0\n\n\n\"Single Stereoi...\n\n\n0\n\n\n0\n\n\n1\n\n\n0\n\n\n0\n\n\n\"Prescription O...\n\n\n\"CC1(C)S[C@@H]2...\n\n\n\n\n\"CHEMBL1220\"\n\n\n\"TINIDAZOLE\"\n\n\n\"CP-12,574|CP-1...\n\n\n\"CP-12,574|CP-1...\n\n\n4.0\n\n\n\"Mission Pharma...\n\n\n\"'-nidazole'\"\n\n\n\"1970\"\n\n\n\"antiprotozoal ...\n\n\n\"'-nidazole(-ni...\n\n\n\"2004\"\n\n\n\"P01AB02 | J01X...\n\n\n\"P01AB - Nitroi...\n\n\n\"P01A - AGENTS ...\n\n\n\"P01 - ANTIPROT...\n\n\n\"P - ANTIPARASI...\n\n\n\"Antiprotozoal\"\n\n\n\"None\"\n\n\n\"1:Synthetic Sm...\n\n\n1\n\n\n0\n\n\n\"Achiral Molecu...\n\n\n1\n\n\n1\n\n\n0\n\n\n0\n\n\n1\n\n\n\"Prescription O...\n\n\n\"CCS(=O)(=O)CCn...\n\n\n\n\n\"CHEMBL501122\"\n\n\n\"CEFTAROLINE FO...\n\n\n\"CEFTAROLINE FO...\n\n\n\"PPI-0903|TAK 5...\n\n\n4.0\n\n\n\"Apotex Inc|All...\n\n\n\"'cef-; fos-'\"\n\n\n\"2006\"\n\n\n\"cephalosporins...\n\n\n\"'cef-(cef-); f...\n\n\n\"2010\"\n\n\n\"J01DI02\"\n\n\n\"J01DI - Other ...\n\n\n\"J01D - OTHER B...\n\n\n\"J01 - ANTIBACT...\n\n\n\"J - ANTIINFECT...\n\n\n\"\"\n\n\n\"US-6417175-B1\"\n\n\n\"1:Synthetic Sm...\n\n\n0\n\n\n0\n\n\n\"Single Stereoi...\n\n\n1\n\n\n0\n\n\n1\n\n\n0\n\n\n0\n\n\n\"Prescription O...\n\n\n\"CCO/N=C(\\C(=O)...\n\n\n\n\n\"CHEMBL137\"\n\n\n\"METRONIDAZOLE\"\n\n\n\"ACEA|ANABACT|B...\n\n\n\"BAY-5360|BAYER...\n\n\n4.0\n\n\n\"Inforlife Sa|L...\n\n\n\"'-nidazole'\"\n\n\n\"1962\"\n\n\n\"antiprotozoal ...\n\n\n\"'-nidazole(-ni...\n\n\n\"1963\"\n\n\n\"D06BX01 | P01A...\n\n\n\"D06BX - Other ...\n\n\n\"D06B - CHEMOTH...\n\n\n\"D06 - ANTIBIOT...\n\n\n\"D - DERMATOLOG...\n\n\n\"Antibacterial,...\n\n\n\"US-6881726-B2\"\n\n\n\"1:Synthetic Sm...\n\n\n1\n\n\n0\n\n\n\"Achiral Molecu...\n\n\n0\n\n\n1\n\n\n1\n\n\n1\n\n\n1\n\n\n\"Prescription O...\n\n\n\"Cc1ncc([N+](=O...\n\n\n\n\n\"CHEMBL376140\"\n\n\n\"TIGECYCLINE\"\n\n\n\"TIGECYCLINE|Ty...\n\n\n\"WAY-GAR-936\"\n\n\n4.0\n\n\n\"Apotex Inc|Fre...\n\n\n\"'-cycline'\"\n\n\n\"2002\"\n\n\n\"antibiotics (t...\n\n\n\"'-cycline(-cyc...\n\n\n\"2005\"\n\n\n\"J01AA12\"\n\n\n\"J01AA - Tetrac...\n\n\n\"J01A - TETRACY...\n\n\n\"J01 - ANTIBACT...\n\n\n\"J - ANTIINFECT...\n\n\n\"\"\n\n\n\"US-7879828-B2\"\n\n\n\"1:Synthetic Sm...\n\n\n0\n\n\n0\n\n\n\"Single Stereoi...\n\n\n0\n\n\n0\n\n\n1\n\n\n0\n\n\n1\n\n\n\"Prescription O...\n\n\n\"CN(C)c1cc(NC(=...\n\n\n\n\n\"CHEMBL1741\"\n\n\n\"CLARITHROMYCIN...\n\n\n\"6-O-METHYLERYT...\n\n\n\"A-56268|ABBOTT...\n\n\n4.0\n\n\n\"Sunshine Lake ...\n\n\n\"'-mycin'\"\n\n\n\"1988\"\n\n\n\"antibiotics (S...\n\n\n\"'-mycin(-mycin...\n\n\n\"1991\"\n\n\n\"J01FA09\"\n\n\n\"J01FA - Macrol...\n\n\n\"J01F - MACROLI...\n\n\n\"J01 - ANTIBACT...\n\n\n\"J - ANTIINFECT...\n\n\n\"Antibacterial\"\n\n\n\"US-7977488-B2\"\n\n\n\"1:Synthetic Sm...\n\n\n0\n\n\n0\n\n\n\"Single Stereoi...\n\n\n0\n\n\n1\n\n\n0\n\n\n0\n\n\n0\n\n\n\"Prescription O...\n\n\n\"CC[C@H]1OC(=O)...\n\n\n\n\n\"CHEMBL1747\"\n\n\n\"TOBRAMYCIN\"\n\n\n\"47663|Aktob|BE...\n\n\n\"47663|NSC-1805...\n\n\n4.0\n\n\n\"Igi Laboratori...\n\n\n\"'-mycin'\"\n\n\n\"1972\"\n\n\n\"antibiotics (S...\n\n\n\"'-mycin(-mycin...\n\n\n\"1975\"\n\n\n\"J01GB01 | S01A...\n\n\n\"J01GB - Other ...\n\n\n\"J01G - AMINOGL...\n\n\n\"J01 - ANTIBACT...\n\n\n\"J - ANTIINFECT...\n\n\n\"Antibacterial\"\n\n\n\"US-6987094-B2\"\n\n\n\"1:Synthetic Sm...\n\n\n0\n\n\n0\n\n\n\"Single Stereoi...\n\n\n0\n\n\n0\n\n\n1\n\n\n1\n\n\n1\n\n\n\"Prescription O...\n\n\n\"NC[C@H]1O[C@H]...\n\n\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n\n\n\"CHEMBL404\"\n\n\n\"TAZOBACTAM\"\n\n\n\"CL 298,741|CL-...\n\n\n\"CL 298,741|CL-...\n\n\n4.0\n\n\n\"Wytells Pharma...\n\n\n\"'-bactam'\"\n\n\n\"1989\"\n\n\n\"beta-lactamase...\n\n\n\"'-bactam(-bact...\n\n\n\"1993\"\n\n\n\"J01CG02\"\n\n\n\"J01CG - Beta-l...\n\n\n\"J01C - BETA-LA...\n\n\n\"J01 - ANTIBACT...\n\n\n\"J - ANTIINFECT...\n\n\n\"Inhibitor (bet...\n\n\n\"US-6900184-B2\"\n\n\n\"1:Synthetic Sm...\n\n\n1\n\n\n0\n\n\n\"Single Stereoi...\n\n\n0\n\n\n0\n\n\n1\n\n\n0\n\n\n0\n\n\n\"Prescription O...\n\n\n\"C[C@]1(Cn2ccnn...\n\n\n\n\n\"CHEMBL1689772\"\n\n\n\"OMADACYCLINE\"\n\n\n\"AMADACYCLINE|B...\n\n\n\"BAY 73-6944|PT...\n\n\n4.0\n\n\n\"Paratek Pharma...\n\n\n\"'-cycline'\"\n\n\n\"2009\"\n\n\n\"antibiotics (t...\n\n\n\"'-cycline(-cyc...\n\n\n\"2018\"\n\n\n\"J01AA15\"\n\n\n\"J01AA - Tetrac...\n\n\n\"J01A - TETRACY...\n\n\n\"J01 - ANTIBACT...\n\n\n\"J - ANTIINFECT...\n\n\n\"\"\n\n\n\"US-7326696-B2\"\n\n\n\"1:Synthetic Sm...\n\n\n0\n\n\n0\n\n\n\"Single Stereoi...\n\n\n0\n\n\n1\n\n\n1\n\n\n0\n\n\n0\n\n\n\"Prescription O...\n\n\n\"CN(C)c1cc(CNCC...\n\n\n\n\n\"CHEMBL3989974\"\n\n\n\"CEFIDEROCOL\"\n\n\n\"CEFIDEROCOL|GS...\n\n\n\"GSK2696266|S-6...\n\n\n4.0\n\n\n\"Shionogi Inc\"\n\n\n\"'cef-'\"\n\n\n\"2017\"\n\n\n\"cephalosporins...\n\n\n\"'cef-(cef-)'\"\n\n\n\"2019\"\n\n\n\"J01DI04\"\n\n\n\"J01DI - Other ...\n\n\n\"J01D - OTHER B...\n\n\n\"J01 - ANTIBACT...\n\n\n\"J - ANTIINFECT...\n\n\n\"\"\n\n\n\"US-9238657-B2\"\n\n\n\"1:Synthetic Sm...\n\n\n0\n\n\n0\n\n\n\"Single Stereoi...\n\n\n0\n\n\n0\n\n\n1\n\n\n0\n\n\n0\n\n\n\"Prescription O...\n\n\n\"CC(C)(O/N=C(\\C...\n\n\n\n\n\"CHEMBL1435\"\n\n\n\"CEFAZOLIN\"\n\n\n\"CEFAZOLIN|CEPH...\n\n\n\"J01DB04|SK&F-4...\n\n\n4.0\n\n\n\"Glaxosmithklin...\n\n\n\"'cef-'\"\n\n\n\"1972\"\n\n\n\"cephalosporins...\n\n\n\"'cef-(cef-)'\"\n\n\n\"1973\"\n\n\n\"J01DB04\"\n\n\n\"J01DB - First-...\n\n\n\"J01D - OTHER B...\n\n\n\"J01 - ANTIBACT...\n\n\n\"J - ANTIINFECT...\n\n\n\"Antibacterial ...\n\n\n\"None\"\n\n\n\"1:Synthetic Sm...\n\n\n0\n\n\n0\n\n\n\"Single Stereoi...\n\n\n0\n\n\n0\n\n\n1\n\n\n0\n\n\n0\n\n\n\"Prescription O...\n\n\n\"Cc1nnc(SCC2=C(...\n\n\n\n\n\"CHEMBL3989751\"\n\n\n\"NEOMYCIN\"\n\n\n\"FRADIOMYCIN|KA...\n\n\n\"\"\n\n\n4.0\n\n\n\"Bayer Pharmace...\n\n\n\"'-mycin'\"\n\n\n\"1966\"\n\n\n\"antibiotics (S...\n\n\n\"'-mycin(-mycin...\n\n\n\"1957\"\n\n\n\"R02AB01 | S01A...\n\n\n\"R02AB - Antibi...\n\n\n\"R02A - THROAT ...\n\n\n\"R02 - THROAT P...\n\n\n\"R - RESPIRATOR...\n\n\n\"\"\n\n\n\"None\"\n\n\n\"1:Synthetic Sm...\n\n\n0\n\n\n0\n\n\n\"Single Stereoi...\n\n\n0\n\n\n1\n\n\n0\n\n\n1\n\n\n1\n\n\n\"Prescription O...\n\n\n\"C1C(C(C(C(C1N)...\n\n\n\n\n\"CHEMBL572\"\n\n\n\"NITROFURANTOIN...\n\n\n\"BERKFURIN|CEDU...\n\n\n\"NSC-2107|NSC-4...\n\n\n4.0\n\n\n\"Sun Pharmaceut...\n\n\n\"'-toin'\"\n\n\n\"\"\n\n\n\"antiepileptics...\n\n\n\"'-toin(-toin)'...\n\n\n\"1953\"\n\n\n\"J01XE01 | J01X...\n\n\n\"J01XE - Nitrof...\n\n\n\"J01X - OTHER A...\n\n\n\"J01 - ANTIBACT...\n\n\n\"J - ANTIINFECT...\n\n\n\"Antibacterial ...\n\n\n\"None\"\n\n\n\"1:Synthetic Sm...\n\n\n1\n\n\n0\n\n\n\"Achiral Molecu...\n\n\n0\n\n\n1\n\n\n1\n\n\n0\n\n\n0\n\n\n\"Prescription O...\n\n\n\"O=C1CN(/N=C/c2...\n\n\n\n\n\"CHEMBL44354\"\n\n\n\"CEFTAZIDIME\"\n\n\n\"CEFTAZIDIME|CE...\n\n\n\"GR 20263|GR-20...\n\n\n4.0\n\n\n\"Glaxosmithklin...\n\n\n\"'cef-'\"\n\n\n\"1980\"\n\n\n\"cephalosporins...\n\n\n\"'cef-(cef-)'\"\n\n\n\"1985\"\n\n\n\"J01DD02\"\n\n\n\"J01DD - Third-...\n\n\n\"J01D - OTHER B...\n\n\n\"J01 - ANTIBACT...\n\n\n\"J - ANTIINFECT...\n\n\n\"Antibacterial\"\n\n\n\"US-7112592-B2\"\n\n\n\"1:Synthetic Sm...\n\n\n0\n\n\n0\n\n\n\"Single Stereoi...\n\n\n0\n\n\n0\n\n\n1\n\n\n0\n\n\n1\n\n\n\"Prescription O...\n\n\n\"CC(C)(O/N=C(\\C...\n\n\n\n\n\"CHEMBL29\"\n\n\n\"BENZYLPENICILL...\n\n\n\"BENZYL PENICIL...\n\n\n\"J01CE01|NSC-19...\n\n\n4.0\n\n\n\"Hq Specialty P...\n\n\n\"'-cillin'\"\n\n\n\"\"\n\n\n\"penicillins\"\n\n\n\"'-cillin(-cill...\n\n\n\"1947\"\n\n\n\"J01CE01 | S01A...\n\n\n\"J01CE - Beta-l...\n\n\n\"J01C - BETA-LA...\n\n\n\"J01 - ANTIBACT...\n\n\n\"J - ANTIINFECT...\n\n\n\"Antibacterial\"\n\n\n\"None\"\n\n\n\"1:Synthetic Sm...\n\n\n1\n\n\n0\n\n\n\"Single Stereoi...\n\n\n0\n\n\n1\n\n\n1\n\n\n0\n\n\n1\n\n\n\"Prescription O...\n\n\n\"CC1(C)S[C@@H]2...\n\n\n\n\n\"CHEMBL8\"\n\n\n\"CIPROFLOXACIN\"\n\n\n\"BAY O 9867 FRE...\n\n\n\"BAY O 9867 FRE...\n\n\n4.0\n\n\n\"Inforlife Sa|A...\n\n\n\"'-oxacin'\"\n\n\n\"1987\"\n\n\n\"antibacterials...\n\n\n\"'-oxacin(-oxac...\n\n\n\"1987\"\n\n\n\"J01MA02 | S03A...\n\n\n\"J01MA - Fluoro...\n\n\n\"J01M - QUINOLO...\n\n\n\"J01 - ANTIBACT...\n\n\n\"J - ANTIINFECT...\n\n\n\"Antibacterial\"\n\n\n\"US-8318817-B2\"\n\n\n\"1:Synthetic Sm...\n\n\n1\n\n\n0\n\n\n\"Achiral Molecu...\n\n\n0\n\n\n1\n\n\n1\n\n\n1\n\n\n1\n\n\n\"Prescription O...\n\n\n\"O=C(O)c1cn(C2C...\n\n\n\n\n\"CHEMBL9\"\n\n\n\"NORFLOXACIN\"\n\n\n\"Baccidal|CHIBR...\n\n\n\"MK-366|NSC-757...\n\n\n4.0\n\n\n\"Merck Research...\n\n\n\"'-oxacin'\"\n\n\n\"1984\"\n\n\n\"antibacterials...\n\n\n\"'-oxacin(-oxac...\n\n\n\"1986\"\n\n\n\"J01MA06 | S01A...\n\n\n\"J01MA - Fluoro...\n\n\n\"J01M - QUINOLO...\n\n\n\"J01 - ANTIBACT...\n\n\n\"J - ANTIINFECT...\n\n\n\"Antibacterial\"\n\n\n\"None\"\n\n\n\"1:Synthetic Sm...\n\n\n1\n\n\n0\n\n\n\"Achiral Molecu...\n\n\n0\n\n\n1\n\n\n0\n\n\n1\n\n\n1\n\n\n\"Prescription O...\n\n\n\"CCn1cc(C(=O)O)...\n\n\n\n\n\"CHEMBL21\"\n\n\n\"SULFANILAMIDE\"\n\n\n\"ANILINE-P-SULF...\n\n\n\"NSC-7618\"\n\n\n4.0\n\n\n\"Mylan Specialt...\n\n\n\"'sulfa-'\"\n\n\n\"\"\n\n\n\"antimicrobials...\n\n\n\"'sulfa-(sulfa-...\n\n\n\"1985\"\n\n\n\"D06BA05 | J01E...\n\n\n\"D06BA - Sulfon...\n\n\n\"D06B - CHEMOTH...\n\n\n\"D06 - ANTIBIOT...\n\n\n\"D - DERMATOLOG...\n\n\n\"\"\n\n\n\"None\"\n\n\n\"1:Synthetic Sm...\n\n\n1\n\n\n0\n\n\n\"Achiral Molecu...\n\n\n0\n\n\n0\n\n\n0\n\n\n1\n\n\n0\n\n\n\"Prescription O...\n\n\n\"Nc1ccc(S(N)(=O...\n\n\n\n\n\"CHEMBL4\"\n\n\n\"OFLOXACIN\"\n\n\n\"DL-8280|EXOCIN...\n\n\n\"DL-8280|HOE 28...\n\n\n4.0\n\n\n\"Bausch And Lom...\n\n\n\"'-oxacin'\"\n\n\n\"1984\"\n\n\n\"antibacterials...\n\n\n\"'-oxacin(-oxac...\n\n\n\"1990\"\n\n\n\"J01MA01 | S02A...\n\n\n\"J01MA - Fluoro...\n\n\n\"J01M - QUINOLO...\n\n\n\"J01 - ANTIBACT...\n\n\n\"J - ANTIINFECT...\n\n\n\"Antibacterial\"\n\n\n\"None\"\n\n\n\"1:Synthetic Sm...\n\n\n1\n\n\n0\n\n\n\"Racemic Mixtur...\n\n\n0\n\n\n1\n\n\n1\n\n\n1\n\n\n1\n\n\n\"Prescription O...\n\n\n\"CC1COc2c(N3CCN...\n\n\n\n\n\n\n\n\n# Keeping only selected columns with information needed for later use\ndf_ai_rx = df_ai_rx.select([\"Smiles\", \"Name\", \"USAN Definition\", \"Level 4 ATC Codes\"])\ndf_ai_rx.head()\n\n\n\n\nshape: (5, 4)\n\n\n\n\nSmiles\n\n\nName\n\n\nUSAN Definition\n\n\nLevel 4 ATC Codes\n\n\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\n\n\n\n\n\"CO/N=C(\\C(=O)N...\n\n\n\"CEFEPIME\"\n\n\n\"cephalosporins...\n\n\n\"J01DE - Fourth...\n\n\n\n\n\"CON(C)Cc1ccc(O...\n\n\n\"SARECYCLINE\"\n\n\n\"antibiotics (t...\n\n\n\"J01AA - Tetrac...\n\n\n\n\n\"COc1c(N2CCNC(C...\n\n\n\"GATIFLOXACIN\"\n\n\n\"antibacterials...\n\n\n\"S01AE - Fluoro...\n\n\n\n\n\"CNC(C)[C@@H]1C...\n\n\n\"GENTAMICIN\"\n\n\n\"antibiotics (M...\n\n\n\"S01AA - Antibi...\n\n\n\n\n\"Cc1onc(-c2c(Cl...\n\n\n\"DICLOXACILLIN\"\n\n\n\"penicillins\"\n\n\n\"J01CF - Beta-l...\n\n\n\n\n\n\n\nThe “Smiles” column name was changed below to ensure _preprocess function would work since the parameter “smiles_column” in _preprocess function had “smiles” with lowercase “s” (this of course could be the other way round, where we could change the parameter name in the function instead - the column name and parameter name had to match for the function to work). The “Name” column was changed accordingly for similar reason.\n\ndf_ai_rx = df_ai_rx.rename({\"Smiles\": \"smiles\", \"Name\": \"names\"})\ndf_ai_rx.head()\n\n\n\n\nshape: (5, 4)\n\n\n\n\nsmiles\n\n\nnames\n\n\nUSAN Definition\n\n\nLevel 4 ATC Codes\n\n\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\n\n\n\n\n\"CO/N=C(\\C(=O)N...\n\n\n\"CEFEPIME\"\n\n\n\"cephalosporins...\n\n\n\"J01DE - Fourth...\n\n\n\n\n\"CON(C)Cc1ccc(O...\n\n\n\"SARECYCLINE\"\n\n\n\"antibiotics (t...\n\n\n\"J01AA - Tetrac...\n\n\n\n\n\"COc1c(N2CCNC(C...\n\n\n\"GATIFLOXACIN\"\n\n\n\"antibacterials...\n\n\n\"S01AE - Fluoro...\n\n\n\n\n\"CNC(C)[C@@H]1C...\n\n\n\"GENTAMICIN\"\n\n\n\"antibiotics (M...\n\n\n\"S01AA - Antibi...\n\n\n\n\n\"Cc1onc(-c2c(Cl...\n\n\n\"DICLOXACILLIN\"\n\n\n\"penicillins\"\n\n\n\"J01CF - Beta-l...\n\n\n\n\n\n\n\nI also wanted to change the all capitalised compound names into lowercases for the ease of reading.\n\n# Convert all compounds to lowercases\ndf_ai_rx = df_ai_rx.with_columns(pl.col(\"names\").str.to_lowercase())\ndf_ai_rx.head()\n\n\n\n\nshape: (5, 4)\n\n\n\n\nsmiles\n\n\nnames\n\n\nUSAN Definition\n\n\nLevel 4 ATC Codes\n\n\n\n\nstr\n\n\nstr\n\n\nstr\n\n\nstr\n\n\n\n\n\n\n\"CO/N=C(\\C(=O)N...\n\n\n\"cefepime\"\n\n\n\"cephalosporins...\n\n\n\"J01DE - Fourth...\n\n\n\n\n\"CON(C)Cc1ccc(O...\n\n\n\"sarecycline\"\n\n\n\"antibiotics (t...\n\n\n\"J01AA - Tetrac...\n\n\n\n\n\"COc1c(N2CCNC(C...\n\n\n\"gatifloxacin\"\n\n\n\"antibacterials...\n\n\n\"S01AE - Fluoro...\n\n\n\n\n\"CNC(C)[C@@H]1C...\n\n\n\"gentamicin\"\n\n\n\"antibiotics (M...\n\n\n\"S01AA - Antibi...\n\n\n\n\n\"Cc1onc(-c2c(Cl...\n\n\n\"dicloxacillin\"\n\n\n\"penicillins\"\n\n\n\"J01CF - Beta-l...\n\n\n\n\n\n\n\nSince Datamol was built as a thin layer library on top of RDKit, which was really only compatible with Pandas, I added the following step to convert the dataframe into a Pandas one.\n\ndf_ai_pd = df_ai_rx.to_pandas()\ndf_ai_pd.head()\n\n\n\n\n\n  \n    \n      \n      smiles\n      names\n      USAN Definition\n      Level 4 ATC Codes\n    \n  \n  \n    \n      0\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[N...\n      cefepime\n      cephalosporins\n      J01DE - Fourth-generation cephalosporins\n    \n    \n      1\n      CON(C)Cc1ccc(O)c2c1C[C@H]1C[C@H]3[C@H](N(C)C)C...\n      sarecycline\n      antibiotics (tetracycline derivatives)\n      J01AA - Tetracyclines\n    \n    \n      2\n      COc1c(N2CCNC(C)C2)c(F)cc2c(=O)c(C(=O)O)cn(C3CC...\n      gatifloxacin\n      antibacterials (quinolone derivatives)\n      S01AE - Fluoroquinolones | J01MA - Fluoroquino...\n    \n    \n      3\n      CNC(C)[C@@H]1CC[C@@H](N)[C@@H](O[C@H]2[C@H](O)...\n      gentamicin\n      antibiotics (Micromonospora strains)\n      S01AA - Antibiotics | S02AA - Antiinfectives |...\n    \n    \n      4\n      Cc1onc(-c2c(Cl)cccc2Cl)c1C(=O)N[C@@H]1C(=O)N2[...\n      dicloxacillin\n      penicillins\n      J01CF - Beta-lactamase resistant penicillins\n    \n  \n\n\n\n\n\n# Check the dataframe has been converted from Polars to Pandas\ntype(df_ai_pd)\n\npandas.core.frame.DataFrame\n\n\n\n\n\nPre-processing and standardising molecules\nI have borrowed and adapted the _preprocess function from Datamol (link here), as shown below. One of the convenient features in this function was that it also included a conversion from “mol” (RDKit molecule) to SELFIES amongst several other common molecular representations such as InChI3 and SMILES.\n\n# Pre-process molecules using _preprocess function - adapted from datamol.io\n\nsmiles_column = \"smiles\"\n\ndm.disable_rdkit_log()\n\ndef _preprocess(row):\n    mol = dm.to_mol(row[smiles_column], ordered=True)\n    mol = dm.fix_mol(mol)\n    mol = dm.sanitize_mol(mol, sanifix=True, charge_neutral=False)\n    mol = dm.standardize_mol(\n        mol,\n        disconnect_metals=False,\n        normalize=True,\n        reionize=True,\n        uncharge=False,\n        stereo=True,\n    )\n\n    row[\"standard_smiles\"] = dm.standardize_smiles(dm.to_smiles(mol))\n    row[\"selfies\"] = dm.to_selfies(mol)\n    row[\"inchi\"] = dm.to_inchi(mol)\n    row[\"inchikey\"] = dm.to_inchikey(mol)\n    return row\n\n\n\n\nConverting multiple SMILES into multiple SELFIES\nThere were two ways to convert multiple SMILES into multiple SELFIES (there might be more options, but I’ve found these two for now):\n\n# Method one - using lambda function:\n# Uncomment code below to run\n# df_ai_pd[\"selfies\"] = df_ai_pd[\"Smiles\"].apply(lambda x: dm.to_selfies(x))\n# df_ai_pd\n\n# Method two - using _preprocess function:\ndata_mol_clean = df_ai_pd.apply(_preprocess, axis = 1)\ndata_mol_clean\n\n\n\n\n\n  \n    \n      \n      smiles\n      names\n      USAN Definition\n      Level 4 ATC Codes\n      standard_smiles\n      selfies\n      inchi\n      inchikey\n    \n  \n  \n    \n      0\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[N...\n      cefepime\n      cephalosporins\n      J01DE - Fourth-generation cephalosporins\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[N...\n      [C][O][/N][=C][Branch2][Ring2][#Branch2][\\C][=...\n      InChI=1S/C19H24N6O5S2/c1-25(5-3-4-6-25)7-10-8-...\n      HVFLCNVBZFFHBT-ZKDACBOMSA-N\n    \n    \n      1\n      CON(C)Cc1ccc(O)c2c1C[C@H]1C[C@H]3[C@H](N(C)C)C...\n      sarecycline\n      antibiotics (tetracycline derivatives)\n      J01AA - Tetracyclines\n      CON(C)Cc1ccc(O)c2c1C[C@H]1C[C@H]3[C@H](N(C)C)C...\n      [C][O][N][Branch1][C][C][C][C][=C][C][=C][Bran...\n      InChI=1S/C24H29N3O8/c1-26(2)18-13-8-11-7-12-10...\n      PQJQFLNBMSCUSH-SBAJWEJLSA-N\n    \n    \n      2\n      COc1c(N2CCNC(C)C2)c(F)cc2c(=O)c(C(=O)O)cn(C3CC...\n      gatifloxacin\n      antibacterials (quinolone derivatives)\n      S01AE - Fluoroquinolones | J01MA - Fluoroquino...\n      COc1c(N2CCNC(C)C2)c(F)cc2c(=O)c(C(=O)O)cn(C3CC...\n      [C][O][C][=C][Branch1][N][N][C][C][N][C][Branc...\n      InChI=1S/C19H22FN3O4/c1-10-8-22(6-5-21-10)16-1...\n      XUBOMFCQGDBHNK-UHFFFAOYSA-N\n    \n    \n      3\n      CNC(C)[C@@H]1CC[C@@H](N)[C@@H](O[C@H]2[C@H](O)...\n      gentamicin\n      antibiotics (Micromonospora strains)\n      S01AA - Antibiotics | S02AA - Antiinfectives |...\n      CNC(C)[C@@H]1CC[C@@H](N)[C@@H](O[C@H]2[C@H](O)...\n      [C][N][C][Branch1][C][C][C@@H1][C][C][C@@H1][B...\n      InChI=1S/C21H43N5O7.C20H41N5O7.C19H39N5O7/c1-9...\n      NPEFREDMMVQEPL-RWPARATISA-N\n    \n    \n      4\n      Cc1onc(-c2c(Cl)cccc2Cl)c1C(=O)N[C@@H]1C(=O)N2[...\n      dicloxacillin\n      penicillins\n      J01CF - Beta-lactamase resistant penicillins\n      Cc1onc(-c2c(Cl)cccc2Cl)c1C(=O)N[C@@H]1C(=O)N2[...\n      [C][C][O][N][=C][Branch1][=N][C][=C][Branch1][...\n      InChI=1S/C19H17Cl2N3O5S/c1-7-10(12(23-29-7)11-...\n      YFAGHNZHGGCZAX-JKIFEVAISA-N\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      67\n      CC1(C)S[C@@H]2[C@H](NC(=O)Cc3ccccc3)C(=O)N2[C@...\n      benzylpenicillin\n      penicillins\n      J01CE - Beta-lactamase sensitive penicillins |...\n      CC1(C)S[C@@H]2[C@H](NC(=O)Cc3ccccc3)C(=O)N2[C@...\n      [C][C][Branch1][C][C][S][C@@H1][C@H1][Branch1]...\n      InChI=1S/C16H18N2O4S/c1-16(2)12(15(21)22)18-13...\n      JGSARLDLIJGVTE-MBNYWOFBSA-N\n    \n    \n      68\n      O=C(O)c1cn(C2CC2)c2cc(N3CCNCC3)c(F)cc2c1=O\n      ciprofloxacin\n      antibacterials (quinolone derivatives)\n      J01MA - Fluoroquinolones | S03AA - Antiinfecti...\n      O=C(O)c1cn(C2CC2)c2cc(N3CCNCC3)c(F)cc2c1=O\n      [O][=C][Branch1][C][O][C][=C][N][Branch1][=Bra...\n      InChI=1S/C17H18FN3O3/c18-13-7-11-14(8-15(13)20...\n      MYSWGUAQZAJSOK-UHFFFAOYSA-N\n    \n    \n      69\n      CCn1cc(C(=O)O)c(=O)c2cc(F)c(N3CCNCC3)cc21\n      norfloxacin\n      antibacterials (quinolone derivatives)\n      J01MA - Fluoroquinolones | S01AE - Fluoroquino...\n      CCn1cc(C(=O)O)c(=O)c2cc(F)c(N3CCNCC3)cc21\n      [C][C][N][C][=C][Branch1][=Branch1][C][=Branch...\n      InChI=1S/C16H18FN3O3/c1-2-19-9-11(16(22)23)15(...\n      OGJPXUAPXNRGGI-UHFFFAOYSA-N\n    \n    \n      70\n      Nc1ccc(S(N)(=O)=O)cc1\n      sulfanilamide\n      antimicrobials (sulfonamides derivatives)\n      D06BA - Sulfonamides | J01EB - Short-acting su...\n      Nc1ccc(S(N)(=O)=O)cc1\n      [N][C][=C][C][=C][Branch1][=Branch2][S][Branch...\n      InChI=1S/C6H8N2O2S/c7-5-1-3-6(4-2-5)11(8,9)10/...\n      FDDDEECHVMSUSB-UHFFFAOYSA-N\n    \n    \n      71\n      CC1COc2c(N3CCN(C)CC3)c(F)cc3c(=O)c(C(=O)O)cn1c23\n      ofloxacin\n      antibacterials (quinolone derivatives)\n      J01MA - Fluoroquinolones | S02AA - Antiinfecti...\n      CC1COc2c(N3CCN(C)CC3)c(F)cc3c(=O)c(C(=O)O)cn1c23\n      [C][C][C][O][C][=C][Branch1][N][N][C][C][N][Br...\n      InChI=1S/C18H20FN3O4/c1-10-9-26-17-14-11(16(23...\n      GSDSWSVVBLHKDQ-UHFFFAOYSA-N\n    \n  \n\n72 rows × 8 columns\n\n\n\n\n\nConverting a single SMILES into a SELFIES\nTo convert only one SMILES string into a SELFIES, the following code example should work with Datamol.\n```{python}\nselfies = dm.to_selfies(\"O=C(N[C@H](CO)[C@H](O)c1ccc([N+](=O)[O-])cc1)C(Cl)Cl\")\nselfies\n```\n\n\n\nVisualise compounds in 2D using Datamol\nThe images generated below might be quite small to see or read clearly. I’ve tried to increase the molecule size (mol_size) and also reduce the column numbers, but it still appeared the same. However, if the code was run in say VS Code, the compound images would appear larger when increasing the mol_size.\n\n# Grab all SMILES of the cleaned/pre-processed ChEMBL anti-infectives\ndf_ai_sm = data_mol_clean[\"standard_smiles\"]\n\n# Load a list of these molecules in SMILES\n# dm.to_mol() has sanitize = True set as default\nmol_ls = [dm.to_mol(smile) for smile in df_ai_sm]\n\n# Alternative way to convert dataframe into a list of mols (same as mol_ls)\n# mols = dm.from_df(df_name, smiles_column = \"Smiles\")\n\n# Add compound name for each 2D image\nlegends_c = list(data_mol_clean[\"names\"])\n\n# Convert the list of molecules into 2D images\ndm.to_image(mol_ls, n_cols = 4, mol_size = (400, 400), legends = legends_c)\n\n\n\n\n\n\n\nExtract scaffolds\n\n# Extract Murcko scaffolds from mol_ls (ChEMBL anti-infectives)\nm_scaffolds = [dm.to_scaffold_murcko(mol) for mol in mol_ls]\ndm.to_image(m_scaffolds, mol_size = (400, 400), legends = legends_c)\n\n\n\n\n\n\n\n\nFilamenting temperature-sensitive mutant Z (FtsZ) compounds\n\nData cleaning\nThis section focuses on 3 compounds from this paper: Lin, H.-Y.J.; Battaje, R.R.; Tan, J.; Doddareddy, M.; Dhaked, H.P.S.; Srivastava, S.; Hawkins, B.A.; Al-Shdifat, L.M.H.; Hibbs, D.E.; Panda, D.; et al. Discovery of 2’,6-Bis(4-hydroxybenzyl)-2-acetylcyclohexanone, a Novel FtsZ Inhibitor. Molecules 2022, 27, 6993. Obviously from the authorship shown, this was from my PhD work and out of interests, I just wanted to look a bit further into them and compare with known anti-infectives.\nBefore I started cleaning any data on FtsZ compounds, I found this useful website, OPSIN: Open Parser for Systematic IUPAC nomenclature, with this link to the journal paper as an acknowledgement of the work. I’ve managed to convert these 3 FtsZ compounds by using their IUPAC names, which were inputted into OPSIN, and converted into the corresponding InChI or SMILES strings.\nAfter that, I started by converting the InChI of compound 1 into a RDKit molecule, which could be visualised in 2D below.\n\n# Convert compound 1 to mol from InChI\ncpd1 = dm.from_inchi(\"InChI=1S/C22H20O4/c23-18-9-4-15(5-10-18)8-13-21(25)20-3-1-2-17(22(20)26)14-16-6-11-19(24)12-7-16/h4-14,20,23-24H,1-3H2/b13-8+,17-14+\")\ncpd1\n\n\n\n\nI then converted compound 2 using SMILES string instead.\n\n# Convert compound 2 SMILES to mol\ncpd2 = dm.to_mol(\"OC1=C(C=CC=C1CC1=CC=C(C=C1)O)C(CCC1=CC=C(C=C1)O)=O\")\ncpd2\n\n\n\n\nSame thing followed for compound 3.\n\n# Convert compound 3 SMILES to mol\ncpd3 = dm.to_mol(\"OC1=CC=C(CC2C(C(CCC2)C(CCC2=CC=C(C=C2)O)=O)=O)C=C1\")\ncpd3\n\n\n\n\n\n# Save these 3 compounds into a list\nmol_lst = [cpd1, cpd2, cpd3]\nmol_lst\n\n[<rdkit.Chem.rdchem.Mol at 0x13426b7d0>,\n <rdkit.Chem.rdchem.Mol at 0x13426a500>,\n <rdkit.Chem.rdchem.Mol at 0x13426ba70>]\n\n\n\n# Convert a list of mols into a dataframe\ndf = dm.to_df(mol_lst)\ndf\n\n\n\n\n\n  \n    \n      \n      smiles\n    \n  \n  \n    \n      0\n      O=C(/C=C/c1ccc(O)cc1)C1CCC/C(=C\\c2ccc(O)cc2)C1=O\n    \n    \n      1\n      O=C(CCc1ccc(O)cc1)c1cccc(Cc2ccc(O)cc2)c1O\n    \n    \n      2\n      O=C(CCc1ccc(O)cc1)C1CCCC(Cc2ccc(O)cc2)C1=O\n    \n  \n\n\n\n\nThen the compound numbers were added into the dataframe as well.\n\nnames = [\"Compound_1\", \"Compound_2\", \"Compound_3\"]\ndf[\"names\"] = names\ndf\n\n\n\n\n\n  \n    \n      \n      smiles\n      names\n    \n  \n  \n    \n      0\n      O=C(/C=C/c1ccc(O)cc1)C1CCC/C(=C\\c2ccc(O)cc2)C1=O\n      Compound_1\n    \n    \n      1\n      O=C(CCc1ccc(O)cc1)c1cccc(Cc2ccc(O)cc2)c1O\n      Compound_2\n    \n    \n      2\n      O=C(CCc1ccc(O)cc1)C1CCCC(Cc2ccc(O)cc2)C1=O\n      Compound_3\n    \n  \n\n\n\n\n\n\n\nPre-processing and standardising molecules\n\n# Pre-processing FtsZ compounds\ndata_cleaned = df.apply(_preprocess, axis=1)\ndata_cleaned\n\n\n\n\n\n  \n    \n      \n      smiles\n      names\n      standard_smiles\n      selfies\n      inchi\n      inchikey\n    \n  \n  \n    \n      0\n      O=C(/C=C/c1ccc(O)cc1)C1CCC/C(=C\\c2ccc(O)cc2)C1=O\n      Compound_1\n      O=C(/C=C/c1ccc(O)cc1)C1CCC/C(=C\\c2ccc(O)cc2)C1=O\n      [O][=C][Branch1][=C][/C][=C][/C][=C][C][=C][Br...\n      InChI=1S/C22H20O4/c23-18-9-4-15(5-10-18)8-13-2...\n      QNBFRAOWJNMPAF-ZIQQYUHESA-N\n    \n    \n      1\n      O=C(CCc1ccc(O)cc1)c1cccc(Cc2ccc(O)cc2)c1O\n      Compound_2\n      O=C(CCc1ccc(O)cc1)c1cccc(Cc2ccc(O)cc2)c1O\n      [O][=C][Branch1][=C][C][C][C][=C][C][=C][Branc...\n      InChI=1S/C22H20O4/c23-18-9-4-15(5-10-18)8-13-2...\n      CWVXMBYGWRWONE-UHFFFAOYSA-N\n    \n    \n      2\n      O=C(CCc1ccc(O)cc1)C1CCCC(Cc2ccc(O)cc2)C1=O\n      Compound_3\n      O=C(CCc1ccc(O)cc1)C1CCCC(Cc2ccc(O)cc2)C1=O\n      [O][=C][Branch1][=C][C][C][C][=C][C][=C][Branc...\n      InChI=1S/C22H24O4/c23-18-9-4-15(5-10-18)8-13-2...\n      KWPXNGBFYRHREW-UHFFFAOYSA-N\n    \n  \n\n\n\n\n\n\n\nVisualise compounds in 2D using Datamol\n\n# Grab all SMILES from cleaned FtsZ compound dataset\ndf_ai_ftsz = data_cleaned[\"standard_smiles\"]\n\n# Load a list of these molecules in SMILES\nmol_ftsz_list = [dm.to_mol(smile) for smile in df_ai_ftsz]\n\n# Add compound names for each 2D image of compounds\nlegends = list(data_cleaned[\"names\"])\n\n# Convert the list of molecules into 2D images\ndm.to_image(mol_ftsz_list, n_cols = 5, mol_size = (400, 400), legends = legends)\n\n\n\n\n\n\n\nExtract scaffolds\n\n# Get Murcko scaffolds of FtsZ compounds\nm_ftsz_scaffolds = [dm.to_scaffold_murcko(mol) for mol in mol_ftsz_list]\ndm.to_image(m_ftsz_scaffolds, mol_size = (400, 400), legends = legends)\n\n\n\n\n\n\n\n\nCombining ChEMBL anti-infectives and FtsZ compounds\n\nCombining dataframes\nIn this part, I wanted to combine the two dataframes I had from above, since my next step was to compare the scaffolds between ChEMBL prescription-only anti-infectives and FtsZ compounds.\n\ncombined_lists = [data_mol_clean, data_cleaned]\nfull_data = pd.concat(combined_lists, ignore_index = True)\nfull_data.head()\n\n\n\n\n\n  \n    \n      \n      smiles\n      names\n      USAN Definition\n      Level 4 ATC Codes\n      standard_smiles\n      selfies\n      inchi\n      inchikey\n    \n  \n  \n    \n      0\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[N...\n      cefepime\n      cephalosporins\n      J01DE - Fourth-generation cephalosporins\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[N...\n      [C][O][/N][=C][Branch2][Ring2][#Branch2][\\C][=...\n      InChI=1S/C19H24N6O5S2/c1-25(5-3-4-6-25)7-10-8-...\n      HVFLCNVBZFFHBT-ZKDACBOMSA-N\n    \n    \n      1\n      CON(C)Cc1ccc(O)c2c1C[C@H]1C[C@H]3[C@H](N(C)C)C...\n      sarecycline\n      antibiotics (tetracycline derivatives)\n      J01AA - Tetracyclines\n      CON(C)Cc1ccc(O)c2c1C[C@H]1C[C@H]3[C@H](N(C)C)C...\n      [C][O][N][Branch1][C][C][C][C][=C][C][=C][Bran...\n      InChI=1S/C24H29N3O8/c1-26(2)18-13-8-11-7-12-10...\n      PQJQFLNBMSCUSH-SBAJWEJLSA-N\n    \n    \n      2\n      COc1c(N2CCNC(C)C2)c(F)cc2c(=O)c(C(=O)O)cn(C3CC...\n      gatifloxacin\n      antibacterials (quinolone derivatives)\n      S01AE - Fluoroquinolones | J01MA - Fluoroquino...\n      COc1c(N2CCNC(C)C2)c(F)cc2c(=O)c(C(=O)O)cn(C3CC...\n      [C][O][C][=C][Branch1][N][N][C][C][N][C][Branc...\n      InChI=1S/C19H22FN3O4/c1-10-8-22(6-5-21-10)16-1...\n      XUBOMFCQGDBHNK-UHFFFAOYSA-N\n    \n    \n      3\n      CNC(C)[C@@H]1CC[C@@H](N)[C@@H](O[C@H]2[C@H](O)...\n      gentamicin\n      antibiotics (Micromonospora strains)\n      S01AA - Antibiotics | S02AA - Antiinfectives |...\n      CNC(C)[C@@H]1CC[C@@H](N)[C@@H](O[C@H]2[C@H](O)...\n      [C][N][C][Branch1][C][C][C@@H1][C][C][C@@H1][B...\n      InChI=1S/C21H43N5O7.C20H41N5O7.C19H39N5O7/c1-9...\n      NPEFREDMMVQEPL-RWPARATISA-N\n    \n    \n      4\n      Cc1onc(-c2c(Cl)cccc2Cl)c1C(=O)N[C@@H]1C(=O)N2[...\n      dicloxacillin\n      penicillins\n      J01CF - Beta-lactamase resistant penicillins\n      Cc1onc(-c2c(Cl)cccc2Cl)c1C(=O)N[C@@H]1C(=O)N2[...\n      [C][C][O][N][=C][Branch1][=N][C][=C][Branch1][...\n      InChI=1S/C19H17Cl2N3O5S/c1-7-10(12(23-29-7)11-...\n      YFAGHNZHGGCZAX-JKIFEVAISA-N\n    \n  \n\n\n\n\n\n# Specifying only the standard SMILES column\ndf_full = full_data[\"standard_smiles\"]\ndf_full\n\n0     CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[N...\n1     CON(C)Cc1ccc(O)c2c1C[C@H]1C[C@H]3[C@H](N(C)C)C...\n2     COc1c(N2CCNC(C)C2)c(F)cc2c(=O)c(C(=O)O)cn(C3CC...\n3     CNC(C)[C@@H]1CC[C@@H](N)[C@@H](O[C@H]2[C@H](O)...\n4     Cc1onc(-c2c(Cl)cccc2Cl)c1C(=O)N[C@@H]1C(=O)N2[...\n                            ...                        \n70                                Nc1ccc(S(N)(=O)=O)cc1\n71     CC1COc2c(N3CCN(C)CC3)c(F)cc3c(=O)c(C(=O)O)cn1c23\n72     O=C(/C=C/c1ccc(O)cc1)C1CCC/C(=C\\c2ccc(O)cc2)C1=O\n73            O=C(CCc1ccc(O)cc1)c1cccc(Cc2ccc(O)cc2)c1O\n74           O=C(CCc1ccc(O)cc1)C1CCCC(Cc2ccc(O)cc2)C1=O\nName: standard_smiles, Length: 75, dtype: object\n\n\n\n# Convert the standard SMILES into RDKit molecules\nmol_full = [dm.to_mol(smile) for smile in df_full]\n\n\n\n\nAligning all the scaffolds\nHere, all the scaffolds from both dataframes of compounds were aligned by using Datamol’s auto_align_many(). The images of all the aligned molecules were generated in the end. The compound structures did re-align, but unfortunately it only showed up to a maximum of 50 compounds only (the maximum number of molecules to be shown in Datamol was set to 32 as default; this number was pushed up to and truncated at 50 in the warning message from RDKit when attempting to run a total of 75 compounds using the Datamol library, without looking further into other ways to alter this for now).\n\naligned_list = dm.align.auto_align_many(mol_full, partition_method = \"anon-scaffold\")\ndm.to_image(aligned_list, mol_size = (400, 400), max_mols = 50)\n\n\n\n\nAn attempt to combine Datamol’s auto_align_many() with mols2grid library was shown below. Unfortunately, the compounds did not re-align but all 75 compounds were shown in the grids.\n\nmols2grid.display(aligned_list)\n\n\n\n\n\n\n\n\n\n\nmols2grid library\nSince I’ve started using mols2grid here, I thought to show an example of this library by combining all 75 compounds using the pre-processed standard SMILES in the grids with corresponding compound names. The resulting table provided a clear overview of all the compounds, with useful options to select or filter compounds. Obviously, other molecular properties or experimental results could be added into the table for other uses.\n\n# Full dataset of 75 compounds \nmols2grid.display(full_data, smiles_col = \"standard_smiles\", subset = [\"img\", \"mols2grid-id\", \"names\"])\n\n\n\n\n\n\n\n\n\n\n\nscaffold_finder library\nRather than only trying out Datamol only, I also thought to try out the scaffold_finder library after reading this Jupyter notebook by Patrick Walters. The GitHub repository of his other useful cheminformatics tutorials can be found here. His blog is here. Without surprises, this post was also inspired by this Jupyter notebook on “Identifying scaffolds in a set of molecules”, with some hope to expand on it a bit more.\nBelow were my notes on how to use this particular library.\nStep 1: Add “mol” column to full_data dataframe (this was needed in order to use the functions from scaffold_finder library, which was also built based on RDKit)\n\nfull_data[\"mol\"] = full_data.standard_smiles.apply(Chem.MolFromSmiles)\n\nStep 2: Change column names of “standard_smiles” to “SMILES” & “names” to “Name” to match with scaffold_finder library functions with set column names (or other way round, by changing the names in the function library)\n\n# Note: New column name \"SMILES\" contains standardised SMILES (old column name as \"standard_smiles\")\nfull_data = full_data.rename(columns = {\"standard_smiles\": \"SMILES\", \"names\": \"Name\"})\nfull_data.head()\n\n\n\n\n\n  \n    \n      \n      smiles\n      Name\n      USAN Definition\n      Level 4 ATC Codes\n      SMILES\n      selfies\n      inchi\n      inchikey\n      mol\n    \n  \n  \n    \n      0\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[N...\n      cefepime\n      cephalosporins\n      J01DE - Fourth-generation cephalosporins\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[N...\n      [C][O][/N][=C][Branch2][Ring2][#Branch2][\\C][=...\n      InChI=1S/C19H24N6O5S2/c1-25(5-3-4-6-25)7-10-8-...\n      HVFLCNVBZFFHBT-ZKDACBOMSA-N\n      <rdkit.Chem.rdchem.Mol object at 0x134307680>\n    \n    \n      1\n      CON(C)Cc1ccc(O)c2c1C[C@H]1C[C@H]3[C@H](N(C)C)C...\n      sarecycline\n      antibiotics (tetracycline derivatives)\n      J01AA - Tetracyclines\n      CON(C)Cc1ccc(O)c2c1C[C@H]1C[C@H]3[C@H](N(C)C)C...\n      [C][O][N][Branch1][C][C][C][C][=C][C][=C][Bran...\n      InChI=1S/C24H29N3O8/c1-26(2)18-13-8-11-7-12-10...\n      PQJQFLNBMSCUSH-SBAJWEJLSA-N\n      <rdkit.Chem.rdchem.Mol object at 0x134306c00>\n    \n    \n      2\n      COc1c(N2CCNC(C)C2)c(F)cc2c(=O)c(C(=O)O)cn(C3CC...\n      gatifloxacin\n      antibacterials (quinolone derivatives)\n      S01AE - Fluoroquinolones | J01MA - Fluoroquino...\n      COc1c(N2CCNC(C)C2)c(F)cc2c(=O)c(C(=O)O)cn(C3CC...\n      [C][O][C][=C][Branch1][N][N][C][C][N][C][Branc...\n      InChI=1S/C19H22FN3O4/c1-10-8-22(6-5-21-10)16-1...\n      XUBOMFCQGDBHNK-UHFFFAOYSA-N\n      <rdkit.Chem.rdchem.Mol object at 0x133e729d0>\n    \n    \n      3\n      CNC(C)[C@@H]1CC[C@@H](N)[C@@H](O[C@H]2[C@H](O)...\n      gentamicin\n      antibiotics (Micromonospora strains)\n      S01AA - Antibiotics | S02AA - Antiinfectives |...\n      CNC(C)[C@@H]1CC[C@@H](N)[C@@H](O[C@H]2[C@H](O)...\n      [C][N][C][Branch1][C][C][C@@H1][C][C][C@@H1][B...\n      InChI=1S/C21H43N5O7.C20H41N5O7.C19H39N5O7/c1-9...\n      NPEFREDMMVQEPL-RWPARATISA-N\n      <rdkit.Chem.rdchem.Mol object at 0x133e72500>\n    \n    \n      4\n      Cc1onc(-c2c(Cl)cccc2Cl)c1C(=O)N[C@@H]1C(=O)N2[...\n      dicloxacillin\n      penicillins\n      J01CF - Beta-lactamase resistant penicillins\n      Cc1onc(-c2c(Cl)cccc2Cl)c1C(=O)N[C@@H]1C(=O)N2[...\n      [C][C][O][N][=C][Branch1][=N][C][=C][Branch1][...\n      InChI=1S/C19H17Cl2N3O5S/c1-7-10(12(23-29-7)11-...\n      YFAGHNZHGGCZAX-JKIFEVAISA-N\n      <rdkit.Chem.rdchem.Mol object at 0x133e719a0>\n    \n  \n\n\n\n\nStep 3: Identify scaffolds\nThe find_scaffolds() function was kindly borrowed from the scaffold_finder library as mentioned above. The scaffold_finder_test.py was the modified version, as I’ve used a different dataset here.\n\nmol_df, scaffold_df = find_scaffolds(full_data)\n\n\n\n\nBelow was a quick overview of the mol_df, showing scaffolds in SMILES, number of atoms, number of R groups, names of compounds and the standardised SMILES of the compounds.\n\nmol_df\n\n\n\n\n\n  \n    \n      \n      Scaffold\n      NumAtoms\n      NumRgroupgs\n      Name\n      SMILES\n    \n  \n  \n    \n      0\n      C[N+]1(CC2=C(C(=O)[O-])N3C(=O)[C@@H](NC(=O)/C(...\n      31\n      1\n      cefepime\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[N...\n    \n    \n      1\n      C[N+]1(CC2=CN3C(=O)[C@@H](NC(=O)C(=NO)c4csc(N)...\n      28\n      2\n      cefepime\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[N...\n    \n    \n      2\n      Nc1nc(C(=NO)C(=O)N[C@@H]2C(=O)N3C=CCS[C@H]23)cs1\n      21\n      3\n      cefepime\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[N...\n    \n    \n      3\n      CC1=CN2C(=O)[C@@H](NC(=O)C(=NO)c3csc(N)n3)[C@H...\n      22\n      3\n      cefepime\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[N...\n    \n    \n      4\n      Nc1nc(C(=NO)C(=O)N[C@@H]2C(=O)N3C=C(C[NH+]4CCC...\n      27\n      3\n      cefepime\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[N...\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      15\n      O=C(CCc1ccccc1)C1CCCC(Cc2ccccc2)C1=O\n      24\n      2\n      Compound_3\n      O=C(CCc1ccc(O)cc1)C1CCCC(Cc2ccc(O)cc2)C1=O\n    \n    \n      16\n      O=C1CCCCC1C(=O)CCc1ccc(O)cc1\n      18\n      1\n      Compound_3\n      O=C(CCc1ccc(O)cc1)C1CCCC(Cc2ccc(O)cc2)C1=O\n    \n    \n      19\n      CC1CCCC(C(=O)CCc2ccc(O)cc2)C1=O\n      19\n      1\n      Compound_3\n      O=C(CCc1ccc(O)cc1)C1CCCC(Cc2ccc(O)cc2)C1=O\n    \n    \n      21\n      O=C(CCc1ccc(O)cc1)C1CCCC(Cc2ccccc2)C1=O\n      25\n      1\n      Compound_3\n      O=C(CCc1ccc(O)cc1)C1CCCC(Cc2ccc(O)cc2)C1=O\n    \n    \n      22\n      O=C(CCc1ccc(O)cc1)C1CCCC(Cc2ccc(O)cc2)C1=O\n      26\n      1\n      Compound_3\n      O=C(CCc1ccc(O)cc1)C1CCCC(Cc2ccc(O)cc2)C1=O\n    \n  \n\n5320 rows × 5 columns\n\n\n\nAgain to have a quick look at the scaffolds of all 75 compounds, along with counts of each scaffold and number of atoms in each scaffold.\n\nscaffold_df\n\n\n\n\n\n  \n    \n      \n      Scaffold\n      Count\n      NumAtoms\n    \n  \n  \n    \n      1156\n      CN(C)[C@@H]1C(O)=C(C(N)=O)C(=O)[C@H]2C(O)=C3C(...\n      7\n      29\n    \n    \n      1101\n      CN(C)[C@@H]1C(O)=C(C(N)=O)C(=O)[C@@]2(O)C(O)=C...\n      6\n      30\n    \n    \n      173\n      CC(=O)N[C@@H]1C(=O)N2[C@@H]1SC(C)(C)[C@@H]2C(=O)O\n      5\n      17\n    \n    \n      174\n      CC(=O)N[C@@H]1C(=O)N2[C@@H]1SC(C)[C@@H]2C(=O)O\n      5\n      16\n    \n    \n      552\n      CC1(C)S[C@@H]2[C@H](NC=O)C(=O)N2[C@H]1C(=O)O\n      5\n      16\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      3684\n      Cc1nccn1C\n      1\n      7\n    \n    \n      4456\n      Nc1ccccc1\n      1\n      7\n    \n    \n      4775\n      O=P(O)(O)[C@@H]1CO1\n      1\n      7\n    \n    \n      3722\n      Cn1ccnc1\n      1\n      6\n    \n    \n      4807\n      c1ccccc1\n      1\n      6\n    \n  \n\n4808 rows × 3 columns\n\n\n\nStep 4: Display all scaffolds in mols2grid, which helped to identify the scaffold with the highest frequency (counts) of occurence in the dataset.\n\nmols2grid.display(scaffold_df, smiles_col = \"Scaffold\", subset = [\"img\", \"Count\"])\n\n\n\n\n\n\n\n\n\n\n\n\nTest datasets\nThese were my sample datasets for later use in the section on “Reading and querying multiple scaffolds in SMILES strings”.\nBelow was the first test dataset on the top 2 scaffolds with highest frequency of appearance in the full dataframe.\n\n# Scaffold of anti-infective with highest count\ncount_top1_scaffold = scaffold_df.Scaffold.values[0]\n# Scaffold of anti-infective with the second highest count\ncount_top2_scaffold = scaffold_df.Scaffold.values[1]\n\n\n# Combine above scaffolds into a list\ncount_top_scaffold = list((count_top1_scaffold, count_top2_scaffold))\ncount_top_scaffold\n\n['CN(C)[C@@H]1C(O)=C(C(N)=O)C(=O)[C@H]2C(O)=C3C(=O)c4c(O)cccc4C[C@H]3C[C@H]21',\n 'CN(C)[C@@H]1C(O)=C(C(N)=O)C(=O)[C@@]2(O)C(O)=C3C(=O)c4c(O)cccc4C[C@H]3C[C@@H]12']\n\n\nThen this was the second sample dataset, purely on the scaffolds for the antibiotic called, “cefepime”.\n\ncefe_scaffolds = pl.from_pandas(mol_df).filter(pl.col(\"Name\") == \"cefepime\")\ncefe_scaffolds.head()\n\n\n\n\nshape: (5, 5)\n\n\n\n\nScaffold\n\n\nNumAtoms\n\n\nNumRgroupgs\n\n\nName\n\n\nSMILES\n\n\n\n\nstr\n\n\ni64\n\n\ni64\n\n\nstr\n\n\nstr\n\n\n\n\n\n\n\"C[N+]1(CC2=C(C...\n\n\n31\n\n\n1\n\n\n\"cefepime\"\n\n\n\"CO/N=C(\\C(=O)N...\n\n\n\n\n\"C[N+]1(CC2=CN3...\n\n\n28\n\n\n2\n\n\n\"cefepime\"\n\n\n\"CO/N=C(\\C(=O)N...\n\n\n\n\n\"Nc1nc(C(=NO)C(...\n\n\n21\n\n\n3\n\n\n\"cefepime\"\n\n\n\"CO/N=C(\\C(=O)N...\n\n\n\n\n\"CC1=CN2C(=O)[C...\n\n\n22\n\n\n3\n\n\n\"cefepime\"\n\n\n\"CO/N=C(\\C(=O)N...\n\n\n\n\n\"Nc1nc(C(=NO)C(...\n\n\n27\n\n\n3\n\n\n\"cefepime\"\n\n\n\"CO/N=C(\\C(=O)N...\n\n\n\n\n\n\n\n\n\n\nFocus on FtsZ compound 3\nCompound 3 was the compound found in the paper to have targeted the FtsZ proteins in Gram positive pathogens such as Streptococcus pneumoniae with more pronounced activities than its predecessor e.g. compound 1. So this section aimed to look into all of compound 3’s scaffolds.\n\n# For ease of dataframe manipulation, decided to convert Pandas df into a Polars one (just my personal preference as I've used Polars more lately)\n# then filtered out all the scaffolds for compound 3 & saved it as an independent dataframe\ncpd3_scaffolds = pl.from_pandas(mol_df).filter(pl.col(\"Name\") == \"Compound_3\")\ncpd3_scaffolds\n\n\n\n\nshape: (14, 5)\n\n\n\n\nScaffold\n\n\nNumAtoms\n\n\nNumRgroupgs\n\n\nName\n\n\nSMILES\n\n\n\n\nstr\n\n\ni64\n\n\ni64\n\n\nstr\n\n\nstr\n\n\n\n\n\n\n\"O=CC1CCCC(Cc2c...\n\n\n17\n\n\n1\n\n\n\"Compound_3\"\n\n\n\"O=C(CCc1ccc(O)...\n\n\n\n\n\"O=CC1CCCC(Cc2c...\n\n\n16\n\n\n2\n\n\n\"Compound_3\"\n\n\n\"O=C(CCc1ccc(O)...\n\n\n\n\n\"CC(=O)C1CCCC(C...\n\n\n18\n\n\n1\n\n\n\"Compound_3\"\n\n\n\"O=C(CCc1ccc(O)...\n\n\n\n\n\"CC(=O)C1CCCC(C...\n\n\n17\n\n\n2\n\n\n\"Compound_3\"\n\n\n\"O=C(CCc1ccc(O)...\n\n\n\n\n\"CCC(=O)C1CCCC(...\n\n\n19\n\n\n1\n\n\n\"Compound_3\"\n\n\n\"O=C(CCc1ccc(O)...\n\n\n\n\n\"CCC(=O)C1CCCC(...\n\n\n18\n\n\n2\n\n\n\"Compound_3\"\n\n\n\"O=C(CCc1ccc(O)...\n\n\n\n\n\"O=C(CCc1ccccc1...\n\n\n25\n\n\n1\n\n\n\"Compound_3\"\n\n\n\"O=C(CCc1ccc(O)...\n\n\n\n\n\"O=C1CCCCC1C(=O...\n\n\n17\n\n\n2\n\n\n\"Compound_3\"\n\n\n\"O=C(CCc1ccc(O)...\n\n\n\n\n\"CC1CCCC(C(=O)C...\n\n\n18\n\n\n2\n\n\n\"Compound_3\"\n\n\n\"O=C(CCc1ccc(O)...\n\n\n\n\n\"O=C(CCc1ccccc1...\n\n\n24\n\n\n2\n\n\n\"Compound_3\"\n\n\n\"O=C(CCc1ccc(O)...\n\n\n\n\n\"O=C1CCCCC1C(=O...\n\n\n18\n\n\n1\n\n\n\"Compound_3\"\n\n\n\"O=C(CCc1ccc(O)...\n\n\n\n\n\"CC1CCCC(C(=O)C...\n\n\n19\n\n\n1\n\n\n\"Compound_3\"\n\n\n\"O=C(CCc1ccc(O)...\n\n\n\n\n\"O=C(CCc1ccc(O)...\n\n\n25\n\n\n1\n\n\n\"Compound_3\"\n\n\n\"O=C(CCc1ccc(O)...\n\n\n\n\n\"O=C(CCc1ccc(O)...\n\n\n26\n\n\n1\n\n\n\"Compound_3\"\n\n\n\"O=C(CCc1ccc(O)...\n\n\n\n\n\n\n\n\n# Convert Polars df into a Pandas one \n# and use mols2grid to show the 2D images of compound 3 scaffolds\n# Total of 14 different scaffolds\ncpd3_scaffolds = cpd3_scaffolds.to_pandas()\nmols2grid.display(cpd3_scaffolds, smiles_col = \"Scaffold\")\n\n\n\n\n\n\n\n\n\nTesting compound 3 scaffolds using scaffold_finder library\nAt this stage, I sort of had an idea of wanting to compare all 14 compound 3 scaffolds against all 75 molecules including ChEMBL-curated prescription-only anti-bacterials.\nI tried the get_molecules_with_scaffold() function from scaffold_finder library but didn’t exactly get what I hoped to achieve. I played around a bit and noticed it was really designed for spotting a single target scaffold with highest counts in the data set. I was hoping to parse multiple scaffolds actually, or imagining there might be situations where we might want to do this.\nI started trialling with one scaffold anyway as shown below on the get_molecule_with_scaffold() function from the scaffold_finder library.\n\n# Trial single scaffold first\nscaffold_test = cpd3_scaffolds.Scaffold.values[0]\nscaffold_test\n\n'O=CC1CCCC(Cc2ccc(O)cc2)C1=O'\n\n\n\ns_smiles_list, chem_mol_df = get_molecules_with_scaffold(scaffold_test, mol_df, full_data)\n\n\ns_smiles_list\n\narray(['O=C1C(Cc2ccc(O)cc2)CCCC1C(=O)[*:1]'], dtype=object)\n\n\n\n# Showing only compound 3 as a distinctive compound (no other molecules with similar scaffold)\nchem_mol_df\n\n\n\n\n\n  \n    \n      \n      SMILES\n      Name\n    \n  \n  \n    \n      0\n      O=C(CCc1ccc(O)cc1)C1CCCC(Cc2ccc(O)cc2)C1=O\n      Compound_3\n    \n  \n\n\n\n\n\n\n\n\nReading and querying multiple scaffolds in SMILES strings\nI also tried to tweak the get_molecule_with_scaffolds() function but realised it might be even better to write my own function to tailor to my need. Therefore, I wrote a small and simple function which would read and query multiple scaffolds of small molecules in SMILES string formats against a dataframe (with information showing scaffolds in SMILES, number of atoms, number of R groups, names of compounds and also the SMILES of the compounds).\nAt first, I started with reading all 14 scaffolds of compound 3 by using the values index method on cpd3_scaffolds dataframe that included all 14 scaffolds of compound 3.\n\n# Trial feeding all 14 SMILES\nscaffold_cpd3_all = cpd3_scaffolds.Scaffold.values[:]\nscaffold_cpd3_all\n\narray(['O=CC1CCCC(Cc2ccc(O)cc2)C1=O', 'O=CC1CCCC(Cc2ccccc2)C1=O',\n       'CC(=O)C1CCCC(Cc2ccc(O)cc2)C1=O', 'CC(=O)C1CCCC(Cc2ccccc2)C1=O',\n       'CCC(=O)C1CCCC(Cc2ccc(O)cc2)C1=O', 'CCC(=O)C1CCCC(Cc2ccccc2)C1=O',\n       'O=C(CCc1ccccc1)C1CCCC(Cc2ccc(O)cc2)C1=O',\n       'O=C1CCCCC1C(=O)CCc1ccccc1', 'CC1CCCC(C(=O)CCc2ccccc2)C1=O',\n       'O=C(CCc1ccccc1)C1CCCC(Cc2ccccc2)C1=O',\n       'O=C1CCCCC1C(=O)CCc1ccc(O)cc1', 'CC1CCCC(C(=O)CCc2ccc(O)cc2)C1=O',\n       'O=C(CCc1ccc(O)cc1)C1CCCC(Cc2ccccc2)C1=O',\n       'O=C(CCc1ccc(O)cc1)C1CCCC(Cc2ccc(O)cc2)C1=O'], dtype=object)\n\n\nThen I thought about how every time if we’d want to convert any molecules from SMILES to RDKit molecules, we really had to have a “mol” column set up, so that was what I did below.\n\ncpd3_scaffolds[\"mol\"] = cpd3_scaffolds.Scaffold.apply(Chem.MolFromSmiles)\n\nThe dataframe would look like this now.\n\ncpd3_scaffolds\n\n\n\n\n\n  \n    \n      \n      Scaffold\n      NumAtoms\n      NumRgroupgs\n      Name\n      SMILES\n      mol\n    \n  \n  \n    \n      0\n      O=CC1CCCC(Cc2ccc(O)cc2)C1=O\n      17\n      1\n      Compound_3\n      O=C(CCc1ccc(O)cc1)C1CCCC(Cc2ccc(O)cc2)C1=O\n      <rdkit.Chem.rdchem.Mol object at 0x13580d3f0>\n    \n    \n      1\n      O=CC1CCCC(Cc2ccccc2)C1=O\n      16\n      2\n      Compound_3\n      O=C(CCc1ccc(O)cc1)C1CCCC(Cc2ccc(O)cc2)C1=O\n      <rdkit.Chem.rdchem.Mol object at 0x13580d4d0>\n    \n    \n      2\n      CC(=O)C1CCCC(Cc2ccc(O)cc2)C1=O\n      18\n      1\n      Compound_3\n      O=C(CCc1ccc(O)cc1)C1CCCC(Cc2ccc(O)cc2)C1=O\n      <rdkit.Chem.rdchem.Mol object at 0x13580dd20>\n    \n    \n      3\n      CC(=O)C1CCCC(Cc2ccccc2)C1=O\n      17\n      2\n      Compound_3\n      O=C(CCc1ccc(O)cc1)C1CCCC(Cc2ccc(O)cc2)C1=O\n      <rdkit.Chem.rdchem.Mol object at 0x13580e880>\n    \n    \n      4\n      CCC(=O)C1CCCC(Cc2ccc(O)cc2)C1=O\n      19\n      1\n      Compound_3\n      O=C(CCc1ccc(O)cc1)C1CCCC(Cc2ccc(O)cc2)C1=O\n      <rdkit.Chem.rdchem.Mol object at 0x13580d930>\n    \n    \n      5\n      CCC(=O)C1CCCC(Cc2ccccc2)C1=O\n      18\n      2\n      Compound_3\n      O=C(CCc1ccc(O)cc1)C1CCCC(Cc2ccc(O)cc2)C1=O\n      <rdkit.Chem.rdchem.Mol object at 0x13580ea40>\n    \n    \n      6\n      O=C(CCc1ccccc1)C1CCCC(Cc2ccc(O)cc2)C1=O\n      25\n      1\n      Compound_3\n      O=C(CCc1ccc(O)cc1)C1CCCC(Cc2ccc(O)cc2)C1=O\n      <rdkit.Chem.rdchem.Mol object at 0x13580ca50>\n    \n    \n      7\n      O=C1CCCCC1C(=O)CCc1ccccc1\n      17\n      2\n      Compound_3\n      O=C(CCc1ccc(O)cc1)C1CCCC(Cc2ccc(O)cc2)C1=O\n      <rdkit.Chem.rdchem.Mol object at 0x13580fbc0>\n    \n    \n      8\n      CC1CCCC(C(=O)CCc2ccccc2)C1=O\n      18\n      2\n      Compound_3\n      O=C(CCc1ccc(O)cc1)C1CCCC(Cc2ccc(O)cc2)C1=O\n      <rdkit.Chem.rdchem.Mol object at 0x13580f4c0>\n    \n    \n      9\n      O=C(CCc1ccccc1)C1CCCC(Cc2ccccc2)C1=O\n      24\n      2\n      Compound_3\n      O=C(CCc1ccc(O)cc1)C1CCCC(Cc2ccc(O)cc2)C1=O\n      <rdkit.Chem.rdchem.Mol object at 0x13580f060>\n    \n    \n      10\n      O=C1CCCCC1C(=O)CCc1ccc(O)cc1\n      18\n      1\n      Compound_3\n      O=C(CCc1ccc(O)cc1)C1CCCC(Cc2ccc(O)cc2)C1=O\n      <rdkit.Chem.rdchem.Mol object at 0x13580c200>\n    \n    \n      11\n      CC1CCCC(C(=O)CCc2ccc(O)cc2)C1=O\n      19\n      1\n      Compound_3\n      O=C(CCc1ccc(O)cc1)C1CCCC(Cc2ccc(O)cc2)C1=O\n      <rdkit.Chem.rdchem.Mol object at 0x13580d770>\n    \n    \n      12\n      O=C(CCc1ccc(O)cc1)C1CCCC(Cc2ccccc2)C1=O\n      25\n      1\n      Compound_3\n      O=C(CCc1ccc(O)cc1)C1CCCC(Cc2ccc(O)cc2)C1=O\n      <rdkit.Chem.rdchem.Mol object at 0x13580de70>\n    \n    \n      13\n      O=C(CCc1ccc(O)cc1)C1CCCC(Cc2ccc(O)cc2)C1=O\n      26\n      1\n      Compound_3\n      O=C(CCc1ccc(O)cc1)C1CCCC(Cc2ccc(O)cc2)C1=O\n      <rdkit.Chem.rdchem.Mol object at 0x13580e2d0>\n    \n  \n\n\n\n\nThen perhaps I would place all of these compound 3 scaffolds into an object.\n\ncpd3_mols = cpd3_scaffolds[\"mol\"]\ncpd3_mols\n\n0     <rdkit.Chem.rdchem.Mol object at 0x13580d3f0>\n1     <rdkit.Chem.rdchem.Mol object at 0x13580d4d0>\n2     <rdkit.Chem.rdchem.Mol object at 0x13580dd20>\n3     <rdkit.Chem.rdchem.Mol object at 0x13580e880>\n4     <rdkit.Chem.rdchem.Mol object at 0x13580d930>\n5     <rdkit.Chem.rdchem.Mol object at 0x13580ea40>\n6     <rdkit.Chem.rdchem.Mol object at 0x13580ca50>\n7     <rdkit.Chem.rdchem.Mol object at 0x13580fbc0>\n8     <rdkit.Chem.rdchem.Mol object at 0x13580f4c0>\n9     <rdkit.Chem.rdchem.Mol object at 0x13580f060>\n10    <rdkit.Chem.rdchem.Mol object at 0x13580c200>\n11    <rdkit.Chem.rdchem.Mol object at 0x13580d770>\n12    <rdkit.Chem.rdchem.Mol object at 0x13580de70>\n13    <rdkit.Chem.rdchem.Mol object at 0x13580e2d0>\nName: mol, dtype: object\n\n\nAt this stage, nothing really clicked at the moment, but then I thought about how Datamol was built on top of RDKit and also how a few other cheminformatics posts I’ve read before utilised the functions in RDKit, so it was time to look deeper in RDKit to search for methods with the intended purpose in mind. I then found the SmilesWriter() method from RDKit after reading a few online references.\nI’ve found out that:\n\nTo write multiple SMILES into a .smi file, use SmilesWriter()\nTo read a set of SMILES from a .smi file, use SmilesMolSupplier()\n\nAcknowledgement of a useful link I’ve found online which had helped me to figure out how to save multiple SMILES strings in a .smi file.\n\n# Figured out how to save multiple SMILES as a text file \ncpd3 = SmilesWriter('cpd3.smi')\n\n# Note: saving multiple SMILES strings from RDKit mol objects (cpd3_mols)\nfor s in cpd3_mols:\n  cpd3.write(s)\ncpd3.close()\n\n\n\nFunction for saving multiple SMILES strings as a .smi file\nSo based on the ideas in the previous section, I came up with the following simple function to save multiple SMILES strings as a .smi file.\n\ndef save_smiles_strings(df, file_name):\n\n  # Create a RDKit mol column in the dataframe\n  df[\"mol\"] = df.Scaffold.apply(Chem.MolFromSmiles)\n\n  # Save the \"mol\" column with target scaffolds as an object\n  smiles_mols = df[\"mol\"]\n\n  # Use RDKit's SmilesWriter() to write the smiles strings from mol objects\n  # Specify file name for .smi file, which will be stored in the working directory\n  smiles = SmilesWriter(f\"{file_name}.smi\")\n  \n  # Use a for loop to iterate through each SMILES string in the dataframe\n  for s in smiles_mols:\n    smiles.write(s)\n  smiles.close()\n\n\n\nTesting on the function\nHere I used one of the dataframes I’ve saved earlier, cefe_scaffolds, to test this function on saving multiple SMILES into a file. Since cefe_scaffolds dataframe was a Polars dataframe from earlier, it needed to be converted into a Pandas dataframe in order to be compatible with RDKit, which was used in the function.\n\n# Convert Polars dataframe into a Pandas one\ncefe_scaffolds = cefe_scaffolds.to_pandas()\n\n# Running function on cefe_scaffolds dataframe\n# First parameter - dataframe to be used\n# Second parameter - file name for the SMILES strings saved\nsave_smiles_strings(cefe_scaffolds, \"cefe\")\n\nA .smi file with the name “cefe.smi” should appear in the working directory after running the function.\nNow, the next stage would be to parse these SMILES strings and save them as a list. I actually worked backwards here where I looked into the Pandas.query() method first, and looked into options I could have on reading and checking for matches in multiple strings. To be able to read multiple strings in one go, a list would be suitable to carry out the matching queries (note: in the scaffold_finder library, this dataframe query method was also used in its “find_scaffolds” and “get_molecules_with_scaffold” functions).\nAn example of Pandas.query() tests:\n\n# Using the test dataset from earlier - list of top two scaffolds with highest frequency of occurrences from ChEMBL dataset\ncount_top_scaffold\n\n['CN(C)[C@@H]1C(O)=C(C(N)=O)C(=O)[C@H]2C(O)=C3C(=O)c4c(O)cccc4C[C@H]3C[C@H]21',\n 'CN(C)[C@@H]1C(O)=C(C(N)=O)C(=O)[C@@]2(O)C(O)=C3C(=O)c4c(O)cccc4C[C@H]3C[C@@H]12']\n\n\n\n# To demonstrate that querying the two top scaffolds \n# will bring back all the anti-bacterials with the same scaffold\nmatch_df = mol_df.query(\"Scaffold in @count_top_scaffold\")\nmatch_df\n\n\n\n\n\n  \n    \n      \n      Scaffold\n      NumAtoms\n      NumRgroupgs\n      Name\n      SMILES\n    \n  \n  \n    \n      102\n      CN(C)[C@@H]1C(O)=C(C(N)=O)C(=O)[C@@]2(O)C(O)=C...\n      30\n      1\n      sarecycline\n      CON(C)Cc1ccc(O)c2c1C[C@H]1C[C@H]3[C@H](N(C)C)C...\n    \n    \n      128\n      CN(C)[C@@H]1C(O)=C(C(N)=O)C(=O)[C@H]2C(O)=C3C(...\n      29\n      2\n      sarecycline\n      CON(C)Cc1ccc(O)c2c1C[C@H]1C[C@H]3[C@H](N(C)C)C...\n    \n    \n      92\n      CN(C)[C@@H]1C(O)=C(C(N)=O)C(=O)[C@H]2C(O)=C3C(...\n      29\n      3\n      tigecycline\n      CN(C)c1cc(NC(=O)CNC(C)(C)C)c(O)c2c1C[C@H]1C[C@...\n    \n    \n      115\n      CN(C)[C@@H]1C(O)=C(C(N)=O)C(=O)[C@H]2C(O)=C3C(...\n      29\n      3\n      demeclocycline\n      CN(C)[C@@H]1C(O)=C(C(N)=O)C(=O)[C@@]2(O)C(O)=C...\n    \n    \n      129\n      CN(C)[C@@H]1C(O)=C(C(N)=O)C(=O)[C@@]2(O)C(O)=C...\n      30\n      2\n      demeclocycline\n      CN(C)[C@@H]1C(O)=C(C(N)=O)C(=O)[C@@]2(O)C(O)=C...\n    \n    \n      39\n      CN(C)[C@@H]1C(O)=C(C(N)=O)C(=O)[C@@]2(O)C(O)=C...\n      30\n      1\n      minocycline\n      CN(C)c1ccc(O)c2c1C[C@H]1C[C@H]3[C@H](N(C)C)C(O...\n    \n    \n      65\n      CN(C)[C@@H]1C(O)=C(C(N)=O)C(=O)[C@H]2C(O)=C3C(...\n      29\n      2\n      minocycline\n      CN(C)c1ccc(O)c2c1C[C@H]1C[C@H]3[C@H](N(C)C)C(O...\n    \n    \n      115\n      CN(C)[C@@H]1C(O)=C(C(N)=O)C(=O)[C@H]2C(O)=C3C(...\n      29\n      3\n      tetracycline\n      CN(C)[C@@H]1C(O)=C(C(N)=O)C(=O)[C@@]2(O)C(O)=C...\n    \n    \n      129\n      CN(C)[C@@H]1C(O)=C(C(N)=O)C(=O)[C@@]2(O)C(O)=C...\n      30\n      2\n      tetracycline\n      CN(C)[C@@H]1C(O)=C(C(N)=O)C(=O)[C@@]2(O)C(O)=C...\n    \n    \n      171\n      CN(C)[C@@H]1C(O)=C(C(N)=O)C(=O)[C@H]2C(O)=C3C(...\n      29\n      3\n      eravacycline\n      CN(C)[C@@H]1C(O)=C(C(N)=O)C(=O)[C@@]2(O)C(O)=C...\n    \n    \n      201\n      CN(C)[C@@H]1C(O)=C(C(N)=O)C(=O)[C@@]2(O)C(O)=C...\n      30\n      2\n      eravacycline\n      CN(C)[C@@H]1C(O)=C(C(N)=O)C(=O)[C@@]2(O)C(O)=C...\n    \n    \n      172\n      CN(C)[C@@H]1C(O)=C(C(N)=O)C(=O)[C@@]2(O)C(O)=C...\n      30\n      3\n      oxytetracycline\n      CN(C)[C@@H]1C(O)=C(C(N)=O)C(=O)[C@@]2(O)C(O)=C...\n    \n    \n      92\n      CN(C)[C@@H]1C(O)=C(C(N)=O)C(=O)[C@H]2C(O)=C3C(...\n      29\n      3\n      omadacycline\n      CN(C)c1cc(CNCC(C)(C)C)c(O)c2c1C[C@H]1C[C@H]3[C...\n    \n  \n\n\n\n\nHere, all tetracycline antibiotics were brought up in the resultant dataframe.\nAs an aside from what I wanted to do, I also learnt a small trick about how to get the number of atoms in the file with multiple SMILES strings.\n\n# Sample use of SmilesMolSupplier & GetNumAtoms()\nsuppl = SmilesMolSupplier('cpd3.smi')\n\nnMols = len(suppl)\n\nfor i in range(nMols):\n\n  a = suppl[i].GetNumAtoms()\n  print(a)\n\n17\n16\n18\n17\n19\n18\n25\n17\n18\n24\n18\n19\n25\n26\n\n\nNow, back to where I was meant to continue working, I wanted to convert these SMILES strings into RDKit molecules first.\n\n# Reading cpd3.smi SMILES strings in text file as RDKit mol objects\nsuppl = SmilesMolSupplier(\"cpd3.smi\")\nsuppl\n\n<rdkit.Chem.rdmolfiles.SmilesMolSupplier at 0x134bf5c10>\n\n\nThis was followed by converting the “mol” objects into SMILES strings, so that we could save each SMILES string into a list.\n\n# Initialise an empty list\nlist = []\n\nfor mol in suppl:\n   # Convert RDKit mol objects into SMILES strings\n   m = Chem.MolToSmiles(mol)\n   # Add each SMILES read from filename.smi into the empty list\n   list.append(m)\n\nlist\n\n['O=CC1CCCC(Cc2ccc(O)cc2)C1=O',\n 'O=CC1CCCC(Cc2ccccc2)C1=O',\n 'CC(=O)C1CCCC(Cc2ccc(O)cc2)C1=O',\n 'CC(=O)C1CCCC(Cc2ccccc2)C1=O',\n 'CCC(=O)C1CCCC(Cc2ccc(O)cc2)C1=O',\n 'CCC(=O)C1CCCC(Cc2ccccc2)C1=O',\n 'O=C(CCc1ccccc1)C1CCCC(Cc2ccc(O)cc2)C1=O',\n 'O=C1CCCCC1C(=O)CCc1ccccc1',\n 'CC1CCCC(C(=O)CCc2ccccc2)C1=O',\n 'O=C(CCc1ccccc1)C1CCCC(Cc2ccccc2)C1=O',\n 'O=C1CCCCC1C(=O)CCc1ccc(O)cc1',\n 'CC1CCCC(C(=O)CCc2ccc(O)cc2)C1=O',\n 'O=C(CCc1ccc(O)cc1)C1CCCC(Cc2ccccc2)C1=O',\n 'O=C(CCc1ccc(O)cc1)C1CCCC(Cc2ccc(O)cc2)C1=O']\n\n\n\n\n\n\nFunction for converting .smi file into a list to query and match scaffolds of interests\nI then came up with the next function that would feed multiple scaffolds into a Pandas.query() to match the strings, meaning we could compare the scaffolds with each other in a dataframe.\n\ndef query_scaffolds_via_smiles(filename):\n\n    # Initialise an empty list\n    list = []\n    # Use SmilesMolSupplier() from RDKit to read in the SMILES strings stored in .smi file\n    suppl = SmilesMolSupplier(filename)\n    # Use a for loop to iterate through the SMILES strings\n    for mol in suppl:\n        # Convert RDKit mol objects into SMILES strings\n        m = Chem.MolToSmiles(mol)\n        # Add each SMILES read from filename.smi into the empty list\n        list.append(m)\n        # Compare the SMILES with the scaffold column in dataframe\n        scaffold_match_df = mol_df.query(\"Scaffold in @list\")\n        \n    return scaffold_match_df\n\n\n\nTesting on the function\nBelow was a test for this query_scaffolds_via_smiles() function using the previously made “cpd3.smi” file.\nTo show that compound 3 scaffolds literally only existed in compound 3 and not in any other prescription-only anti-bacterials based on the ChEMBL-extracted anti-infective dataset only (note: other sources not checked at this stage).\n\n# Testing query_scaffolds_via_smiles() function\nquery_scaffolds_via_smiles(\"cpd3.smi\")\n\n\n\n\n\n  \n    \n      \n      Scaffold\n      NumAtoms\n      NumRgroupgs\n      Name\n      SMILES\n    \n  \n  \n    \n      0\n      O=CC1CCCC(Cc2ccc(O)cc2)C1=O\n      17\n      1\n      Compound_3\n      O=C(CCc1ccc(O)cc1)C1CCCC(Cc2ccc(O)cc2)C1=O\n    \n    \n      4\n      O=CC1CCCC(Cc2ccccc2)C1=O\n      16\n      2\n      Compound_3\n      O=C(CCc1ccc(O)cc1)C1CCCC(Cc2ccc(O)cc2)C1=O\n    \n    \n      5\n      CC(=O)C1CCCC(Cc2ccc(O)cc2)C1=O\n      18\n      1\n      Compound_3\n      O=C(CCc1ccc(O)cc1)C1CCCC(Cc2ccc(O)cc2)C1=O\n    \n    \n      8\n      CC(=O)C1CCCC(Cc2ccccc2)C1=O\n      17\n      2\n      Compound_3\n      O=C(CCc1ccc(O)cc1)C1CCCC(Cc2ccc(O)cc2)C1=O\n    \n    \n      9\n      CCC(=O)C1CCCC(Cc2ccc(O)cc2)C1=O\n      19\n      1\n      Compound_3\n      O=C(CCc1ccc(O)cc1)C1CCCC(Cc2ccc(O)cc2)C1=O\n    \n    \n      11\n      CCC(=O)C1CCCC(Cc2ccccc2)C1=O\n      18\n      2\n      Compound_3\n      O=C(CCc1ccc(O)cc1)C1CCCC(Cc2ccc(O)cc2)C1=O\n    \n    \n      12\n      O=C(CCc1ccccc1)C1CCCC(Cc2ccc(O)cc2)C1=O\n      25\n      1\n      Compound_3\n      O=C(CCc1ccc(O)cc1)C1CCCC(Cc2ccc(O)cc2)C1=O\n    \n    \n      13\n      O=C1CCCCC1C(=O)CCc1ccccc1\n      17\n      2\n      Compound_3\n      O=C(CCc1ccc(O)cc1)C1CCCC(Cc2ccc(O)cc2)C1=O\n    \n    \n      14\n      CC1CCCC(C(=O)CCc2ccccc2)C1=O\n      18\n      2\n      Compound_3\n      O=C(CCc1ccc(O)cc1)C1CCCC(Cc2ccc(O)cc2)C1=O\n    \n    \n      15\n      O=C(CCc1ccccc1)C1CCCC(Cc2ccccc2)C1=O\n      24\n      2\n      Compound_3\n      O=C(CCc1ccc(O)cc1)C1CCCC(Cc2ccc(O)cc2)C1=O\n    \n    \n      16\n      O=C1CCCCC1C(=O)CCc1ccc(O)cc1\n      18\n      1\n      Compound_3\n      O=C(CCc1ccc(O)cc1)C1CCCC(Cc2ccc(O)cc2)C1=O\n    \n    \n      19\n      CC1CCCC(C(=O)CCc2ccc(O)cc2)C1=O\n      19\n      1\n      Compound_3\n      O=C(CCc1ccc(O)cc1)C1CCCC(Cc2ccc(O)cc2)C1=O\n    \n    \n      21\n      O=C(CCc1ccc(O)cc1)C1CCCC(Cc2ccccc2)C1=O\n      25\n      1\n      Compound_3\n      O=C(CCc1ccc(O)cc1)C1CCCC(Cc2ccc(O)cc2)C1=O\n    \n    \n      22\n      O=C(CCc1ccc(O)cc1)C1CCCC(Cc2ccc(O)cc2)C1=O\n      26\n      1\n      Compound_3\n      O=C(CCc1ccc(O)cc1)C1CCCC(Cc2ccc(O)cc2)C1=O\n    \n  \n\n\n\n\nThen I also tested on “cefe.smi” created before.\n\n# Test on cefe.smi\nquery_scaffolds_via_smiles(\"cefe.smi\")\n\n\n\n\n\n  \n    \n      \n      Scaffold\n      NumAtoms\n      NumRgroupgs\n      Name\n      SMILES\n    \n  \n  \n    \n      0\n      C[N+]1(CC2=C(C(=O)[O-])N3C(=O)[C@@H](NC(=O)/C(...\n      31\n      1\n      cefepime\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[N...\n    \n    \n      1\n      C[N+]1(CC2=CN3C(=O)[C@@H](NC(=O)C(=NO)c4csc(N)...\n      28\n      2\n      cefepime\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[N...\n    \n    \n      2\n      Nc1nc(C(=NO)C(=O)N[C@@H]2C(=O)N3C=CCS[C@H]23)cs1\n      21\n      3\n      cefepime\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[N...\n    \n    \n      3\n      CC1=CN2C(=O)[C@@H](NC(=O)C(=NO)c3csc(N)n3)[C@H...\n      22\n      3\n      cefepime\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[N...\n    \n    \n      4\n      Nc1nc(C(=NO)C(=O)N[C@@H]2C(=O)N3C=C(C[NH+]4CCC...\n      27\n      3\n      cefepime\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[N...\n    \n    \n      5\n      C[N+]1(CC2=CN3C(=O)[C@@H](NC(=O)C=NO)[C@H]3SC2...\n      22\n      3\n      cefepime\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[N...\n    \n    \n      6\n      C[N+]1(CC2=CN3C(=O)[C@@H](NC(=O)C(=NO)c4cscn4)...\n      27\n      3\n      cefepime\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[N...\n    \n    \n      7\n      Nc1nc(C(=NO)C(=O)N[C@@H]2C(=O)N3C(C(=O)[O-])=C...\n      24\n      2\n      cefepime\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[N...\n    \n    \n      8\n      O=C([O-])C1=CCS[C@@H]2[C@H](NC(=O)C(=NO)c3cscn...\n      23\n      3\n      cefepime\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[N...\n    \n    \n      9\n      CC1=C(C(=O)[O-])N2C(=O)[C@@H](NC(=O)C(=NO)c3cs...\n      25\n      2\n      cefepime\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[N...\n    \n    \n      10\n      CC1=C(C(=O)[O-])N2C(=O)[C@@H](NC(=O)C=NO)[C@H]...\n      19\n      3\n      cefepime\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[N...\n    \n    \n      11\n      CC1=C(C(=O)[O-])N2C(=O)[C@@H](NC(=O)C(=NO)c3cs...\n      24\n      3\n      cefepime\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[N...\n    \n    \n      12\n      Nc1nc(C(=NO)C(=O)N[C@@H]2C(=O)N3C(C(=O)[O-])=C...\n      30\n      2\n      cefepime\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[N...\n    \n    \n      13\n      O=C(C=NO)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[NH+]3...\n      24\n      3\n      cefepime\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[N...\n    \n    \n      14\n      O=C([O-])C1=C(C[NH+]2CCCC2)CS[C@@H]2[C@H](NC(=...\n      29\n      3\n      cefepime\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[N...\n    \n    \n      15\n      C[N+]1(CC2=C(C(=O)[O-])N3C(=O)[C@@H](NC(=O)C=N...\n      25\n      2\n      cefepime\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[N...\n    \n    \n      16\n      C[N+]1(CC2=C(C(=O)[O-])N3C(=O)[C@@H](NC(=O)C(=...\n      30\n      2\n      cefepime\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[N...\n    \n    \n      17\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C=C(C[N+]3(C)CCCC3...\n      29\n      1\n      cefepime\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[N...\n    \n    \n      18\n      CON=C(C(=O)N[C@@H]1C(=O)N2C=CCS[C@H]12)c1csc(N)n1\n      22\n      2\n      cefepime\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[N...\n    \n    \n      19\n      CON=C(C(=O)N[C@@H]1C(=O)N2C=CCS[C@H]12)c1cscn1\n      21\n      3\n      cefepime\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[N...\n    \n    \n      20\n      CON=C(C(=O)N[C@@H]1C(=O)N2C=C(C)CS[C@H]12)c1cs...\n      23\n      2\n      cefepime\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[N...\n    \n    \n      21\n      CON=C(C(=O)N[C@@H]1C(=O)N2C=C(C)CS[C@H]12)c1cscn1\n      22\n      3\n      cefepime\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[N...\n    \n    \n      22\n      CON=C(C(=O)N[C@@H]1C(=O)N2C=C(C[NH+]3CCCC3)CS[...\n      28\n      2\n      cefepime\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[N...\n    \n    \n      23\n      CON=CC(=O)N[C@@H]1C(=O)N2C=C(C[NH+]3CCCC3)CS[C...\n      22\n      3\n      cefepime\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[N...\n    \n    \n      24\n      CON=C(C(=O)N[C@@H]1C(=O)N2C=C(C[NH+]3CCCC3)CS[...\n      27\n      3\n      cefepime\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[N...\n    \n    \n      25\n      CON=CC(=O)N[C@@H]1C(=O)N2C=C(C[N+]3(C)CCCC3)CS...\n      23\n      2\n      cefepime\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[N...\n    \n    \n      26\n      CON=C(C(=O)N[C@@H]1C(=O)N2C=C(C[N+]3(C)CCCC3)C...\n      28\n      2\n      cefepime\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[N...\n    \n    \n      27\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=CCS[C...\n      25\n      1\n      cefepime\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[N...\n    \n    \n      28\n      CON=C(C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=CCS[C@H...\n      25\n      1\n      cefepime\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[N...\n    \n    \n      30\n      CON=C(C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=CCS[C@H...\n      24\n      2\n      cefepime\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[N...\n    \n    \n      31\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C)C...\n      26\n      1\n      cefepime\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[N...\n    \n    \n      32\n      CON=C(C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C)CS[...\n      26\n      1\n      cefepime\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[N...\n    \n    \n      33\n      CON=CC(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C)CS[C...\n      20\n      2\n      cefepime\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[N...\n    \n    \n      34\n      CON=C(C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C)CS[...\n      25\n      2\n      cefepime\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[N...\n    \n    \n      35\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[N...\n      31\n      1\n      cefepime\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[N...\n    \n    \n      36\n      CON=CC(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[NH+]...\n      25\n      2\n      cefepime\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[N...\n    \n    \n      37\n      CON=C(C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[NH+...\n      30\n      2\n      cefepime\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[N...\n    \n    \n      38\n      CO/N=C\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[N+...\n      26\n      1\n      cefepime\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[N...\n    \n    \n      39\n      CON=CC(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[N+]3...\n      26\n      1\n      cefepime\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[N...\n    \n    \n      40\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[N...\n      31\n      1\n      cefepime\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[N...\n    \n    \n      41\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[N...\n      32\n      1\n      cefepime\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(C[N...\n    \n    \n      2\n      Nc1nc(C(=NO)C(=O)N[C@@H]2C(=O)N3C=CCS[C@H]23)cs1\n      21\n      3\n      cefixime\n      C=CC1=C(C(=O)O)N2C(=O)[C@@H](NC(=O)/C(=N\\OCC(=...\n    \n    \n      3\n      CON=C(C(=O)N[C@@H]1C(=O)N2C=CCS[C@H]12)c1csc(N)n1\n      22\n      3\n      cefixime\n      C=CC1=C(C(=O)O)N2C(=O)[C@@H](NC(=O)/C(=N\\OCC(=...\n    \n    \n      2\n      CC1=CN2C(=O)[C@@H](NC(=O)C(=NO)c3csc(N)n3)[C@H...\n      22\n      3\n      ceftriaxone\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)O)=C(CSc3nc...\n    \n    \n      24\n      CON=C(C(=O)N[C@@H]1C(=O)N2C=C(C)CS[C@H]12)c1cs...\n      23\n      2\n      ceftriaxone\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)O)=C(CSc3nc...\n    \n    \n      25\n      CON=C(C(=O)N[C@@H]1C(=O)N2C=C(C)CS[C@H]12)c1cscn1\n      22\n      3\n      ceftriaxone\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)O)=C(CSc3nc...\n    \n    \n      1\n      Nc1nc(C(=NO)C(=O)N[C@@H]2C(=O)N3C=CCS[C@H]23)cs1\n      21\n      2\n      cefdinir\n      C=CC1=C(C(=O)O)N2C(=O)[C@@H](NC(=O)/C(=N\\O)c3c...\n    \n    \n      2\n      Nc1nc(C(=NO)C(=O)N[C@@H]2C(=O)N3C=CCS[C@H]23)cs1\n      21\n      3\n      cefotaxime\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)O)=C(COC(C)...\n    \n    \n      3\n      CC1=CN2C(=O)[C@@H](NC(=O)C(=NO)c3csc(N)n3)[C@H...\n      22\n      3\n      cefotaxime\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)O)=C(COC(C)...\n    \n    \n      19\n      CON=C(C(=O)N[C@@H]1C(=O)N2C=CCS[C@H]12)c1csc(N)n1\n      22\n      2\n      cefotaxime\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)O)=C(COC(C)...\n    \n    \n      20\n      CON=C(C(=O)N[C@@H]1C(=O)N2C=CCS[C@H]12)c1cscn1\n      21\n      3\n      cefotaxime\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)O)=C(COC(C)...\n    \n    \n      21\n      CON=C(C(=O)N[C@@H]1C(=O)N2C=C(C)CS[C@H]12)c1cs...\n      23\n      2\n      cefotaxime\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)O)=C(COC(C)...\n    \n    \n      22\n      CON=C(C(=O)N[C@@H]1C(=O)N2C=C(C)CS[C@H]12)c1cscn1\n      22\n      3\n      cefotaxime\n      CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)O)=C(COC(C)...\n    \n    \n      33\n      CC1=CN2C(=O)[C@@H](NC(=O)C(=NO)c3csc(N)n3)[C@H...\n      22\n      3\n      ceftazidime\n      CC(C)(O/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=...\n    \n    \n      36\n      Nc1nc(C(=NO)C(=O)N[C@@H]2C(=O)N3C(C(=O)[O-])=C...\n      24\n      2\n      ceftazidime\n      CC(C)(O/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=...\n    \n    \n      37\n      O=C([O-])C1=CCS[C@@H]2[C@H](NC(=O)C(=NO)c3cscn...\n      23\n      3\n      ceftazidime\n      CC(C)(O/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=...\n    \n    \n      38\n      CC1=C(C(=O)[O-])N2C(=O)[C@@H](NC(=O)C(=NO)c3cs...\n      25\n      2\n      ceftazidime\n      CC(C)(O/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=...\n    \n    \n      39\n      CC1=C(C(=O)[O-])N2C(=O)[C@@H](NC(=O)C(=NO)c3cs...\n      24\n      3\n      ceftazidime\n      CC(C)(O/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=...\n    \n  \n\n\n\n\nOnly cephalosporins were brought up as the result from this scaffold query, which matched with the antibiotic class of cefepime.\n\n\n\n\n\nSome answers\nThere were no other prescription-only anti-bacterials from ChEMBL database with the same scaffold as compound 3 after comparing the SMILES strings between these selected scaffolds only. This was only limited to the dataset obtained from ChEMBL at this stage, with compound indications limited to anti-infectives for now. This might imply that the scaffold of compound 3 could be considered novel when comparing with molecules with similar indications. Obviously, this was too preliminary to confirm anything substantial, since there were no in vivo tests on finding out the efficacy, safety and toxicity of compound 3 apart from the in vitro experimental results mentioned in the paper. It probably would provide some ideas for scaffold hopping in hit compounds, or functional group (R-group) comparisons when looking for new compounds for synthesis. Overall, it was interesting to have a re-visit on this work using a more cheminformatics approach.\n\n\n\nAfterthoughts\nWhat I wanted to achieve in this post were:\n\nTo familiarise myself with Datamol and scaffold_finder libraries\nTo use Polars dataframe library for initial data wrangling along with Datamol Python library, and the later trial of scaffold_finder library. Using Polars would be a small degree only, as Datamol was likely written with Pandas in mind mostly (based on RDKit), while Pandas was also the more commonly used dataframe libray in many cheminformatics packages. Some people might prefer to stick with Pandas all the way, which I agree, but I’d just wanted to use Polars for the initial data wrangling only as I’ve been using it more lately\nTo reveal my thought process on building simple cheminformatics-related functions (this was unplanned, but kind of evolved while working on this post)\nTo show some evidence of my own growth from computational and medicinal chemistry with no code, to using data science tools with Python code to help guiding drug discovery projects\nTo mention that experimental validations will always be crucial for computational predictions, and since I had some experimental results from the paper, I thought to accompany it with some computational findings here\n\nI hope I’ve at least achieved some these points in this post if not all.\nThanks for reading and looking forward to comments if any.\n\n\n\n\n\nFootnotes\n\n\nSimplified Molecular Input Line Entry Systems↩︎\nSELF-referencIng Embedded Strings↩︎\nInternational Chemical Identifier↩︎"
  },
  {
    "objectID": "posts/16_ML2-1_Decision_tree/1_data_col_prep.html",
    "href": "posts/16_ML2-1_Decision_tree/1_data_col_prep.html",
    "title": "Decision tree",
    "section": "",
    "text": "Series overview\n\nPost 1 (this post) - data collection from ChEMBL database using web resource client in Python, with initial data preprocessing\nPost 2 - more data preprocessing and transformation to reach the final dataset prior to model building\nPost 3 - estimating experimental errors and building decision tree model using scikit-learn\n\n\n\n\nIntroduction\nI’ve now come to a stage to do some more machine learning (ML) work after reading a few peer-reviewed papers about ML and drug discovery. It seemed that traditional ML methods were still indispensible performance-wise, and when used in combination with deep learning neural networks, they tend to increase prediction accuracy more. I also haven’t ventured into the practicality and usefulness of large language models in drug discovery yet, but I’m aware work in this area has been started. However, comments from experienced seniors did mention that they are still very much novel and therefore may not be as useful yet. Although by the speed of how things evolve in the so-called “AI” field, this possibly may change very soon. Also from what I can imagine, molecular representations in texts or strings are not quite the same as natural human language texts, since there are a lot of other chemistry-specific features to consider, e.g. chiralities, aromaticities and so on. Because of this, I’m sticking with learning to walk first by trying to cover conventional ML methods in a more thorough way, before trying to run in the deep learning zone.\nSo this leads to this series of posts (3 in total) about decision tree. Previously, I’ve only lightly touched on a commonly used classifier algorithm, logistic regression, as the first series in the ML realm. Reflecting back, I think I could’ve done a more thorough job during the data preparation stage. So this would be attempted this time. The data preparation used here was carried out with strong reference to the materials and methods section in this paper (Tilborg, Alenicheva, and Grisoni 2022), which was one of the papers I’ve read. There are probably other useful methods out there, but this paper made sense to me, so I’ve adopted a few of their ways of doing things during data preprocessing.\n\n\n\nData retrieval\nThis time I decided to try something new which was to use the ChEMBL web resource client to collect data (i.e. not by direct file downloads from ChEMBL website, although other useful way could be through SQL queries, which is also on my list to try later). I found this great online resource about fetching data this way from the TeachOpenCADD talktorial on compound data acquisition. The data retrieval workflow used below was mainly adapted from this talktorial with a few changes to suit the selected dataset and ML model.\nThe web resource client was supported by the ChEMBL group and was based on a Django QuerySet interface. Their GitHub repository might explain a bit more about it, particularly the Jupyter notebook link provided in the repository would help a lot regarding how to write code to search for specific data.\nTo do this, a few libraries needed to be loaded first.\n\n# Import libraries\n# Fetch data through ChEMBL web resource client\nfrom chembl_webresource_client.new_client import new_client\n\n# Dataframe library\nimport pandas as pd\n\n# Progress bar\nfrom tqdm import tqdm\n\nTo see what types of data were provided by ChEMBL web resource client, run the following code and refer to ChEMBL documentations to find out what data were embedded inside different data categories. Sometimes, it might not be that straight forward and some digging would be required (I went back to this step below to find the “data_validity_comment” when I was trying to do some compound sanitisations actually).\n\n\n\n\n\n\nNote\n\n\n\nThe link provided above also talked about other useful techniques for data checks in the ChEMBL database - a very important step to do during data preprocessing, which was also something I was trying to cover and achieve as much as possible in this post.\n\n\n\navailable_resources = [resource for resource in dir(new_client) if not resource.startswith('_')]\nprint(available_resources)\n\n['activity', 'activity_supplementary_data_by_activity', 'assay', 'assay_class', 'atc_class', 'binding_site', 'biotherapeutic', 'cell_line', 'chembl_id_lookup', 'compound_record', 'compound_structural_alert', 'description', 'document', 'document_similarity', 'drug', 'drug_indication', 'drug_warning', 'go_slim', 'image', 'mechanism', 'metabolism', 'molecule', 'molecule_form', 'official', 'organism', 'protein_classification', 'similarity', 'source', 'substructure', 'target', 'target_component', 'target_relation', 'tissue', 'xref_source']\n\n\nResource objects were created to enable API access as suggested by the talktorial.\n\n# for targets (proteins)\ntargets_api = new_client.target\n\n# for bioactivities\nbioact_api = new_client.activity\n\n# for assays\nassay_api = new_client.assay\n\n# for compounds\ncpd_api = new_client.molecule\n\nChecked object type for one of these API objects (e.g. bioactivity API object).\n\ntype(bioact_api)\n\nchembl_webresource_client.query_set.QuerySet\n\n\n\n\n\nFetching target data\nA protein target e.g. acetylcholinesterase was randomly chosen by using UniProt to look up the protein UniProt ID.\n\n# Specify Uniprot ID for acetylcholinesterase\nuniprot_id = \"P22303\"\n\n# Get info from ChEMBL about this protein target, \n# with selected features only\ntargets = targets_api.get(target_components__accession = uniprot_id).only(\n    \"target_chembl_id\",\n    \"organism\", \n    \"pref_name\", \n    \"target_type\"\n)\n\nThe query results were stored in a “targets” object, which was a QuerySet with lazy data evaluation only, meaning it would only react when there was a request for the data. Therefore, to see the results, the “targets” object was then read through Pandas DataFrame.\n\n# Read \"targets\" with Pandas\ntargets = pd.DataFrame.from_records(targets)\ntargets\n\n\n\n\n\n  \n    \n      \n      organism\n      pref_name\n      target_chembl_id\n      target_type\n    \n  \n  \n    \n      0\n      Homo sapiens\n      Acetylcholinesterase\n      CHEMBL220\n      SINGLE PROTEIN\n    \n    \n      1\n      Homo sapiens\n      Acetylcholinesterase\n      CHEMBL220\n      SINGLE PROTEIN\n    \n    \n      2\n      Homo sapiens\n      Cholinesterases; ACHE & BCHE\n      CHEMBL2095233\n      SELECTIVITY GROUP\n    \n  \n\n\n\n\nSelected the first protein target from this dataframe.\n\n# Save the first protein in the dataframe\nselect_target = targets.iloc[0]\nselect_target\n\norganism                    Homo sapiens\npref_name           Acetylcholinesterase\ntarget_chembl_id               CHEMBL220\ntarget_type               SINGLE PROTEIN\nName: 0, dtype: object\n\n\nThen saved the selected ChEMBL ID for the first protein (to be used later).\n\nchembl_id = select_target.target_chembl_id\n# Check it's saved\nprint(chembl_id)\n\nCHEMBL220\n\n\n\n\n\nFetching bioactivity data\nObtaining bioactivity data for the selected target.\n\nbioact = bioact_api.filter(\n    # Use the previously saved target ChEMBL ID\n    target_chembl_id = chembl_id, \n    # Selecting for Ki\n    standard_type = \"Ki\",\n    # Requesting exact measurements\n    relation = \"=\",\n    # Binding data as \"B\"\n    assay_type = \"B\",\n).only(\n    \"activity_id\",\n    \"data_validity_comment\"\n    \"assay_chembl_id\",\n    \"assay_description\",\n    \"assay_type\",\n    \"molecule_chembl_id\",\n    \"standard_units\",\n    \"standard_type\",\n    \"relation\",\n    \"standard_value\",\n    \"target_chembl_id\",\n    \"target_organism\"\n)\n\n# Check the length and type of bioactivities object\nprint(len(bioact), type(bioact))\n\n706 <class 'chembl_webresource_client.query_set.QuerySet'>\n\n\nTo have a quick look at the data being held inside each entry of the bioactivity dataset, e.g. for first entry.\n\nprint(len(bioact[0]), type(bioact[0]))\nbioact[0]\n\n15 <class 'dict'>\n\n\n{'activity_id': 111024,\n 'assay_chembl_id': 'CHEMBL641011',\n 'assay_description': 'Inhibition constant determined against Acetylcholinesterase (AChE) receptor.',\n 'assay_type': 'B',\n 'data_validity_comment': 'Potential transcription error',\n 'molecule_chembl_id': 'CHEMBL11805',\n 'relation': '=',\n 'standard_type': 'Ki',\n 'standard_units': 'nM',\n 'standard_value': '0.104',\n 'target_chembl_id': 'CHEMBL220',\n 'target_organism': 'Homo sapiens',\n 'type': 'Ki',\n 'units': 'nM',\n 'value': '0.104'}\n\n\nThe next step might take a few minutes - downloading the QuerySet as a Pandas DataFrame.\n\nbioact_df = pd.DataFrame.from_dict(bioact)\n\nbioact_df.head(3)\n\n\n\n\n\n  \n    \n      \n      activity_id\n      assay_chembl_id\n      assay_description\n      assay_type\n      data_validity_comment\n      molecule_chembl_id\n      relation\n      standard_type\n      standard_units\n      standard_value\n      target_chembl_id\n      target_organism\n      type\n      units\n      value\n    \n  \n  \n    \n      0\n      111024\n      CHEMBL641011\n      Inhibition constant determined against Acetylc...\n      B\n      Potential transcription error\n      CHEMBL11805\n      =\n      Ki\n      nM\n      0.104\n      CHEMBL220\n      Homo sapiens\n      Ki\n      nM\n      0.104\n    \n    \n      1\n      118575\n      CHEMBL641012\n      Inhibitory activity against human AChE\n      B\n      None\n      CHEMBL208599\n      =\n      Ki\n      nM\n      0.026\n      CHEMBL220\n      Homo sapiens\n      Ki\n      nM\n      0.026\n    \n    \n      2\n      125075\n      CHEMBL641011\n      Inhibition constant determined against Acetylc...\n      B\n      None\n      CHEMBL60745\n      =\n      Ki\n      nM\n      1.63\n      CHEMBL220\n      Homo sapiens\n      Ki\n      nM\n      1.63\n    \n  \n\n\n\n\nChecked total rows and columns in the bioactivities dataframe.\n\nbioact_df.shape\n\n(706, 15)\n\n\n\n\nPreprocess bioactivity data\nWhen I reached the second half of data preprocessing, an alarm bell went off regarding using half maximal inhibitory concentration (IC50) values in ChEMBL. I remembered reading recent blog posts by Greg Landrum about using IC50 and inhibition constant (Ki) values from ChEMBL. A useful open-access paper (Kalliokoski et al. 2013) from 2013 also looked into this issue about using mixed IC50 data in ChEMBL, and provided a thorough overview about how to deal with situations like this. There was also another paper (Kramer et al. 2012) on mixed Ki data from the same author group in 2012 that touched on similar issues.\nTo summarise both the paper about IC50 and blog posts mentioned above:\n\nit would be the best to check the details of assays used to test the compounds to ensure they were aligned and not extremely heterogeneous, since IC50 values were very assay-specific, and knowing that these values were extracted from different papers from different labs all over the world, mixing them without knowing was definitely not a good idea\nthe slightly better news was that it was more likely okay to combine Ki values for the same protein target from ChEMBL as they were found to be adding less noise to the data (however ideally similar data caution should also apply)\nit was also possible to mix Ki values with IC50 values, but the data would need to be corrected via using a conversion factor of 2.0 to convert Ki values to IC50 values (note: I also wondered if this needed to be re-looked again since this paper was published 10 years ago…)\n\nBecause of this, I decided to stick with Ki values only for now before adding more complexities as I wasn’t entirely confident about mixing IC50 values with Ki values yet. Firstly, I checked for all types of units being used in bioact_df. There were numerous different units and formats, which meant they would need to be converted to nanomolar (nM) units first.\n\nbioact_df[\"units\"].unique()\n\narray(['nM', 'M', 'uM', None, 'pM', \"10'-9M\", \"10'-3M\", \"10'-6M\",\n       \"10'-10M\", '/min/M', \"10'5/M/min\", \"10'2/M/min\", \"10'3/M/min\",\n       \"10'8/M/min\", \"10'7/M/min\", 'microM/L', 'umol/L', 'mM',\n       \"10'4/M/min\", \"10'6/M/min\", 'mM/min', '10^8M'], dtype=object)\n\n\nChecking again that I’ve fetched Ki values only.\n\nbioact_df[\"standard_type\"].unique()\n\narray(['Ki'], dtype=object)\n\n\nIt looked like there were duplicates of columns on units and values, so the “units” and “value” columns were removed and “standard_units” and “standard_value” columns were kept instead. Also, “type” column was dropped as there were already a “standard_type” column.\n\n\n\n\n\n\nNote\n\n\n\nDifferences between “type” and “standard_type” columns were mentioned by this ChEMBL blog post.\n\n\n\nbioact_df.drop([\"units\", \"value\", \"type\"], axis = 1, inplace = True)\n# Re-check df\nbioact_df.head(3)\n\n\n\n\n\n  \n    \n      \n      activity_id\n      assay_chembl_id\n      assay_description\n      assay_type\n      data_validity_comment\n      molecule_chembl_id\n      relation\n      standard_type\n      standard_units\n      standard_value\n      target_chembl_id\n      target_organism\n    \n  \n  \n    \n      0\n      111024\n      CHEMBL641011\n      Inhibition constant determined against Acetylc...\n      B\n      Potential transcription error\n      CHEMBL11805\n      =\n      Ki\n      nM\n      0.104\n      CHEMBL220\n      Homo sapiens\n    \n    \n      1\n      118575\n      CHEMBL641012\n      Inhibitory activity against human AChE\n      B\n      None\n      CHEMBL208599\n      =\n      Ki\n      nM\n      0.026\n      CHEMBL220\n      Homo sapiens\n    \n    \n      2\n      125075\n      CHEMBL641011\n      Inhibition constant determined against Acetylc...\n      B\n      None\n      CHEMBL60745\n      =\n      Ki\n      nM\n      1.63\n      CHEMBL220\n      Homo sapiens\n    \n  \n\n\n\n\n\nbioact_df.dtypes\n\nactivity_id               int64\nassay_chembl_id          object\nassay_description        object\nassay_type               object\ndata_validity_comment    object\nmolecule_chembl_id       object\nrelation                 object\nstandard_type            object\nstandard_units           object\nstandard_value           object\ntarget_chembl_id         object\ntarget_organism          object\ndtype: object\n\n\nThe column of “standard_value” was converted from “object” to “float64” so we could use the Ki values for calculations later.\n\nbioact_df = bioact_df.astype({\"standard_value\": \"float64\"})\n# Check column data types again\nbioact_df.dtypes\n\nactivity_id                int64\nassay_chembl_id           object\nassay_description         object\nassay_type                object\ndata_validity_comment     object\nmolecule_chembl_id        object\nrelation                  object\nstandard_type             object\nstandard_units            object\nstandard_value           float64\ntarget_chembl_id          object\ntarget_organism           object\ndtype: object\n\n\nThen the next step was taking care of any missing entries by removing them in the first place. I excluded “data_validity_comment” column here as this was required to check if there were any unusual activity data e.g. excessively low or high Ki values. A lot of the compounds in this column probably had empty cells or “None”, which ensured that there were no particular alarm bells to the extracted bioactivity data.\n\nbioact_df.dropna(subset = [\"activity_id\", \"assay_chembl_id\", \"assay_description\", \"assay_type\", \"molecule_chembl_id\", \"relation\",  \"standard_type\", \"standard_units\", \"standard_value\", \"target_chembl_id\", \"target_organism\"], axis = 0, how = \"any\", inplace = True)\n# Check number of rows and columns again (in this case, there appeared to be no change for rows)\nbioact_df.shape\n\n(706, 12)\n\n\nSince all unique units inside the “units” and “values” columns were checked previously, I’d done the same for the “standard_units” column to see the ones recorded in it.\n\nbioact_df[\"standard_units\"].unique()\n\narray(['nM', '/min/M', \"10'5/M/min\", \"10'2/M/min\", \"10'3/M/min\",\n       \"10'8/M/min\", \"10'7/M/min\", \"10'4/M/min\", \"10'6/M/min\", 'mM/min',\n       '10^8M'], dtype=object)\n\n\nThere were a mixture of different units.\n\n# Check for number of non-nM units\nbioact_df[bioact_df[\"standard_units\"] != \"nM\"].shape[0]\n\n61\n\n\nThere appeared to be 61 non-nM values inside the fetched bioactivity data.\n\nbioact_df = bioact_df[bioact_df[\"standard_units\"] == \"nM\"]\n\nI then narrowed the results to only “nM” and checked the dataframe again to see what units were left now.\n\n# Check there were only nM\nbioact_df[\"standard_units\"].unique()\n\narray(['nM'], dtype=object)\n\n\nSo the filtering worked and the number of rows and columns were reduced.\n\n# Check df rows & columns\nbioact_df.shape\n\n(645, 12)\n\n\nNext part would be to remove all the duplicates in the dataframe, especially when there were duplicate tests for the same compound.\n\nbioact_df.drop_duplicates(\"molecule_chembl_id\", keep = \"first\", inplace = True)\n\nRenamed the “standard_value” and “standard_units” columns to “Ki” and “units” respectively.\n\nbioact_df.rename(\n    columns = {\n        \"standard_value\": \"Ki\",\n        \"standard_units\": \"units\"\n    }, inplace = True\n)\n\n# Check df to ensure name change\nbioact_df.head(3)\n\n\n\n\n\n  \n    \n      \n      activity_id\n      assay_chembl_id\n      assay_description\n      assay_type\n      data_validity_comment\n      molecule_chembl_id\n      relation\n      standard_type\n      units\n      Ki\n      target_chembl_id\n      target_organism\n    \n  \n  \n    \n      0\n      111024\n      CHEMBL641011\n      Inhibition constant determined against Acetylc...\n      B\n      Potential transcription error\n      CHEMBL11805\n      =\n      Ki\n      nM\n      0.104\n      CHEMBL220\n      Homo sapiens\n    \n    \n      1\n      118575\n      CHEMBL641012\n      Inhibitory activity against human AChE\n      B\n      None\n      CHEMBL208599\n      =\n      Ki\n      nM\n      0.026\n      CHEMBL220\n      Homo sapiens\n    \n    \n      2\n      125075\n      CHEMBL641011\n      Inhibition constant determined against Acetylc...\n      B\n      None\n      CHEMBL60745\n      =\n      Ki\n      nM\n      1.630\n      CHEMBL220\n      Homo sapiens\n    \n  \n\n\n\n\nLastly, the index of the dataframe was reset.\n\nbioact_df.reset_index(drop = True, inplace = True)\nbioact_df.head(3)\n\n\n\n\n\n  \n    \n      \n      activity_id\n      assay_chembl_id\n      assay_description\n      assay_type\n      data_validity_comment\n      molecule_chembl_id\n      relation\n      standard_type\n      units\n      Ki\n      target_chembl_id\n      target_organism\n    \n  \n  \n    \n      0\n      111024\n      CHEMBL641011\n      Inhibition constant determined against Acetylc...\n      B\n      Potential transcription error\n      CHEMBL11805\n      =\n      Ki\n      nM\n      0.104\n      CHEMBL220\n      Homo sapiens\n    \n    \n      1\n      118575\n      CHEMBL641012\n      Inhibitory activity against human AChE\n      B\n      None\n      CHEMBL208599\n      =\n      Ki\n      nM\n      0.026\n      CHEMBL220\n      Homo sapiens\n    \n    \n      2\n      125075\n      CHEMBL641011\n      Inhibition constant determined against Acetylc...\n      B\n      None\n      CHEMBL60745\n      =\n      Ki\n      nM\n      1.630\n      CHEMBL220\n      Homo sapiens\n    \n  \n\n\n\n\nOne final check on the number of columns and rows after preprocessing the bioactivity dataframe.\n\nbioact_df.shape\n\n(540, 12)\n\n\nThere were a total of 12 columns with 540 rows of data left in the bioactivity dataframe.\n\n\n\n\nFetching assay data\nThe assay data was added after I went through the rest of the data preprocessing and also after remembering to check on the confidence scores for assays used in the final data collected (to somewhat assess assay-to-target relationships). This link from ChEMBL explained what the confidence score meant.\n\nassays = assay_api.filter(\n    # Use the previously saved target ChEMBL ID\n    target_chembl_id = chembl_id, \n    # Binding assays only as before\n    assay_type = \"B\"\n).only(\n    \"assay_chembl_id\",\n    \"confidence_score\"\n)\n\nPlacing the fetched assay data into a Pandas DataFrame.\n\nassays_df = pd.DataFrame.from_dict(assays)\n\nprint(assays_df.shape)\nassays_df.head(3)\n\n(2044, 2)\n\n\n\n\n\n\n  \n    \n      \n      assay_chembl_id\n      confidence_score\n    \n  \n  \n    \n      0\n      CHEMBL634034\n      8\n    \n    \n      1\n      CHEMBL642512\n      8\n    \n    \n      2\n      CHEMBL642513\n      8\n    \n  \n\n\n\n\n\nassays_df.describe()\n\n\n\n\n\n  \n    \n      \n      confidence_score\n    \n  \n  \n    \n      count\n      2044.000000\n    \n    \n      mean\n      8.778865\n    \n    \n      std\n      0.415113\n    \n    \n      min\n      8.000000\n    \n    \n      25%\n      9.000000\n    \n    \n      50%\n      9.000000\n    \n    \n      75%\n      9.000000\n    \n    \n      max\n      9.000000\n    \n  \n\n\n\n\nIt looked like the lowest confidence score for this particular protein target in binding assays was at 8, with others sitting at 9 (the highest). There were 452 assays with confidence score of 8.\n\n# Some had score of 8 - find out which ones\nassays_df[assays_df[\"confidence_score\"] == 8]\n\n\n\n\n\n  \n    \n      \n      assay_chembl_id\n      confidence_score\n    \n  \n  \n    \n      0\n      CHEMBL634034\n      8\n    \n    \n      1\n      CHEMBL642512\n      8\n    \n    \n      2\n      CHEMBL642513\n      8\n    \n    \n      3\n      CHEMBL642514\n      8\n    \n    \n      4\n      CHEMBL642515\n      8\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      1141\n      CHEMBL3887379\n      8\n    \n    \n      1142\n      CHEMBL3887855\n      8\n    \n    \n      1143\n      CHEMBL3887947\n      8\n    \n    \n      1144\n      CHEMBL3888161\n      8\n    \n    \n      1874\n      CHEMBL5058677\n      8\n    \n  \n\n452 rows × 2 columns\n\n\n\n\n\n\nCombining bioactivity & assay data\nThe key was to combine the bioactivity and assay data along the “assay_chembl_id” column.\n\nbioact_assay_df = pd.merge(\n    bioact_df[[\"assay_chembl_id\", \"molecule_chembl_id\", \"Ki\", \"units\", \"data_validity_comment\"]],\n    assays_df,\n    on = \"assay_chembl_id\",\n)\nprint(bioact_assay_df.shape)\nbioact_assay_df.head(3)\n\n(540, 6)\n\n\n\n\n\n\n  \n    \n      \n      assay_chembl_id\n      molecule_chembl_id\n      Ki\n      units\n      data_validity_comment\n      confidence_score\n    \n  \n  \n    \n      0\n      CHEMBL641011\n      CHEMBL11805\n      0.104\n      nM\n      Potential transcription error\n      8\n    \n    \n      1\n      CHEMBL641011\n      CHEMBL60745\n      1.630\n      nM\n      None\n      8\n    \n    \n      2\n      CHEMBL641012\n      CHEMBL208599\n      0.026\n      nM\n      None\n      8\n    \n  \n\n\n\n\nI actually came back to this step to relax the confidence score limit to include all the 8s as well as the 9s (otherwise previously I tried only using assays with score of 9), so that donepezil and galantamine could be included in the dataset as well (the purpose of this would be clearer in post 3 when building the model).\n\n\n\nFetching compound data\nWhile having identified the protein target, obtained the bioactivity data, and also the assay data, this next step was to fetch the compound data. This could be done by having the ChEMBL IDs available in the bioactivity dataset.\n\ncpds = cpd_api.filter(\n    molecule_chembl_id__in = list(bioact_df[\"molecule_chembl_id\"])\n).only(\n    \"molecule_chembl_id\",\n    \"molecule_structures\",\n    \"max_phase\"\n)\n\nHere, the same step was applied where the compound QuerySet object was converted into a Pandas dataframe. However, the compound data extracted here might take longer than the bioactivity one. One way to monitor progress was through using tqdm package.\n\ncompds = list(tqdm(cpds))\n\n  0%|          | 0/540 [00:00<?, ?it/s]\n\n\n 93%|█████████▎| 501/540 [00:00<00:00, 4845.36it/s]\n\n\n100%|██████████| 540/540 [00:00<00:00, 5020.27it/s]\n\n\n\n\n\nConverting retrieved compound QuerySet into a Pandas DataFrame.\n\ncpds_df = pd.DataFrame.from_records(compds)\nprint(cpds_df.shape)\ncpds_df.head(3)\n\n(540, 3)\n\n\n\n\n\n\n  \n    \n      \n      max_phase\n      molecule_chembl_id\n      molecule_structures\n    \n  \n  \n    \n      0\n      None\n      CHEMBL28\n      {'canonical_smiles': 'O=c1cc(-c2ccc(O)cc2)oc2c...\n    \n    \n      1\n      3.0\n      CHEMBL50\n      {'canonical_smiles': 'O=c1c(O)c(-c2ccc(O)c(O)c...\n    \n    \n      2\n      None\n      CHEMBL8320\n      {'canonical_smiles': 'O=C1C=CC(=O)C=C1', 'molf...\n    \n  \n\n\n\n\n\n\nPreprocess compound data\nRemoving any missing entries in the compound data (excluding the “max_phase” column as it was needed during the model training/testing part in post 3 - note: “None” entries meant they were preclinical molecules so not assigned with a max phase yet).\n\ncpds_df.dropna(subset = [\"molecule_chembl_id\", \"molecule_structures\"], axis = 0, how = \"any\", inplace = True)\n\n# Check columns & rows in df\ncpds_df.shape\n\n(540, 3)\n\n\nRemoving any duplicates in the compound data.\n\ncpds_df.drop_duplicates(\"molecule_chembl_id\", keep = \"first\", inplace = True)\n\n# Check columns & rows again\ncpds_df.shape\n\n(540, 3)\n\n\nIdeally, only the compounds with canonical SMILES would be kept. Checking for the types of molecular representations used in the “molecule_structures” column of the compound dataset.\n\n# Randomly choosing the 2nd entry as example\ncpds_df.iloc[1].molecule_structures.keys()\n\ndict_keys(['canonical_smiles', 'molfile', 'standard_inchi', 'standard_inchi_key'])\n\n\nThere were 4 types: “canonical_smiles”, “molfile”, “standard_inchi” and “standard_inchi_key”.\n\n# Create an empty list to store the canonical smiles\ncan_smiles = []\n\n# Create a for loop to loop over each row of data, \n# searching for only canonical_smiles to append to the created list\nfor i, cpd in cpds_df.iterrows():\n    try:\n        can_smiles.append(cpd[\"molecule_structures\"][\"canonical_smiles\"])\n    except KeyError:\n        can_smiles.append(None)\n\n# Create a new df column with name as \"smiles\", \n# which will store all the canonical smiles collected from the list above\ncpds_df[\"smiles\"] = can_smiles\n\nCheck the compound dataframe quickly to see if a new column for SMILES has been created.\n\ncpds_df.head(3)\n\n\n\n\n\n  \n    \n      \n      max_phase\n      molecule_chembl_id\n      molecule_structures\n      smiles\n    \n  \n  \n    \n      0\n      None\n      CHEMBL28\n      {'canonical_smiles': 'O=c1cc(-c2ccc(O)cc2)oc2c...\n      O=c1cc(-c2ccc(O)cc2)oc2cc(O)cc(O)c12\n    \n    \n      1\n      3.0\n      CHEMBL50\n      {'canonical_smiles': 'O=c1c(O)c(-c2ccc(O)c(O)c...\n      O=c1c(O)c(-c2ccc(O)c(O)c2)oc2cc(O)cc(O)c12\n    \n    \n      2\n      None\n      CHEMBL8320\n      {'canonical_smiles': 'O=C1C=CC(=O)C=C1', 'molf...\n      O=C1C=CC(=O)C=C1\n    \n  \n\n\n\n\nOnce confirmed, the old “molecule_structures” column was then removed.\n\ncpds_df.drop(\"molecule_structures\", axis = 1, inplace = True)\n\nFinally, adding another step to ensure all missing entries or entries without canonical SMILES strings were removed from the compound dataset.\n\ncpds_df.dropna(subset = [\"smiles\"], axis = 0, how = \"any\", inplace = True)\n\nprint(cpds_df.shape)\n\n(540, 3)\n\n\nFinal look at the compound dataset, which should only include max phase, compound ChEMBL IDs and SMILES columns.\n\ncpds_df.head(3)\n\n\n\n\n\n  \n    \n      \n      max_phase\n      molecule_chembl_id\n      smiles\n    \n  \n  \n    \n      0\n      None\n      CHEMBL28\n      O=c1cc(-c2ccc(O)cc2)oc2cc(O)cc(O)c12\n    \n    \n      1\n      3.0\n      CHEMBL50\n      O=c1c(O)c(-c2ccc(O)c(O)c2)oc2cc(O)cc(O)c12\n    \n    \n      2\n      None\n      CHEMBL8320\n      O=C1C=CC(=O)C=C1\n    \n  \n\n\n\n\n\n\n\n\nCombining bioactivity and compound data\nTo combine both datasets, the key was to look for common column (similar to a SQL “join” query) between the two datasets.\nListing all the column names for both datasets.\n\nbioact_assay_df.columns\n\nIndex(['assay_chembl_id', 'molecule_chembl_id', 'Ki', 'units',\n       'data_validity_comment', 'confidence_score'],\n      dtype='object')\n\n\n\ncpds_df.columns\n\nIndex(['max_phase', 'molecule_chembl_id', 'smiles'], dtype='object')\n\n\nClearly, the column that existed in both dataframes was the “molecule_chembl_id” column.\nThe next step was to combine or merge both datasets.\n\n# Create a final dataframe that will contain both bioactivity and compound data\ndtree_df = pd.merge(\n    bioact_assay_df[[\"molecule_chembl_id\",\"Ki\", \"units\", \"data_validity_comment\"]],\n    cpds_df,\n    on = \"molecule_chembl_id\",\n)\n\ndtree_df.head(3)\n\n\n\n\n\n  \n    \n      \n      molecule_chembl_id\n      Ki\n      units\n      data_validity_comment\n      max_phase\n      smiles\n    \n  \n  \n    \n      0\n      CHEMBL11805\n      0.104\n      nM\n      Potential transcription error\n      None\n      COc1ccccc1CN(C)CCCCCC(=O)N(C)CCCCCCCCN(C)C(=O)...\n    \n    \n      1\n      CHEMBL60745\n      1.630\n      nM\n      None\n      None\n      CC[N+](C)(C)c1cccc(O)c1.[Br-]\n    \n    \n      2\n      CHEMBL208599\n      0.026\n      nM\n      None\n      None\n      CCC1=CC2Cc3nc4cc(Cl)ccc4c(N)c3[C@@H](C1)C2\n    \n  \n\n\n\n\nShape of the final dataframe was checked.\n\nprint(dtree_df.shape)\n\n(540, 6)\n\n\nSaving a copy of the merged dataframe for now to avoid re-running the previous code repeatedly, and also to be ready for second-half of the data preprocessing work, which will be in post 2.\n\ndtree_df.to_csv(\"ache_chembl.csv\")\n\n\n\n\n\n\nReferences\n\nKalliokoski, Tuomo, Christian Kramer, Anna Vulpetti, and Peter Gedeck. 2013. “Comparability of Mixed IC50 Data  A Statistical Analysis.” Edited by Andrea Cavalli. PLoS ONE 8 (4): e61007. https://doi.org/10.1371/journal.pone.0061007.\n\n\nKramer, Christian, Tuomo Kalliokoski, Peter Gedeck, and Anna Vulpetti. 2012. “The Experimental Uncertainty of Heterogeneous Public Ki Data.” Journal of Medicinal Chemistry 55 (11): 5165–73. https://doi.org/10.1021/jm300131x.\n\n\nTilborg, Derek van, Alisa Alenicheva, and Francesca Grisoni. 2022. “Exposing the Limitations of Molecular Machine Learning with Activity Cliffs.” Journal of Chemical Information and Modeling 62 (23): 5938–51. https://doi.org/10.1021/acs.jcim.2c01073."
  },
  {
    "objectID": "posts/16_ML2-1_Decision_tree/2_data_prep_tran.html",
    "href": "posts/16_ML2-1_Decision_tree/2_data_prep_tran.html",
    "title": "Decision tree",
    "section": "",
    "text": "Data source\nThe data used in this post 2 for data preprocessing was extracted from ChEMBL database by using ChEMBL web resource client in Python. The details of all the steps taken to reach the final .csv file could be seen in post 1.\n\n\n\nChecklist for preprocessing ChEMBL compound data\nBelow was a checklist summary for post 1 and post 2 (current post), and was highly inspired by this journal paper (Tilborg, Alenicheva, and Grisoni 2022) and also ChEMBL’s FAQ on “Assay and Activity Questions”.\nNote: not an exhaustive list, only a suggestion from my experience working on this series, may need to tailor to different scenarios\nFor molecular data containing chemical compounds, check for:\n\nduplicates\nmissing values\nsalts or mixture\n\nCheck the consistency of structural annotations:\n\nmolecular validity\nmolecular sanity\ncharge standardisation\nstereochemistry\n\nCheck the reliability of reported experimental values (e.g. activity values like IC50, Ki, EC50 etc.):\n\nannotated validity (data_validity_comment)\npresence of outliers\nconfidence score (assays)\nstandard deviation of multiple entries (if applicable)\n\n\n\n\nImport libraries\n\n# Import all libraries used\nimport pandas as pd\nimport math\nfrom rdkit.Chem import Descriptors\nimport datamol as dm\n# tqdm library used in datamol's batch descriptor code\nfrom tqdm import tqdm\nimport mols2grid\n\n\n\n\nRe-import saved data\nRe-imported the partly preprocessed data from the earlier post.\n\ndtree_df = pd.read_csv(\"ache_chembl.csv\")\ndtree_df.head(3)\n\n\n\n\n\n  \n    \n      \n      Unnamed: 0\n      molecule_chembl_id\n      Ki\n      units\n      data_validity_comment\n      max_phase\n      smiles\n    \n  \n  \n    \n      0\n      0\n      CHEMBL11805\n      0.104\n      nM\n      Potential transcription error\n      NaN\n      COc1ccccc1CN(C)CCCCCC(=O)N(C)CCCCCCCCN(C)C(=O)...\n    \n    \n      1\n      1\n      CHEMBL60745\n      1.630\n      nM\n      NaN\n      NaN\n      CC[N+](C)(C)c1cccc(O)c1.[Br-]\n    \n    \n      2\n      2\n      CHEMBL208599\n      0.026\n      nM\n      NaN\n      NaN\n      CCC1=CC2Cc3nc4cc(Cl)ccc4c(N)c3[C@@H](C1)C2\n    \n  \n\n\n\n\nThere was an extra index column (named “Unnamed: 0”) here, which was likely inherited from how the .csv file was saved with the index already in place from part 1, so this column was dropped for now.\n\ndtree_df = dtree_df.drop(\"Unnamed: 0\", axis = 1)\ndtree_df.head(3)\n\n\n\n\n\n  \n    \n      \n      molecule_chembl_id\n      Ki\n      units\n      data_validity_comment\n      max_phase\n      smiles\n    \n  \n  \n    \n      0\n      CHEMBL11805\n      0.104\n      nM\n      Potential transcription error\n      NaN\n      COc1ccccc1CN(C)CCCCCC(=O)N(C)CCCCCCCCN(C)C(=O)...\n    \n    \n      1\n      CHEMBL60745\n      1.630\n      nM\n      NaN\n      NaN\n      CC[N+](C)(C)c1cccc(O)c1.[Br-]\n    \n    \n      2\n      CHEMBL208599\n      0.026\n      nM\n      NaN\n      NaN\n      CCC1=CC2Cc3nc4cc(Cl)ccc4c(N)c3[C@@H](C1)C2\n    \n  \n\n\n\n\n\n\n\nCalculate pKi\nThe distribution of Ki values were shown below via a simple statistical summary.\n\ndtree_df[\"Ki\"].describe()\n\ncount    5.400000e+02\nmean     2.544039e+05\nstd      4.103437e+06\nmin      1.700000e-03\n25%      2.437500e+01\n50%      1.995000e+02\n75%      3.100000e+03\nmax      9.496300e+07\nName: Ki, dtype: float64\n\n\nFrom the above quick statistical summary and also the code below to find the minimum Ki value, it confirmed there were no zero Ki values recorded.\n\ndtree_df[\"Ki\"].min()\n\n0.0017\n\n\nNow the part about converting the Ki values to pKi values, which were the negative logs of Ki in molar units (a PubChem example might help to explain it a little). The key to understand pKi here was to treat pKi similarly to how we normally understand pH for our acids and bases. The formula to convert Ki to pKi for nanomolar (nM) units was:\n\\[\n\\text{pKi} = 9 - log _{10}(Ki)\n\\]\nSet up a small function to do the conversion.\n\ndef calc_pKi(Ki):\n    pKi_value = 9 - math.log10(Ki)\n    return pKi_value\n\nApplying the calc_pKi function to convert all rows of the compound dataset for the “Ki” column.\n\n# Create a new column for pKi\n# Apply calc_pKi function to data in Ki column\ndtree_df[\"pKi\"] = dtree_df.apply(lambda x: calc_pKi(x.Ki), axis = 1)\n\nThe dataframe would now look like this, with a new pKi column (scroll to the very right to see it).\n\ndtree_df.head(3)\n\n\n\n\n\n  \n    \n      \n      molecule_chembl_id\n      Ki\n      units\n      data_validity_comment\n      max_phase\n      smiles\n      pKi\n    \n  \n  \n    \n      0\n      CHEMBL11805\n      0.104\n      nM\n      Potential transcription error\n      NaN\n      COc1ccccc1CN(C)CCCCCC(=O)N(C)CCCCCCCCN(C)C(=O)...\n      9.982967\n    \n    \n      1\n      CHEMBL60745\n      1.630\n      nM\n      NaN\n      NaN\n      CC[N+](C)(C)c1cccc(O)c1.[Br-]\n      8.787812\n    \n    \n      2\n      CHEMBL208599\n      0.026\n      nM\n      NaN\n      NaN\n      CCC1=CC2Cc3nc4cc(Cl)ccc4c(N)c3[C@@H](C1)C2\n      10.585027\n    \n  \n\n\n\n\n\n\n\nPlan other data preprocessing steps\nFor a decision tree model, a few more molecular descriptors were most likely needed rather than only Ki or pKi and SMILES, since I’ve now arrived at the step of planning other preprocessing steps. One way to do this could be through computations based on canonical SMILES of compounds by using RDKit, which would give the RDKit 2D descriptors. In this single tree model, I decided to stick with only RDKit 2D descriptors for now, before adding on fingerprints (as a side note: I have very lightly touched on generating fingerprints in this earlier post - “Molecular similarities in selected COVID-19 antivirals” in the subsection on “Fingerprint generator”).\nAt this stage, a compound sanitisation step should also be applied to the compound column before starting any calculations to rule out compounds with questionable chemical validities. RDKit or Datamol (a Python wrapper library built based on RDKit) was also capable of doing this.\nI’ve added a quick step here to convert the data types of “smiles” and “data_validity_comment” columns to string (in case of running into problems later).\n\ndtree_df = dtree_df.astype({\"smiles\": \"string\", \"data_validity_comment\": \"string\"})\ndtree_df.dtypes\n\nmolecule_chembl_id        object\nKi                       float64\nunits                     object\ndata_validity_comment     string\nmax_phase                float64\nsmiles                    string\npKi                      float64\ndtype: object\n\n\n\n\n\nCheck data validity\nAlso, before jumping straight to compound sanitisation, I needed to check the “data_validity_comment” column.\n\ndtree_df[\"data_validity_comment\"].unique()\n\n<StringArray>\n['Potential transcription error', <NA>, 'Outside typical range']\nLength: 3, dtype: string\n\n\nThere were 3 different types of data validity comments here, which were “Potential transcription error”, “NaN” and “Outside typical range”. So, this meant compounds with comments as “Potential transcription error” and “Outside typical range” should be addressed first.\n\n# Find out number of compounds with \"outside typical range\" as data validity comment\ndtree_df_err = dtree_df[dtree_df[\"data_validity_comment\"] == \"Outside typical range\"]\nprint(dtree_df_err.shape)\ndtree_df_err.head()\n\n(58, 7)\n\n\n\n\n\n\n  \n    \n      \n      molecule_chembl_id\n      Ki\n      units\n      data_validity_comment\n      max_phase\n      smiles\n      pKi\n    \n  \n  \n    \n      111\n      CHEMBL225198\n      0.0090\n      nM\n      Outside typical range\n      NaN\n      O=C(CCc1c[nH]c2ccccc12)NCCCCCCCNc1c2c(nc3cc(Cl...\n      11.045757\n    \n    \n      114\n      CHEMBL225021\n      0.0017\n      nM\n      Outside typical range\n      NaN\n      O=C(CCCc1c[nH]c2ccccc12)NCCCCCNc1c2c(nc3cc(Cl)...\n      11.769551\n    \n    \n      118\n      CHEMBL402976\n      313700.0000\n      nM\n      Outside typical range\n      NaN\n      CN(C)CCOC(=O)Nc1ccncc1\n      3.503485\n    \n    \n      119\n      CHEMBL537454\n      140200.0000\n      nM\n      Outside typical range\n      NaN\n      CN(C)CCOC(=O)Nc1cc(Cl)nc(Cl)c1.Cl\n      3.853252\n    \n    \n      120\n      CHEMBL3216883\n      316400.0000\n      nM\n      Outside typical range\n      NaN\n      CN(C)CCOC(=O)Nc1ccncc1Br.Cl.Cl\n      3.499764\n    \n  \n\n\n\n\nThere were a total of 58 compounds with Ki outside typical range.\n\ndtree_df_err2 = dtree_df[dtree_df[\"data_validity_comment\"] == \"Potential transcription error\"]\ndtree_df_err2\n\n\n\n\n\n  \n    \n      \n      molecule_chembl_id\n      Ki\n      units\n      data_validity_comment\n      max_phase\n      smiles\n      pKi\n    \n  \n  \n    \n      0\n      CHEMBL11805\n      0.104\n      nM\n      Potential transcription error\n      NaN\n      COc1ccccc1CN(C)CCCCCC(=O)N(C)CCCCCCCCN(C)C(=O)...\n      9.982967\n    \n  \n\n\n\n\nWith the other comment for potential transciption error, there seemed to be only one compound here.\nThese compounds with questionable Ki values were removed, as they could be potential sources of errors in ML models later on (error trickling effect). One of the ways to filter out data was to fill the empty cells within the “data_validity_comment” column first, so those ones to be kept could be selected.\n\n# Fill \"NaN\" entries with an actual name e.g. none\ndtree_df[\"data_validity_comment\"].fillna(\"none\", inplace=True)\ndtree_df.head()\n\n\n\n\n\n  \n    \n      \n      molecule_chembl_id\n      Ki\n      units\n      data_validity_comment\n      max_phase\n      smiles\n      pKi\n    \n  \n  \n    \n      0\n      CHEMBL11805\n      0.104\n      nM\n      Potential transcription error\n      NaN\n      COc1ccccc1CN(C)CCCCCC(=O)N(C)CCCCCCCCN(C)C(=O)...\n      9.982967\n    \n    \n      1\n      CHEMBL60745\n      1.630\n      nM\n      none\n      NaN\n      CC[N+](C)(C)c1cccc(O)c1.[Br-]\n      8.787812\n    \n    \n      2\n      CHEMBL208599\n      0.026\n      nM\n      none\n      NaN\n      CCC1=CC2Cc3nc4cc(Cl)ccc4c(N)c3[C@@H](C1)C2\n      10.585027\n    \n    \n      3\n      CHEMBL95\n      151.000\n      nM\n      none\n      4.0\n      Nc1c2c(nc3ccccc13)CCCC2\n      6.821023\n    \n    \n      4\n      CHEMBL173309\n      12.200\n      nM\n      none\n      NaN\n      CCN(CCCCCC(=O)N(C)CCCCCCCCN(C)C(=O)CCCCCN(CC)C...\n      7.913640\n    \n  \n\n\n\n\nFiltered out only the compounds with nil data validity comments.\n\n#dtree_df[\"data_validity_comment\"].unique()\ndtree_df = dtree_df[dtree_df[\"data_validity_comment\"] == \"none\"]\n\nChecking the dtree_df dataframe again and also whether if only the compounds with “none” labelled for “data_validity_comment” column were kept.\n\nprint(dtree_df.shape)\ndtree_df[\"data_validity_comment\"].unique()\n\n(481, 7)\n\n\n<StringArray>\n['none']\nLength: 1, dtype: string\n\n\n\n\n\nSanitise compounds\nThis preprocessing molecules tutorial and reference links provided by Datamol were very informative, and the preprocess function code by Datamol was used below. Each step of fix_mol(), sanitize_mol() and standardize_mol() was explained in this tutorial. I think the key was to select preprocessing options required to fit the purpose of the ML models, and the more experiences in doing this, the more likely it will help with the preprocessing step.\n\n# _preprocess function to sanitise compounds - adapted from datamol.io\n\nsmiles_column = \"smiles\"\n\ndm.disable_rdkit_log()\n\ndef _preprocess(row):\n    # Convert each compound to a RDKit molecule in the smiles column\n    mol = dm.to_mol(row[smiles_column], ordered=True)\n    # Fix common errors in the molecules\n    mol = dm.fix_mol(mol)\n    # Sanitise the molecules \n    mol = dm.sanitize_mol(mol, sanifix=True, charge_neutral=False)\n    # Standardise the molecules\n    mol = dm.standardize_mol(\n        mol,\n        # Switch on to disconnect metal ions\n        disconnect_metals=True,\n        normalize=True,\n        reionize=True,\n        # Switch on \"uncharge\" to neutralise charges\n        uncharge=True,\n        # Taking care of stereochemistries of compounds\n        stereo=True,\n    )\n\n    # Added a new column below for RDKit molecules\n    row[\"rdkit_mol\"] = dm.to_mol(mol)\n    row[\"standard_smiles\"] = dm.standardize_smiles(dm.to_smiles(mol))\n    row[\"selfies\"] = dm.to_selfies(mol)\n    row[\"inchi\"] = dm.to_inchi(mol)\n    row[\"inchikey\"] = dm.to_inchikey(mol)\n    return row\n\nThen the compound sanitisation function was applied to the dtree_df.\n\ndtree_san_df = dtree_df.apply(_preprocess, axis = 1)\ndtree_san_df.head()\n\n\n\n\n\n  \n    \n      \n      molecule_chembl_id\n      Ki\n      units\n      data_validity_comment\n      max_phase\n      smiles\n      pKi\n      rdkit_mol\n      standard_smiles\n      selfies\n      inchi\n      inchikey\n    \n  \n  \n    \n      1\n      CHEMBL60745\n      1.630\n      nM\n      none\n      NaN\n      CC[N+](C)(C)c1cccc(O)c1.[Br-]\n      8.787812\n      <rdkit.Chem.rdchem.Mol object at 0x120080f90>\n      CC[N+](C)(C)c1cccc(O)c1.[Br-]\n      [C][C][N+1][Branch1][C][C][Branch1][C][C][C][=...\n      InChI=1S/C10H15NO.BrH/c1-4-11(2,3)9-6-5-7-10(1...\n      CAEPIUXAUPYIIJ-UHFFFAOYSA-N\n    \n    \n      2\n      CHEMBL208599\n      0.026\n      nM\n      none\n      NaN\n      CCC1=CC2Cc3nc4cc(Cl)ccc4c(N)c3[C@@H](C1)C2\n      10.585027\n      <rdkit.Chem.rdchem.Mol object at 0x120081cb0>\n      CCC1=CC2Cc3nc4cc(Cl)ccc4c(N)c3[C@@H](C1)C2\n      [C][C][C][=C][C][C][C][=N][C][=C][C][Branch1][...\n      InChI=1S/C18H19ClN2/c1-2-10-5-11-7-12(6-10)17-...\n      QTPHSDHUHXUYFE-KIYNQFGBSA-N\n    \n    \n      3\n      CHEMBL95\n      151.000\n      nM\n      none\n      4.0\n      Nc1c2c(nc3ccccc13)CCCC2\n      6.821023\n      <rdkit.Chem.rdchem.Mol object at 0x120081700>\n      Nc1c2c(nc3ccccc13)CCCC2\n      [N][C][=C][C][=Branch1][N][=N][C][=C][C][=C][C...\n      InChI=1S/C13H14N2/c14-13-9-5-1-3-7-11(9)15-12-...\n      YLJREFDVOIBQDA-UHFFFAOYSA-N\n    \n    \n      4\n      CHEMBL173309\n      12.200\n      nM\n      none\n      NaN\n      CCN(CCCCCC(=O)N(C)CCCCCCCCN(C)C(=O)CCCCCN(CC)C...\n      7.913640\n      <rdkit.Chem.rdchem.Mol object at 0x1200af450>\n      CCN(CCCCCC(=O)N(C)CCCCCCCCN(C)C(=O)CCCCCN(CC)C...\n      [C][C][N][Branch2][Branch1][Ring1][C][C][C][C]...\n      InChI=1S/C42H70N4O4/c1-7-45(35-37-25-17-19-27-...\n      VJXLWYGKZGTXAF-UHFFFAOYSA-N\n    \n    \n      5\n      CHEMBL1128\n      200.000\n      nM\n      none\n      4.0\n      CC[N+](C)(C)c1cccc(O)c1.[Cl-]\n      6.698970\n      <rdkit.Chem.rdchem.Mol object at 0x1200af3e0>\n      CC[N+](C)(C)c1cccc(O)c1.[Cl-]\n      [C][C][N+1][Branch1][C][C][Branch1][C][C][C][=...\n      InChI=1S/C10H15NO.ClH/c1-4-11(2,3)9-6-5-7-10(1...\n      BXKDSDJJOVIHMX-UHFFFAOYSA-N\n    \n  \n\n\n\n\nIf the dataset required for sanitisation is large, Datamol has suggested using their example code to add parallelisation as shown below.\n```{python}\n# Code adapted from: https://docs.datamol.io/stable/tutorials/Preprocessing.html#references\ndata_clean = dm.parallelized(\n    _preprocess, \n    data.iterrows(), \n    arg_type=\"args\", \n    progress=True, \n    total=len(data)\n    )\ndata_clean = pd.DataFrame(data_clean)\n```\n\ndtree_san_df.shape\n\n(481, 12)\n\n\nIn this case, I tried using the preprocessing function without adding parallelisation, the whole process wasn’t very long (since I had a small dataset), and was done within a minute or so.\nAlso, as a sanity check on the sanitised compounds in dtree_san_df, I just wanted to see if I could display all compounds in this dataframe as 2D images. I also had a look through each page just to see if there were any odd bonds or anything strange in general.\n\n# Create a list to store all cpds in dtree_san_df\nmol_list = dtree_san_df[\"rdkit_mol\"]\n# Convert to list\nmol_list = list(mol_list)\n# Check data type\ntype(mol_list)\n# Show 2D compound structures in grids\nmols2grid.display(mol_list)\n\n\n\n\n\n\n\n\n\n\n\nDetect outliers\nPlotting a histogram to see the distribution of pKi values first.\n\ndtree_san_df.hist(column = \"pKi\")\n\narray([[<AxesSubplot: title={'center': 'pKi'}>]], dtype=object)\n\n\n\n\n\nI read a bit about Dixon’s Q test and realised that there were a few required assumptions prior to using this test, and the current dataset used here (dtree_san_df) might not fit the requirements, which were:\n\nnormally distributed data\na small sample size e.g. between 3 and 10, which was originally stated in this paper (Dean and Dixon 1951).\n\nI’ve also decided that rather than showing Python code for Dixon’s Q test myself, I would attach a few examples from others instead, for example, Q test from Plotly and Dixon’s Q test for outlier identification – a questionable practice, since this dataset here wasn’t quite normally distributed as shown from the histogram above.\n\ndtree_san_df.boxplot(column = \"pKi\")\n\n# the boxplot version below shows a blank background\n# rather than above version with horizontal grid lines\n#dtree_san_df.plot.box(column = \"pKi\")\n\n<AxesSubplot: >\n\n\n\n\n\nI also used Pandas’ built-in boxplot in addition to the histogram to show the possible outliers within the pKi values. Clearly, the outliers for pKi values appeared to be above 10. I also didn’t remove these outliers completely due to the dataset itself wasn’t quite in a Gaussian distribution (they might not be true outliers).\n\n\n\nCalculate RDKit 2D molecular descriptors\nI’ve explored a few different ways to compute molecular descriptors, essentially RDKit was used as the main library to do this (there might be other options via other programming languages, but I was only exploring RDKit-based methods via Python for now). A blog post I’ve come across on calculating RDKit 2D molecular descriptors has explained it well, it gave details about how to bundle the functions together in a class (the idea of building a small library yourself to be used in projects was quite handy). I’ve also read RDKit’s documentations and also the ones from Datamol. So rather than re-inventing the wheels of all the RDKit code, I’ve opted to use only a small chunk of RDKit code as a demonstration, then followed by Datamol’s version to compute the 2D descriptors, since there were already a few really well-explained blog posts about this. One of the examples was this useful descriptor calculation tutorial by Greg Landrum.\n\n\nRDKit code\nWith the lastest format of the dtree_san_df, it already included a RDKit molecule column (named “rdkit_mol”), so this meant I could go ahead with the calculations. So here I used RDKit’s Descriptors.CalcMolDescriptors() to calculate the 2D descriptors - note: there might be more code variations depending on needs, this was just a small example.\n\n# Run descriptor calculations on mol_list (created earlier)\n# and save as a new list\nmol_rdkit_ls = [Descriptors.CalcMolDescriptors(mol) for mol in mol_list]\n\n# Convert the list into a dataframe\ndf_rdkit_2d = pd.DataFrame(mol_rdkit_ls)\nprint(df_rdkit_2d.shape)\ndf_rdkit_2d.head(3)\n\n(481, 209)\n\n\n\n\n\n\n  \n    \n      \n      MaxAbsEStateIndex\n      MaxEStateIndex\n      MinAbsEStateIndex\n      MinEStateIndex\n      qed\n      MolWt\n      HeavyAtomMolWt\n      ExactMolWt\n      NumValenceElectrons\n      NumRadicalElectrons\n      ...\n      fr_sulfide\n      fr_sulfonamd\n      fr_sulfone\n      fr_term_acetylene\n      fr_tetrazole\n      fr_thiazole\n      fr_thiocyan\n      fr_thiophene\n      fr_unbrch_alkane\n      fr_urea\n    \n  \n  \n    \n      0\n      9.261910\n      9.261910\n      0.000000\n      0.000000\n      0.662462\n      246.148\n      230.020\n      245.041526\n      74\n      0\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      1\n      6.509708\n      6.509708\n      0.547480\n      0.547480\n      0.763869\n      298.817\n      279.665\n      298.123676\n      108\n      0\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      2\n      6.199769\n      6.199769\n      0.953981\n      0.953981\n      0.706488\n      198.269\n      184.157\n      198.115698\n      76\n      0\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n  \n\n3 rows × 209 columns\n\n\n\nIn total, it generated 209 descriptors.\n\n\n\nDatamol code\nThen I tested Datamol’s code on this as shown below.\n\n# Datamol's batch descriptor code for a list of compounds\ndtree_san_df_dm = dm.descriptors.batch_compute_many_descriptors(mol_list)\nprint(dtree_san_df_dm.shape)\ndtree_san_df_dm.head(3)\n\n(481, 22)\n\n\n\n\n\n\n  \n    \n      \n      mw\n      fsp3\n      n_lipinski_hba\n      n_lipinski_hbd\n      n_rings\n      n_hetero_atoms\n      n_heavy_atoms\n      n_rotatable_bonds\n      n_radical_electrons\n      tpsa\n      ...\n      sas\n      n_aliphatic_carbocycles\n      n_aliphatic_heterocyles\n      n_aliphatic_rings\n      n_aromatic_carbocycles\n      n_aromatic_heterocyles\n      n_aromatic_rings\n      n_saturated_carbocycles\n      n_saturated_heterocyles\n      n_saturated_rings\n    \n  \n  \n    \n      0\n      245.041526\n      0.400000\n      2\n      1\n      1\n      3\n      13\n      2\n      0\n      20.23\n      ...\n      3.185866\n      0\n      0\n      0\n      1\n      0\n      1\n      0\n      0\n      0\n    \n    \n      1\n      298.123676\n      0.388889\n      2\n      2\n      4\n      3\n      21\n      1\n      0\n      38.91\n      ...\n      4.331775\n      2\n      0\n      2\n      1\n      1\n      2\n      0\n      0\n      0\n    \n    \n      2\n      198.115698\n      0.307692\n      2\n      2\n      3\n      2\n      15\n      0\n      0\n      38.91\n      ...\n      2.014719\n      1\n      0\n      1\n      1\n      1\n      2\n      0\n      0\n      0\n    \n  \n\n3 rows × 22 columns\n\n\n\nThere were a total of 22 molecular descriptors generated, which seemed more like what I might use for the decision tree model. The limitation with this batch descriptor code was that the molecular features were pre-selected, so if other types were needed, it would be the best to go for RDKit code or look into other Datamol descriptor code that allow users to specify features. The types of descriptors were shown below.\n\ndtree_san_df_dm.columns\n\nIndex(['mw', 'fsp3', 'n_lipinski_hba', 'n_lipinski_hbd', 'n_rings',\n       'n_hetero_atoms', 'n_heavy_atoms', 'n_rotatable_bonds',\n       'n_radical_electrons', 'tpsa', 'qed', 'clogp', 'sas',\n       'n_aliphatic_carbocycles', 'n_aliphatic_heterocyles',\n       'n_aliphatic_rings', 'n_aromatic_carbocycles', 'n_aromatic_heterocyles',\n       'n_aromatic_rings', 'n_saturated_carbocycles',\n       'n_saturated_heterocyles', 'n_saturated_rings'],\n      dtype='object')\n\n\n\n\n\n\nCombine dataframes\nThe trickier part for data preprocessing was actually trying to merge, join or concatenate dataframes of the preprocessed dataframe (dtree_san_df) and the dataframe from Datamol’s descriptor code (dtree_san_df_dm).\nInitially, I tried using all of Pandas’ code of merge/join/concat() dataframes. They all failed to create the correct final combined dataframe with too many rows generated, with one run actually created more than 500 rows (maximum should be 481 rows). One of the possible reasons for this could be that some of the descriptors had zeros generated as results for some of the compounds, and when combining dataframes using Pandas code like the ones mentioned here, they might cause unexpected results (as suggested by Pandas, these code were not exactly equivalent to SQL joins). So I looked into different ways, and while there were no other common columns for both dataframes, the index column seemed to be the only one that correlated both.\nI also found out after going back to the previous steps that when I applied the compound preprocessing function from Datamol, the index of the resultant dataframe was changed to start from 1 (rather than zero). Because of this, I tried re-setting the index of dtree_san_df first, then dropped the index column, followed by re-setting the index again to ensure it started at zero, which has worked. So now the dtree_san_df would have exactly the same index as the one for dtree_san_df_dm.\n\n# 1st index re-set\ndtree_san_df = dtree_san_df.reset_index()\n# Drop the index column\ndtree_san_df = dtree_san_df.drop([\"index\"], axis = 1)\ndtree_san_df.head(3)\n\n\n\n\n\n  \n    \n      \n      molecule_chembl_id\n      Ki\n      units\n      data_validity_comment\n      max_phase\n      smiles\n      pKi\n      rdkit_mol\n      standard_smiles\n      selfies\n      inchi\n      inchikey\n    \n  \n  \n    \n      0\n      CHEMBL60745\n      1.630\n      nM\n      none\n      NaN\n      CC[N+](C)(C)c1cccc(O)c1.[Br-]\n      8.787812\n      <rdkit.Chem.rdchem.Mol object at 0x120080f90>\n      CC[N+](C)(C)c1cccc(O)c1.[Br-]\n      [C][C][N+1][Branch1][C][C][Branch1][C][C][C][=...\n      InChI=1S/C10H15NO.BrH/c1-4-11(2,3)9-6-5-7-10(1...\n      CAEPIUXAUPYIIJ-UHFFFAOYSA-N\n    \n    \n      1\n      CHEMBL208599\n      0.026\n      nM\n      none\n      NaN\n      CCC1=CC2Cc3nc4cc(Cl)ccc4c(N)c3[C@@H](C1)C2\n      10.585027\n      <rdkit.Chem.rdchem.Mol object at 0x120081cb0>\n      CCC1=CC2Cc3nc4cc(Cl)ccc4c(N)c3[C@@H](C1)C2\n      [C][C][C][=C][C][C][C][=N][C][=C][C][Branch1][...\n      InChI=1S/C18H19ClN2/c1-2-10-5-11-7-12(6-10)17-...\n      QTPHSDHUHXUYFE-KIYNQFGBSA-N\n    \n    \n      2\n      CHEMBL95\n      151.000\n      nM\n      none\n      4.0\n      Nc1c2c(nc3ccccc13)CCCC2\n      6.821023\n      <rdkit.Chem.rdchem.Mol object at 0x120081700>\n      Nc1c2c(nc3ccccc13)CCCC2\n      [N][C][=C][C][=Branch1][N][=N][C][=C][C][=C][C...\n      InChI=1S/C13H14N2/c14-13-9-5-1-3-7-11(9)15-12-...\n      YLJREFDVOIBQDA-UHFFFAOYSA-N\n    \n  \n\n\n\n\n\n# 2nd index re-set\ndtree_san_df = dtree_san_df.reset_index()\nprint(dtree_san_df.shape)\ndtree_san_df.head(3)\n\n(481, 13)\n\n\n\n\n\n\n  \n    \n      \n      index\n      molecule_chembl_id\n      Ki\n      units\n      data_validity_comment\n      max_phase\n      smiles\n      pKi\n      rdkit_mol\n      standard_smiles\n      selfies\n      inchi\n      inchikey\n    \n  \n  \n    \n      0\n      0\n      CHEMBL60745\n      1.630\n      nM\n      none\n      NaN\n      CC[N+](C)(C)c1cccc(O)c1.[Br-]\n      8.787812\n      <rdkit.Chem.rdchem.Mol object at 0x120080f90>\n      CC[N+](C)(C)c1cccc(O)c1.[Br-]\n      [C][C][N+1][Branch1][C][C][Branch1][C][C][C][=...\n      InChI=1S/C10H15NO.BrH/c1-4-11(2,3)9-6-5-7-10(1...\n      CAEPIUXAUPYIIJ-UHFFFAOYSA-N\n    \n    \n      1\n      1\n      CHEMBL208599\n      0.026\n      nM\n      none\n      NaN\n      CCC1=CC2Cc3nc4cc(Cl)ccc4c(N)c3[C@@H](C1)C2\n      10.585027\n      <rdkit.Chem.rdchem.Mol object at 0x120081cb0>\n      CCC1=CC2Cc3nc4cc(Cl)ccc4c(N)c3[C@@H](C1)C2\n      [C][C][C][=C][C][C][C][=N][C][=C][C][Branch1][...\n      InChI=1S/C18H19ClN2/c1-2-10-5-11-7-12(6-10)17-...\n      QTPHSDHUHXUYFE-KIYNQFGBSA-N\n    \n    \n      2\n      2\n      CHEMBL95\n      151.000\n      nM\n      none\n      4.0\n      Nc1c2c(nc3ccccc13)CCCC2\n      6.821023\n      <rdkit.Chem.rdchem.Mol object at 0x120081700>\n      Nc1c2c(nc3ccccc13)CCCC2\n      [N][C][=C][C][=Branch1][N][=N][C][=C][C][=C][C...\n      InChI=1S/C13H14N2/c14-13-9-5-1-3-7-11(9)15-12-...\n      YLJREFDVOIBQDA-UHFFFAOYSA-N\n    \n  \n\n\n\n\nAlso re-setting the index of the dtree_san_df_dm.\n\ndtree_san_df_dm = dtree_san_df_dm.reset_index()\nprint(dtree_san_df_dm.shape)\ndtree_san_df_dm.head(3)\n\n(481, 23)\n\n\n\n\n\n\n  \n    \n      \n      index\n      mw\n      fsp3\n      n_lipinski_hba\n      n_lipinski_hbd\n      n_rings\n      n_hetero_atoms\n      n_heavy_atoms\n      n_rotatable_bonds\n      n_radical_electrons\n      ...\n      sas\n      n_aliphatic_carbocycles\n      n_aliphatic_heterocyles\n      n_aliphatic_rings\n      n_aromatic_carbocycles\n      n_aromatic_heterocyles\n      n_aromatic_rings\n      n_saturated_carbocycles\n      n_saturated_heterocyles\n      n_saturated_rings\n    \n  \n  \n    \n      0\n      0\n      245.041526\n      0.400000\n      2\n      1\n      1\n      3\n      13\n      2\n      0\n      ...\n      3.185866\n      0\n      0\n      0\n      1\n      0\n      1\n      0\n      0\n      0\n    \n    \n      1\n      1\n      298.123676\n      0.388889\n      2\n      2\n      4\n      3\n      21\n      1\n      0\n      ...\n      4.331775\n      2\n      0\n      2\n      1\n      1\n      2\n      0\n      0\n      0\n    \n    \n      2\n      2\n      198.115698\n      0.307692\n      2\n      2\n      3\n      2\n      15\n      0\n      0\n      ...\n      2.014719\n      1\n      0\n      1\n      1\n      1\n      2\n      0\n      0\n      0\n    \n  \n\n3 rows × 23 columns\n\n\n\nMerged both dataframes of dtree_san_df and dtree_san_df_dm based on their indices.\n\n# merge dtree_san_df & dtree_san_df_dm\ndtree_f_df = pd.merge(\n    dtree_san_df[[\"index\", \"molecule_chembl_id\", \"pKi\", \"max_phase\"]],\n    dtree_san_df_dm,\n    left_index=True,\n    right_index=True\n)\n\nChecking final dataframe to make sure there were 481 rows (also that index_x and index_y were identical) and also there was an increased number of columns (columns combined from both dataframes). So this finally seemed to work.\n\nprint(dtree_f_df.shape)\ndtree_f_df.head(3)\n\n(481, 27)\n\n\n\n\n\n\n  \n    \n      \n      index_x\n      molecule_chembl_id\n      pKi\n      max_phase\n      index_y\n      mw\n      fsp3\n      n_lipinski_hba\n      n_lipinski_hbd\n      n_rings\n      ...\n      sas\n      n_aliphatic_carbocycles\n      n_aliphatic_heterocyles\n      n_aliphatic_rings\n      n_aromatic_carbocycles\n      n_aromatic_heterocyles\n      n_aromatic_rings\n      n_saturated_carbocycles\n      n_saturated_heterocyles\n      n_saturated_rings\n    \n  \n  \n    \n      0\n      0\n      CHEMBL60745\n      8.787812\n      NaN\n      0\n      245.041526\n      0.400000\n      2\n      1\n      1\n      ...\n      3.185866\n      0\n      0\n      0\n      1\n      0\n      1\n      0\n      0\n      0\n    \n    \n      1\n      1\n      CHEMBL208599\n      10.585027\n      NaN\n      1\n      298.123676\n      0.388889\n      2\n      2\n      4\n      ...\n      4.331775\n      2\n      0\n      2\n      1\n      1\n      2\n      0\n      0\n      0\n    \n    \n      2\n      2\n      CHEMBL95\n      6.821023\n      4.0\n      2\n      198.115698\n      0.307692\n      2\n      2\n      3\n      ...\n      2.014719\n      1\n      0\n      1\n      1\n      1\n      2\n      0\n      0\n      0\n    \n  \n\n3 rows × 27 columns\n\n\n\nThe two index columns (“index_x” and “index_y”) were removed, which brought out the final preprocessed dataframe.\n\n# Remove index_x & index_y\ndtree_f_df.drop([\"index_x\", \"index_y\"], axis = 1, inplace = True)\ndtree_f_df.head(3)\n\n\n\n\n\n  \n    \n      \n      molecule_chembl_id\n      pKi\n      max_phase\n      mw\n      fsp3\n      n_lipinski_hba\n      n_lipinski_hbd\n      n_rings\n      n_hetero_atoms\n      n_heavy_atoms\n      ...\n      sas\n      n_aliphatic_carbocycles\n      n_aliphatic_heterocyles\n      n_aliphatic_rings\n      n_aromatic_carbocycles\n      n_aromatic_heterocyles\n      n_aromatic_rings\n      n_saturated_carbocycles\n      n_saturated_heterocyles\n      n_saturated_rings\n    \n  \n  \n    \n      0\n      CHEMBL60745\n      8.787812\n      NaN\n      245.041526\n      0.400000\n      2\n      1\n      1\n      3\n      13\n      ...\n      3.185866\n      0\n      0\n      0\n      1\n      0\n      1\n      0\n      0\n      0\n    \n    \n      1\n      CHEMBL208599\n      10.585027\n      NaN\n      298.123676\n      0.388889\n      2\n      2\n      4\n      3\n      21\n      ...\n      4.331775\n      2\n      0\n      2\n      1\n      1\n      2\n      0\n      0\n      0\n    \n    \n      2\n      CHEMBL95\n      6.821023\n      4.0\n      198.115698\n      0.307692\n      2\n      2\n      3\n      2\n      15\n      ...\n      2.014719\n      1\n      0\n      1\n      1\n      1\n      2\n      0\n      0\n      0\n    \n  \n\n3 rows × 25 columns\n\n\n\nI then saved this preprocessed dataframe as another file in my working directory, so that it could be used for estimating experimental errors and model building in the next post.\n\ndtree_f_df.to_csv(\"ache_2d_chembl.csv\")\n\n\n\n\nData preprocessing reflections\nIn general, the order of steps could be swapped in a more logical way. The subsections presented in this post bascially reflected my thought processes, as there were some back-and-forths. The whole data preprocessing step was probably still not thorough enough, but I’ve tried to cover as much as I could (hopefully I didn’t go overboard with it…). Also, it might still not be ideal to use Ki values this freely as mentioned in post 1 (noises in data issues).\nIt was mentioned in scikit-learn that for decision tree models, because of its non-parametric nature, there were not a lot of data cleaning required. However, I think that might be domain-specific, since for the purpose of drug discovery, if this step wasn’t done properly, whatever result that came out of the ML model most likely would not work and also would not reflect real-life scenarios. I was also planning on extending this series to add more trees to the model, that is, from one tree (decision tree), to multiple trees (random forests), and then hopefully move on to boosted trees (XGBoost and LightGBM). Therefore, I’d better do this data cleaning step well first to save some time later (if using the same set of data).\nNext post will be about model building using scikit-learn and also a small part on estimating experimental errors on the dataset - this is going to be in post 3.\n\n\n\n\n\nReferences\n\nDean, R. B., and W. J. Dixon. 1951. “Simplified Statistics for Small Numbers of Observations.” Analytical Chemistry 23 (4): 636–38. https://doi.org/10.1021/ac60052a025.\n\n\nTilborg, Derek van, Alisa Alenicheva, and Francesca Grisoni. 2022. “Exposing the Limitations of Molecular Machine Learning with Activity Cliffs.” Journal of Chemical Information and Modeling 62 (23): 5938–51. https://doi.org/10.1021/acs.jcim.2c01073."
  },
  {
    "objectID": "posts/16_ML2-1_Decision_tree/3_model_build.html",
    "href": "posts/16_ML2-1_Decision_tree/3_model_build.html",
    "title": "Decision tree",
    "section": "",
    "text": "Post updated on 28th April 2024 - dtreeviz code (under the “Model building” section) were updated to improve the scale of the dtreeviz tree plot\n\n\nData source\nThe data used here was extracted from ChEMBL database by using ChEMBL web resource client in Python. The details of all the steps taken to reach the final .csv file could be seen in these earlier posts - post 1 and post 2 (yes, it took quite a while to clean the data, so it was splitted into two posts).\n\nThe final .csv file used to train the model was named, “ache_2d_chembl.csv”\nThe earlier version without any RDKit 2D descriptors calculated was named, “ache_chembl.csv”\nBoth files should be in a GitHub repository called, “ML2-1_decision_tree” or in my blog repository, under “posts” folder (look for “16_ML2-1_Decision_tree” folder)\n\n\n\n\nEstimate experimental errors\nThis part was about estimating the impact of experimental errors (pKi values) on the predictive machine learning (ML) models. It was also needed to estimate the maximum possible correlation that could be drawn from the dataset prepared from the previous two posts. I supposed it made more sense if this was done prior to building the ML model, so this wouldn’t be forgotten or missed, as we know that real-life is full of many imperfections.\nThis subsection was inspired by Pat Walters’ posts, which have discussed about estimating errors for experimental data with code links available in these posts:\n\nHow Good Could (Should) My Models Be? - a reference paper (Brown, Muchmore, and Hajduk 2009) was mentioned as the simulation basis for estimating the impact of experimental errors on the correlation from a predictive ML model\nGetting Real with Molecular Property Prediction (under subsection of “How Well Should We Be Able to Model the Data?”)\n\nTo get started, all the required libraries were loaded as below.\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.metrics import r2_score\nimport seaborn as sns\nfrom sklearn import tree\n\nImported the preprocessed data from previous posts.\n\n# Import data\ndtree = pd.read_csv(\"ache_2d_chembl.csv\")\ndtree.drop(columns = [\"Unnamed: 0\"], inplace=True)\ndtree.head()\n\n\n\n\n\n  \n    \n      \n      molecule_chembl_id\n      pKi\n      max_phase\n      mw\n      fsp3\n      n_lipinski_hba\n      n_lipinski_hbd\n      n_rings\n      n_hetero_atoms\n      n_heavy_atoms\n      ...\n      sas\n      n_aliphatic_carbocycles\n      n_aliphatic_heterocyles\n      n_aliphatic_rings\n      n_aromatic_carbocycles\n      n_aromatic_heterocyles\n      n_aromatic_rings\n      n_saturated_carbocycles\n      n_saturated_heterocyles\n      n_saturated_rings\n    \n  \n  \n    \n      0\n      CHEMBL60745\n      8.787812\n      NaN\n      245.041526\n      0.400000\n      2\n      1\n      1\n      3\n      13\n      ...\n      3.185866\n      0\n      0\n      0\n      1\n      0\n      1\n      0\n      0\n      0\n    \n    \n      1\n      CHEMBL208599\n      10.585027\n      NaN\n      298.123676\n      0.388889\n      2\n      2\n      4\n      3\n      21\n      ...\n      4.331775\n      2\n      0\n      2\n      1\n      1\n      2\n      0\n      0\n      0\n    \n    \n      2\n      CHEMBL95\n      6.821023\n      4.0\n      198.115698\n      0.307692\n      2\n      2\n      3\n      2\n      15\n      ...\n      2.014719\n      1\n      0\n      1\n      1\n      1\n      2\n      0\n      0\n      0\n    \n    \n      3\n      CHEMBL173309\n      7.913640\n      NaN\n      694.539707\n      0.666667\n      8\n      0\n      2\n      8\n      50\n      ...\n      2.803680\n      0\n      0\n      0\n      2\n      0\n      2\n      0\n      0\n      0\n    \n    \n      4\n      CHEMBL1128\n      6.698970\n      4.0\n      201.092042\n      0.400000\n      2\n      1\n      1\n      3\n      13\n      ...\n      3.185866\n      0\n      0\n      0\n      1\n      0\n      1\n      0\n      0\n      0\n    \n  \n\n5 rows × 25 columns\n\n\n\nThe pKi column was used in the code below as it contained the experimental values (calculated from measured Ki values, usually derived from countless lab experiments) collected from different scientific literatures or other sources as stated in ChEMBL. The aim was to simulate pKi values with experimental errors added to them.\nCode used for the rest of the subsection were adapted with thanks from Pat Walters’ “maximum_correlation.ipynb” with my own added comments for further explanations\n\n# Save exp data (pKi) as an object\ndata = dtree[\"pKi\"]\n# Save the object as a list\ndata_ls = [data]\n\n# Trial 3-, 5- & 10-fold errors\nfor fold in (3, 5, 10):\n    # Retrieve error samples randomly from a normal distribution\n    # Bewteen 0 and log10 of number-fold \n    # for the length of provided data only\n    error = np.random.normal(0, np.log10(fold), len(data))\n    data_ls.append(error + data)\n\n# Convert data_ls to dataframe\ndtree_err = pd.DataFrame(data_ls)\n# Re-align dataframe (switch column header & index)\ndtree_err = dtree_err.transpose()\n# Rename columns\ndtree_err.columns = [\"pKi\", \"3-fold\", \"5-fold\", \"10-fold\"]\nprint(dtree_err.shape)\ndtree_err.head()\n\n(481, 4)\n\n\n\n\n\n\n  \n    \n      \n      pKi\n      3-fold\n      5-fold\n      10-fold\n    \n  \n  \n    \n      0\n      8.787812\n      8.710912\n      9.101193\n      7.471251\n    \n    \n      1\n      10.585027\n      10.883334\n      10.291557\n      9.455301\n    \n    \n      2\n      6.821023\n      6.134753\n      6.799967\n      7.122006\n    \n    \n      3\n      7.913640\n      8.390146\n      7.874722\n      7.209130\n    \n    \n      4\n      6.698970\n      7.359148\n      7.290723\n      5.770489\n    \n  \n\n\n\n\nMelting the created dtree_err so it could be plotted later (noticed there should be an increased number of rows after re-stacking the data).\n\n# Melt the dtree_err dataframe \n# to make error values in one column (for plotting)\ndtree_err_melt = dtree_err.melt(id_vars = \"pKi\")\nprint(dtree_err_melt.shape)\ndtree_err_melt.head()\n\n(1443, 3)\n\n\n\n\n\n\n  \n    \n      \n      pKi\n      variable\n      value\n    \n  \n  \n    \n      0\n      8.787812\n      3-fold\n      8.710912\n    \n    \n      1\n      10.585027\n      3-fold\n      10.883334\n    \n    \n      2\n      6.821023\n      3-fold\n      6.134753\n    \n    \n      3\n      7.913640\n      3-fold\n      8.390146\n    \n    \n      4\n      6.698970\n      3-fold\n      7.359148\n    \n  \n\n\n\n\nPresenting this in regression plots.\nNote: There was a matplotlib bug which would always show a tight_layout user warning for FacetGrid plots in seaborn (the lmplot used below). Seaborn was built based on matplotlib so unsurprisingly this occurred (this GitHub issue link might explain it). I have therefore temporarily silenced this user warning for the sake of post publication.\n\n# To silence the tight-layout user warning\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# variable = error-fold e.g. 3-fold\n# value = pKi value plus error\nsns.set_theme(font_scale = 1.5)\nplot = sns.lmplot(\n    x = \"pKi\", \n    y = \"value\", \n    col = \"variable\", \n    data = dtree_err_melt, \n    # alpha = mark’s opacity (low - more transparent)\n    # s = mark size (increase with higher number)\n    scatter_kws = dict(alpha = 0.5, s = 15)\n    )\ntitle_list = [\"3-fold\", \"5-fold\", \"10-fold\"]\nfor i in range(0, 3):\n    plot.axes[0, i].set_ylabel(\"pKi + error\")\n    plot.axes[0, i].set_title(title_list[i])\n\n\n\n\nSimulating the impact of error on the correlation between experimental pKi and also pKi with errors (3-fold, 5-fold and 10-fold). R2 calculated using scikit-learn was introduced in the code below.\n\n# Calculating r2 score (coefficient of determination) \n# based on 1000 trials for each fold\n# note: data = dtree[\"pKi\"]\n\n# Create an empty list for correlation\ncor_ls = []\nfor fold in [3, 5, 10]:\n    # Set up 1000 trials\n    for i in range(0, 1000):\n        error = np.random.normal(0, np.log10(fold), len(data))\n        cor_ls.append([r2_score(data, data + error), f\"{fold}-fold\"])\n\n# Convert cor_ls into dataframe\nerr_df = pd.DataFrame(cor_ls, columns = [\"r2\", \"fold_error\"])\nerr_df.head()\n\n\n\n\n\n  \n    \n      \n      r2\n      fold_error\n    \n  \n  \n    \n      0\n      0.899830\n      3-fold\n    \n    \n      1\n      0.890129\n      3-fold\n    \n    \n      2\n      0.895605\n      3-fold\n    \n    \n      3\n      0.880796\n      3-fold\n    \n    \n      4\n      0.887374\n      3-fold\n    \n  \n\n\n\n\nPlotting the R2 and fold-errors as violin plots.\n\nsns.set_theme(rc = {\"figure.figsize\": (9, 8)}, font_scale = 1.5)\nvplot = sns.violinplot(x = \"fold_error\", y = \"r2\", data = err_df)\nvplot.set(xlabel = \"Fold error\", ylabel = \"R$^2$\")\n\n[Text(0.5, 0, 'Fold error'), Text(0, 0.5, 'R$^2$')]\n\n\n\n\n\nThis definitely helped a lot with visualising the estimated errors for the experimental Ki values curated in ChEMBL for this specific protein target (CHEMBL220, acetylcholinesterase (AChE)). The larger the error-fold, the lower the R2, and once the experimental error reached 10-fold, we could see an estimated R2 (maximum correlation) with its median sitting below 0.55, indicating a likely poor predictive ML model if it was built based on these data with the estimated 10-fold experimental errors.\n\n\n\nCheck max phase distribution\nAt this stage, I’ve planned to do model training on compounds with max phase 4 (i.e. prescription medicines), so this would somewhat be an attempt to mirror real-life scenarios for the ML prediction model.\nMax phases were assigned to each ChEMBL-curated compound according to this ChEMBL FAQ link (under the question of “What is max phase?”). As quoted from this ChEMBL FAQ link, a max phase 4 compound means:\n\n“Approved (4): A marketed drug e.g. AMINOPHYLLINE (CHEMBL1370561) is an FDA approved drug for treatment of asthma.”\n\nChecking out the actual counts of each max phase group in the dataset.\n\ndtree[[\"molecule_chembl_id\", \"max_phase\"]].groupby(\"max_phase\").count()\n\n\n\n\n\n  \n    \n      \n      molecule_chembl_id\n    \n    \n      max_phase\n      \n    \n  \n  \n    \n      -1.0\n      2\n    \n    \n      2.0\n      2\n    \n    \n      3.0\n      1\n    \n    \n      4.0\n      10\n    \n  \n\n\n\n\nThere was only a very small number of compounds with max phase 4 assigned (a total count of 10, which was also unsurprising since there weren’t many AChE inhibitors used as prescription medications for dementia - some of the well-known examples were donepezil, galantamine and rivastigmine).\nFilling in actual “null” labels for all “NaN” rows in the “max_phase” columns to help with filtering out these compounds later on.\n\ndtree[\"max_phase\"].fillna(\"null\", inplace=True)\ndtree.head()\n\n\n\n\n\n  \n    \n      \n      molecule_chembl_id\n      pKi\n      max_phase\n      mw\n      fsp3\n      n_lipinski_hba\n      n_lipinski_hbd\n      n_rings\n      n_hetero_atoms\n      n_heavy_atoms\n      ...\n      sas\n      n_aliphatic_carbocycles\n      n_aliphatic_heterocyles\n      n_aliphatic_rings\n      n_aromatic_carbocycles\n      n_aromatic_heterocyles\n      n_aromatic_rings\n      n_saturated_carbocycles\n      n_saturated_heterocyles\n      n_saturated_rings\n    \n  \n  \n    \n      0\n      CHEMBL60745\n      8.787812\n      null\n      245.041526\n      0.400000\n      2\n      1\n      1\n      3\n      13\n      ...\n      3.185866\n      0\n      0\n      0\n      1\n      0\n      1\n      0\n      0\n      0\n    \n    \n      1\n      CHEMBL208599\n      10.585027\n      null\n      298.123676\n      0.388889\n      2\n      2\n      4\n      3\n      21\n      ...\n      4.331775\n      2\n      0\n      2\n      1\n      1\n      2\n      0\n      0\n      0\n    \n    \n      2\n      CHEMBL95\n      6.821023\n      4.0\n      198.115698\n      0.307692\n      2\n      2\n      3\n      2\n      15\n      ...\n      2.014719\n      1\n      0\n      1\n      1\n      1\n      2\n      0\n      0\n      0\n    \n    \n      3\n      CHEMBL173309\n      7.913640\n      null\n      694.539707\n      0.666667\n      8\n      0\n      2\n      8\n      50\n      ...\n      2.803680\n      0\n      0\n      0\n      2\n      0\n      2\n      0\n      0\n      0\n    \n    \n      4\n      CHEMBL1128\n      6.698970\n      4.0\n      201.092042\n      0.400000\n      2\n      1\n      1\n      3\n      13\n      ...\n      3.185866\n      0\n      0\n      0\n      1\n      0\n      1\n      0\n      0\n      0\n    \n  \n\n5 rows × 25 columns\n\n\n\n\n\n\nSanity check on the dataframe\nThis was just another sanity check for myself on the dtree dataframe - making sure there weren’t any “NaN” cells in it (so dropping any “NaN” again, even though I might have already done this as one of the steps during data preprocessing).\n\ndtree.dropna()\nprint(dtree.shape)\ndtree.head()\n\n(481, 25)\n\n\n\n\n\n\n  \n    \n      \n      molecule_chembl_id\n      pKi\n      max_phase\n      mw\n      fsp3\n      n_lipinski_hba\n      n_lipinski_hbd\n      n_rings\n      n_hetero_atoms\n      n_heavy_atoms\n      ...\n      sas\n      n_aliphatic_carbocycles\n      n_aliphatic_heterocyles\n      n_aliphatic_rings\n      n_aromatic_carbocycles\n      n_aromatic_heterocyles\n      n_aromatic_rings\n      n_saturated_carbocycles\n      n_saturated_heterocyles\n      n_saturated_rings\n    \n  \n  \n    \n      0\n      CHEMBL60745\n      8.787812\n      null\n      245.041526\n      0.400000\n      2\n      1\n      1\n      3\n      13\n      ...\n      3.185866\n      0\n      0\n      0\n      1\n      0\n      1\n      0\n      0\n      0\n    \n    \n      1\n      CHEMBL208599\n      10.585027\n      null\n      298.123676\n      0.388889\n      2\n      2\n      4\n      3\n      21\n      ...\n      4.331775\n      2\n      0\n      2\n      1\n      1\n      2\n      0\n      0\n      0\n    \n    \n      2\n      CHEMBL95\n      6.821023\n      4.0\n      198.115698\n      0.307692\n      2\n      2\n      3\n      2\n      15\n      ...\n      2.014719\n      1\n      0\n      1\n      1\n      1\n      2\n      0\n      0\n      0\n    \n    \n      3\n      CHEMBL173309\n      7.913640\n      null\n      694.539707\n      0.666667\n      8\n      0\n      2\n      8\n      50\n      ...\n      2.803680\n      0\n      0\n      0\n      2\n      0\n      2\n      0\n      0\n      0\n    \n    \n      4\n      CHEMBL1128\n      6.698970\n      4.0\n      201.092042\n      0.400000\n      2\n      1\n      1\n      3\n      13\n      ...\n      3.185866\n      0\n      0\n      0\n      1\n      0\n      1\n      0\n      0\n      0\n    \n  \n\n5 rows × 25 columns\n\n\n\n\n\n\nModel building\n\nTraining data based on max phase 4 compounds\nSo here I wanted to separate the collected data by splitting the compounds into two groups based on their assigned max phases. Compounds with max phase 4 were chosen as the training data, and the rest of the compounds with max phases of “null” would be the testing data.\n\n# Create a df for compounds with max phase 4 only\ndtree_mp4 = dtree[dtree[\"max_phase\"] == 4]\ndtree_mp4\n\n\n\n\n\n  \n    \n      \n      molecule_chembl_id\n      pKi\n      max_phase\n      mw\n      fsp3\n      n_lipinski_hba\n      n_lipinski_hbd\n      n_rings\n      n_hetero_atoms\n      n_heavy_atoms\n      ...\n      sas\n      n_aliphatic_carbocycles\n      n_aliphatic_heterocyles\n      n_aliphatic_rings\n      n_aromatic_carbocycles\n      n_aromatic_heterocyles\n      n_aromatic_rings\n      n_saturated_carbocycles\n      n_saturated_heterocyles\n      n_saturated_rings\n    \n  \n  \n    \n      2\n      CHEMBL95\n      6.821023\n      4.0\n      198.115698\n      0.307692\n      2\n      2\n      3\n      2\n      15\n      ...\n      2.014719\n      1\n      0\n      1\n      1\n      1\n      2\n      0\n      0\n      0\n    \n    \n      4\n      CHEMBL1128\n      6.698970\n      4.0\n      201.092042\n      0.400000\n      2\n      1\n      1\n      3\n      13\n      ...\n      3.185866\n      0\n      0\n      0\n      1\n      0\n      1\n      0\n      0\n      0\n    \n    \n      6\n      CHEMBL640\n      6.000000\n      4.0\n      235.168462\n      0.461538\n      4\n      3\n      1\n      4\n      17\n      ...\n      1.791687\n      0\n      0\n      0\n      1\n      0\n      1\n      0\n      0\n      0\n    \n    \n      9\n      CHEMBL502\n      7.688246\n      4.0\n      379.214744\n      0.458333\n      4\n      0\n      4\n      4\n      28\n      ...\n      2.677222\n      1\n      1\n      2\n      2\n      0\n      2\n      0\n      1\n      1\n    \n    \n      131\n      CHEMBL481\n      7.296709\n      4.0\n      586.279135\n      0.515152\n      10\n      1\n      7\n      10\n      43\n      ...\n      3.632560\n      0\n      4\n      4\n      1\n      2\n      3\n      0\n      2\n      2\n    \n    \n      133\n      CHEMBL360055\n      4.431798\n      4.0\n      510.461822\n      0.800000\n      6\n      0\n      1\n      6\n      36\n      ...\n      3.257653\n      0\n      0\n      0\n      1\n      0\n      1\n      0\n      0\n      0\n    \n    \n      160\n      CHEMBL1025\n      5.221849\n      4.0\n      184.066459\n      1.000000\n      3\n      0\n      0\n      5\n      11\n      ...\n      3.345144\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      171\n      CHEMBL659\n      6.522879\n      4.0\n      287.152144\n      0.529412\n      4\n      1\n      4\n      4\n      21\n      ...\n      4.226843\n      1\n      2\n      3\n      1\n      0\n      1\n      0\n      0\n      0\n    \n    \n      180\n      CHEMBL1200970\n      4.607303\n      4.0\n      348.142697\n      0.368421\n      2\n      0\n      3\n      4\n      23\n      ...\n      4.223591\n      0\n      1\n      1\n      2\n      0\n      2\n      0\n      0\n      0\n    \n    \n      195\n      CHEMBL1677\n      6.995679\n      4.0\n      234.092376\n      0.307692\n      2\n      2\n      3\n      3\n      16\n      ...\n      3.218715\n      1\n      0\n      1\n      1\n      1\n      2\n      0\n      0\n      0\n    \n  \n\n10 rows × 25 columns\n\n\n\nMaking sure donepezil and galantamine were in this dtree_mp4 dataframe, so the model training would be based on these medicines and also other max phase 4 AChE inhibitors.\nThe screenshots of both medicines were taken from ChEMBL website:\n\n\n\nScreenshot of donepezil (parent drug form) with its molecule ChEMBL ID\n\n\n\n\n\nScreenshot of galantamine (parent drug form) with its molecule ChEMBL ID\n\n\nThe following regex string check confirmed that these two compounds were in the dtree_mp4 dataframe - row indices 9 and 171 contained these two drugs.\n\nlist_ache_inh = [\"CHEMBL502\", \"CHEMBL659\"]\ndtree_mp4[\"molecule_chembl_id\"].str.contains(r\"|\".join(list_ache_inh))\n\n2      False\n4      False\n6      False\n9       True\n131    False\n133    False\n160    False\n171     True\n180    False\n195    False\nName: molecule_chembl_id, dtype: bool\n\n\nSetting up the features for the training set.\n\n# Set X (features) for max phase 4 compounds\nX_mp4_df = dtree_mp4[['mw', 'fsp3', 'n_lipinski_hba', 'n_lipinski_hbd', 'n_rings', 'n_hetero_atoms', 'n_heavy_atoms', 'n_rotatable_bonds', 'n_radical_electrons', 'tpsa', 'qed', 'clogp', 'sas', 'n_aliphatic_carbocycles', 'n_aliphatic_heterocyles', 'n_aliphatic_rings', 'n_aromatic_carbocycles', 'n_aromatic_heterocyles', 'n_aromatic_rings', 'n_saturated_carbocycles', 'n_saturated_heterocyles', 'n_saturated_rings']]\n\n# Convert X_mp4_df to numpy array\nX_mp4 = X_mp4_df.to_numpy()\nX_mp4\n\narray([[ 1.98115698e+02,  3.07692308e-01,  2.00000000e+00,\n         2.00000000e+00,  3.00000000e+00,  2.00000000e+00,\n         1.50000000e+01,  0.00000000e+00,  0.00000000e+00,\n         3.89100000e+01,  7.06488238e-01,  2.69580000e+00,\n         2.01471913e+00,  1.00000000e+00,  0.00000000e+00,\n         1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n         2.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00],\n       [ 2.01092042e+02,  4.00000000e-01,  2.00000000e+00,\n         1.00000000e+00,  1.00000000e+00,  3.00000000e+00,\n         1.30000000e+01,  2.00000000e+00,  0.00000000e+00,\n         2.02300000e+01,  6.08112327e-01, -1.01700000e+00,\n         3.18586632e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n         1.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00],\n       [ 2.35168462e+02,  4.61538462e-01,  4.00000000e+00,\n         3.00000000e+00,  1.00000000e+00,  4.00000000e+00,\n         1.70000000e+01,  6.00000000e+00,  0.00000000e+00,\n         5.83600000e+01,  7.31539693e-01,  1.34040000e+00,\n         1.79168720e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n         1.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00],\n       [ 3.79214744e+02,  4.58333333e-01,  4.00000000e+00,\n         0.00000000e+00,  4.00000000e+00,  4.00000000e+00,\n         2.80000000e+01,  6.00000000e+00,  0.00000000e+00,\n         3.87700000e+01,  7.47461492e-01,  4.36110000e+00,\n         2.67722173e+00,  1.00000000e+00,  1.00000000e+00,\n         2.00000000e+00,  2.00000000e+00,  0.00000000e+00,\n         2.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n         1.00000000e+00],\n       [ 5.86279135e+02,  5.15151515e-01,  1.00000000e+01,\n         1.00000000e+00,  7.00000000e+00,  1.00000000e+01,\n         4.30000000e+01,  4.00000000e+00,  0.00000000e+00,\n         1.14200000e+02,  3.55955569e-01,  4.09110000e+00,\n         3.63256044e+00,  0.00000000e+00,  4.00000000e+00,\n         4.00000000e+00,  1.00000000e+00,  2.00000000e+00,\n         3.00000000e+00,  0.00000000e+00,  2.00000000e+00,\n         2.00000000e+00],\n       [ 5.10461822e+02,  8.00000000e-01,  6.00000000e+00,\n         0.00000000e+00,  1.00000000e+00,  6.00000000e+00,\n         3.60000000e+01,  2.10000000e+01,  0.00000000e+00,\n         2.76900000e+01,  2.05822189e-01,  5.45250000e+00,\n         3.25765349e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n         1.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00],\n       [ 1.84066459e+02,  1.00000000e+00,  3.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  5.00000000e+00,\n         1.10000000e+01,  4.00000000e+00,  0.00000000e+00,\n         3.55300000e+01,  6.29869319e-01,  2.91400000e+00,\n         3.34514393e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00],\n       [ 2.87152144e+02,  5.29411765e-01,  4.00000000e+00,\n         1.00000000e+00,  4.00000000e+00,  4.00000000e+00,\n         2.10000000e+01,  1.00000000e+00,  0.00000000e+00,\n         4.19300000e+01,  8.00524269e-01,  1.85030000e+00,\n         4.22684283e+00,  1.00000000e+00,  2.00000000e+00,\n         3.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n         1.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00],\n       [ 3.48142697e+02,  3.68421053e-01,  2.00000000e+00,\n         0.00000000e+00,  3.00000000e+00,  4.00000000e+00,\n         2.30000000e+01,  5.00000000e+00,  0.00000000e+00,\n         6.48000000e+00,  7.09785317e-01,  5.44140000e+00,\n         4.22359068e+00,  0.00000000e+00,  1.00000000e+00,\n         1.00000000e+00,  2.00000000e+00,  0.00000000e+00,\n         2.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00],\n       [ 2.34092376e+02,  3.07692308e-01,  2.00000000e+00,\n         2.00000000e+00,  3.00000000e+00,  3.00000000e+00,\n         1.60000000e+01,  0.00000000e+00,  0.00000000e+00,\n         3.89100000e+01,  7.60853221e-01,  3.11760000e+00,\n         3.21871482e+00,  1.00000000e+00,  0.00000000e+00,\n         1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n         2.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00]])\n\n\nSetting up the target for the training set.\n\n# Set y (target) for max phase 4 compounds\ny_mp4_df = dtree_mp4[\"pKi\"]\n\n# Convert y_mp4_df to numpy array\ny_mp4 = y_mp4_df.to_numpy()\ny_mp4\n\narray([6.82102305, 6.69897   , 6.        , 7.68824614, 7.29670862,\n       4.43179828, 5.22184875, 6.52287875, 4.60730305, 6.99567863])\n\n\nThe DecisionTreeRegressor() was fitted on the compounds with max phase 4 as shown below, keeping tree depth at 3 for now to avoid complicating the overall tree graph (the deeper the tree, the more branches - potentially might overfit and create noises for the model).\n\nache_tree_mp4 = tree.DecisionTreeRegressor(max_depth=3, random_state=1)\nache_tree_mp4 = ache_tree_mp4.fit(X_mp4, y_mp4)\n\n\n\n\nscikit-learn tree plot\nA simple decision tree plot based on scikit-learn’s plot_tree() was shown below.\n\ntree.plot_tree(ache_tree_mp4, feature_names=list(X_mp4_df.columns), filled=True, rounded=True)\n\n[Text(0.5909090909090909, 0.875, 'clogp <= 4.901\\nsquared_error = 1.144\\nsamples = 10\\nvalue = 6.228'),\n Text(0.36363636363636365, 0.625, 'n_aromatic_rings <= 1.5\\nsquared_error = 0.516\\nsamples = 8\\nvalue = 6.656'),\n Text(0.18181818181818182, 0.375, 'n_aromatic_rings <= 0.5\\nsquared_error = 0.33\\nsamples = 4\\nvalue = 6.111'),\n Text(0.09090909090909091, 0.125, 'squared_error = 0.0\\nsamples = 1\\nvalue = 5.222'),\n Text(0.2727272727272727, 0.125, 'squared_error = 0.088\\nsamples = 3\\nvalue = 6.407'),\n Text(0.5454545454545454, 0.375, 'n_rotatable_bonds <= 2.0\\nsquared_error = 0.108\\nsamples = 4\\nvalue = 7.2'),\n Text(0.45454545454545453, 0.125, 'squared_error = 0.008\\nsamples = 2\\nvalue = 6.908'),\n Text(0.6363636363636364, 0.125, 'squared_error = 0.038\\nsamples = 2\\nvalue = 7.492'),\n Text(0.8181818181818182, 0.625, 'mw <= 429.302\\nsquared_error = 0.008\\nsamples = 2\\nvalue = 4.52'),\n Text(0.7272727272727273, 0.375, 'squared_error = 0.0\\nsamples = 1\\nvalue = 4.607'),\n Text(0.9090909090909091, 0.375, 'squared_error = -0.0\\nsamples = 1\\nvalue = 4.432')]\n\n\n\n\n\n\n\nscikit-learn tree plot in texts\nIt could also be in the text form.\n\nfrom sklearn.tree import export_text\n\ntext = export_text(ache_tree_mp4, feature_names=list(X_mp4_df.columns))\nprint(text)\n\n|--- clogp <= 4.90\n|   |--- n_aromatic_rings <= 1.50\n|   |   |--- n_aromatic_rings <= 0.50\n|   |   |   |--- value: [5.22]\n|   |   |--- n_aromatic_rings >  0.50\n|   |   |   |--- value: [6.41]\n|   |--- n_aromatic_rings >  1.50\n|   |   |--- n_rotatable_bonds <= 2.00\n|   |   |   |--- value: [6.91]\n|   |   |--- n_rotatable_bonds >  2.00\n|   |   |   |--- value: [7.49]\n|--- clogp >  4.90\n|   |--- mw <= 429.30\n|   |   |--- value: [4.61]\n|   |--- mw >  429.30\n|   |   |--- value: [4.43]\n\n\n\n\n\n\ngraphviz tree plot\nThe graphviz version, which showed a small variation in graph presentation, seemed to be much larger in size and easier to view.\n\nimport graphviz\n\ndot_data = tree.export_graphviz(ache_tree_mp4, out_file=None, feature_names=list(X_mp4_df.columns), filled=True, rounded=True, special_characters=False)\n\ngraph = graphviz.Source(dot_data)\ngraph\n\n\n\n\n\n\n\ndtreeviz tree plot\nThe following was a dtreeviz version of the decision tree, which actually included the regression plots of different molecular features e.g. clogp versus the target value of pKi. It seemed a bit more intuitive as these plots clearly showed where the threshold cut-offs would be for each feature (molecular descriptors). The GitHub repository link for dtreeviz could be accessed here.\n\nimport dtreeviz \n\nviz = dtreeviz.model(ache_tree_mp4, X_train=X_mp4, y_train=y_mp4, target_name=\"pKi\", feature_names=list(X_mp4_df.columns))\n# Added \"scale = 2\" to view()\n# to make plot larger in size\nviz.view(scale = 2)\n\n\n\n\n\n\n\nTesting and predicting data based on max phase of null compounds\n\n# Compounds with max phase as \"null\"\ndtree_mp_null = dtree[dtree[\"max_phase\"] == \"null\"]\nprint(dtree_mp_null.shape)\ndtree_mp_null.head() \n\n(466, 25)\n\n\n\n\n\n\n  \n    \n      \n      molecule_chembl_id\n      pKi\n      max_phase\n      mw\n      fsp3\n      n_lipinski_hba\n      n_lipinski_hbd\n      n_rings\n      n_hetero_atoms\n      n_heavy_atoms\n      ...\n      sas\n      n_aliphatic_carbocycles\n      n_aliphatic_heterocyles\n      n_aliphatic_rings\n      n_aromatic_carbocycles\n      n_aromatic_heterocyles\n      n_aromatic_rings\n      n_saturated_carbocycles\n      n_saturated_heterocyles\n      n_saturated_rings\n    \n  \n  \n    \n      0\n      CHEMBL60745\n      8.787812\n      null\n      245.041526\n      0.400000\n      2\n      1\n      1\n      3\n      13\n      ...\n      3.185866\n      0\n      0\n      0\n      1\n      0\n      1\n      0\n      0\n      0\n    \n    \n      1\n      CHEMBL208599\n      10.585027\n      null\n      298.123676\n      0.388889\n      2\n      2\n      4\n      3\n      21\n      ...\n      4.331775\n      2\n      0\n      2\n      1\n      1\n      2\n      0\n      0\n      0\n    \n    \n      3\n      CHEMBL173309\n      7.913640\n      null\n      694.539707\n      0.666667\n      8\n      0\n      2\n      8\n      50\n      ...\n      2.803680\n      0\n      0\n      0\n      2\n      0\n      2\n      0\n      0\n      0\n    \n    \n      5\n      CHEMBL102226\n      4.698970\n      null\n      297.152928\n      0.923077\n      3\n      0\n      0\n      5\n      18\n      ...\n      2.965170\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      7\n      CHEMBL103873\n      5.698970\n      null\n      269.121628\n      0.909091\n      3\n      0\n      0\n      5\n      16\n      ...\n      3.097106\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n  \n\n5 rows × 25 columns\n\n\n\nThere were 466 compounds with max phase as “null”, meaning they were pre-clinical compounds. This was confirmed through the answer from ChEMBL FAQ link, a max phase of “null” compound means:\n\n“Preclinical (NULL): preclinical compounds with bioactivity data e.g. is a preclinical compound with bioactivity data that has been extracted from scientific literature. However, the sources of drug and clinical candidate drug information in ChEMBL do not show that this compound has reached clinical trials and therefore the max_phase is set to null.”\n\nAgain, setting up the features for the testing dataset.\n\nX_mp_test_df = dtree_mp_null[['mw', 'fsp3', 'n_lipinski_hba', 'n_lipinski_hbd', 'n_rings', 'n_hetero_atoms', 'n_heavy_atoms', 'n_rotatable_bonds', 'n_radical_electrons', 'tpsa', 'qed', 'clogp', 'sas', 'n_aliphatic_carbocycles', 'n_aliphatic_heterocyles', 'n_aliphatic_rings', 'n_aromatic_carbocycles', 'n_aromatic_heterocyles', 'n_aromatic_rings', 'n_saturated_carbocycles', 'n_saturated_heterocyles', 'n_saturated_rings']]\n\n# Convert X_mp_test_df to numpy array\nX_mp_test = X_mp_test_df.to_numpy()\nX_mp_test\n\narray([[2.45041526e+02, 4.00000000e-01, 2.00000000e+00, ...,\n        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n       [2.98123676e+02, 3.88888889e-01, 2.00000000e+00, ...,\n        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n       [6.94539707e+02, 6.66666667e-01, 8.00000000e+00, ...,\n        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n       ...,\n       [3.11152144e+02, 3.15789474e-01, 4.00000000e+00, ...,\n        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n       [3.68096076e+02, 9.23076923e-01, 4.00000000e+00, ...,\n        0.00000000e+00, 2.00000000e+00, 2.00000000e+00],\n       [2.46136828e+02, 5.00000000e-01, 4.00000000e+00, ...,\n        0.00000000e+00, 3.00000000e+00, 3.00000000e+00]])\n\n\nThen setting up the target for the testing set.\n\ny_test = ache_tree_mp4.predict(X_mp_test)\n\nThe trained model, ache_tree_mp4, was used to predict on the testing dataset (max phase of null compounds).\n\nache_tree_mp4 = ache_tree_mp4.fit(X_mp_test, y_test)\n\nUsing the graphviz graph version to show the decision tree on the testing set, as the prediction result.\n\ndot_data = tree.export_graphviz(ache_tree_mp4, out_file=None, feature_names=list(X_mp_test_df.columns), filled=True, rounded=True, special_characters=False)\n\ngraph = graphviz.Source(dot_data)\ngraph\n\n\n\n\n\n\n\n\nDiscussions\nBecause of the small amount of training data, this might hint at using an ensemble approach in the future, where model averaging would be derived from a bunch of tree models rather than using a single tree model, which was what I did here. The reason I started with one tree was because it was no point in building a multiple-tree model if one had no clue about how one tree was built. To learn as much as possible, I had to dissect the multiple-tree version first to focus on one tree at a time.\nOne thing I’d like to mention was that rivastigmine was not included in the training dataset because it was actually not a pure AChE inhibitor (as it was also a butyrylcholinesterase (BChE) inhibitor), since my focus was purely on AChE at this time, this particular drug was unfortunately excluded. However, I did make sure the other two drugs (donepezil and galantamine) were included in the training dataset. One possible thing to do in the future if I want to improve this was to add BChE as another protein target and perhaps add this as an additional dataset towards the model.\nAs described in the subsection of “Estimate experimental errors”, there were experimental errors of 3-fold, 5-fold and 10-fold estimated based on the provided pKi data. With the prediction model used in this post, the estimated experimental errors would need to be taken into consideration, particularly at the time when the model was being investigated during the model evaluation and validation step (however due to the length of series 2.1 posts, I decided not to add this step yet, but would try to look at this later in the multiple tree model series if this applies).\nA bit about the last decision tree plot, tentatively clogp (calculated partition coefficient) might be the crucial molecular feature in deciding whether a molecule might be closer to being an AChE inhibitor. Other important molecular features also included the number of aromatic rings, molecular weights, solvent accessible surface area and others (I’ve set the random state to 1 for now, so hopefully the result will be reproducible as I realised my old code without it always generated different tree plots, then all of the sudden I remembered that I forgot to set the random state of the estimator, so this was added).\nSince the type of AChE inhibitors was not the focus of this series, I won’t go into details about which value of pKi or Ki would lead to the ideal AChE inhibitor (the well-known Cheng-Prusoff equation (Cheng and Prusoff 1973) might also lead to many discussions about Ki and IC50 values). This is because there are at least two types of AChE inhibitors available - reversible and irreversible (Colovic et al. 2013). Donepezil, galantamine and rivastigmine mentioned previously are the commonly known reversible AChE inhibitors. The irreversible type, as the name suggested, is usually used as insecticides or nerve agents. Another reason is that I didn’t go into details checking all of the identities for the 10 max phase 4 compounds used in the training set, as I only really made sure that donepezil and galantamine were included in the 10 molecules. If I were to re-model again purely on reversible AChE inhibitors targeting dementia or Alzheimer’s disease, I think I had to be quite sure of what I was training the model with, i.e. excluding irreversible AChE inhibitors from the training set.\nHowever, if our aim was to only find novel AChE inhibitors in a general manner, one of the ways to check post-model building would be to re-run the dataframe again on compounds with max phase as null, including the molecular feature names to find out which compounds were at the predicted threshold cut-off values to see if their corresponding pKi values (note: these preclinical compounds had Ki values extracted from literature sources etc.) would match the predicted ones. One caveat of this method was that there might be pre-existing experimental errors in all the obtained and recorded Ki values, so this might not confirm that the model was truly a good reflection of the real-life scenario. Therefore, at most, this would probably add a very small value during the model evaluation phase.\nThe best way would be to test all of these compounds in the same experimental set-ups, through same experimental steps, and in the same laboratory to find out their respective Ki (or pKi) values. However, this was most likely not very feasible due to various real-life restrictions (the availability of financial and staffing resources). The most likely outcome might be to choose a selected group of compound candidates with the highest possibilities to proceed in the drug discovery pipeline based on past experimental, ML and clinical experiences, and then test them in the ways mentioned here.\nI also came across a blog post about calculating the prediction intervals of ML prediction models (which mentioned the MAPIE package), but I didn’t quite get time to look into this package yet, and from what I have read in its repository link, it potentially could be quite useful for classification, regression and time-series models.\n\n\n\nFinal words\nI didn’t think a definite conclusion could be drawn here, as this was only purely from one very simple and single decision tree, so I have named this last part as “final words”, as I felt if I didn’t stop here, this post or series of posts could go on forever or as long it could. The main thing here was to fully understand how one single decision tree was constructed based on hopefully reasonable-ish data (still not the best as I could not rule out all the noises from the data), and then to view the tree visually in different styles of plots. It was also important to understand how this was a white-box ML approach with clear features or descriptions shown to trace where the tree would branch off to reach different final outcomes or targets. This series was really a preamble for the multiple-tree models e.g. random forest and boosted trees, as I have bravely planned to do a series of posts on tree models due to my interests in them, so that might take a while, slowly but hopefully surely.\n\n\n\nAcknowledgements\nI’d like to thank all the authors for all the open-source packages used in the series 2.1 posts. I’d also like to thank all the authors of all the blog posts mentioned in this series as well since I’ve learnt a lot from them too.\n\n\n\n\n\nReferences\n\nBrown, Scott P., Steven W. Muchmore, and Philip J. Hajduk. 2009. “Healthy Skepticism: Assessing Realistic Model Performance.” Drug Discovery Today 14 (7-8): 420–27. https://doi.org/10.1016/j.drudis.2009.01.012.\n\n\nCheng, Yung-Chi, and William H. Prusoff. 1973. “Relationship Between the Inhibition Constant (KI) and the Concentration of Inhibitor Which Causes 50 Per Cent Inhibition (I50) of an Enzymatic Reaction.” Biochemical Pharmacology 22 (23): 3099–3108. https://doi.org/10.1016/0006-2952(73)90196-2.\n\n\nColovic, Mirjana B., Danijela Z. Krstic, Tamara D. Lazarevic-Pasti, Aleksandra M. Bondzic, and Vesna M. Vasic. 2013. “Acetylcholinesterase Inhibitors: Pharmacology and Toxicology.” Current Neuropharmacology 11 (3): 315–35. https://doi.org/10.2174/1570159x11311030006."
  },
  {
    "objectID": "posts/08_ML1-1_Small_molecules_in_ChEMBL_database/ML1-1_chembl_cpds.html",
    "href": "posts/08_ML1-1_Small_molecules_in_ChEMBL_database/ML1-1_chembl_cpds.html",
    "title": "Small molecules in ChEMBL database (old)",
    "section": "",
    "text": "This post has been updated since October 2024 (separated into four shorter posts) using only Polars dataframe library (the older version uses both Polars and Pandas):\n1st post - Parquet file in Polars dataframe library\n2nd post - Preprocessing data in Polars dataframe library\n3rd post - Building logistic regression model using scikit-learn\n4th post - Evaluating logistic regression model in scikit-learn\n\n\nMachine learning in drug discovery - series 1.1\n\n*Latest update from 19th April 2024 - Polars is currently more integrated with Scikit-learn from version 1.4 (since January 2024), see this link re. Polars output in set_output for Polars dataframe outputs in Scikit-learn, and also a few other Polars enhancements from release version 1.4 changelog.\nPrevious post update was on 16th August 2023 - some code updates only, please always refer to Polars API reference documentations for most up-to-date code.\n\n\n\nBackground\nAs my interests gradually grew for Rust, I realised why so many people said it might be a hard programming language to learn. My head was spinning after reading the Rust programming language book and watching a few online teaching videos about it. I then decided to start from something I was more familiar with, and somehow through various online ventures and searching, I’ve managed to start two projects in parallel. The first one was where I used Polars dataframe library, and the second one would be about using Rust through an interactive user interface such as Jupyter notebook. I’ve anticipated that the second project would take much longer time for me to finish, so I would be tackling the first project for now.\nThis project was about using Polars, a blazingly fast dataframe library that was written completely in Rust with a very light Python binding that was available for use via Python or Rust, so I started using Polars via Python on Jupyter Lab initially, which involved data wrangling, some exploratory data analysis (EDA), and a reasonably larger section on using machine learning (ML) through scikit-learn. The editing and publishing of this post was mainly achieved via RStudio IDE.\n\n\n\nInstall Polars\n\n# To install Polars dataframe library\n# Uncomment below to download and install Polars\n#!pip install polars\n\n# Update Polars version\n# Uncomment the line below to update Polars\n#!pip install --upgrade polars\n\nOnce Polars was installed, the next step was to import it for use.\n\nimport polars as pl\n\n\n# Show version of Polars\n# Uncomment line below to check version of Polars installed/updated\n#pl.show_versions()\n\n\n\n\nDownload dataset\nThe dataset, which was purely about small molecules and their physicochemical properties, was downloaded from ChEMBL database and saved as a .csv file. I’ve decided not to upload the “chembl_mols.csv” file due to its sheer size (around 0.6 GB), and also I’d like to stay using free open-source resources (including GitHub) at this stage. I’ve looked into the Git large file system, but for the free version it only provides 2 GB, which at this stage, I think by adding this larger than usual .csv file along with my portfolio blog repository may exceed this limit in no time.\nFor anyone who would like to use the same dataset, the file I used would be equivalent to a straight download from the home page of ChEMBL database, via clicking on the “Distinct compounds” (please see the circled area in the image below). Options were available to download the files as .csv, .tsv or .sdf formats (located at the top right of the page).\n\n\n\n\nImage adapted from ChEMBL database website\n\n\n\nOnce we’ve had the file ready, it would be read via the usual read_csv() method.\n\ndf = pl.read_csv(\"chembl_mols.csv\")\ndf.head() #read first 5 rows\n#df #read full dataset\n\n\n\nshape: (5, 1)ChEMBL ID\";\"Name\";\"Synonyms\";\"Type\";\"Max Phase\";\"Molecular Weight\";\"Targets\";\"Bioactivities\";\"AlogP\";\"Polar Surface Area\";\"HBA\";\"HBD\";\"#RO5 Violations\";\"#Rotatable Bonds\";\"Passes Ro3\";\"QED Weighted\";\"CX Acidic pKa\";\"CX Basic pKa\";\"CX LogP\";\"CX LogD\";\"Aromatic Rings\";\"Structure Type\";\"Inorganic Flag\";\"Heavy Atoms\";\"HBA (Lipinski)\";\"HBD (Lipinski)\";\"#RO5 Violations (Lipinski)\";\"Molecular Weight (Monoisotopic)\";\"Molecular Species\";\"Molecular Formula\";\"Smiles\";\"Inchi Keystr\"CHEMBL1206185;\";\";Small molecu…\"CHEMBL539070;\";\";Small molecul…\"CHEMBL3335528;\";\";Small molecu…\"CHEMBL2419030;\";\";Small molecu…\"CHEMBL4301448;\";\";Small molecu…\n\n\n\n\n\nData wrangling\nNow, since this dataset was downloaded as a .csv file, this meant it was likely to have a certain delimiter between each variable. So the whole dataset was presented as strings where each string represented each compound in each row. Each variable was separated by semicolons. To read it properly, I’ve added a delimiter term in the code to transform the dataframe into a more readable format.\n\n# By referring to Polars documentation, \n# *use \"sep\" to set the delimiter of the file\n# which was semicolons in this case\n# *please note this has been updated to \"separator\" \n# due to updates in Polars since the published date of this post\ndf = pl.read_csv(\"chembl_mols.csv\", separator = \";\")\n# Show the first 10 rows of data\n#df.head(10)\n# or full dataset\ndf\n\n\n\nshape: (2_331_700, 32)ChEMBL IDNameSynonymsTypeMax PhaseMolecular WeightTargetsBioactivitiesAlogPPolar Surface AreaHBAHBD#RO5 Violations#Rotatable BondsPasses Ro3QED WeightedCX Acidic pKaCX Basic pKaCX LogPCX LogDAromatic RingsStructure TypeInorganic FlagHeavy AtomsHBA (Lipinski)HBD (Lipinski)#RO5 Violations (Lipinski)Molecular Weight (Monoisotopic)Molecular SpeciesMolecular FormulaSmilesInchi Keystrstrstrstri64strstrstrstrstrstrstrstrstrstrstrstrstrstrstrstrstri64strstrstrstrstrstrstrstrstr\"CHEMBL1206185\"\"\"\"\"\"Small molecule\"0\"607.88\"\"\"\"\"\"9.46\"\"89.62\"\"5\"\"2\"\"2\"\"17\"\"N\"\"0.09\"\"-1.91\"\"8.38\"\"9.40\"\"9.36\"\"3\"\"MOL\"-1\"42\"\"5\"\"3\"\"2\"\"607.2790\"\"ACID\"\"C35H45NO4S2\"\"CCCCCCCCCCC#CC(N)c1ccccc1-c1cc…\"UFBLKYIDZFRLPR-UHFFFAOYSA-N\"\"CHEMBL539070\"\"\"\"\"\"Small molecule\"0\"286.79\"\"1\"\"1\"\"2.28\"\"73.06\"\"6\"\"2\"\"0\"\"5\"\"N\"\"0.63\"\"13.84\"\"3.64\"\"2.57\"\"2.57\"\"2\"\"MOL\"-1\"17\"\"5\"\"3\"\"0\"\"250.0888\"\"NEUTRAL\"\"C11H15ClN4OS\"\"CCCOc1ccccc1-c1nnc(NN)s1.Cl\"\"WPEWNRKLKLNLSO-UHFFFAOYSA-N\"\"CHEMBL3335528\"\"\"\"\"\"Small molecule\"0\"842.80\"\"2\"\"6\"\"0.18\"\"269.57\"\"18\"\"5\"\"2\"\"17\"\"N\"\"0.09\"\"3.20\"\"None\"\"3.31\"\"-0.14\"\"3\"\"MOL\"-1\"60\"\"19\"\"5\"\"2\"\"842.2633\"\"ACID\"\"C41H46O19\"\"COC(=O)[C@H](O[C@@H]1O[C@@H](C…\"KGUJQZWYZPYYRZ-LWEWUKDVSA-N\"\"CHEMBL2419030\"\"\"\"\"\"Small molecule\"0\"359.33\"\"4\"\"4\"\"3.94\"\"85.13\"\"6\"\"1\"\"0\"\"3\"\"N\"\"0.66\"\"None\"\"None\"\"3.66\"\"3.66\"\"2\"\"MOL\"-1\"24\"\"6\"\"1\"\"0\"\"359.0551\"\"NEUTRAL\"\"C14H12F3N3O3S\"\"O=c1nc(NC2CCCC2)sc2c([N+](=O)[…\"QGDMYSDFCXOKML-UHFFFAOYSA-N\"\"CHEMBL4301448\"\"\"\"\"\"Small molecule\"0\"465.55\"\"\"\"\"\"5.09\"\"105.28\"\"6\"\"4\"\"1\"\"10\"\"N\"\"0.15\"\"None\"\"12.14\"\"4.41\"\"2.00\"\"4\"\"MOL\"-1\"33\"\"7\"\"5\"\"1\"\"465.1635\"\"BASE\"\"C24H24FN5O2S\"\"N=C(N)NCCCOc1ccc(CNc2nc3ccc(Oc…\"RXTJPHLPHOZLFS-UHFFFAOYSA-N\"……………………………………………………………………………………\"CHEMBL2017916\"\"\"\"\"\"Small molecule\"0\"312.35\"\"3\"\"3\"\"2.86\"\"77.00\"\"6\"\"1\"\"0\"\"4\"\"N\"\"0.80\"\"8.13\"\"3.49\"\"2.17\"\"2.10\"\"3\"\"MOL\"-1\"22\"\"6\"\"1\"\"0\"\"312.0681\"\"NEUTRAL\"\"C15H12N4O2S\"\"COc1ccc(-c2nnc(NC(=O)c3cccnc3)…\"XIZUJGDKNPVNQA-UHFFFAOYSA-N\"\"CHEMBL374652\"\"\"\"\"\"Small molecule\"0\"403.83\"\"1\"\"1\"\"5.98\"\"36.02\"\"2\"\"2\"\"1\"\"4\"\"N\"\"0.42\"\"13.65\"\"None\"\"5.36\"\"5.36\"\"3\"\"MOL\"-1\"26\"\"2\"\"2\"\"1\"\"403.0421\"\"NEUTRAL\"\"C18H14ClF4NOS\"\"CC(O)(CSc1ccc(F)cc1)c1cc2cc(Cl…\"CRPQTBRTHURKII-UHFFFAOYSA-N\"\"CHEMBL1416264\"\"\"\"\"\"Small molecule\"0\"380.41\"\"6\"\"8\"\"3.06\"\"85.07\"\"7\"\"1\"\"0\"\"5\"\"N\"\"0.54\"\"13.85\"\"3.86\"\"2.47\"\"2.47\"\"4\"\"MOL\"-1\"27\"\"7\"\"1\"\"0\"\"380.0856\"\"NEUTRAL\"\"C18H13FN6OS\"\"O=C(CSc1ccc2nnc(-c3cccnc3)n2n1…\"QVYIEKHEJKFNAT-UHFFFAOYSA-N\"\"CHEMBL213734\"\"\"\"\"\"Small molecule\"0\"288.26\"\"2\"\"3\"\"2.32\"\"101.70\"\"5\"\"2\"\"0\"\"5\"\"N\"\"0.50\"\"7.20\"\"None\"\"2.36\"\"1.95\"\"2\"\"MOL\"-1\"21\"\"7\"\"2\"\"0\"\"288.0746\"\"NEUTRAL\"\"C14H12N2O5\"\"O=C(COc1ccccc1)Nc1ccc([N+](=O)…\"PZTWAHGBGTWVEB-UHFFFAOYSA-N\"\"CHEMBL1531634\"\"\"\"\"\"Small molecule\"0\"320.16\"\"19\"\"21\"\"4.40\"\"29.10\"\"2\"\"1\"\"0\"\"4\"\"N\"\"0.67\"\"None\"\"None\"\"4.04\"\"4.04\"\"2\"\"MOL\"-1\"19\"\"2\"\"1\"\"0\"\"319.0008\"\"NEUTRAL\"\"C15H11BrFNO\"\"O=C(/C=C/Nc1ccc(F)cc1)c1ccc(Br…\"DKPWCCDDKFLKEC-MDZDMXLPSA-N\"\n\n\n\nInitially, I only wanted to download around 24 compounds from the ChEMBL database first. Unknowingly, I ended up downloading the whole curated set of 2,331,700 small molecules (!), and I found this out when I loaded the dataframe after setting up the delimiter for the csv file, which later led to the file size problem mentioned earlier.\nLoading these 2,331,700 rows of data was fast, which occurred within a few seconds without exaggeration. This echoed many users’ experiences with Polars, so this was another nice surprise, and once again confirmed that Rust, and also Apache arrow, which was used as Polars’ foundation, were solid in speed.\nNow I had the full dataframe, and I wanted to find out what types of physicochemical properties were there for the compounds.\n\n# Print all column names and data types \nprint(df.glimpse())\n\nRows: 2331700\nColumns: 32\n$ ChEMBL ID                       <str> 'CHEMBL1206185', 'CHEMBL539070', 'CHEMBL3335528', 'CHEMBL2419030', 'CHEMBL4301448', 'CHEMBL3827271', 'CHEMBL1969944', 'CHEMBL3465961', 'CHEMBL587495', 'CHEMBL3824158'\n$ Name                            <str> '', '', '', '', '', '', '', '', '', ''\n$ Synonyms                        <str> '', '', '', '', '', '', '', '', '', ''\n$ Type                            <str> 'Small molecule', 'Small molecule', 'Small molecule', 'Small molecule', 'Small molecule', 'Small molecule', 'Small molecule', 'Small molecule', 'Small molecule', 'Small molecule'\n$ Max Phase                       <i64> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n$ Molecular Weight                <str> '607.88', '286.79', '842.80', '359.33', '465.55', '712.85', '', '319.42', '478.54', '422.48'\n$ Targets                         <str> '', '1', '2', '4', '', '1', '56', '16', '', '2'\n$ Bioactivities                   <str> '', '1', '6', '4', '', '1', '56', '22', '', '4'\n$ AlogP                           <str> '9.46', '2.28', '0.18', '3.94', '5.09', '-2.84', '', '2.22', '6.85', '5.09'\n$ Polar Surface Area              <str> '89.62', '73.06', '269.57', '85.13', '105.28', '319.06', '', '50.50', '66.73', '109.54'\n$ HBA                             <str> '5', '6', '18', '6', '6', '10', '', '4', '4', '6'\n$ HBD                             <str> '2', '2', '5', '1', '4', '11', '', '1', '3', '2'\n$ #RO5 Violations                 <str> '2', '0', '2', '0', '1', '2', '', '0', '1', '1'\n$ #Rotatable Bonds                <str> '17', '5', '17', '3', '10', '16', '', '6', '6', '10'\n$ Passes Ro3                      <str> 'N', 'N', 'N', 'N', 'N', 'N', '', 'N', 'N', 'N'\n$ QED Weighted                    <str> '0.09', '0.63', '0.09', '0.66', '0.15', '0.07', '', '0.87', '0.23', '0.31'\n$ CX Acidic pKa                   <str> '-1.91', '13.84', '3.20', 'None', 'None', '4.08', '', 'None', '10.67', '4.59'\n$ CX Basic pKa                    <str> '8.38', '3.64', 'None', 'None', '12.14', '10.49', '', '9.38', '8.47', '7.99'\n$ CX LogP                         <str> '9.40', '2.57', '3.31', '3.66', '4.41', '-6.88', '', '2.13', '6.04', '2.49'\n$ CX LogD                         <str> '9.36', '2.57', '-0.14', '3.66', '2.00', '-8.95', '', '-0.44', '4.93', '2.42'\n$ Aromatic Rings                  <str> '3', '2', '3', '2', '4', '0', '', '1', '5', '2'\n$ Structure Type                  <str> 'MOL', 'MOL', 'MOL', 'MOL', 'MOL', 'MOL', 'NONE', 'MOL', 'MOL', 'MOL'\n$ Inorganic Flag                  <i64> -1, -1, -1, -1, -1, -1, -1, -1, -1, -1\n$ Heavy Atoms                     <str> '42', '17', '60', '24', '33', '50', '', '23', '34', '31'\n$ HBA (Lipinski)                  <str> '5', '5', '19', '6', '7', '19', '', '4', '4', '7'\n$ HBD (Lipinski)                  <str> '3', '3', '5', '1', '5', '14', '', '1', '4', '2'\n$ #RO5 Violations (Lipinski)      <str> '2', '0', '2', '0', '1', '3', '', '0', '1', '1'\n$ Molecular Weight (Monoisotopic) <str> '607.2790', '250.0888', '842.2633', '359.0551', '465.1635', '712.4232', '', '319.2060', '478.1439', '422.1842'\n$ Molecular Species               <str> 'ACID', 'NEUTRAL', 'ACID', 'NEUTRAL', 'BASE', 'ZWITTERION', '', 'BASE', 'NEUTRAL', 'ACID'\n$ Molecular Formula               <str> 'C35H45NO4S2', 'C11H15ClN4OS', 'C41H46O19', 'C14H12F3N3O3S', 'C24H24FN5O2S', 'C31H56N10O9', '', 'C18H26FN3O', 'C26H21F3N4S', 'C24H26N2O5'\n$ Smiles                          <str> 'CCCCCCCCCCC#CC(N)c1ccccc1-c1ccc(Sc2ccc(OCCCC)cc2)c(S(=O)(=O)O)c1', 'CCCOc1ccccc1-c1nnc(NN)s1.Cl', 'COC(=O)[C@H](O[C@@H]1O[C@@H](C)[C@@H](O)[C@@H](O)[C@@H]1O)[C@@H](O[C@@H]1O[C@H](CO)[C@H](OC(=O)c2ccccc2)[C@H](O[C@H](Cc2ccccc2)C(=O)O)[C@H]1OC(=O)c1ccccc1)C(=O)OC', 'O=c1nc(NC2CCCC2)sc2c([N+](=O)[O-])cc(C(F)(F)F)cc12', 'N=C(N)NCCCOc1ccc(CNc2nc3ccc(Oc4ccc(F)cc4)cc3s2)cc1', 'CC(C)C[C@@H]1NC(=O)[C@H](CCCNC(N)=O)NC(=O)[C@H](CCCCN)NC(=O)[C@H](CC(=O)O)NC(=O)[C@H](CCCCN)NC(=O)CCNC1=O', '', 'CC(O)CN1CCC(CN(C)Cc2cc(C#N)ccc2F)CC1', 'Nc1cccc(CNCc2ccc(-c3ccc(-c4nc5cc(C(F)(F)F)ccc5[nH]4)s3)cc2)c1', 'CCCCCCCNC(C1=C(O)C(=O)c2ccccc2C1=O)c1ccc([N+](=O)[O-])cc1'\n$ Inchi Key                       <str> 'UFBLKYIDZFRLPR-UHFFFAOYSA-N', 'WPEWNRKLKLNLSO-UHFFFAOYSA-N', 'KGUJQZWYZPYYRZ-LWEWUKDVSA-N', 'QGDMYSDFCXOKML-UHFFFAOYSA-N', 'RXTJPHLPHOZLFS-UHFFFAOYSA-N', 'QJQNNLICZLLPMB-VUBDRERZSA-N', '', 'FZEVYCHTADTXPM-UHFFFAOYSA-N', 'KZOHKPSNJBXTRJ-UHFFFAOYSA-N', 'AXOVDUYYBUYLPC-UHFFFAOYSA-N'\n\nNone\n\n\nThere were a few terms where I wasn’t sure of their exact meanings, so I went through the ChEMBL_31 schema documentation and ChEMBL database website to find out. This took a while and was an important step to take so that I would know what to do when reaching the ML phase.\nI have selected a few physicochemical properties down below so that readers and I could gather some reasonable understandings for each term. The explanations for each term were adapted from ChEMBL_31 schema documentation (available as “Release notes” on the website), or if definitions for certain terms were not available from the documentation, I resorted to interpret them myself by going into “Dinstict compounds” section on the ChEMBL database, where I would click on, e.g. bioactivities, for a random compound in there to see what results showed up and then described them below.\nThe definitions for some of the listed physicochemical properties were:\nMax Phase - Maximum phase of development reached for the compound (where 4 = approved). Null was where max phase has not yet been assigned.\nBioactivities - Various biological assays used for the compounds e.g. IC50, GI50, potency tests etc.\nAlogP - Calculated partition coefficient\nHBA - Number of hydrogen bond acceptors\nHBD - Number of hydrogen bond donors\n#RO5 Violations - Number of violations of Lipinski’s rule-of-five, using HBA and HBD definitions\nPasses Ro3 - Indicated whether the compound passed the rule-of-three (MW < 300, logP < 3 etc)\nQED Weighted - Weighted quantitative estimate of drug likeness (as defined by Bickerton et al., Nature Chem 2012)\nInorganic flag - Indicated whether the molecule was inorganic (i.e., containing only metal atoms and <2 carbon atoms), where 1 = inorganic compound and -1 = not inorganic compound (assuming 0 meant it was neither case or yet to be assigned)\nHeavy Atoms - Number of heavy (non-hydrogen) atoms\nCX Acidic pKa - The most acidic pKa calculated using ChemAxon v17.29.0\nCX Basic pKa - The most basic pKa calculated using ChemAxon v17.29.0\nCX LogP - The calculated octanol/water partition coefficient using ChemAxon v17.29.0\nCX LogD - The calculated octanol/water distribution coefficient at pH = 7.4 using ChemAxon v17.29.0\nStructure Type - based on compound_structures table, where SEQ indicated an entry in the protein_therapeutics table instead, NONE indicated an entry in neither tables, e.g. structure unknown\nInchi Key - the IUPAC international chemical identifier key\nFrom the df.glimpse() method previously, there were a lot of columns with the data type of “Utf8”, which meant they were strings. There were only two columns that had “Int64”, which meant they were integers. A lot of these columns were actually storing numbers as strings. So to make my life easier, I went on to convert these data types into the more appropriate ones for selected columns.\n\n# Convert data types for multiple selected columns\n# Note: only takes two positional arguments, \n# so needed to use [] in code to allow more than two\n\n# Multiple columns all at once - with_columns()\n# *Single column - with_column() \n# *this only worked at the time of writing the post (around published date), \n# this is not going to work currently as Polars has been updated, \n# please use with_columns() for single or multiple columns instead*\n\n# Use alias if wanting to keep original data type in column, \n# as it adds a new column under an alias name to dataframe\ndf_new = df.with_columns(\n    [\n        (pl.col(\"Molecular Weight\")).cast(pl.Float64, strict = False),\n        (pl.col(\"Targets\")).cast(pl.Int64, strict = False),\n        (pl.col(\"Bioactivities\")).cast(pl.Int64, strict = False),\n        (pl.col(\"AlogP\")).cast(pl.Float64, strict = False),\n        (pl.col(\"Polar Surface Area\")).cast(pl.Float64, strict = False),\n        (pl.col(\"HBA\")).cast(pl.Int64, strict = False),\n        (pl.col(\"HBD\")).cast(pl.Int64, strict = False),\n        (pl.col(\"#RO5 Violations\")).cast(pl.Int64, strict = False),\n        (pl.col(\"#Rotatable Bonds\")).cast(pl.Int64, strict = False),\n        (pl.col(\"QED Weighted\")).cast(pl.Float64, strict = False),\n        (pl.col(\"CX Acidic pKa\")).cast(pl.Float64, strict = False),\n        (pl.col(\"CX Basic pKa\")).cast(pl.Float64, strict = False),\n        (pl.col(\"CX LogP\")).cast(pl.Float64, strict = False),\n        (pl.col(\"CX LogD\")).cast(pl.Float64, strict = False),\n        (pl.col(\"Aromatic Rings\")).cast(pl.Int64, strict = False),\n        (pl.col(\"Heavy Atoms\")).cast(pl.Int64, strict = False),\n        (pl.col(\"HBA (Lipinski)\")).cast(pl.Int64, strict = False),\n        (pl.col(\"HBD (Lipinski)\")).cast(pl.Int64, strict = False),\n        (pl.col(\"#RO5 Violations (Lipinski)\")).cast(pl.Int64, strict = False),\n        (pl.col(\"Molecular Weight (Monoisotopic)\")).cast(pl.Float64, strict = False)\n    ]\n)\ndf_new.head()\n\n\n\nshape: (5, 32)ChEMBL IDNameSynonymsTypeMax PhaseMolecular WeightTargetsBioactivitiesAlogPPolar Surface AreaHBAHBD#RO5 Violations#Rotatable BondsPasses Ro3QED WeightedCX Acidic pKaCX Basic pKaCX LogPCX LogDAromatic RingsStructure TypeInorganic FlagHeavy AtomsHBA (Lipinski)HBD (Lipinski)#RO5 Violations (Lipinski)Molecular Weight (Monoisotopic)Molecular SpeciesMolecular FormulaSmilesInchi Keystrstrstrstri64f64i64i64f64f64i64i64i64i64strf64f64f64f64f64i64stri64i64i64i64i64f64strstrstrstr\"CHEMBL1206185\"\"\"\"\"\"Small molecule\"0607.88nullnull9.4689.6252217\"N\"0.09-1.918.389.49.363\"MOL\"-142532607.279\"ACID\"\"C35H45NO4S2\"\"CCCCCCCCCCC#CC(N)c1ccccc1-c1cc…\"UFBLKYIDZFRLPR-UHFFFAOYSA-N\"\"CHEMBL539070\"\"\"\"\"\"Small molecule\"0286.79112.2873.066205\"N\"0.6313.843.642.572.572\"MOL\"-117530250.0888\"NEUTRAL\"\"C11H15ClN4OS\"\"CCCOc1ccccc1-c1nnc(NN)s1.Cl\"\"WPEWNRKLKLNLSO-UHFFFAOYSA-N\"\"CHEMBL3335528\"\"\"\"\"\"Small molecule\"0842.8260.18269.57185217\"N\"0.093.2null3.31-0.143\"MOL\"-1601952842.2633\"ACID\"\"C41H46O19\"\"COC(=O)[C@H](O[C@@H]1O[C@@H](C…\"KGUJQZWYZPYYRZ-LWEWUKDVSA-N\"\"CHEMBL2419030\"\"\"\"\"\"Small molecule\"0359.33443.9485.136103\"N\"0.66nullnull3.663.662\"MOL\"-124610359.0551\"NEUTRAL\"\"C14H12F3N3O3S\"\"O=c1nc(NC2CCCC2)sc2c([N+](=O)[…\"QGDMYSDFCXOKML-UHFFFAOYSA-N\"\"CHEMBL4301448\"\"\"\"\"\"Small molecule\"0465.55nullnull5.09105.2864110\"N\"0.15null12.144.412.04\"MOL\"-133751465.1635\"BASE\"\"C24H24FN5O2S\"\"N=C(N)NCCCOc1ccc(CNc2nc3ccc(Oc…\"RXTJPHLPHOZLFS-UHFFFAOYSA-N\"\n\n\nOnce all the columns’ data types have been checked and converted to appropriate types accordingly, I used null_count() to see the distributions of all null entries in the dataset.\n\n# Check for any null or NA or \"\" entries in the dataset\n# Alternative code that worked similarly was df.select(pl.all().null_count())\ndf_new.null_count()\n\n\n\nshape: (1, 32)ChEMBL IDNameSynonymsTypeMax PhaseMolecular WeightTargetsBioactivitiesAlogPPolar Surface AreaHBAHBD#RO5 Violations#Rotatable BondsPasses Ro3QED WeightedCX Acidic pKaCX Basic pKaCX LogPCX LogDAromatic RingsStructure TypeInorganic FlagHeavy AtomsHBA (Lipinski)HBD (Lipinski)#RO5 Violations (Lipinski)Molecular Weight (Monoisotopic)Molecular SpeciesMolecular FormulaSmilesInchi Keyu32u32u32u32u32u32u32u32u32u32u32u32u32u32u32u32u32u32u32u32u32u32u32u32u32u32u32u32u32u32u32u320000023249962239622383571835718357183571835718357108357110524398821688379583795835710083571835718357183571232520000\n\n\n\n# Drop rows with null entries\ndf_dn = df_new.drop_nulls()\ndf_dn \n# Number of rows reduced to 736,570\n\n\n\nshape: (736_570, 32)ChEMBL IDNameSynonymsTypeMax PhaseMolecular WeightTargetsBioactivitiesAlogPPolar Surface AreaHBAHBD#RO5 Violations#Rotatable BondsPasses Ro3QED WeightedCX Acidic pKaCX Basic pKaCX LogPCX LogDAromatic RingsStructure TypeInorganic FlagHeavy AtomsHBA (Lipinski)HBD (Lipinski)#RO5 Violations (Lipinski)Molecular Weight (Monoisotopic)Molecular SpeciesMolecular FormulaSmilesInchi Keystrstrstrstri64f64i64i64f64f64i64i64i64i64strf64f64f64f64f64i64stri64i64i64i64i64f64strstrstrstr\"CHEMBL539070\"\"\"\"\"\"Small molecule\"0286.79112.2873.066205\"N\"0.6313.843.642.572.572\"MOL\"-117530250.0888\"NEUTRAL\"\"C11H15ClN4OS\"\"CCCOc1ccccc1-c1nnc(NN)s1.Cl\"\"WPEWNRKLKLNLSO-UHFFFAOYSA-N\"\"CHEMBL3827271\"\"\"\"\"\"Small molecule\"0712.8511-2.84319.061011216\"N\"0.074.0810.49-6.88-8.950\"MOL\"-15019143712.4232\"ZWITTERION\"\"C31H56N10O9\"\"CC(C)C[C@@H]1NC(=O)[C@H](CCCNC…\"QJQNNLICZLLPMB-VUBDRERZSA-N\"\"CHEMBL3824158\"\"\"\"\"\"Small molecule\"0422.48245.09109.5462110\"N\"0.314.597.992.492.422\"MOL\"-131721422.1842\"ACID\"\"C24H26N2O5\"\"CCCCCCCNC(C1=C(O)C(=O)c2ccccc2…\"AXOVDUYYBUYLPC-UHFFFAOYSA-N\"\"CHEMBL1991010\"\"\"\"\"\"Small molecule\"0454.0560605.1840.543118\"N\"0.613.888.486.345.222\"MOL\"-131311417.2668\"NEUTRAL\"\"C28H36ClNO2\"\"CCc1ccc(/C=C/C(=O)C2CN(CC)CCC2…\"XJDPAUYFONOZBC-DCPGAFKKSA-N\"\"CHEMBL195644\"\"\"\"\"\"Small molecule\"0375.47234.9570.424202\"N\"0.739.523.733.923.912\"MOL\"-128420375.1834\"NEUTRAL\"\"C24H25NO3\"\"C[C@]12CCC3c4ccc(O)cc4CCC3C1CC…\"MOBPUUUBXAHZBM-KSAYNYSMSA-N\"……………………………………………………………………………………\"CHEMBL2419480\"\"\"\"\"\"Small molecule\"0456.52331.56129.468108\"N\"0.593.991.92.141.22\"MOL\"-132910456.1467\"ACID\"\"C22H24N4O5S\"\"CCOC(=O)c1cc(C#N)c(N2CC(C(=O)N…\"TXYSLOQUANFYQS-UHFFFAOYSA-N\"\"CHEMBL540121\"\"\"\"\"\"Small molecule\"0540.05232.39147.146418\"N\"0.225.0211.48-0.75-0.784\"MOL\"-136951503.1627\"ZWITTERION\"\"C26H26ClN5O4S\"\"Cc1ccn(NS(=O)(=O)c2cccc3ccccc2…\"TZLGWENJAJXWGA-UHFFFAOYSA-N\"\"CHEMBL374041\"\"\"\"\"\"Small molecule\"0504.5243.04144.9583110\"N\"0.286.594.372.171.333\"MOL\"-1371132504.1645\"NEUTRAL\"\"C26H24N4O7\"\"CCOCCC1(Oc2ccc(Oc3ccc(C(=O)Nc4…\"ABCSNHDQYHOLOO-UHFFFAOYSA-N\"\"CHEMBL2017916\"\"\"\"\"\"Small molecule\"0312.35332.8677.06104\"N\"0.88.133.492.172.13\"MOL\"-122610312.0681\"NEUTRAL\"\"C15H12N4O2S\"\"COc1ccc(-c2nnc(NC(=O)c3cccnc3)…\"XIZUJGDKNPVNQA-UHFFFAOYSA-N\"\"CHEMBL1416264\"\"\"\"\"\"Small molecule\"0380.41683.0685.077105\"N\"0.5413.853.862.472.474\"MOL\"-127710380.0856\"NEUTRAL\"\"C18H13FN6OS\"\"O=C(CSc1ccc2nnc(-c3cccnc3)n2n1…\"QVYIEKHEJKFNAT-UHFFFAOYSA-N\"\n\n\n\n# Check that all rows with null values were dropped\ndf_dn.null_count()\n\n\n\nshape: (1, 32)ChEMBL IDNameSynonymsTypeMax PhaseMolecular WeightTargetsBioactivitiesAlogPPolar Surface AreaHBAHBD#RO5 Violations#Rotatable BondsPasses Ro3QED WeightedCX Acidic pKaCX Basic pKaCX LogPCX LogDAromatic RingsStructure TypeInorganic FlagHeavy AtomsHBA (Lipinski)HBD (Lipinski)#RO5 Violations (Lipinski)Molecular Weight (Monoisotopic)Molecular SpeciesMolecular FormulaSmilesInchi Keyu32u32u32u32u32u32u32u32u32u32u32u32u32u32u32u32u32u32u32u32u32u32u32u32u32u32u32u32u32u32u32u3200000000000000000000000000000000\n\n\n\n# To see summary statistics for df_dn dataset\ndf_dn.describe()\n\n\n\nshape: (9, 33)statisticChEMBL IDNameSynonymsTypeMax PhaseMolecular WeightTargetsBioactivitiesAlogPPolar Surface AreaHBAHBD#RO5 Violations#Rotatable BondsPasses Ro3QED WeightedCX Acidic pKaCX Basic pKaCX LogPCX LogDAromatic RingsStructure TypeInorganic FlagHeavy AtomsHBA (Lipinski)HBD (Lipinski)#RO5 Violations (Lipinski)Molecular Weight (Monoisotopic)Molecular SpeciesMolecular FormulaSmilesInchi Keystrstrstrstrstrf64f64f64f64f64f64f64f64f64f64strf64f64f64f64f64f64strf64f64f64f64f64f64strstrstrstr\"count\"\"736570\"\"736570\"\"736570\"\"736570\"736570.0736570.0736570.0736570.0736570.0736570.0736570.0736570.0736570.0736570.0\"736570\"736570.0736570.0736570.0736570.0736570.0736570.0\"736570\"736570.0736570.0736570.0736570.0736570.0736570.0\"736570\"\"736570\"\"736570\"\"736570\"\"null_count\"\"0\"\"0\"\"0\"\"0\"0.00.00.00.00.00.00.00.00.00.0\"0\"0.00.00.00.00.00.0\"0\"0.00.00.00.00.00.0\"0\"\"0\"\"0\"\"0\"\"mean\"nullnullnullnull0.007937431.8800425.5207158.7054713.32520497.581165.8902212.2747210.4891246.216262null0.5109369.599445.0743772.8151152.173632.754412null-0.92952130.2661137.2765552.4978470.576319428.334452nullnullnullnull\"std\"nullnullnullnull0.164565135.63754314.78479355.5378361.98041447.408472.4591061.6819430.7941713.894505null0.2290393.5836393.2340992.2863252.6456941.2009null0.2559539.544063.0671582.0814850.908719133.755653nullnullnullnull\"min\"\"CHEMBL10\"\"\"\"\"\"\"0.045.041.01.0-12.923.241.00.00.00.0\"N\"0.01-20.030.0-16.71-26.040.0\"BOTH\"-1.03.01.00.00.045.0215\"ACID\"\"C10H10Br2N2O\"\"Br.Br.C/C(=N/NC(=N)N)c1ccc(CNC…\"AAAADVYFXUUVEO-UHFFFAOYSA-N\"\"25%\"nullnullnullnull0.0340.471.02.02.2168.294.01.00.04.0null0.347.692.251.640.972.0null-1.024.05.01.00.0339.0582nullnullnullnull\"50%\"nullnullnullnull0.0413.462.03.03.3788.325.02.00.05.0null0.5110.514.72.972.463.0null-1.029.07.02.00.0410.2066nullnullnullnull\"75%\"nullnullnullnull0.0494.575.08.04.53113.237.03.01.08.0null0.712.457.854.233.794.0null-1.035.09.03.01.0491.0028nullnullnullnull\"max\"\"CHEMBL99998\"\"t-4-AMINOCROTONIC ACID (TACA)\"\"trovafloxacin9\"\"Unknown\"4.01901.511334.017911.016.83595.2232.025.04.059.0\"Y\"0.9514.038.818.3118.3128.0\"MOL\"0.076.034.032.04.0999.4063\"ZWITTERION\"\"HNNa2O8S2\"\"n1nc2c([nH]1)c1nn[nH]c1c1nn[nH…\"ZZZZEJJXQQRZBH-UHFFFAOYSA-N\"\n\n\n\n\n\nSome exploratory data analysis\nOne of the columns that jumped out from the summary statistics of the df_dn dataset was the “Targets” column. It ranged from 1 to 1334 targets. Out of curiosity, I went through several places on ChEMBL website to find out the exact definition of “Target”. Eventually I settled on an answer which explained that the “Target” column represented the number of targets associated with the particular ChEMBL compound listed. I then singled out the ChEMBL compound with 1334 targets recorded, it turned out to be imatinib, which was marketed as Gleevec, and was a well-known prescription medicine for leukaemia and other selected oncological disorders with many well-documented drug interactions.\n\n# This was confirmed via a filter function, which brought up CHEMBL1421, or also known as dasatinib\ndf_dn.filter(pl.col(\"Targets\") == 1334)\n\n\n\nshape: (1, 32)ChEMBL IDNameSynonymsTypeMax PhaseMolecular WeightTargetsBioactivitiesAlogPPolar Surface AreaHBAHBD#RO5 Violations#Rotatable BondsPasses Ro3QED WeightedCX Acidic pKaCX Basic pKaCX LogPCX LogDAromatic RingsStructure TypeInorganic FlagHeavy AtomsHBA (Lipinski)HBD (Lipinski)#RO5 Violations (Lipinski)Molecular Weight (Monoisotopic)Molecular SpeciesMolecular FormulaSmilesInchi Keystrstrstrstri64f64i64i64f64f64i64i64i64i64strf64f64f64f64f64i64stri64i64i64i64i64f64strstrstrstr\"CHEMBL941\"\"IMATINIB\"\"GLAMOX|Gleevec|IMATINIB|Imatin…\"Small molecule\"4493.62133443594.5986.287207\"N\"0.3912.697.844.383.84\"MOL\"037820493.259\"NEUTRAL\"\"C29H31N7O\"\"Cc1ccc(NC(=O)c2ccc(CN3CCN(C)CC…\"KTUFNOKKBVMGRW-UHFFFAOYSA-N\"\n\n\nTo explore other physicochemical and molecular properties in the dataframe, “Max Phase” was one of the first few that drew my interests. So it tagged each ChEMBL compound with a max phase number from 0 to 4, where 4 meant the compound was approved (usually also meant it was already a prescription medicine). Thinking along this line, I thought what about those compounds that had max phase as 0, because they were the ones still pending associations with max phase numbers. By extending on this idea, this could be a good opportunity to introduce some ML to predict whether these zero max phase compounds would enter the approved max phase.\nFirstly, I had a look at the overall distribution of the max phase compounds in this dataframe df_dn.\n\n# Interested in what types of \"Max Phase\" were recorded \n# for the curated small molecules in ChEMBL database\ndf_dn.group_by(\"Max Phase\", maintain_order = True).agg(pl.count())\n\n/var/folders/0y/p72zn_cx4vz1lv6zmyd7gkt00000gn/T/ipykernel_2417/3278305966.py:3: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n  df_dn.group_by(\"Max Phase\", maintain_order = True).agg(pl.count())\n\n\n\n\nshape: (5, 2)Max Phasecounti64u3207346333303495424411239\n\n\nA quick groupby function showed that there were only 954 small molecules approved. Phase 3 recorded a total of 303 small molecules. For phase 2, there were 441 small molecules, followed by 239 compounds in phase 1. There were, however, a total amount of 734,633 small molecules that had zero as phase number (as per ChEMBL_31 schema documentation). Note: these figures were only for ChEMBL compounds with full documentations in the dataset (excluding entries or compounds with N/A or “” (empty) string cells).\nOne of the other parameters I was interested in was “QED Weighted”. So I went further into understanding what it meant, as the original reference was conveniently provided in the ChEMBL_31 schema documentation. The reference paper was by Bickerton, G., Paolini, G., Besnard, J. et al. Quantifying the chemical beauty of drugs. Nature Chem 4, 90–98 (2012) (note: author’s manuscript was available to view via PubMed link, the Nature Chemistry link only provided abstract with access to article via other means as stated).\nIn short, it was a measure of druglikeness for small molecules based on the concept of desirability, which was based on a total of 8 different molecular properties. These molecular properties included molecular weight, ALogP, polar surface area, number of hydrogen bond acceptors, number of hydrogen bond donors, number of rotatable bonds, number of aromatic rings and structural alerts. Without going into too much details for this QED Weighted parameter, it was normally recorded as a number that ranged from 0 to 1, with 0 being the least druglike and 1 being the most druglike.\n\n\n\nPrepare dataframe prior to running machine learning model\nBefore I got too carried away with further EDA, I wanted to get started on preparing a dataframe for the ML model. A rough plan at this stage was to filter out Max Phase 4 and 0 compounds. Max phase 0 compounds were the ones that were not assigned with any max phase numbers yet, so they would be ideal for use as the testing set. Another main idea was to use “Max Phase” parameter as the target y variable for a LR model, because ultimately stakeholders would be more interested in knowing which candidate compounds had the most likely chance to reach the final approved phase during a drug discovery and development project or otherwise. This would also provide a chance to potentially reduce the amount of resources and time required in such a complex and sophisticated matter.\nThe goal of this ML model was to answer this question: which physicochemical parameters would be the most suitable ones to predict whether a compound would enter max phase 4 (approved) or not? (implicitly, this might also help to predict which max phase 0 compounds would likely enter max phase 4 in the end)\nI’ve then narrowed down the df_dn dataset to fulfill the following criteria:\n\nOnly small molecules present\nMax phase of 0 and 4 only\n\nAnother reason behind choosing only small molecules that had max phase of 0 and 4 was that a confusion matrix could be built in the end to see if the parameters selected would give us a reasonably good model for predicting the outcomes of these small molecules.\nFor now, I’ve chosen the following columns (or physicochemical parameters) to appear in the interim df_0 and df_4 datasets.\n\n# Selecting Max phase 0 small molecules with desired parameters\ndf_0 = df_dn.filter(\n    (pl.col(\"Type\") == \"Small molecule\") &\n    (pl.col(\"Max Phase\") == 0)\n).select([\"ChEMBL ID\", \n          \"Type\", \n          \"Max Phase\",\n          \"#RO5 Violations\", \n          \"QED Weighted\", \n          \"CX LogP\", \n          \"CX LogD\", \n          \"Heavy Atoms\"]\n        )\ndf_0\n\n\n\nshape: (612_795, 8)ChEMBL IDTypeMax Phase#RO5 ViolationsQED WeightedCX LogPCX LogDHeavy Atomsstrstri64i64f64f64f64i64\"CHEMBL539070\"\"Small molecule\"000.632.572.5717\"CHEMBL3827271\"\"Small molecule\"020.07-6.88-8.9550\"CHEMBL3824158\"\"Small molecule\"010.312.492.4231\"CHEMBL1991010\"\"Small molecule\"010.66.345.2231\"CHEMBL195644\"\"Small molecule\"000.733.923.9128……………………\"CHEMBL2419480\"\"Small molecule\"000.592.141.232\"CHEMBL540121\"\"Small molecule\"010.22-0.75-0.7836\"CHEMBL374041\"\"Small molecule\"010.282.171.3337\"CHEMBL2017916\"\"Small molecule\"000.82.172.122\"CHEMBL1416264\"\"Small molecule\"000.542.472.4727\n\n\n\n# Selecting Max phase 4 small molecules with desired parameters\ndf_4 = df_dn.filter(\n    (pl.col(\"Type\") == \"Small molecule\") &\n    (pl.col(\"Max Phase\") == 4)\n).select([\"ChEMBL ID\", \n          \"Type\", \n          \"Max Phase\",\n          \"#RO5 Violations\", \n          \"QED Weighted\", \n          \"CX LogP\", \n          \"CX LogD\", \n          \"Heavy Atoms\"]\n        )\ndf_4\n\n\n\nshape: (944, 8)ChEMBL IDTypeMax Phase#RO5 ViolationsQED WeightedCX LogPCX LogDHeavy Atomsstrstri64i64f64f64f64i64\"CHEMBL1096882\"\"Small molecule\"400.31-1.97-5.1224\"CHEMBL2023898\"\"Small molecule\"420.144.184.1654\"CHEMBL1029\"\"Small molecule\"400.46-1.18-2.315\"CHEMBL1616\"\"Small molecule\"400.722.882.5820\"CHEMBL2146123\"\"Small molecule\"410.33-3.51-3.8132……………………\"CHEMBL3545062\"\"Small molecule\"420.15.575.5765\"CHEMBL3039520\"\"Small molecule\"400.833.32.6127\"CHEMBL1198857\"\"Small molecule\"400.263.61.9332\"CHEMBL2146133\"\"Small molecule\"400.772.432.4324\"CHEMBL1619785\"\"Small molecule\"400.492.091.8634\n\n\n\n\nRe-sampling via under-sampling\nBecause of the large number of Max Phase 0 compounds present in the original dataset, I’ve randomly sampled about 950 small molecules from this group, so that there were similar amount of data in each group to avoid having an imbalanced dataset.\n\ndf_s_0 = df_0.sample(n = 950, shuffle = True, seed = 0)\ndf_s_0\n\n\n\nshape: (950, 8)ChEMBL IDTypeMax Phase#RO5 ViolationsQED WeightedCX LogPCX LogDHeavy Atomsstrstri64i64f64f64f64i64\"CHEMBL1381048\"\"Small molecule\"000.661.251.2420\"CHEMBL14441\"\"Small molecule\"000.713.293.2817\"CHEMBL3916046\"\"Small molecule\"010.381.291.2837\"CHEMBL1091700\"\"Small molecule\"020.293.273.1345\"CHEMBL4109628\"\"Small molecule\"000.553.523.5234……………………\"CHEMBL3261532\"\"Small molecule\"000.782.99-0.3524\"CHEMBL3343507\"\"Small molecule\"000.52.180.0324\"CHEMBL1720477\"\"Small molecule\"000.922.34-0.7421\"CHEMBL4293746\"\"Small molecule\"000.482.612.5429\"CHEMBL3219994\"\"Small molecule\"000.834.464.1822\n\n\nSince the plan was to use LR method for ML model, the y variable I was interested in was going to be a binary categorical variable - meaning it needed to be 0 (not approved) or 1 (approved). To do this, I’ve added a new column with a new name of “Max_Phase” and replace “4” as “1” by dividing the whole column by 4 to reach this new label.\n\ndf_4_f = df_4.with_columns((pl.col(\"Max Phase\") / 4).alias(\"Max_Phase\"))\ndf_4_f\n\n\n\nshape: (944, 9)ChEMBL IDTypeMax Phase#RO5 ViolationsQED WeightedCX LogPCX LogDHeavy AtomsMax_Phasestrstri64i64f64f64f64i64f64\"CHEMBL1096882\"\"Small molecule\"400.31-1.97-5.12241.0\"CHEMBL2023898\"\"Small molecule\"420.144.184.16541.0\"CHEMBL1029\"\"Small molecule\"400.46-1.18-2.3151.0\"CHEMBL1616\"\"Small molecule\"400.722.882.58201.0\"CHEMBL2146123\"\"Small molecule\"410.33-3.51-3.81321.0………………………\"CHEMBL3545062\"\"Small molecule\"420.15.575.57651.0\"CHEMBL3039520\"\"Small molecule\"400.833.32.61271.0\"CHEMBL1198857\"\"Small molecule\"400.263.61.93321.0\"CHEMBL2146133\"\"Small molecule\"400.772.432.43241.0\"CHEMBL1619785\"\"Small molecule\"400.492.091.86341.0\n\n\nThen I changed the data type of “Max_Phase” from float to integer, so that the two different dataframes could be concatenated (which would only work if both were of same data types).\n\ndf_4_f = df_4_f.with_columns((pl.col(\"Max_Phase\")).cast(pl.Int64, strict = False))\ndf_4_f\n\n\n\nshape: (944, 9)ChEMBL IDTypeMax Phase#RO5 ViolationsQED WeightedCX LogPCX LogDHeavy AtomsMax_Phasestrstri64i64f64f64f64i64i64\"CHEMBL1096882\"\"Small molecule\"400.31-1.97-5.12241\"CHEMBL2023898\"\"Small molecule\"420.144.184.16541\"CHEMBL1029\"\"Small molecule\"400.46-1.18-2.3151\"CHEMBL1616\"\"Small molecule\"400.722.882.58201\"CHEMBL2146123\"\"Small molecule\"410.33-3.51-3.81321………………………\"CHEMBL3545062\"\"Small molecule\"420.15.575.57651\"CHEMBL3039520\"\"Small molecule\"400.833.32.61271\"CHEMBL1198857\"\"Small molecule\"400.263.61.93321\"CHEMBL2146133\"\"Small molecule\"400.772.432.43241\"CHEMBL1619785\"\"Small molecule\"400.492.091.86341\n\n\nAlso I’ve created a new column with the same name of “Max_Phase” for Max phase 0 small molecules, so that the two dataframes could be combined (also needed to have exactly the same column names for it to work).\n\ndf_s_0_f = df_s_0.with_columns((pl.col(\"Max Phase\")).alias(\"Max_Phase\"))\ndf_s_0_f\n\n\n\nshape: (950, 9)ChEMBL IDTypeMax Phase#RO5 ViolationsQED WeightedCX LogPCX LogDHeavy AtomsMax_Phasestrstri64i64f64f64f64i64i64\"CHEMBL1381048\"\"Small molecule\"000.661.251.24200\"CHEMBL14441\"\"Small molecule\"000.713.293.28170\"CHEMBL3916046\"\"Small molecule\"010.381.291.28370\"CHEMBL1091700\"\"Small molecule\"020.293.273.13450\"CHEMBL4109628\"\"Small molecule\"000.553.523.52340………………………\"CHEMBL3261532\"\"Small molecule\"000.782.99-0.35240\"CHEMBL3343507\"\"Small molecule\"000.52.180.03240\"CHEMBL1720477\"\"Small molecule\"000.922.34-0.74210\"CHEMBL4293746\"\"Small molecule\"000.482.612.54290\"CHEMBL3219994\"\"Small molecule\"000.834.464.18220\n\n\nThen I combined df_s_0_f (dataframe with max phase 0 compounds) and df_4_f (dataframe with max phase 4 compounds).\n\ndf_concat = pl.concat([df_s_0_f, df_4_f], how = \"vertical\",)\nprint(df_concat)\n\nshape: (1_894, 9)\n┌───────────────┬──────────┬───────────┬────────────┬───┬─────────┬─────────┬───────┬───────────┐\n│ ChEMBL ID     ┆ Type     ┆ Max Phase ┆ #RO5       ┆ … ┆ CX LogP ┆ CX LogD ┆ Heavy ┆ Max_Phase │\n│ ---           ┆ ---      ┆ ---       ┆ Violations ┆   ┆ ---     ┆ ---     ┆ Atoms ┆ ---       │\n│ str           ┆ str      ┆ i64       ┆ ---        ┆   ┆ f64     ┆ f64     ┆ ---   ┆ i64       │\n│               ┆          ┆           ┆ i64        ┆   ┆         ┆         ┆ i64   ┆           │\n╞═══════════════╪══════════╪═══════════╪════════════╪═══╪═════════╪═════════╪═══════╪═══════════╡\n│ CHEMBL1381048 ┆ Small    ┆ 0         ┆ 0          ┆ … ┆ 1.25    ┆ 1.24    ┆ 20    ┆ 0         │\n│               ┆ molecule ┆           ┆            ┆   ┆         ┆         ┆       ┆           │\n│ CHEMBL14441   ┆ Small    ┆ 0         ┆ 0          ┆ … ┆ 3.29    ┆ 3.28    ┆ 17    ┆ 0         │\n│               ┆ molecule ┆           ┆            ┆   ┆         ┆         ┆       ┆           │\n│ CHEMBL3916046 ┆ Small    ┆ 0         ┆ 1          ┆ … ┆ 1.29    ┆ 1.28    ┆ 37    ┆ 0         │\n│               ┆ molecule ┆           ┆            ┆   ┆         ┆         ┆       ┆           │\n│ CHEMBL1091700 ┆ Small    ┆ 0         ┆ 2          ┆ … ┆ 3.27    ┆ 3.13    ┆ 45    ┆ 0         │\n│               ┆ molecule ┆           ┆            ┆   ┆         ┆         ┆       ┆           │\n│ CHEMBL4109628 ┆ Small    ┆ 0         ┆ 0          ┆ … ┆ 3.52    ┆ 3.52    ┆ 34    ┆ 0         │\n│               ┆ molecule ┆           ┆            ┆   ┆         ┆         ┆       ┆           │\n│ …             ┆ …        ┆ …         ┆ …          ┆ … ┆ …       ┆ …       ┆ …     ┆ …         │\n│ CHEMBL3545062 ┆ Small    ┆ 4         ┆ 2          ┆ … ┆ 5.57    ┆ 5.57    ┆ 65    ┆ 1         │\n│               ┆ molecule ┆           ┆            ┆   ┆         ┆         ┆       ┆           │\n│ CHEMBL3039520 ┆ Small    ┆ 4         ┆ 0          ┆ … ┆ 3.3     ┆ 2.61    ┆ 27    ┆ 1         │\n│               ┆ molecule ┆           ┆            ┆   ┆         ┆         ┆       ┆           │\n│ CHEMBL1198857 ┆ Small    ┆ 4         ┆ 0          ┆ … ┆ 3.6     ┆ 1.93    ┆ 32    ┆ 1         │\n│               ┆ molecule ┆           ┆            ┆   ┆         ┆         ┆       ┆           │\n│ CHEMBL2146133 ┆ Small    ┆ 4         ┆ 0          ┆ … ┆ 2.43    ┆ 2.43    ┆ 24    ┆ 1         │\n│               ┆ molecule ┆           ┆            ┆   ┆         ┆         ┆       ┆           │\n│ CHEMBL1619785 ┆ Small    ┆ 4         ┆ 0          ┆ … ┆ 2.09    ┆ 1.86    ┆ 34    ┆ 1         │\n│               ┆ molecule ┆           ┆            ┆   ┆         ┆         ┆       ┆           │\n└───────────────┴──────────┴───────────┴────────────┴───┴─────────┴─────────┴───────┴───────────┘\n\n\nThis df_concat dataset was checked to see it had all compounds in Max Phase 0 and 4 only. Note: Max Phase 4 (approved) compounds were re-labelled as Max_Phase = 1.\n\ndf_concat.group_by(\"Max_Phase\").count()\n\n/var/folders/0y/p72zn_cx4vz1lv6zmyd7gkt00000gn/T/ipykernel_2417/631682218.py:1: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n  df_concat.group_by(\"Max_Phase\").count()\n\n\n\n\nshape: (2, 2)Max_Phasecounti64u3209501944\n\n\nI then checked df_concat dataset only had small molecules to confirm what I’ve tried to achieve.\n\ndf_concat.group_by(\"Type\").count()\n\n/var/folders/0y/p72zn_cx4vz1lv6zmyd7gkt00000gn/T/ipykernel_2417/3888448416.py:1: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n  df_concat.group_by(\"Type\").count()\n\n\n\n\nshape: (1, 2)Typecountstru32\"Small molecule\"1894\n\n\nSo here we had the final version of the dataset, which I’ve renamed to df_ml to avoid confusion from the previous dataframes, before entering the ML phase.\n\n# Leave out ChEMBL ID and Type\ndf_ml = df_concat.select([\"Max_Phase\", \n                          \"#RO5 Violations\", \n                          \"QED Weighted\", \n                          \"CX LogP\", \n                          \"CX LogD\", \n                          \"Heavy Atoms\"]\n                        )\ndf_ml\n\n\n\nshape: (1_894, 6)Max_Phase#RO5 ViolationsQED WeightedCX LogPCX LogDHeavy Atomsi64i64f64f64f64i64000.661.251.2420000.713.293.2817010.381.291.2837020.293.273.1345000.553.523.5234………………120.15.575.5765100.833.32.6127100.263.61.9332100.772.432.4324100.492.091.8634\n\n\n\n# Check for any nulls in the dataset\ndf_ml.null_count()\n\n\n\nshape: (1, 6)Max_Phase#RO5 ViolationsQED WeightedCX LogPCX LogDHeavy Atomsu32u32u32u32u32u32000000\n\n\n\n# Check data types in df_ml dataset\n# Needed to be integers or floats for scikit-learn algorithms to work\ndf_ml.dtypes\n\n[Int64, Int64, Float64, Float64, Float64, Int64]\n\n\n```{python}\n# Note: exported df_ml dataframe as csv file for ML series 1.2.\ndf_ml.write_csv(\"df_ml.csv\", sep = \",\")\n```\n\n\n\n\nImport libraries for machine learning\n\n# Install scikit-learn - an open-source ML library\n# Uncomment the line below if needing to install this library\n#!pip install -U scikit-learn\n\n\n# Import scikit-learn\nimport sklearn\n\n# Check version of scikit-learn \nprint(sklearn.__version__)\n\n1.5.0\n\n\nOther libraries needed to generate ML model were imported as below.\n\n# To use NumPy arrays to prepare X & y variables\nimport numpy as np\n\n# Needed for dataframe in scikit-learn ML\n# Uncomment line below if requiring to install pandas\n#!pip install pandas\nimport pandas as pd\n\n# To normalise dataset prior to running ML\nfrom sklearn import preprocessing\n# To split dataset into training & testing sets\nfrom sklearn.model_selection import train_test_split\n\n# For data visualisations\n# Uncomment line below if requiring to install matplotlib\n#!pip install matplotlib\nimport matplotlib.pyplot as plt\n\nI’ve then installed pyarrow, to convert Polars dataframe into a Pandas dataframe, which was needed to run scikit-learn.\n\n# Uncomment line below to install pyarrow\n#!pip install pyarrow\n\n\n# Convert Polars df to Pandas df \ndf_ml_pd = df_ml.to_pandas()\ntype(df_ml_pd)\n\npandas.core.frame.DataFrame\n\n\n\n\n\nLogistic regression with scikit-learn\nLR was one of the supervised methods in statistical ML realm. As the term “supervised” suggested, this type of ML was purely data-driven to allow computers to learn patterns from input data with known outcomes, in order to predict new outcomes on novel data.\n\n\nDefining X and y variables\n\n# Define X variables from df_ml_pd dataset\nX = np.asarray(df_ml_pd[[\"#RO5 Violations\", \n                         \"QED Weighted\", \n                         \"CX LogP\", \n                         \"CX LogD\", \n                         \"Heavy Atoms\"]]\n              )\nX[0:5]\n\narray([[ 0.  ,  0.66,  1.25,  1.24, 20.  ],\n       [ 0.  ,  0.71,  3.29,  3.28, 17.  ],\n       [ 1.  ,  0.38,  1.29,  1.28, 37.  ],\n       [ 2.  ,  0.29,  3.27,  3.13, 45.  ],\n       [ 0.  ,  0.55,  3.52,  3.52, 34.  ]])\n\n\n\n# Define y variable\n# Note to use \"Max_Phase\", not the original \"Max Phase\"\ny = np.asarray(df_ml_pd[\"Max_Phase\"])\ny[0:5]\n\narray([0, 0, 0, 0, 0])\n\n\n\n\n\nTraining and testing sets\n\n# Split dataset into training & testing sets\n\n# Random number generator\n#rng = np.random.RandomState(0) - note: this may produce different result each time\n\n# Edited post to use random_state = 250 to show comparison with ML series 1.2\n# for reproducible result\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 250)\nprint('Training set:', X_train.shape, y_train.shape)\nprint('Testing set:', X_test.shape, y_test.shape)\n\nTraining set: (1515, 5) (1515,)\nTesting set: (379, 5) (379,)\n\n\n\n\n\nPreprocessing data\n\n# Normalise & clean the dataset\n# Fit on the training set - not on testing set as this might lead to data leakage\n# Transform on the testing set\nX = preprocessing.StandardScaler().fit(X_train).transform(X_test)\nX[0:5]\n\narray([[ 0.60894516, -0.22530057, -1.42757534, -0.9045478 , -0.66822519],\n       [-0.6081418 , -0.5780968 ,  0.47438747,  0.26911898,  0.2876441 ],\n       [-0.6081418 ,  1.45048155, -0.28333614,  0.03629921, -0.57263826],\n       [-0.6081418 ,  1.18588438, -0.7349088 , -0.38787927, -1.14615983],\n       [-0.6081418 , -0.48989774,  0.65042427,  0.82724856, -0.19029055]])\n\n\n\n\n\nFitting LR classifier on training set\n\n# Import logistic regression \nfrom sklearn.linear_model import LogisticRegression\n# Create an instance of logistic regression classifier and fit the data\nLogR = LogisticRegression().fit(X_train, y_train)\nLogR\n\nLogisticRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  LogisticRegression?Documentation for LogisticRegressioniFittedLogisticRegression() \n\n\n\n\n\nApplying LR classifier on testing set for prediction\n\ny_mp = LogR.predict(X_test)\ny_mp\n\narray([1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n       0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1,\n       1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n       0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n       1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n       0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n       0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n       0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1,\n       0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1,\n       0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n       1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0,\n       0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1,\n       0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n       0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1,\n       1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1,\n       0, 1, 1, 0, 1])\n\n\n\n\n\nConverting predicted values into a dataframe\n\n# Predicted values were based on log odds\n# Use describe() method to get characteristics of the distribution\npred = pd.DataFrame(LogR.predict_log_proba(X))\npred.describe()\n\n\n\n\n\n  \n    \n      \n      0\n      1\n    \n  \n  \n    \n      count\n      379.000000\n      379.000000\n    \n    \n      mean\n      -0.862452\n      -0.616678\n    \n    \n      std\n      0.318816\n      0.258353\n    \n    \n      min\n      -1.622114\n      -1.537892\n    \n    \n      25%\n      -1.096951\n      -0.775959\n    \n    \n      50%\n      -0.826656\n      -0.575382\n    \n    \n      75%\n      -0.616677\n      -0.406300\n    \n    \n      max\n      -0.241859\n      -0.219999\n    \n  \n\n\n\n\nAlternatively, a quicker way to get predicted probabilities was via predict_proba() method in scikit-learn.\n\ny_mp_proba = LogR.predict_proba(X_test)\n# Uncomment below to see the predicted probabilities printed\n#print(y_mp_proba)\n\n\n\n\nConverting predicted probabilities into a dataframe\n\n# Use describe() to show distributions\ny_mp_prob = pd.DataFrame(y_mp_proba)\ny_mp_prob.describe()\n\n\n\n\n\n  \n    \n      \n      0\n      1\n    \n  \n  \n    \n      count\n      379.000000\n      379.000000\n    \n    \n      mean\n      0.482996\n      0.517004\n    \n    \n      std\n      0.169226\n      0.169226\n    \n    \n      min\n      0.008877\n      0.151562\n    \n    \n      25%\n      0.365433\n      0.393816\n    \n    \n      50%\n      0.504758\n      0.495242\n    \n    \n      75%\n      0.606184\n      0.634567\n    \n    \n      max\n      0.848438\n      0.991123\n    \n  \n\n\n\n\n\n\n\nPipeline method for LR\nThis was something I thought to try when I was reading through scikit-learn documentation. One major advantage of using pipeline was that it was designed to chain all the estimators used for ML. The benefit of this was that we only had to call fit and predict once in our data to fit the whole chain of estimators. The other useful thing was that this could avoid data leakage from our testing set into the training set by making sure the same set of samples were used to train the transformers and predictors. One other key thing it also helped was that it also avoided the possibility of missing out on the transformation step.\nThe example below used the function of make_pipeline, which took in a number of estimators as inputted, and then constructed a pipeline based on them.\n\n# Test pipline from scikit-Learn\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\n\nLR = make_pipeline(StandardScaler(), LogisticRegression())\nLR.fit(X_train, y_train)\n\nPipeline(steps=[('standardscaler', StandardScaler()),\n                ('logisticregression', LogisticRegression())])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  Pipeline?Documentation for PipelineiFittedPipeline(steps=[('standardscaler', StandardScaler()),\n                ('logisticregression', LogisticRegression())])  StandardScaler?Documentation for StandardScalerStandardScaler()  LogisticRegression?Documentation for LogisticRegressionLogisticRegression() \n\n\n\n\n\n\nEvaluation of the logistic regression model\n\nAccuracy scores\n\nfrom sklearn.metrics import accuracy_score\naccuracy_score(y_mp, y_test)\n\n0.7018469656992085\n\n\nThe accuracy score was 0.7 (after rounding up) based on the original data preprocessing method, which meant that there were around 70% of the cases (or compounds) classified correctly by using this LR classifier. Accuracy literally provided a measure of how close the predicted samples were to the true values. One caveat to note was that for imbalanced dataset, accuracy score might not be very informative, and other evaluation metrics would need to be considered instead.\nThe accuracy score shown below was from the pipeline method used previously, which showed a very similar accuracy score of 0.69656992 (close to 0.7), confirming the method was in line with the original preprocessing method.\n\nLR.score(X_test, y_test)\n\n0.6965699208443272\n\n\n\n\n\nConfusion matrix\nNext, I’ve built a confusion matrix based on the model in order to visualise the counts of correct and incorrect predictions. The function code used below was adapted from the IBM data science course I’ve taken around the end of last year. I’ve added comments to try and explain what each section of the code meant.\n\n# Import confusion matrix from scikit-learn\nfrom sklearn.metrics import confusion_matrix\n# Import itertools - functions to create iterators for efficient looping\nimport itertools\n\n# Function to print and plot confusion matrix\ndef plot_confusion_matrix(# Sets a cm object (cm = confusion matrix)\n                          cm, \n                          # Sets classes of '1s' (Successes) & '0s' (Non-successes) for the cm\n                          classes,\n                          # If setting normalize = true, reports in ratios instead of counts\n                          normalize,\n                          title = 'Confusion matrix',\n                          # Choose colour of the cm (using colourmap recognised by matplotlib)\n                          cmap = plt.cm.Reds):\n    \n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis = 1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    # Plot the confusion matrix \n    plt.imshow(cm, interpolation = 'nearest', cmap = cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation = 45)\n    plt.yticks(tick_marks, classes)\n\n    # Floats to be round up to two decimal places if using normalize = True\n    # or else use integers\n    fmt = '.2f' if normalize else 'd'\n    # Sets threshold of 0.5\n    thresh = cm.max() / 2.\n    # Iterate through the results and differentiate between two text colours \n    # by using the threshold as a cut-off\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment = \"center\",\n                 color = \"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n\n# Compute confusion matrix\nmatrix = confusion_matrix(y_test, y_mp, labels = [0,1])\nnp.set_printoptions(precision = 2)\n\n# Plot confusion matrix without normalisation\nplt.figure()\nplot_confusion_matrix(matrix, \n                      # Define classes of outcomes\n                      classes = ['Max_Phase = 0','Max_Phase = 1'], \n                      # Set normalize = True if wanting ratios instead\n                      normalize = False, \n                      title = \"Confusion matrix without normalisation\"\n                     )\n\nConfusion matrix, without normalization\n[[143  59]\n [ 54 123]]\n\n\n\n\n\nA common rule of thumb for confusion matrix was that all predicted outcomes were columns and all the true outcomes were rows. However, there might be exceptions where this was the other way round. Four different categories could be seen in the confusion matrix which were:\n\nTrue positive - Predicted Max_Phase = 1 & True Max_Phase = 1 (126 out of 189 samples)\nTrue negative - Predicted Max_Phase = 0 & True Max_Phase = 0 (139 out of 190 samples)\nFalse positive - Predicted Max_Phase = 1 & True Max_Phase = 0 (63 out of 189 samples)\nFalse negative - Predicted Max_Phase = 0 & True Max_Phase = 1 (51 out of 190 samples)\n\nBy having these four categories known would then lead us to the next section about classification report, which showed all the precision, recall, f1-score and support metrics to evaluate the performance of this classifier.\n\n\n\nClassification report\n\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test, y_mp))\n\n              precision    recall  f1-score   support\n\n           0       0.73      0.71      0.72       202\n           1       0.68      0.69      0.69       177\n\n    accuracy                           0.70       379\n   macro avg       0.70      0.70      0.70       379\nweighted avg       0.70      0.70      0.70       379\n\n\n\nPrecision was a measure of the accuracy of a predicted outcome, where a class label had been predicted by the classifier. So in this case, we could see that for class label 1, the precision was 0.67, which corresponded to the true positive result of 126 out of 189 samples (= 0.666). It was defined by:\n\\[\n\\text{Precision} = \\frac{\\Sigma\\ True\\ Positive}{(\\Sigma\\ True\\ Positive + \\Sigma\\ False\\ Positive)}\n\\]\nRecall, also known as sensitivity (especially widely used in biostatistics and medical diagnostic fields), was a measure of the strength of the classifier to predict a positive outcome. In simple words, it measured the true positive rate. In this example, there was a total of 126 out of 177 samples (which = 0.712, for True Max_Phase = 1 row) that had a true positive outcome of having a max phase of 1. It was defined by:\n\\[\n\\text{Recall} = \\frac{\\Sigma\\ True\\ Positive}{(\\Sigma\\ True\\ Positive + \\Sigma\\ False\\ Negative)}\n\\]\nThe precision and recall metrics could also be calculated for class label = 0, which were shown for the row 0 in the classification report.\nf1-score, or also known as balanced F-score or F-measure, denoted the harmonic average of both precision and recall metrics. This metric would also give another indication about whether this model performed well on outcome predictions. It normally ranged from 0 (worst precision and recall) to 1 (perfect precision and recall). For this particular classifier, f1-score was at 0.69 (for class label = 1), which was definitely not at its worst, but also could be further improved. It was defined as:\n\\[\n\\text{F1-score} = \\frac{2 \\times (Precision \\times Recall)}{(Precision + Recall)}\n\\]\nSupport, which some readers might have already worked out how the numbers were derived, was the total number of true samples in each class label (reading row-wise from the confusion matrix). The main purpose of showing this metric was to help clarifying whether the model or classifier had a reasonably balanced dataset for each class or otherwise.\n\n\n\nLog loss\nLog loss could be used as another gauge to show how good the classifier was at making the outcome predictions. The further the predicted probability was from the true value, the larger the log loss, which was also ranged from 0 to 1. Ideally, the smaller the log loss the better the model would be. Here, we had a log loss of 0.607 for this particular model.\n\n# Log loss\nfrom sklearn.metrics import log_loss\nlog_loss(y_test, y_mp_proba)\n\n0.6171675830247453\n\n\n\n\n\nDiscussions and conclusion\nSo here I’ve completed a very basic LR classifier model for ChEMBL compound dataset. By no means was this a perfect ML model as I haven’t actually changed the default settings of scikit-learn’s LogisticRegression() classifier, with examples such as adjusting C, a regularization parameter which was set at ‘1.0’ by default, and also solvers, which could take in different algorithms for use in optimisation problems and normally set as ‘lbfgs’ by default.\nSo with this default LR model, the evaluation metrics demonstrated a LR classifer of moderate quality to predict the approval outcomes on ChEMBL small molecules, with a lot of rooms for improvements. Therefore, I could not yet confirm fully that the physicochemical parameters chosen would be the best ones to predict the approval outcomes for any small molecules. However, I might be okay to say that these molecular parameters were on the right track to help with making this prediction.\nTo further improve this model, I could possibly trial changing the C value and use different solvers to see if better outcomes could be achieved, or even add more molecular parameters in the model to test. I could have also trialled adding more class labels, e.g. making it between max phase 1, 2 and 4, or a mix-and-match between each max phase category. Other things to consider would be to use other types of ML methods such as naive Bayes, K-nearest neighbours or decision trees and so on. To tackle the problem thoroughly, I would most likely need to do an ensemble of different ML models to find out which model would be the most optimal to answer our target question.\n\n\n\nFinal words\nI’ve experienced the fun of ML after completing this project. The idea was to build on what I knew gradually and enjoy what ML could do when making critical decisions. From what I’ve learnt about ML so far (and definitely more to learn) was that the quality of data was vital for making meaningful interpretations of the results.\nHowever, jumping back to present time, I’ll need to work on my second project first, which is about using Rust interactively via Jupyter notebook. At the moment, I’m not sure how long it will take or how the content will play out. I’ll certainly do as much as I can since Rust is very new to me. If I get very stuck, I’d most likely continue on this ML series. Thanks for reading.\n\n\n\nReferences\nI’ve listed below most of the references used throughout this project. Again, huge thanks could not be forgotten for our online communities, and definitely also towards the references I’ve used here.\n\nscikit-learn documentation\nScikit-learn: Machine Learning in Python, Pedregosa et al., JMLR 12, pp. 2825-2830, 2011.\nBruce, P., Bruce, A. & Gedeck P. (2020). Practical statistics for data scientists. O’Reilly.\nStack Overflow\nPolars references:\n\nPolars - User Guide - https://pola-rs.github.io/polars-book/user-guide/introduction.html\nPolars documentation - https://pola-rs.github.io/polars/py-polars/html/index.html#\nPolars GitHub repository - https://github.com/pola-rs/polars"
  },
  {
    "objectID": "posts/17_ML2-2_Random_forest/2_random_forest_classifier.html",
    "href": "posts/17_ML2-2_Random_forest/2_random_forest_classifier.html",
    "title": "Random forest classifier",
    "section": "",
    "text": "The section on “Data retrieval using chembl_downloader” has been updated and finalised on 31st January 2024 - many thanks for the comment from Charles Tapley Hoyt (cthoyt).\nJupyter notebook version can be accessed here.\n\n\nBrief introduction\nThis post was really just an addition towards the last random forest (RF) post. It was mainly inspired by this paper (Esposito et al. 2021) from rinikerlab1. It was nice to complete the RF series by adding a RF classifier since last post was only on a regressor. Another thing was that imbalanced datasets were common in drug discovery projects, learning different strategies to deal with them was also very useful. While working on this post, I also came across a few other packages that I haven’t used before so I’ve included them all down below.\n\n\n\nOverview of post\n\nData sourcing via chembl_downloader\nMinor data preprocessing using own little script and also SMILES checker from scikit_mol\nscikit-learn’s RandomForestClassifier()\nDealing with imbalanced dataset in RF classifiers by using ghostml\nA small section on plotting receiver operating characteristic (ROC) curves\n\n\n\n\nImporting libraries\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport chembl_downloader\nfrom chembl_downloader import latest, queries, query\nfrom rdkit.Chem import Descriptors\nimport datamol as dm\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import ConfusionMatrixDisplay\nfrom sklearn.metrics import RocCurveDisplay, roc_curve\nfrom scikit_mol.utilities import CheckSmilesSanitazion\nimport ghostml\n\n\n\n\nData retrieval using chembl_downloader\nchembl_downloader was something I wanted to try a while back. I’ve tried manual download and chembl_webresource_client previously, and they were probably not the best strategies for data reproducibility. The idea of chembl_downloader was to generate a reproducible ChEMBL data source. It involved some SQL at the beginning to specify the exact type of data needed, so some SQL knowledge were required. Other uses for this package were elaborated much more clearly in its GitHub repository at https://github.com/cthoyt/chembl-downloader. One of the reference notebooks that I’ve used could be reached here (more available in its repository).\nWhat I did was shown below.\n\n# Show the latest version of ChEMBL used\nlatest_version = latest()\nprint(f\"The latest ChEMBL version is: {latest_version}\")\n\nThe latest ChEMBL version is: 33\n\n\nThe following section was updated as suggested by cthoyt (via his comment for post below). I ended up putting through my first ever pull request in an open-source and cheminformatics-related repository. A new option to choose max_phase was added into the get_target_sql function in chembl_downloader by keeping it as a togglable option via boolean flag. Many thanks for the patience from cthoyt for guiding me through it. The overall code was now changed as shown below.\n::: {.cell execution_count=3}\n# Generate SQL for a query on acetylcholinesterase (AChE): CHEMBL220\nsql = queries.get_target_sql(target_id=\"CHEMBL220\", target_type=\"SINGLE PROTEIN\", max_phase=True)\n\n# Pretty-print the SQL in Jupyter\nqueries.markdown(sql)\n\nSELECT\n    ASSAYS.chembl_id              AS assay_chembl_id,\n    TARGET_DICTIONARY.target_type,\n    TARGET_DICTIONARY.tax_id,\n    COMPOUND_STRUCTURES.canonical_smiles,\n    MOLECULE_DICTIONARY.chembl_id AS molecule_chembl_id,\n    MOLECULE_DICTIONARY.max_phase,\n    ACTIVITIES.standard_type,\n    ACTIVITIES.pchembl_value\nFROM TARGET_DICTIONARY\n     JOIN ASSAYS ON TARGET_DICTIONARY.tid == ASSAYS.tid\n     JOIN ACTIVITIES ON ASSAYS.assay_id == ACTIVITIES.assay_id\n     JOIN MOLECULE_DICTIONARY ON MOLECULE_DICTIONARY.molregno == ACTIVITIES.molregno\n     JOIN COMPOUND_STRUCTURES ON MOLECULE_DICTIONARY.molregno == COMPOUND_STRUCTURES.molregno\nWHERE TARGET_DICTIONARY.chembl_id = 'CHEMBL220'\n    AND ACTIVITIES.pchembl_value IS NOT NULL\n    AND TARGET_DICTIONARY.target_type = 'SINGLE PROTEIN'```\n:::\n:::\n\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\n# The SQL still works as shown above, \n# please ignore the non-SQL texts\n# - bit of a formatting issue \n# when pretty-printing the sql, \n# but shouldn't affect the code\n\nI’ve also updated how I retrieved and saved the ChEMBL data with the following code suggested and provided by cthoyt. This would be a better and more reproducible way for anyone who might be interested in re-running this notebook.\n\nfrom pathlib import Path\n\n# Pick any directory, but make sure it's relative to your home directory\ndirectory = Path.home().joinpath(\".data\", \"blog\")\n# Create the directory if it doesn't exist\ndirectory.mkdir(exist_ok=True, parents=True)\n\n# Create a file path that corresponds to the version, since this could change\npath = directory.joinpath(f\"chembl_d_ache_{latest_version}.tsv\")\n\nif path.is_file():\n    # If the file already exists, load it\n    df_ache = pd.read_csv(path, sep=',')\nelse:\n    # If the file doesn't already exist, make the query then cache it\n    df_ache = chembl_downloader.query(sql)\n    df_ache.to_csv(path, sep=\",\", index=False)\n\nThe rest of the code outputs in the post stayed the same as before. The only thing changed and updated was the part on retrieving ChEMBL data via chembl_downloader.\n\n\n\nSome data cleaning\nMinor cleaning and preprocessing were done for this post only, as the focus was more on dealing with imbalanced dataset in RF classifier. Since I used a different way to retrieve ChEMBL data this time, the dataset used here might be slightly different from the one used in previous post.\n\n\nmol_prep.py\nI’ve more or less accumulated small pieces of code over time, and I’ve decided to compile them into a Python script. The idea was to remove most function code in the post to avoid repeating them all the time since they’ve been used frequently in the last few posts. The script would be saved into the RF repository, and would still be considered as a “work-in-progress” script (needs more work in the future).\n\n## Trial own mol_prep.py script\nfrom mol_prep import preprocess, rdkit_2d_descriptors\n\n\n## Preprocess/standardise molecules\n# Running preprocess function \ndf_ache = df_ache.copy()\ndf_prep = df_ache.apply(preprocess, axis = 1)\ndf_prep.head(3)\n\n\n\n\n\n  \n    \n      \n      assay_chembl_id\n      target_type\n      tax_id\n      chembl_id\n      canonical_smiles\n      molecule_chembl_id\n      max_phase\n      standard_type\n      pchembl_value\n      rdkit_mol\n      standard_smiles\n      selfies\n      inchi\n      inchikey\n    \n  \n  \n    \n      0\n      CHEMBL1909212\n      SINGLE PROTEIN\n      9606\n      CHEMBL220\n      CC/C(=C(/CC)c1ccc(O)cc1)c1ccc(O)cc1\n      CHEMBL411\n      4.0\n      IC50\n      4.59\n      <rdkit.Chem.rdchem.Mol object at 0x12b7f2180>\n      CC/C(=C(/CC)c1ccc(O)cc1)c1ccc(O)cc1\n      [C][C][/C][=Branch1][P][=C][Branch1][Ring1][/C...\n      InChI=1S/C18H20O2/c1-3-17(13-5-9-15(19)10-6-13...\n      RGLYKWWBQGJZGM-ISLYRVAYSA-N\n    \n    \n      1\n      CHEMBL1003053\n      SINGLE PROTEIN\n      9606\n      CHEMBL220\n      COc1c2occc2cc2ccc(=O)oc12\n      CHEMBL416\n      4.0\n      IC50\n      4.27\n      <rdkit.Chem.rdchem.Mol object at 0x12b7f22d0>\n      COc1c2occc2cc2ccc(=O)oc12\n      [C][O][C][=C][O][C][=C][C][Ring1][Branch1][=C]...\n      InChI=1S/C12H8O4/c1-14-12-10-8(4-5-15-10)6-7-2...\n      QXKHYNVANLEOEG-UHFFFAOYSA-N\n    \n    \n      2\n      CHEMBL2406149\n      SINGLE PROTEIN\n      9606\n      CHEMBL220\n      COc1c2occc2cc2ccc(=O)oc12\n      CHEMBL416\n      4.0\n      IC50\n      6.12\n      <rdkit.Chem.rdchem.Mol object at 0x12b7f2340>\n      COc1c2occc2cc2ccc(=O)oc12\n      [C][O][C][=C][O][C][=C][C][Ring1][Branch1][=C]...\n      InChI=1S/C12H8O4/c1-14-12-10-8(4-5-15-10)6-7-2...\n      QXKHYNVANLEOEG-UHFFFAOYSA-N\n    \n  \n\n\n\n\n\n\n\nscikit_mol\nscikit_mol was a package originated from RDKit UGM hackathon in 2022. This blog post elaborated further on its functions and uses in machine learning. For this post I’ve only used it for a very small portion, mainly to check for missing SMILES or errors in SMILES (kind of like double checking whether the preprocess function code worked as expected). It could be integrated with scikit-learn’s pipeline method for multiple estimators. Its GitHub Repository link: https://github.com/EBjerrum/scikit-mol - I’ve referred to this reference notebook while working on this post.\n\n# Quick simple way to check for missing SMILES\nprint(f'Dataset contains {df_prep.standard_smiles.isna().sum()} unparsable mols')\n\nDataset contains 0 unparsable mols\n\n\n\n# Checking for invalid SMILES using scikit_mol\nsmileschecker = CheckSmilesSanitazion()\nsmileschecker.sanitize(list(df_prep.standard_smiles))\n\n# Showing SMILES errors\nsmileschecker.errors\n\n\n\n\n\n  \n    \n      \n      SMILES\n    \n  \n  \n  \n\n\n\n\nIt showed no errors in SMILES (errors should be listed in the code cell output).\n\n## Generate RDKit 2D descriptors/fingerprints\n# Running rdkit_2d_descriptors function\ndf_2d = rdkit_2d_descriptors(df_prep)\ndf_2d.head(3)\n\n\n\n\n\n  \n    \n      \n      MaxAbsEStateIndex\n      MaxEStateIndex\n      MinAbsEStateIndex\n      MinEStateIndex\n      qed\n      SPS\n      MolWt\n      HeavyAtomMolWt\n      ExactMolWt\n      NumValenceElectrons\n      ...\n      fr_sulfide\n      fr_sulfonamd\n      fr_sulfone\n      fr_term_acetylene\n      fr_tetrazole\n      fr_thiazole\n      fr_thiocyan\n      fr_thiophene\n      fr_unbrch_alkane\n      fr_urea\n    \n  \n  \n    \n      0\n      9.41068\n      9.41068\n      0.284153\n      0.284153\n      0.779698\n      12.1000\n      268.356\n      248.196\n      268.146330\n      104\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      1\n      11.17310\n      11.17310\n      0.405828\n      -0.405828\n      0.586359\n      11.0625\n      216.192\n      208.128\n      216.042259\n      80\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      2\n      11.17310\n      11.17310\n      0.405828\n      -0.405828\n      0.586359\n      11.0625\n      216.192\n      208.128\n      216.042259\n      80\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n  \n\n3 rows × 210 columns\n\n\n\n\n# Merge dataframes df_prep & df_2d via index\ndf_merge = pd.merge(\n    df_prep[[\"max_phase\", \"molecule_chembl_id\"]],\n    df_2d,\n    left_index=True,\n    right_index=True\n)\nprint(df_merge.shape)\ndf_merge.head(3)\n\n(7144, 212)\n\n\n\n\n\n\n  \n    \n      \n      max_phase\n      molecule_chembl_id\n      MaxAbsEStateIndex\n      MaxEStateIndex\n      MinAbsEStateIndex\n      MinEStateIndex\n      qed\n      SPS\n      MolWt\n      HeavyAtomMolWt\n      ...\n      fr_sulfide\n      fr_sulfonamd\n      fr_sulfone\n      fr_term_acetylene\n      fr_tetrazole\n      fr_thiazole\n      fr_thiocyan\n      fr_thiophene\n      fr_unbrch_alkane\n      fr_urea\n    \n  \n  \n    \n      0\n      4.0\n      CHEMBL411\n      9.41068\n      9.41068\n      0.284153\n      0.284153\n      0.779698\n      12.1000\n      268.356\n      248.196\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      1\n      4.0\n      CHEMBL416\n      11.17310\n      11.17310\n      0.405828\n      -0.405828\n      0.586359\n      11.0625\n      216.192\n      208.128\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      2\n      4.0\n      CHEMBL416\n      11.17310\n      11.17310\n      0.405828\n      -0.405828\n      0.586359\n      11.0625\n      216.192\n      208.128\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n  \n\n3 rows × 212 columns\n\n\n\nA different spreads of max phases were shown this time in the dataframe, as the SQL query mainly used IC50, whereas last post was strictly limited to Ki via ChEMBL web resource client. Other likely reason was that in the decision tree series, I’ve attempted data preprocessing at a larger scale so some data were eliminated. It appeared that there were more max phase 4 compounds here than last time (note: null compounds were not shown in the value counts as it was labelled as “NaN”, it should be the largest max phase portion in the data).\n\n# Find out counts of each max phase\ndf_merge.value_counts(\"max_phase\")\n\nmax_phase\n 4.0    618\n-1.0     69\n 2.0     29\n 3.0     10\n 1.0      7\n 0.5      1\nName: count, dtype: int64\n\n\nI then tried searching for the chembl_id of the 10 max phase 4 compounds used in the last post in the dataframe (df_merge).\n\n# Previously used 10 max phase 4 compounds\n# donepezil = CHEMBL502 & galantamine = CHEMBL659\nlist_mp4 = [\"CHEMBL95\", \"CHEMBL1128\", \"CHEMBL640\", \"CHEMBL502\", \"CHEMBL481\", \"CHEMBL360055\", \"CHEMBL1025\", \"CHEMBL659\", \"CHEMBL1200970\", \"CHEMBL1677\"]\n\n# Search for compounds in list_mp4 within df_merge's \"molecule_chembl_id\" column\n# using Series.isin\ndf_prev = df_merge.loc[df_merge[\"molecule_chembl_id\"].isin(list_mp4)]\ndf_prev.head()\n\n\n\n\n\n  \n    \n      \n      max_phase\n      molecule_chembl_id\n      MaxAbsEStateIndex\n      MaxEStateIndex\n      MinAbsEStateIndex\n      MinEStateIndex\n      qed\n      SPS\n      MolWt\n      HeavyAtomMolWt\n      ...\n      fr_sulfide\n      fr_sulfonamd\n      fr_sulfone\n      fr_term_acetylene\n      fr_tetrazole\n      fr_thiazole\n      fr_thiocyan\n      fr_thiophene\n      fr_unbrch_alkane\n      fr_urea\n    \n  \n  \n    \n      9\n      4.0\n      CHEMBL481\n      13.581173\n      13.581173\n      0.095133\n      -1.863974\n      0.355956\n      22.209302\n      586.689\n      548.385\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      10\n      4.0\n      CHEMBL481\n      13.581173\n      13.581173\n      0.095133\n      -1.863974\n      0.355956\n      22.209302\n      586.689\n      548.385\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      67\n      4.0\n      CHEMBL95\n      6.199769\n      6.199769\n      0.953981\n      0.953981\n      0.706488\n      15.200000\n      198.269\n      184.157\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      68\n      4.0\n      CHEMBL95\n      6.199769\n      6.199769\n      0.953981\n      0.953981\n      0.706488\n      15.200000\n      198.269\n      184.157\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      69\n      4.0\n      CHEMBL95\n      6.199769\n      6.199769\n      0.953981\n      0.953981\n      0.706488\n      15.200000\n      198.269\n      184.157\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n  \n\n5 rows × 212 columns\n\n\n\nThere were many duplicates of compounds.\n\nprint(df_prev.shape)\ndf_prev.value_counts(\"molecule_chembl_id\")\n\n(439, 212)\n\n\nmolecule_chembl_id\nCHEMBL95         182\nCHEMBL502        143\nCHEMBL659         76\nCHEMBL1128        12\nCHEMBL1677        10\nCHEMBL1200970      6\nCHEMBL640          4\nCHEMBL1025         3\nCHEMBL481          2\nCHEMBL360055       1\nName: count, dtype: int64\n\n\n\n# Dropping duplicated compound via chembl IDs in the main df\ndf_merge_new = df_merge.drop_duplicates(subset=[\"molecule_chembl_id\"], keep=\"first\")\nprint(df_merge_new.shape)\ndf_merge_new.head()\n\n(5357, 212)\n\n\n\n\n\n\n  \n    \n      \n      max_phase\n      molecule_chembl_id\n      MaxAbsEStateIndex\n      MaxEStateIndex\n      MinAbsEStateIndex\n      MinEStateIndex\n      qed\n      SPS\n      MolWt\n      HeavyAtomMolWt\n      ...\n      fr_sulfide\n      fr_sulfonamd\n      fr_sulfone\n      fr_term_acetylene\n      fr_tetrazole\n      fr_thiazole\n      fr_thiocyan\n      fr_thiophene\n      fr_unbrch_alkane\n      fr_urea\n    \n  \n  \n    \n      0\n      4.0\n      CHEMBL411\n      9.410680\n      9.410680\n      0.284153\n      0.284153\n      0.779698\n      12.100000\n      268.356\n      248.196\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      1\n      4.0\n      CHEMBL416\n      11.173100\n      11.173100\n      0.405828\n      -0.405828\n      0.586359\n      11.062500\n      216.192\n      208.128\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      3\n      -1.0\n      CHEMBL7002\n      11.591481\n      11.591481\n      0.189306\n      -0.309798\n      0.886859\n      23.608696\n      333.453\n      310.269\n      ...\n      1\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      4\n      NaN\n      CHEMBL28\n      12.020910\n      12.020910\n      0.018823\n      -0.410347\n      0.631833\n      10.800000\n      270.240\n      260.160\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      5\n      4.0\n      CHEMBL41\n      12.564531\n      12.564531\n      0.203346\n      -4.329869\n      0.851796\n      12.909091\n      309.331\n      291.187\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n  \n\n5 rows × 212 columns\n\n\n\n\n# Making sure previously used 10 max phase 4 compounds could be found in df_merge_new\ndf_mp4 = df_merge_new.loc[df_merge_new[\"molecule_chembl_id\"].isin(list_mp4)]\ndf_mp4\n\n\n\n\n\n  \n    \n      \n      max_phase\n      molecule_chembl_id\n      MaxAbsEStateIndex\n      MaxEStateIndex\n      MinAbsEStateIndex\n      MinEStateIndex\n      qed\n      SPS\n      MolWt\n      HeavyAtomMolWt\n      ...\n      fr_sulfide\n      fr_sulfonamd\n      fr_sulfone\n      fr_term_acetylene\n      fr_tetrazole\n      fr_thiazole\n      fr_thiocyan\n      fr_thiophene\n      fr_unbrch_alkane\n      fr_urea\n    \n  \n  \n    \n      9\n      4.0\n      CHEMBL481\n      13.581173\n      13.581173\n      0.095133\n      -1.863974\n      0.355956\n      22.209302\n      586.689\n      548.385\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      67\n      4.0\n      CHEMBL95\n      6.199769\n      6.199769\n      0.953981\n      0.953981\n      0.706488\n      15.200000\n      198.269\n      184.157\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      249\n      4.0\n      CHEMBL502\n      12.936933\n      12.936933\n      0.108783\n      0.108783\n      0.747461\n      20.214286\n      379.500\n      350.268\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      508\n      4.0\n      CHEMBL640\n      11.743677\n      11.743677\n      0.044300\n      -0.044300\n      0.731540\n      10.529412\n      235.331\n      214.163\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      512\n      4.0\n      CHEMBL659\n      9.972866\n      9.972866\n      0.008380\n      -0.411699\n      0.800524\n      33.857143\n      287.359\n      266.191\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      1013\n      4.0\n      CHEMBL1025\n      12.703056\n      12.703056\n      0.426312\n      -4.304784\n      0.629869\n      13.000000\n      184.147\n      170.035\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      1345\n      4.0\n      CHEMBL1128\n      9.261910\n      9.261910\n      0.000000\n      0.000000\n      0.608112\n      10.692308\n      201.697\n      185.569\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      2028\n      4.0\n      CHEMBL360055\n      6.476818\n      6.476818\n      0.656759\n      0.656759\n      0.205822\n      12.583333\n      510.828\n      450.348\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      2725\n      4.0\n      CHEMBL1677\n      6.199769\n      6.199769\n      0.000000\n      0.000000\n      0.760853\n      14.250000\n      234.730\n      219.610\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      3271\n      4.0\n      CHEMBL1200970\n      2.520809\n      2.520809\n      0.000000\n      0.000000\n      0.709785\n      14.000000\n      348.943\n      323.743\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n  \n\n10 rows × 212 columns\n\n\n\n\n# note: compounds with max phase 0 not shown in the count\ndf_merge_new.value_counts(\"max_phase\")\n\nmax_phase\n 4.0    55\n-1.0    26\n 2.0     8\n 3.0     7\n 1.0     4\n 0.5     1\nName: count, dtype: int64\n\n\n\n\n\n\nModel building\nThe aim of this post was to model and classify the max phases of ChEMBL small molecules, i.e. whether the compounds in the testing set (consisted of max phase 0 or null compounds) might be eventually classified as max phase 4 or not. This was one of the approaches to answer the question in mind, and not the ultimate way to solve the problem (just thought to mention). The target was “max_phase” and features to be used were the various RDKit 2D descriptors (RDKit2D).\nThe steps I’ve taken to build the model were shown below:\n\nRe-labelled max phases as binary labels (e.g. max phase null as 0, max phase 4 as 1)\n\n\n# Re-label max phase NaN as 0\ndf_merge_new = df_merge_new.fillna(0)\ndf_merge_new.head()\n\n\n\n\n\n  \n    \n      \n      max_phase\n      molecule_chembl_id\n      MaxAbsEStateIndex\n      MaxEStateIndex\n      MinAbsEStateIndex\n      MinEStateIndex\n      qed\n      SPS\n      MolWt\n      HeavyAtomMolWt\n      ...\n      fr_sulfide\n      fr_sulfonamd\n      fr_sulfone\n      fr_term_acetylene\n      fr_tetrazole\n      fr_thiazole\n      fr_thiocyan\n      fr_thiophene\n      fr_unbrch_alkane\n      fr_urea\n    \n  \n  \n    \n      0\n      4.0\n      CHEMBL411\n      9.410680\n      9.410680\n      0.284153\n      0.284153\n      0.779698\n      12.100000\n      268.356\n      248.196\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      1\n      4.0\n      CHEMBL416\n      11.173100\n      11.173100\n      0.405828\n      -0.405828\n      0.586359\n      11.062500\n      216.192\n      208.128\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      3\n      -1.0\n      CHEMBL7002\n      11.591481\n      11.591481\n      0.189306\n      -0.309798\n      0.886859\n      23.608696\n      333.453\n      310.269\n      ...\n      1\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      4\n      0.0\n      CHEMBL28\n      12.020910\n      12.020910\n      0.018823\n      -0.410347\n      0.631833\n      10.800000\n      270.240\n      260.160\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      5\n      4.0\n      CHEMBL41\n      12.564531\n      12.564531\n      0.203346\n      -4.329869\n      0.851796\n      12.909091\n      309.331\n      291.187\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n  \n\n5 rows × 212 columns\n\n\n\n\nSplitted data into max phase null & max phase 4 (needing to re-label max phase 4 column only as 1, and not disrupting the labels of max phase 0 compounds)\n\n\n# Select all max phase null compounds\ndf_null = df_merge_new[df_merge_new[\"max_phase\"] == 0]\nprint(df_null.shape)\ndf_null.head()\n\n(5256, 212)\n\n\n\n\n\n\n  \n    \n      \n      max_phase\n      molecule_chembl_id\n      MaxAbsEStateIndex\n      MaxEStateIndex\n      MinAbsEStateIndex\n      MinEStateIndex\n      qed\n      SPS\n      MolWt\n      HeavyAtomMolWt\n      ...\n      fr_sulfide\n      fr_sulfonamd\n      fr_sulfone\n      fr_term_acetylene\n      fr_tetrazole\n      fr_thiazole\n      fr_thiocyan\n      fr_thiophene\n      fr_unbrch_alkane\n      fr_urea\n    \n  \n  \n    \n      4\n      0.0\n      CHEMBL28\n      12.020910\n      12.020910\n      0.018823\n      -0.410347\n      0.631833\n      10.800000\n      270.240\n      260.160\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      8\n      0.0\n      CHEMBL8320\n      10.282778\n      10.282778\n      0.120741\n      -0.120741\n      0.416681\n      17.500000\n      108.096\n      104.064\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      14\n      0.0\n      CHEMBL11833\n      11.201531\n      11.201531\n      0.428520\n      -0.466092\n      0.838024\n      25.157895\n      262.309\n      244.165\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      392\n      0.0\n      CHEMBL12324\n      11.257704\n      11.257704\n      0.462395\n      -0.462395\n      0.797990\n      26.150000\n      277.344\n      256.176\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      393\n      0.0\n      CHEMBL274107\n      11.359778\n      11.359778\n      0.372211\n      -0.473241\n      0.838024\n      25.157895\n      262.309\n      244.165\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n  \n\n5 rows × 212 columns\n\n\n\n\n# Using pd.DataFrame.assign to add a new column to re-label max_phase 4 as \"1\"\ndf_mp4_lb = df_mp4.assign(max_phase_lb = df_mp4[\"max_phase\"] / 4)\n\n# Using pd.DataFrame.pop() & insert() to shift added column to first column position\nfirst_col = df_mp4_lb.pop(\"max_phase_lb\")\ndf_mp4_lb.insert(0, \"max_phase_lb\", first_col)\ndf_mp4_lb.head()\n\n\n\n\n\n  \n    \n      \n      max_phase_lb\n      max_phase\n      molecule_chembl_id\n      MaxAbsEStateIndex\n      MaxEStateIndex\n      MinAbsEStateIndex\n      MinEStateIndex\n      qed\n      SPS\n      MolWt\n      ...\n      fr_sulfide\n      fr_sulfonamd\n      fr_sulfone\n      fr_term_acetylene\n      fr_tetrazole\n      fr_thiazole\n      fr_thiocyan\n      fr_thiophene\n      fr_unbrch_alkane\n      fr_urea\n    \n  \n  \n    \n      9\n      1.0\n      4.0\n      CHEMBL481\n      13.581173\n      13.581173\n      0.095133\n      -1.863974\n      0.355956\n      22.209302\n      586.689\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      67\n      1.0\n      4.0\n      CHEMBL95\n      6.199769\n      6.199769\n      0.953981\n      0.953981\n      0.706488\n      15.200000\n      198.269\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      249\n      1.0\n      4.0\n      CHEMBL502\n      12.936933\n      12.936933\n      0.108783\n      0.108783\n      0.747461\n      20.214286\n      379.500\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      508\n      1.0\n      4.0\n      CHEMBL640\n      11.743677\n      11.743677\n      0.044300\n      -0.044300\n      0.731540\n      10.529412\n      235.331\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      512\n      1.0\n      4.0\n      CHEMBL659\n      9.972866\n      9.972866\n      0.008380\n      -0.411699\n      0.800524\n      33.857143\n      287.359\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n  \n\n5 rows × 213 columns\n\n\n\n\n# Also create a new column max_phase_lb column for df_null \n# in order to merge 2 dfs later\ndf_null_lb = df_null.assign(max_phase_lb = df_null[\"max_phase\"])\nfirst_col_null = df_null_lb.pop(\"max_phase_lb\")\ndf_null_lb.insert(0, \"max_phase_lb\", first_col_null)\ndf_null_lb.head()\n\n\n\n\n\n  \n    \n      \n      max_phase_lb\n      max_phase\n      molecule_chembl_id\n      MaxAbsEStateIndex\n      MaxEStateIndex\n      MinAbsEStateIndex\n      MinEStateIndex\n      qed\n      SPS\n      MolWt\n      ...\n      fr_sulfide\n      fr_sulfonamd\n      fr_sulfone\n      fr_term_acetylene\n      fr_tetrazole\n      fr_thiazole\n      fr_thiocyan\n      fr_thiophene\n      fr_unbrch_alkane\n      fr_urea\n    \n  \n  \n    \n      4\n      0.0\n      0.0\n      CHEMBL28\n      12.020910\n      12.020910\n      0.018823\n      -0.410347\n      0.631833\n      10.800000\n      270.240\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      8\n      0.0\n      0.0\n      CHEMBL8320\n      10.282778\n      10.282778\n      0.120741\n      -0.120741\n      0.416681\n      17.500000\n      108.096\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      14\n      0.0\n      0.0\n      CHEMBL11833\n      11.201531\n      11.201531\n      0.428520\n      -0.466092\n      0.838024\n      25.157895\n      262.309\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      392\n      0.0\n      0.0\n      CHEMBL12324\n      11.257704\n      11.257704\n      0.462395\n      -0.462395\n      0.797990\n      26.150000\n      277.344\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      393\n      0.0\n      0.0\n      CHEMBL274107\n      11.359778\n      11.359778\n      0.372211\n      -0.473241\n      0.838024\n      25.157895\n      262.309\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n  \n\n5 rows × 213 columns\n\n\n\n\n# Concatenate df_mp4_lb & df_null_lb\ndf_full = pd.concat([df_null_lb, df_mp4_lb])\ndf_full\n\n\n\n\n\n  \n    \n      \n      max_phase_lb\n      max_phase\n      molecule_chembl_id\n      MaxAbsEStateIndex\n      MaxEStateIndex\n      MinAbsEStateIndex\n      MinEStateIndex\n      qed\n      SPS\n      MolWt\n      ...\n      fr_sulfide\n      fr_sulfonamd\n      fr_sulfone\n      fr_term_acetylene\n      fr_tetrazole\n      fr_thiazole\n      fr_thiocyan\n      fr_thiophene\n      fr_unbrch_alkane\n      fr_urea\n    \n  \n  \n    \n      4\n      0.0\n      0.0\n      CHEMBL28\n      12.020910\n      12.020910\n      0.018823\n      -0.410347\n      0.631833\n      10.800000\n      270.240\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      8\n      0.0\n      0.0\n      CHEMBL8320\n      10.282778\n      10.282778\n      0.120741\n      -0.120741\n      0.416681\n      17.500000\n      108.096\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      14\n      0.0\n      0.0\n      CHEMBL11833\n      11.201531\n      11.201531\n      0.428520\n      -0.466092\n      0.838024\n      25.157895\n      262.309\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      392\n      0.0\n      0.0\n      CHEMBL12324\n      11.257704\n      11.257704\n      0.462395\n      -0.462395\n      0.797990\n      26.150000\n      277.344\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      393\n      0.0\n      0.0\n      CHEMBL274107\n      11.359778\n      11.359778\n      0.372211\n      -0.473241\n      0.838024\n      25.157895\n      262.309\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      1013\n      1.0\n      4.0\n      CHEMBL1025\n      12.703056\n      12.703056\n      0.426312\n      -4.304784\n      0.629869\n      13.000000\n      184.147\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      1345\n      1.0\n      4.0\n      CHEMBL1128\n      9.261910\n      9.261910\n      0.000000\n      0.000000\n      0.608112\n      10.692308\n      201.697\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      2028\n      1.0\n      4.0\n      CHEMBL360055\n      6.476818\n      6.476818\n      0.656759\n      0.656759\n      0.205822\n      12.583333\n      510.828\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      2725\n      1.0\n      4.0\n      CHEMBL1677\n      6.199769\n      6.199769\n      0.000000\n      0.000000\n      0.760853\n      14.250000\n      234.730\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      3271\n      1.0\n      4.0\n      CHEMBL1200970\n      2.520809\n      2.520809\n      0.000000\n      0.000000\n      0.709785\n      14.000000\n      348.943\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n  \n\n5266 rows × 213 columns\n\n\n\n\nDefined X and y variables and trained RF classifier model\n\nEventually df_full contained 10 active compounds and 5256 inactive compounds (from the value counts).\n\ndf_full.value_counts(\"max_phase_lb\")\n\nmax_phase_lb\n0.0    5256\n1.0      10\nName: count, dtype: int64\n\n\n\n# Defining X (features) & y (target)\nX = df_full.iloc[:, 3:]\ny = df_full.iloc[:, 0]\n\n\n# Checking right data were selected e.g. y as target\ny\n\n4       0.0\n8       0.0\n14      0.0\n392     0.0\n393     0.0\n       ... \n1013    1.0\n1345    1.0\n2028    1.0\n2725    1.0\n3271    1.0\nName: max_phase_lb, Length: 5266, dtype: float64\n\n\n\n# Convert both X & y to arrays\nX = X.to_numpy()\ny = y.to_numpy()\n\n\n# Using train_test_split() this time to split data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=1)\n\nAfter data splitting, a RF classifier was trained with reference to this notebook.\n\n# max_features = \"sqrt\" by default\nrfc = RandomForestClassifier(max_depth=3, random_state=1, max_features=\"sqrt\", oob_score=True)\nrfc.fit(X_train, y_train)\n\nRandomForestClassifier(max_depth=3, oob_score=True, random_state=1)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.RandomForestClassifierRandomForestClassifier(max_depth=3, oob_score=True, random_state=1)\n\n\n\nExtracted positive prediction probabilities for the testing set and showed confusion matrix with classification metrics\n\n\ntest_probs = rfc.predict_proba(X_test)[:, 1]\n\nSome reference links and explanations for area under the ROC curve and Cohen’s Kappa.\nArea under the ROC curve: reference - the area under a curve plot between sensitivity or recall (percent of all 1s classified correctly by a classifier or true positive rate) and specificity (percent of all 0s classified correctly by a classifier, or equivalent to 1 - false positive rate or true negative rate) (Bruce, Bruce, and Gedeck 2020). It is useful for evaluating the performance of a classification model via comparing the true positive rate and false positive rate which are influenced by shifting the decision threshold. Area under the ROC is usually represented as a number ranging from 0 to 1 (1 being a perfect classifier, 0.5 or below meaning a poor, ineffective classifier)\nCohen’s Kappa score: reference - a score that is used to measure the agreement of labelling between two annotators (usually between -1 and 1, the higher the score the better the agreement)\nRather than re-inventing the wheel, the following function code for calculating metrics of the RF model were adapted from this notebook, from GHOST repository. I have only added some comments for clarities, and also added a zero_division parameter for the classification_report to mute the warning message when the results ended up being 0 due to divisions by zero.\n\ndef calc_metrics(y_test, test_probs, threshold = 0.5):\n    # Target label assigned according to stated decision threshold (default = 0.5)\n    # e.g. second annotator (expected label)\n    scores = [1 if x>=threshold else 0 for x in test_probs]\n    # Calculate area under the ROC curve based on prediction score\n    auc = metrics.roc_auc_score(y_test, test_probs)\n    # Calculate Cohen's Kappa score\n    # e.g. y_test as first annotator (predicted label)\n    kappa = metrics.cohen_kappa_score(y_test, scores)\n    # Formulate the confusion matrix\n    confusion = metrics.confusion_matrix(y_test, scores, labels = list(set(y_test)))\n    print('thresh: %.2f, kappa: %.3f, AUC test-set: %.3f'%(threshold, kappa, auc))\n    print(confusion)\n    print(metrics.classification_report(y_test, scores, zero_division=0.0))\n    return \n\nNote: roc_auc_score measures true positive and false positive rates, requiring binary labels (e.g. 0s and 1s) in the data\nThen showed confusion matrix along with area under the ROC curve and Cohen’s Kappa.\n\ncalc_metrics(y_test, test_probs, threshold = 0.5)\n\nthresh: 0.50, kappa: 0.000, AUC test-set: 0.536\n[[1052    0]\n [   2    0]]\n              precision    recall  f1-score   support\n\n         0.0       1.00      1.00      1.00      1052\n         1.0       0.00      0.00      0.00         2\n\n    accuracy                           1.00      1054\n   macro avg       0.50      0.50      0.50      1054\nweighted avg       1.00      1.00      1.00      1054\n\n\n\nTo help with interpreting the confusion matrix, scikit-learn actually had a handy plotting code to visualise the matrix.\n\nConfusionMatrixDisplay.from_estimator(rfc, X_test, y_test)\nplt.show()\n\n\n\n\nIt was very obvious that not all of the compounds were classified in the testing set. There were only 1052 compounds classified as true negative, and none in the testing set were labelled as true positive. The likely reason was due to the very imbalanced ratio of actives (only 10 max phase 4 which were labelled as “1” compounds) and inactives (5256 max phase 0 compounds). Besides the imbalanced dataset, the decision threshold was also normally set at 0.5, meaning the classifier was likely going to lose the chance to classify the true positive compounds due to the very skewed ratio of actives to inactives.\n\nTwo approaches were used in the GHOST (generalized threshold shifting) paper:\n\nApproach 1 (out-of-bag method, more computer efficient, aimed for RF classifiers) based on RDKit blog post or its viewable notebook version via nbviewer\nApproach 2 led to GHOST procedure with a goal to optimise and shift the decision threshold in any classification methods to catch the minor portion of actives (rather than the major portion of inactives)\nnote: both approaches were shown to be performing similarly in the paper\n\n\nI only used approach 2 here since the RDKit blog post had already explained approach 1 in depth.\nThe next step involved extracting prediction probabilities from the RF classifier trained model.\n\n# Get the positive prediction probabilities of the training set\ntrain_probs = rfc.predict_proba(X_train)[:, 1]\n\n\nUsed GHOST strategy in a postprocessing way (note: last post used data re-sampling method in a preprocessing way)\n\nThe decision threshold were optimised by using ghostml code via testing various different thresholds, e.g. in spaces of 0.05 that ranged from 0.05 to 0.5. The most optimal threshold would have the most maximised Cohen’s kappa.\n\n# Setting up different decision thresholds\nthresholds = np.round(np.arange(0.05,0.55,0.05), 2)\nthresholds\n\narray([0.05, 0.1 , 0.15, 0.2 , 0.25, 0.3 , 0.35, 0.4 , 0.45, 0.5 ])\n\n\n\n# Looking for the best threshold with the most optimal Cohen's Kappa\nnew_threshold = ghostml.optimize_threshold_from_predictions(y_train, train_probs, thresholds, ThOpt_metrics = 'ROC') \n\nUsing the calc_metrics function again on the newly-found or shifted decision threshold.\n\ncalc_metrics(y_train, train_probs, threshold = new_threshold)\n\nthresh: 0.10, kappa: 0.933, AUC test-set: 1.000\n[[4204    0]\n [   1    7]]\n              precision    recall  f1-score   support\n\n         0.0       1.00      1.00      1.00      4204\n         1.0       1.00      0.88      0.93         8\n\n    accuracy                           1.00      4212\n   macro avg       1.00      0.94      0.97      4212\nweighted avg       1.00      1.00      1.00      4212\n\n\n\nHere, after shifting the decision threshold with the most optimal Cohen’s Kappa score, we could see an improved number of compounds labelled within the true negative class (increasing from 1052 to 4204), and more importantly, we could see the true positive class improved from 0 to 7 as well.\n\n\n\nPlotting ROC curves\nTime for some plots - I’ve shown two different ways to plot ROC curves below.\n\nUsing scikit-learn\n\nTesting set ROC curve - obviously, this was not a good classifier with a poor AUC.\n\nRocCurveDisplay.from_predictions(y_test, test_probs, plot_chance_level = True)\n\n<sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x12ce82710>\n\n\n\n\n\n\nTraining set ROC curve - this probably looked too good to be true or a textbook-standard ROC curve with AUC at 1.0.\n\nRocCurveDisplay.from_predictions(y_train, train_probs, plot_chance_level = True)\n\n<sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x12cece890>\n\n\n\n\n\n\nAlternative method using matplotlib which reproduced a similar training set ROC plot:\n\n\n# Looking for true positive rate (tpr), false positive rate (fpr) & threshold\nfpr, tpr, thresh = metrics.roc_curve(y_train, train_probs)\n# Plotting\nplt.figure()\n# lw = linewidth\nplt.plot(fpr, tpr, lw = 2)\n# show random guessing line (threshold = 0.5)\nplt.plot([0, 1], [0, 1], color = \"g\", lw = 2, linestyle=\"--\")\nplt.ylim([-0.05, 1.05])\nplt.xlim([-0.05, 1.0])\nplt.xlabel(\"specificity\")\nplt.ylabel(\"recall\")\nplt.show()\n\n\n\n\n\n\n\nDownsides and thoughts\nI wanted to mention that the testing set used here was most likely not the best ones to be used. There could be many overlaps or similarities between the training and testing sets, since they all came from ChEMBL database. For demonstration and learning purposes, I ended up using similar dataset as last time. Hopefully, I can try other open-source or public drug discovery datasets in the near future.\nThe other thing to mention was that I should try different molecular fingerprints or descriptors as well, rather than only using RDKit2D, which might lead to different results. I should also probably slowly move onto using multiple datasets or targets in a project, which would likely make things more interesting. On the other hand, I also wanted to avoid this in order to make the topic of interest as clear and simple as possible for me or anyone who’s trying to learn.\n\n\n\nAcknowledgements\nI’d like to thank Riniker lab again for the GHOST paper, along with all the authors, contributors or developers for all of the software packages mentioned in this post, and also, huge thanks should also go to the authors of the reference notebooks mentioned in the post as well.\n\n\n\n\n\n\nReferences\n\nBruce, Peter, Andrew Bruce, and Peter Gedeck. 2020. Practical Statistics for Data Scientists. https://www.oreilly.com/library/view/practical-statistics-for/9781492072935/.\n\n\nEsposito, Carmen, Gregory A. Landrum, Nadine Schneider, Nikolaus Stiefl, and Sereina Riniker. 2021. “GHOST: Adjusting the Decision Threshold to Handle Imbalanced Data in Machine Learning.” Journal of Chemical Information and Modeling 61 (6): 2623–40. https://doi.org/10.1021/acs.jcim.1c00160.\n\nFootnotes\n\n\nh/t: Greg Landrum for his comment on Mastodon for the last RF post (which led to this follow-up post)↩︎"
  },
  {
    "objectID": "posts/17_ML2-2_Random_forest/1_random_forest.html",
    "href": "posts/17_ML2-2_Random_forest/1_random_forest.html",
    "title": "Random forest",
    "section": "",
    "text": "Post updated on 3rd May 2024 - Added comment regarding ImbalancedLearningRegression package (installation tip) & Jupyter notebook link of this post\n\nQuick overview of this post\n\nShort introduction of random forest\nRandom forest methods or classes in scikit-learn\nRandom forest regressor model in scikit-learn\nTraining and testing data splits\n\nChEMBL-assigned max phase splits\nImbalanced learning regression and max phase splits\n\nScoring metrics of trained models\nFeature importances in dataset\n\nfeature_importances_attribute in scikit-learn\npermutation_importance function in scikit-learn\nSHAP approach\n\nHyperparameter tuning on number of trees\n\n\n\n\nWhat is a random forest?\nThe decision tree model built last time was purely based on one model on its own, which often might not be as accurate or reflective in real-life. To improve the model, the average outcome from multiple models (Breiman 1998) should be considered to see if this would provide a more realistic image. This model averaging approach was also constantly used in our daily lives, for example, using majority votes during decision-making steps.\nThe same model averaging concept was also used in random forest (Breiman 2001), which as the name suggested, was composed of many decision trees (models) forming a forest. Each tree model would be making its own model prediction. By accruing multiple predictions since we have multiple trees, the average obtained from these predictions would produce one single result in the end. The advantage of this was that it improved the accuracy of the prediction by reducing variances, and also minimised the problem of overfitting the model if it was purely based on one model only (more details in section 1.11.2.1. Random Forests from scikit-learn).\nThe “random” part of the random forest was introduced in two ways. The first one was via using bootstrap samples, which was also known as bagging or bootstrap aggregating (Bruce, Bruce, and Gedeck 2020), where samples were drawn with replacements within the training datasets for each tree built in the ensemble (also known as the perturb-and-combine technique (Breiman 1998)). While bootstrap sampling was happening, randomness was also incorporated into the training sets at the same time. The second way randomness was introduced was by using a random subset of features for splitting at the nodes, or a full set of features could also be used (although this was generally not recommended). The main goal here was to achieve best splits at each node.\n\n\n\nRandom forest in scikit-learn\nScikit-learn had two main types of random forest classes - ensemble.RandomForestClassifier() and ensemble.RandomForestRegressor(). When to use which class would depend on the target values. The easiest thing to do was to decide whether the target variables had class labels (binary types or non-continuous variables e.g. yes or no, or other different categories to be assigned) or continuous (numerical) variables, which in this case, if I were to continue using the same dataset from the decision tree series, it would be a continuous variable or feature, pKi, the inhibition constant.\nThere were also two other alternative random forest methods in scikit-learn, which were ensemble.RandomTreesEmbedding() and ensemble.ExtraTreesClassifier() or ensemble.ExtraTreesRegressor(). The difference for RandomTreesEmbedding() was that it was an unsupervised method that used data transformations (more details from section 1.11.2.6. on “Totally Random Trees Embedding” in scikit-learn). On the other side, there was also an option to use ExtraTreesClassifier() or ExtraTreesRegressor() to generate extremely randomised trees that would go for another level up in randomness (more deatils in section 1.11.2.2. on Extremely Randomized Trees from scikit-learn). The main difference for this type of random forest was that while there was already a random subset of feature selection used (with an intention to select the most discerning features), more randomness were added on top of this by using purely randomly generated splitting rules for picking features at the nodes. The advantage of this type of method was that it would reduce variance and increase the accuracy of the model, but the downside was there might be an increase in bias within the model.\n\n\n\nBuilding a random forest regressor model using scikit-learn\nAs usual, all the required libraries were imported first.\n\nimport pandas as pd\nimport sklearn\nfrom sklearn.ensemble import RandomForestRegressor\n\n# For imbalanced datasets in regression \n# May need to set env variable (SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True) when installing\n# due to package dependency on older sklearn version\nimport ImbalancedLearningRegression as iblr\n\n# Plots\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Metrics\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score\n\n# Feature importances\n# Permutation_importance\nfrom sklearn.inspection import permutation_importance\n# SHAP values\nimport shap\n\n# Hyperparameter tuning\nfrom sklearn.model_selection import cross_val_score, RepeatedKFold\n\nfrom numpy import mean, std\nfrom natsort import index_natsorted\nimport numpy as np\n\n# Showing version of scikit-learn used\nprint(sklearn.__version__)\n\n1.3.2\n\n\nImporting dataset that was preprocessed from last time - link to data source: first decision tree post.\n\ndata = pd.read_csv(\"ache_2d_chembl.csv\")\ndata.drop(columns = [\"Unnamed: 0\"], inplace=True)\n# Preparing data for compounds with max phase with \"NaN\" by re-labelling to \"null\"\ndata[\"max_phase\"].fillna(\"null\", inplace=True)\ndata.head()\n\nSetting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'null' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n\n\n\n\n\n\n  \n    \n      \n      molecule_chembl_id\n      pKi\n      max_phase\n      mw\n      fsp3\n      n_lipinski_hba\n      n_lipinski_hbd\n      n_rings\n      n_hetero_atoms\n      n_heavy_atoms\n      ...\n      sas\n      n_aliphatic_carbocycles\n      n_aliphatic_heterocyles\n      n_aliphatic_rings\n      n_aromatic_carbocycles\n      n_aromatic_heterocyles\n      n_aromatic_rings\n      n_saturated_carbocycles\n      n_saturated_heterocyles\n      n_saturated_rings\n    \n  \n  \n    \n      0\n      CHEMBL60745\n      8.787812\n      null\n      245.041526\n      0.400000\n      2\n      1\n      1\n      3\n      13\n      ...\n      3.185866\n      0\n      0\n      0\n      1\n      0\n      1\n      0\n      0\n      0\n    \n    \n      1\n      CHEMBL208599\n      10.585027\n      null\n      298.123676\n      0.388889\n      2\n      2\n      4\n      3\n      21\n      ...\n      4.331775\n      2\n      0\n      2\n      1\n      1\n      2\n      0\n      0\n      0\n    \n    \n      2\n      CHEMBL95\n      6.821023\n      4.0\n      198.115698\n      0.307692\n      2\n      2\n      3\n      2\n      15\n      ...\n      2.014719\n      1\n      0\n      1\n      1\n      1\n      2\n      0\n      0\n      0\n    \n    \n      3\n      CHEMBL173309\n      7.913640\n      null\n      694.539707\n      0.666667\n      8\n      0\n      2\n      8\n      50\n      ...\n      2.803680\n      0\n      0\n      0\n      2\n      0\n      2\n      0\n      0\n      0\n    \n    \n      4\n      CHEMBL1128\n      6.698970\n      4.0\n      201.092042\n      0.400000\n      2\n      1\n      1\n      3\n      13\n      ...\n      3.185866\n      0\n      0\n      0\n      1\n      0\n      1\n      0\n      0\n      0\n    \n  \n\n5 rows × 25 columns\n\n\n\n\n\n\nTraining/testing splits\nTwo approaches were used, where one was based purely on max phase split (between max phases null and 4), which was used last time in the decision tree series, and the other one was using the same max phase split but with an ImbalancedLearningRegression method added on top of it.\n\n\nPreparing training data using max phase split\nX variable was set up first from the dataframe, and then converted into a NumPy array, which consisted of the number of samples and number of features. This was kept the same as how it was in the decision tree posts.\n\n\n\n\n\n\nNote\n\n\n\nIt’s usually recommended to copy the original data or dataframe before doing any data manipulations to avoid unnecessary changes to the original dataset (this was not used in the decision tree posts, but since I’m going to use the same set of data again I’m doing it here.)\n\n\n\n# X variables (molecular features)\n# Make a copy of the original dataframe first\ndata_mp4 = data.copy()\n# Selecting all max phase 4 compounds\ndata_mp4 = data_mp4[data_mp4[\"max_phase\"] == 4]\nprint(data_mp4.shape)\ndata_mp4.head()\n\n(10, 25)\n\n\n\n\n\n\n  \n    \n      \n      molecule_chembl_id\n      pKi\n      max_phase\n      mw\n      fsp3\n      n_lipinski_hba\n      n_lipinski_hbd\n      n_rings\n      n_hetero_atoms\n      n_heavy_atoms\n      ...\n      sas\n      n_aliphatic_carbocycles\n      n_aliphatic_heterocyles\n      n_aliphatic_rings\n      n_aromatic_carbocycles\n      n_aromatic_heterocyles\n      n_aromatic_rings\n      n_saturated_carbocycles\n      n_saturated_heterocyles\n      n_saturated_rings\n    \n  \n  \n    \n      2\n      CHEMBL95\n      6.821023\n      4.0\n      198.115698\n      0.307692\n      2\n      2\n      3\n      2\n      15\n      ...\n      2.014719\n      1\n      0\n      1\n      1\n      1\n      2\n      0\n      0\n      0\n    \n    \n      4\n      CHEMBL1128\n      6.698970\n      4.0\n      201.092042\n      0.400000\n      2\n      1\n      1\n      3\n      13\n      ...\n      3.185866\n      0\n      0\n      0\n      1\n      0\n      1\n      0\n      0\n      0\n    \n    \n      6\n      CHEMBL640\n      6.000000\n      4.0\n      235.168462\n      0.461538\n      4\n      3\n      1\n      4\n      17\n      ...\n      1.791687\n      0\n      0\n      0\n      1\n      0\n      1\n      0\n      0\n      0\n    \n    \n      9\n      CHEMBL502\n      7.688246\n      4.0\n      379.214744\n      0.458333\n      4\n      0\n      4\n      4\n      28\n      ...\n      2.677222\n      1\n      1\n      2\n      2\n      0\n      2\n      0\n      1\n      1\n    \n    \n      131\n      CHEMBL481\n      7.296709\n      4.0\n      586.279135\n      0.515152\n      10\n      1\n      7\n      10\n      43\n      ...\n      3.632560\n      0\n      4\n      4\n      1\n      2\n      3\n      0\n      2\n      2\n    \n  \n\n5 rows × 25 columns\n\n\n\n\n# Select molecular features for X array (n_samples, n_features)\nX_mp4_df = data_mp4[['mw', 'fsp3', 'n_lipinski_hba', 'n_lipinski_hbd', 'n_rings', 'n_hetero_atoms', 'n_heavy_atoms', 'n_rotatable_bonds', 'n_radical_electrons', 'tpsa', 'qed', 'clogp', 'sas', 'n_aliphatic_carbocycles', 'n_aliphatic_heterocyles', 'n_aliphatic_rings', 'n_aromatic_carbocycles', 'n_aromatic_heterocyles', 'n_aromatic_rings', 'n_saturated_carbocycles', 'n_saturated_heterocyles', 'n_saturated_rings']]\n\nprint(X_mp4_df.shape)\nX_mp4_df.head()\n\n(10, 22)\n\n\n\n\n\n\n  \n    \n      \n      mw\n      fsp3\n      n_lipinski_hba\n      n_lipinski_hbd\n      n_rings\n      n_hetero_atoms\n      n_heavy_atoms\n      n_rotatable_bonds\n      n_radical_electrons\n      tpsa\n      ...\n      sas\n      n_aliphatic_carbocycles\n      n_aliphatic_heterocyles\n      n_aliphatic_rings\n      n_aromatic_carbocycles\n      n_aromatic_heterocyles\n      n_aromatic_rings\n      n_saturated_carbocycles\n      n_saturated_heterocyles\n      n_saturated_rings\n    \n  \n  \n    \n      2\n      198.115698\n      0.307692\n      2\n      2\n      3\n      2\n      15\n      0\n      0\n      38.91\n      ...\n      2.014719\n      1\n      0\n      1\n      1\n      1\n      2\n      0\n      0\n      0\n    \n    \n      4\n      201.092042\n      0.400000\n      2\n      1\n      1\n      3\n      13\n      2\n      0\n      20.23\n      ...\n      3.185866\n      0\n      0\n      0\n      1\n      0\n      1\n      0\n      0\n      0\n    \n    \n      6\n      235.168462\n      0.461538\n      4\n      3\n      1\n      4\n      17\n      6\n      0\n      58.36\n      ...\n      1.791687\n      0\n      0\n      0\n      1\n      0\n      1\n      0\n      0\n      0\n    \n    \n      9\n      379.214744\n      0.458333\n      4\n      0\n      4\n      4\n      28\n      6\n      0\n      38.77\n      ...\n      2.677222\n      1\n      1\n      2\n      2\n      0\n      2\n      0\n      1\n      1\n    \n    \n      131\n      586.279135\n      0.515152\n      10\n      1\n      7\n      10\n      43\n      4\n      0\n      114.20\n      ...\n      3.632560\n      0\n      4\n      4\n      1\n      2\n      3\n      0\n      2\n      2\n    \n  \n\n5 rows × 22 columns\n\n\n\n\n# Convert X_mp4_df to numpy array\nX_mp4 = X_mp4_df.to_numpy()\nX_mp4\n\narray([[ 1.98115698e+02,  3.07692308e-01,  2.00000000e+00,\n         2.00000000e+00,  3.00000000e+00,  2.00000000e+00,\n         1.50000000e+01,  0.00000000e+00,  0.00000000e+00,\n         3.89100000e+01,  7.06488238e-01,  2.69580000e+00,\n         2.01471913e+00,  1.00000000e+00,  0.00000000e+00,\n         1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n         2.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00],\n       [ 2.01092042e+02,  4.00000000e-01,  2.00000000e+00,\n         1.00000000e+00,  1.00000000e+00,  3.00000000e+00,\n         1.30000000e+01,  2.00000000e+00,  0.00000000e+00,\n         2.02300000e+01,  6.08112327e-01, -1.01700000e+00,\n         3.18586632e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n         1.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00],\n       [ 2.35168462e+02,  4.61538462e-01,  4.00000000e+00,\n         3.00000000e+00,  1.00000000e+00,  4.00000000e+00,\n         1.70000000e+01,  6.00000000e+00,  0.00000000e+00,\n         5.83600000e+01,  7.31539693e-01,  1.34040000e+00,\n         1.79168720e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n         1.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00],\n       [ 3.79214744e+02,  4.58333333e-01,  4.00000000e+00,\n         0.00000000e+00,  4.00000000e+00,  4.00000000e+00,\n         2.80000000e+01,  6.00000000e+00,  0.00000000e+00,\n         3.87700000e+01,  7.47461492e-01,  4.36110000e+00,\n         2.67722173e+00,  1.00000000e+00,  1.00000000e+00,\n         2.00000000e+00,  2.00000000e+00,  0.00000000e+00,\n         2.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n         1.00000000e+00],\n       [ 5.86279135e+02,  5.15151515e-01,  1.00000000e+01,\n         1.00000000e+00,  7.00000000e+00,  1.00000000e+01,\n         4.30000000e+01,  4.00000000e+00,  0.00000000e+00,\n         1.14200000e+02,  3.55955569e-01,  4.09110000e+00,\n         3.63256044e+00,  0.00000000e+00,  4.00000000e+00,\n         4.00000000e+00,  1.00000000e+00,  2.00000000e+00,\n         3.00000000e+00,  0.00000000e+00,  2.00000000e+00,\n         2.00000000e+00],\n       [ 5.10461822e+02,  8.00000000e-01,  6.00000000e+00,\n         0.00000000e+00,  1.00000000e+00,  6.00000000e+00,\n         3.60000000e+01,  2.10000000e+01,  0.00000000e+00,\n         2.76900000e+01,  2.05822189e-01,  5.45250000e+00,\n         3.25765349e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n         1.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00],\n       [ 1.84066459e+02,  1.00000000e+00,  3.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  5.00000000e+00,\n         1.10000000e+01,  4.00000000e+00,  0.00000000e+00,\n         3.55300000e+01,  6.29869319e-01,  2.91400000e+00,\n         3.34514393e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00],\n       [ 2.87152144e+02,  5.29411765e-01,  4.00000000e+00,\n         1.00000000e+00,  4.00000000e+00,  4.00000000e+00,\n         2.10000000e+01,  1.00000000e+00,  0.00000000e+00,\n         4.19300000e+01,  8.00524269e-01,  1.85030000e+00,\n         4.22684283e+00,  1.00000000e+00,  2.00000000e+00,\n         3.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n         1.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00],\n       [ 3.48142697e+02,  3.68421053e-01,  2.00000000e+00,\n         0.00000000e+00,  3.00000000e+00,  4.00000000e+00,\n         2.30000000e+01,  5.00000000e+00,  0.00000000e+00,\n         6.48000000e+00,  7.09785317e-01,  5.44140000e+00,\n         4.22359068e+00,  0.00000000e+00,  1.00000000e+00,\n         1.00000000e+00,  2.00000000e+00,  0.00000000e+00,\n         2.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00],\n       [ 2.34092376e+02,  3.07692308e-01,  2.00000000e+00,\n         2.00000000e+00,  3.00000000e+00,  3.00000000e+00,\n         1.60000000e+01,  0.00000000e+00,  0.00000000e+00,\n         3.89100000e+01,  7.60853221e-01,  3.11760000e+00,\n         3.21871482e+00,  1.00000000e+00,  0.00000000e+00,\n         1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n         2.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00]])\n\n\nAgain, y variable was arranged via the dataframe as well, and converted into a NumPy array. It consisted of the number of samples only as this was the target variable.\n\n# y array (n_samples) - target outcome pKi\ny_mp4_df = data_mp4[\"pKi\"]\ny_mp4_df\n\n2      6.821023\n4      6.698970\n6      6.000000\n9      7.688246\n131    7.296709\n133    4.431798\n160    5.221849\n171    6.522879\n180    4.607303\n195    6.995679\nName: pKi, dtype: float64\n\n\n\n# Convert y_mp4_df to numpy array\ny_mp4 = y_mp4_df.to_numpy()\ny_mp4\n\narray([6.82102305, 6.69897   , 6.        , 7.68824614, 7.29670862,\n       4.43179828, 5.22184875, 6.52287875, 4.60730305, 6.99567863])\n\n\n\n\n\nTraining model using max phase split only\nBoth X and y variables were used to fit the RandomForestRegressor() estimator.\n\n# n_estimators = 100 by default\n# note: if wanting to use whole dataset - switch off \"bootstrap\" parameter by using \"False\"\nrfreg = RandomForestRegressor(max_depth=3, random_state=1, max_features=0.3)\nrfreg.fit(X_mp4, y_mp4)\n\nRandomForestRegressor(max_depth=3, max_features=0.3, random_state=1)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.RandomForestRegressorRandomForestRegressor(max_depth=3, max_features=0.3, random_state=1)\n\n\n\n\n\nPreparing testing data using max phase split only\nTesting data was mainly based on compounds with max phase assigned as “0” or “null” after I renamed it above.\n\ndata_mp_null = data.copy()\n# Selecting all max phase \"null\" compounds\ndata_mp_null = data_mp_null[data_mp_null[\"max_phase\"] == \"null\"]\nprint(data_mp_null.shape)\ndata_mp_null.head() \n\n(466, 25)\n\n\n\n\n\n\n  \n    \n      \n      molecule_chembl_id\n      pKi\n      max_phase\n      mw\n      fsp3\n      n_lipinski_hba\n      n_lipinski_hbd\n      n_rings\n      n_hetero_atoms\n      n_heavy_atoms\n      ...\n      sas\n      n_aliphatic_carbocycles\n      n_aliphatic_heterocyles\n      n_aliphatic_rings\n      n_aromatic_carbocycles\n      n_aromatic_heterocyles\n      n_aromatic_rings\n      n_saturated_carbocycles\n      n_saturated_heterocyles\n      n_saturated_rings\n    \n  \n  \n    \n      0\n      CHEMBL60745\n      8.787812\n      null\n      245.041526\n      0.400000\n      2\n      1\n      1\n      3\n      13\n      ...\n      3.185866\n      0\n      0\n      0\n      1\n      0\n      1\n      0\n      0\n      0\n    \n    \n      1\n      CHEMBL208599\n      10.585027\n      null\n      298.123676\n      0.388889\n      2\n      2\n      4\n      3\n      21\n      ...\n      4.331775\n      2\n      0\n      2\n      1\n      1\n      2\n      0\n      0\n      0\n    \n    \n      3\n      CHEMBL173309\n      7.913640\n      null\n      694.539707\n      0.666667\n      8\n      0\n      2\n      8\n      50\n      ...\n      2.803680\n      0\n      0\n      0\n      2\n      0\n      2\n      0\n      0\n      0\n    \n    \n      5\n      CHEMBL102226\n      4.698970\n      null\n      297.152928\n      0.923077\n      3\n      0\n      0\n      5\n      18\n      ...\n      2.965170\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      7\n      CHEMBL103873\n      5.698970\n      null\n      269.121628\n      0.909091\n      3\n      0\n      0\n      5\n      16\n      ...\n      3.097106\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n  \n\n5 rows × 25 columns\n\n\n\n\n# Set up X test variable with the same molecular features\nX_mp_test_df = data_mp_null[['mw', 'fsp3', 'n_lipinski_hba', 'n_lipinski_hbd', 'n_rings', 'n_hetero_atoms', 'n_heavy_atoms', 'n_rotatable_bonds', 'n_radical_electrons', 'tpsa', 'qed', 'clogp', 'sas', 'n_aliphatic_carbocycles', 'n_aliphatic_heterocyles', 'n_aliphatic_rings', 'n_aromatic_carbocycles', 'n_aromatic_heterocyles', 'n_aromatic_rings', 'n_saturated_carbocycles', 'n_saturated_heterocyles', 'n_saturated_rings']]\n\n# Convert X test variables from df to arrays\nX_mp_test = X_mp_test_df.to_numpy()\n\nX_mp_test\n\narray([[2.45041526e+02, 4.00000000e-01, 2.00000000e+00, ...,\n        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n       [2.98123676e+02, 3.88888889e-01, 2.00000000e+00, ...,\n        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n       [6.94539707e+02, 6.66666667e-01, 8.00000000e+00, ...,\n        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n       ...,\n       [3.11152144e+02, 3.15789474e-01, 4.00000000e+00, ...,\n        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n       [3.68096076e+02, 9.23076923e-01, 4.00000000e+00, ...,\n        0.00000000e+00, 2.00000000e+00, 2.00000000e+00],\n       [2.46136828e+02, 5.00000000e-01, 4.00000000e+00, ...,\n        0.00000000e+00, 3.00000000e+00, 3.00000000e+00]])\n\n\n\n\n\nTraining/testing splits using ImbalancedLearningRegression and max phase splits\nI didn’t really pay a lot of attentions when I was doing data splits in the decision tree series, as my main focus was on building a single tree in order to fully understand and see what could be derived from just one tree. Now, when I reached this series on random forest, I realised I forgot to mention in the last series that data splitting was actually very crucial on model performance and could influence outcome predictions. It could also become quite complicated as more approaches were available to split the data. Also, the way the data was splitted could produce different outcomes.\nAfter I’ve splitted the same dataset based on compounds’ max phase assignments in ChEMBL and also fitted the training data on the random forest regressor, I went back and noticed that the training and testing data were very imbalanced and I probably should do something about it before fitting them onto another model.\nAt this stage, I went further to look into whether imbalanced datasets should be addressed in regression tasks, and did a surface search online. So based on common ML concensus, addressing imbalanced datasets were more applicable to classification tasks (e.g. binary labels or multi-class labels), rather than regression problems. However, recent ML research looked into the issue of imbalanced datasets in regression. This blog post mentioned a few studies that looked into this type of problem, and I thought they were very interesting and worth a mention at least. One of them that I’ve looked into was SMOTER, which was based on synthetic minority over-sampling technique (SMOTE)(Chawla et al. 2002), and was named this way because it was basically a SMOTE for regression (hence SMOTER)(Torgo et al. 2013). Synthetic minority over-sampling technique for regression with Gaussian noise (SMOGN)(Kunz 2020) was another technique that was built upon SMOTER, but with Gaussian noises added. This has subsequently led me to ImbalancedLearningRegression library (Wu, Kunz, and Branco 2022), which was a variation of SMOGN. This was the one used on my imbalanced dataset, shown in the section below.\nA simple flow diagram was drawn below showing the evolution of different techniques when dealing with imbalanced datasets in classification (SMOTE) and regression (SMOTER, SMOGN and ImbalancedLearningRegression):\n\n\n\n\nflowchart LR\n  A(SMOTE) --> B(SMOTER)\n  B --> C(SMOGN)\n  C --> D(ImbalancedLearningRegression)\n\n\n\n\n\n\n\n\nGitHub repository for ImbalancedLearningRegression package is available here, with its documentation available here.\nAlso, I just wanted to mention that these were not the only techniques available for treating imbalanced datasets in regression, as there were other ones in the literature and most likely more are being developed currently, but I only had time to cover these here for now.\nI also would like to mention another really useful open-source resource for treating imbalanced datasets in classifications since I did not use it in this post due to the problem being more of a regression one than a classification one - imbalance-learn library.\n\n# Original dataset - checking shape again\nprint(data.shape)\ndata.head()\n\n(481, 25)\n\n\n\n\n\n\n  \n    \n      \n      molecule_chembl_id\n      pKi\n      max_phase\n      mw\n      fsp3\n      n_lipinski_hba\n      n_lipinski_hbd\n      n_rings\n      n_hetero_atoms\n      n_heavy_atoms\n      ...\n      sas\n      n_aliphatic_carbocycles\n      n_aliphatic_heterocyles\n      n_aliphatic_rings\n      n_aromatic_carbocycles\n      n_aromatic_heterocyles\n      n_aromatic_rings\n      n_saturated_carbocycles\n      n_saturated_heterocyles\n      n_saturated_rings\n    \n  \n  \n    \n      0\n      CHEMBL60745\n      8.787812\n      null\n      245.041526\n      0.400000\n      2\n      1\n      1\n      3\n      13\n      ...\n      3.185866\n      0\n      0\n      0\n      1\n      0\n      1\n      0\n      0\n      0\n    \n    \n      1\n      CHEMBL208599\n      10.585027\n      null\n      298.123676\n      0.388889\n      2\n      2\n      4\n      3\n      21\n      ...\n      4.331775\n      2\n      0\n      2\n      1\n      1\n      2\n      0\n      0\n      0\n    \n    \n      2\n      CHEMBL95\n      6.821023\n      4.0\n      198.115698\n      0.307692\n      2\n      2\n      3\n      2\n      15\n      ...\n      2.014719\n      1\n      0\n      1\n      1\n      1\n      2\n      0\n      0\n      0\n    \n    \n      3\n      CHEMBL173309\n      7.913640\n      null\n      694.539707\n      0.666667\n      8\n      0\n      2\n      8\n      50\n      ...\n      2.803680\n      0\n      0\n      0\n      2\n      0\n      2\n      0\n      0\n      0\n    \n    \n      4\n      CHEMBL1128\n      6.698970\n      4.0\n      201.092042\n      0.400000\n      2\n      1\n      1\n      3\n      13\n      ...\n      3.185866\n      0\n      0\n      0\n      1\n      0\n      1\n      0\n      0\n      0\n    \n  \n\n5 rows × 25 columns\n\n\n\nSo my little test on using ImbalancedLearningRegression package started from below.\n\niblr_data = data.copy()\n\n# Introducing Gaussian noise for data sampling\ndata_gn = iblr.gn(data = iblr_data, y = \"pKi\", pert = 1)\nprint(data_gn.shape)\n\nsynth_matrix:   0%|          | 0/58 [00:00<?, ?it/s]\n\n\nsynth_matrix:  14%|#3        | 8/58 [00:00<00:00, 75.97it/s]\n\n\nsynth_matrix:  31%|###1      | 18/58 [00:00<00:00, 84.29it/s]\n\n\nsynth_matrix:  47%|####6     | 27/58 [00:00<00:00, 85.90it/s]\n\n\nsynth_matrix:  62%|######2   | 36/58 [00:00<00:00, 83.02it/s]\n\n\nsynth_matrix:  78%|#######7  | 45/58 [00:00<00:00, 83.24it/s]\n\n\nsynth_matrix:  93%|#########3| 54/58 [00:00<00:00, 84.17it/s]\n\n\nsynth_matrix: 100%|##########| 58/58 [00:00<00:00, 84.10it/s]\n\n\n\n\n\nr_index:   0%|          | 0/8 [00:00<?, ?it/s]\n\n\nr_index: 100%|##########| 8/8 [00:00<00:00, 267.33it/s]\n\n\n\n\n\n(480, 25)\n\n\n\n# Followed by max phase split, where max phase 4 = training dataset\ndata_gn_mp4 = data_gn[data_gn[\"max_phase\"] == 4]\ndata_gn_mp4\nprint(data_gn_mp4.shape)\n\n(7, 25)\n\n\n\n# Also splitted max phase null compounds = testing dataset\ndata_gn_mp_null = data_gn[data_gn[\"max_phase\"] == \"null\"]\ndata_gn_mp_null\nprint(data_gn_mp_null.shape)\n\n(465, 25)\n\n\nThere were several different sampling techniques in ImbalancedLearningRegression package. I’ve only tried random over-sampling, under-sampling and Gaussian noise, but there were also other ones such as SMOTE and ADASYN (in over-sampling technique) or condensed nearest neighbor, Tomeklinks and edited nearest neightbour (in under-sampling technique) that I haven’t used.\nRandom over-sampling actually oversampled the max phase null compounds (sample size increased), while keeping all 10 max phase 4 compounds. Under-sampling removed all of the max phase 4 compounds (which was most likely not the best option, since I was aiming to use them as training compounds), with max phase null compounds also reduced in size too. Due to post length, I did not show the code for random over-sampling and under-sampling, but for people who are interested, I think it would be interesting to test them out.\nI ended up using Gauissian noise sampling and it reduced max phase 4 compounds slightly, and increased the max phase null compounds a little bit too, which seemed to be the most balanced data sampling at the first try. (Note: as stated from the documentation for ImbalancedLearningRegression package, missing values within features would be removed automatically, I’ve taken care of this in my last series of posts so no difference were observed here.)\nThe change in the distribution of pKi values for the Gaussian noise sampling method between the original and sample-modified datasets could be seen in the kernel density estimate plot below. The modified dataset had a flatter target density curve than the original density plot, which was more concentrated and peaked between pKi values of 6 and 8. The range of pKi values for the ten max phase 4 compounds collected was between 4 and 8.\nPlot reference\n\n# Quick look at how the pKi values differed \n# after applying Gaussian noise sampling to dataset\n# Plot target variable, pKi distributions\nsns.kdeplot(data[\"pKi\"], label = \"Original\")\nsns.kdeplot(data_gn[\"pKi\"], label = \"Modified\")\nplt.legend(labels = [\"Original\", \"Modified\"])\n\n<matplotlib.legend.Legend at 0x13b87ae60>\n\n\n\n\n\nNext, the modified ImbalancedLearningRegression-Gaussian noise (iblr-gn) training data was converted into a NumPy array.\n\n# Select molecular features for X variable\nX_mp4_gn_df = data_gn_mp4[['mw', 'fsp3', 'n_lipinski_hba', 'n_lipinski_hbd', 'n_rings', 'n_hetero_atoms', 'n_heavy_atoms', 'n_rotatable_bonds', 'n_radical_electrons', 'tpsa', 'qed', 'clogp', 'sas', 'n_aliphatic_carbocycles', 'n_aliphatic_heterocyles', 'n_aliphatic_rings', 'n_aromatic_carbocycles', 'n_aromatic_heterocyles', 'n_aromatic_rings', 'n_saturated_carbocycles', 'n_saturated_heterocyles', 'n_saturated_rings']]\n\nprint(X_mp4_gn_df.shape)\nX_mp4_gn_df.head()\n\n(7, 22)\n\n\n\n\n\n\n  \n    \n      \n      mw\n      fsp3\n      n_lipinski_hba\n      n_lipinski_hbd\n      n_rings\n      n_hetero_atoms\n      n_heavy_atoms\n      n_rotatable_bonds\n      n_radical_electrons\n      tpsa\n      ...\n      sas\n      n_aliphatic_carbocycles\n      n_aliphatic_heterocyles\n      n_aliphatic_rings\n      n_aromatic_carbocycles\n      n_aromatic_heterocyles\n      n_aromatic_rings\n      n_saturated_carbocycles\n      n_saturated_heterocyles\n      n_saturated_rings\n    \n  \n  \n    \n      244\n      348.142697\n      0.368421\n      2.0\n      0.0\n      3.0\n      4.0\n      23.0\n      5.0\n      0\n      6.48\n      ...\n      4.223591\n      0.0\n      1.0\n      1.0\n      2.0\n      0.0\n      2.0\n      0.0\n      0.0\n      0.0\n    \n    \n      247\n      201.092042\n      0.400000\n      2.0\n      1.0\n      1.0\n      3.0\n      13.0\n      2.0\n      0\n      20.23\n      ...\n      3.185866\n      0.0\n      0.0\n      0.0\n      1.0\n      0.0\n      1.0\n      0.0\n      0.0\n      0.0\n    \n    \n      266\n      184.066459\n      1.000000\n      3.0\n      0.0\n      0.0\n      5.0\n      11.0\n      4.0\n      0\n      35.53\n      ...\n      3.345144\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      365\n      198.115698\n      0.307692\n      2.0\n      2.0\n      3.0\n      2.0\n      15.0\n      0.0\n      0\n      38.91\n      ...\n      2.014719\n      1.0\n      0.0\n      1.0\n      1.0\n      1.0\n      2.0\n      0.0\n      0.0\n      0.0\n    \n    \n      385\n      235.168462\n      0.461538\n      4.0\n      3.0\n      1.0\n      4.0\n      17.0\n      6.0\n      0\n      58.36\n      ...\n      1.791687\n      0.0\n      0.0\n      0.0\n      1.0\n      0.0\n      1.0\n      0.0\n      0.0\n      0.0\n    \n  \n\n5 rows × 22 columns\n\n\n\n\nX_mp4_gn = X_mp4_gn_df.to_numpy()\n\nSimilarly, this was also applied to the target y variable in the iblr-gn dataset.\n\n# y variable (target outcome - pKi)\ny_mp4_gn_df = data_gn_mp4[\"pKi\"]\n\ny_mp4_gn = y_mp4_gn_df.to_numpy()\ny_mp4_gn\n\narray([4.60730305, 6.69897   , 5.22184875, 6.82102305, 6.        ,\n       7.68824614, 6.99567863])\n\n\nThen the iblr-gn training data were fitted onto another random forest regressor model.\n\n# n_estimators = 100 by default\n# note: if wanting to use whole dataset - switch off \"bootstrap\" parameter by using \"False\"\nrfreg_gn = RandomForestRegressor(max_depth=3, random_state=1, max_features=0.3)\nrfreg_gn.fit(X_mp4_gn, y_mp4_gn)\n\nRandomForestRegressor(max_depth=3, max_features=0.3, random_state=1)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.RandomForestRegressorRandomForestRegressor(max_depth=3, max_features=0.3, random_state=1)\n\n\nModified iblr-gn testing data were also prepared and converted into a NumPy array.\n\n# Set up X test variable with the same molecular features\nX_mp_gn_test_df = data_gn_mp_null[['mw', 'fsp3', 'n_lipinski_hba', 'n_lipinski_hbd', 'n_rings', 'n_hetero_atoms', 'n_heavy_atoms', 'n_rotatable_bonds', 'n_radical_electrons', 'tpsa', 'qed', 'clogp', 'sas', 'n_aliphatic_carbocycles', 'n_aliphatic_heterocyles', 'n_aliphatic_rings', 'n_aromatic_carbocycles', 'n_aromatic_heterocyles', 'n_aromatic_rings', 'n_saturated_carbocycles', 'n_saturated_heterocyles', 'n_saturated_rings']]\n\n# Convert X test variables from df to arrays\nX_mp_gn_test = X_mp_gn_test_df.to_numpy()\n\nX_mp_gn_test\n\narray([[5.80224119e+02, 2.64705882e-01, 7.00000000e+00, ...,\n        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n       [3.77210327e+02, 3.91304348e-01, 5.00000000e+00, ...,\n        0.00000000e+00, 1.00000000e+00, 1.00000000e+00],\n       [5.24297368e+02, 4.54545455e-01, 4.00000000e+00, ...,\n        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n       ...,\n       [3.37167794e+02, 2.85714286e-01, 4.00000000e+00, ...,\n        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n       [5.09129751e+02, 4.16666667e-01, 9.00000000e+00, ...,\n        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n       [3.40189926e+02, 4.21052632e-01, 6.00000000e+00, ...,\n        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])\n\n\n\n\n\nUsing trained model for prediction on testing data\nPredicting max phase-splitted data only.\n\n# Predict pKi values for the compounds with \"null\" max phase\n# using the training model rfreg \n# Uncomment code below to print prediction result\n#print(rfreg.predict(X_mp_test))\n\n# or use:\ny_mp_test = rfreg.predict(X_mp_test)\n\nPredicting iblr-gn data with max phase splits.\n\ny_mp_gn_test = rfreg_gn.predict(X_mp_gn_test)\n\n\n\n\nScoring and metrics of trained models\nChecking model accuracy for both training and testing datasets was recommended to take place before moving onto discovering feature importances. A scikit-learn explanation for this could be found in the section on “Permutation feature importance”. So the accuracy scores for the model were shown below.\n\n# Training set accuracy\nprint(f\"Random forest regressor training accuracy: {rfreg.score(X_mp4, y_mp4):.2f}\")\n\n# Testing set accuracy\nprint(f\"Random forest regressor testing accuracy: {rfreg.score(X_mp_test, y_mp_test):.2f}\")\n\nRandom forest regressor training accuracy: 0.86\nRandom forest regressor testing accuracy: 1.00\n\n\nIt looked like both the training and testing accuracies for the random forest regressor model (rfreg) were quite high, meaning that the model was able to remember the molecular features well from the training set (the tiny sample of 10 compounds), and the model was able to apply them to the testing set (which should contain about 400 or so compounds) as well, in order to make predictions on the target value of pKi. This has somewhat confirmed that the model was indeed making predictions, rather than not making any predictions at all, which meant there might be no point in finding out which features were important in the data. Therefore, we could now move onto processing the feature importances to fill in the bigger story i.e. which features were more pivotal towards influencing pKi values of approved drugs targeting acetylcholinesterase (AChE).\nSimilar model accuracy scores were also generated for the iblr-gn modified dataset, which appeared to follow a similar pattern as the max phase-splitted dataset.\n\n# iblr-Gaussian noise & max phase splitted data\n# Training set accuracy\nprint(f\"Random forest regressor training accuracy: {rfreg_gn.score(X_mp4_gn, y_mp4_gn):.2f}\")\n\n# Testing set accuracy\nprint(f\"Random forest regressor testing accuracy: {rfreg_gn.score(X_mp_gn_test, y_mp_gn_test):.2f}\")\n\nRandom forest regressor training accuracy: 0.79\nRandom forest regressor testing accuracy: 1.00\n\n\nNow, setting up the y_true, which was the acutal pKi values of the testing set, and were converted into a NumPy array too.\n\ny_true = data_mp_null[\"pKi\"]\ny_true = y_true.to_numpy(copy=True)\n\nI also found out the mean squared error (MSE) between y_true (actual max phase null compounds’ pKi values) and y_pred (predicted max phase null compounds’ pKi values). When MSE was closer to zero, the better the model was, meaning less errors were present.\nSome references that might help with explaining MSE:\n\nscikit-learn link\nStats StackExchange link\nblog post link\n\n\n# For max phase splitted dataset only\nmean_squared_error(y_true, y_mp_test)\n\n2.3988097789702505\n\n\nWhen R2 (coefficient of determination) was closer to 1, the better the model is, with a usual range between 0 and 1 (Bruce, Bruce, and Gedeck 2020). If it was negative, then the model might not be performing as well as expected. However, there could be exceptions as other model evaluation methods should also be interpreted together with R2 (a poor R2 might not be wholly indicating it’s a poor model).\nSome references that might help with understanding R2:\n\nStats StackExchange link\nscikit-learn link\n\n\n# For max phase splitted dataset only\nr2_score(y_true, y_mp_test)\n\n-0.16228227953132635\n\n\nBecause the data was re-sampled in a iblr-gn way, the size of array would be different from the original dataset, so here I’ve specifically grabbed pKi values from the iblr-gn modified data to get the actual pKi values for the max phase null compounds.\n\ny_true_gn = data_gn_mp_null[\"pKi\"]\ny_true_gn = y_true_gn.to_numpy(copy=True)\n\n\n# MSE for iblr-gn data\nmean_squared_error(y_true_gn, y_mp_gn_test)\n\n5.7895732090189185\n\n\n\n# R squared for iblr-gn data\nr2_score(y_true_gn, y_mp_gn_test)\n\n-0.7425920410726885\n\n\nWell, it appeared iblr-gn dataset might not offer much advantage than the original max phase splitted method. However, even the max phase splitted method wasn’t that great either, but it might still be interesting to find out which features were important in relation to the pKi values.\n\n\n\n\nFeature importances\nThere were two types of feature importances available in scikit-learn, which I’ve described below. I’ve also added a Shapley additive explanations (SHAP) approach to this section as well to show different visualisation styles for feature importances on the same set of data.\n\n\nfeature_importances_ attribute from scikit-learn\nThe impurity-based feature importances (also known as Gini importance) were shown below.\n\n# Compute feature importances on rfreg training model\nfeature_imp = rfreg.feature_importances_\n\n\n# Check what feature_imp looks like (an array)\nfeature_imp\n\narray([0.0396524 , 0.06608031, 0.01129602, 0.09707957, 0.03625411,\n       0.04393835, 0.05287614, 0.03339396, 0.        , 0.14225505,\n       0.03562854, 0.16945464, 0.04450665, 0.02810539, 0.01437198,\n       0.0220527 , 0.02136604, 0.00803076, 0.04866529, 0.        ,\n       0.044468  , 0.04052409])\n\n\nI decided to write a function to convert a NumPy array into a plot below as this was also needed in the next section.\n\n# Function to convert array to df leading to plots \n# - for use in feature_importances_ & permutation_importance\n\ndef feat_imp_plot(feat_imp_array, X_df):\n\n    \"\"\"\n    Function to convert feature importance array into a dataframe, \n    which is then used to plot a bar graph \n    to show the feature importance ranking in the random forest model for the dataset used.\n\n    feat_imp_array is the array obtained from the feature_importances_ attribute, \n    after having a estimator/model fitted.\n\n    X_df is the dataframe for the X variable, \n    where the feature column names will be used in the plot.\n    \"\"\"\n\n    # Convert the feat_imp array into dataframe\n    feat_imp_df = pd.DataFrame(feat_imp_array)\n    \n    # Obtain feature names via column names of dataframe\n    # Rename the index as \"features\"\n    feature = X_df.columns.rename(\"features\")\n\n    # Convert the index to dataframe\n    feature_name_df = feature.to_frame(index = False)\n\n    # Concatenate feature_imp_df & feature_name_df\n    feature_df = pd.concat(\n        [feat_imp_df, feature_name_df], \n        axis=1\n        ).rename(\n            # Rename the column for feature importances\n            columns = {0: \"feature_importances\"}\n            ).sort_values(\n                # Sort values of feature importances in descending order\n                \"feature_importances\", ascending=False\n                )\n    \n    # Seaborn bar plot\n    sns.barplot(\n        feature_df, \n        x = \"feature_importances\", \n        y = \"features\")\n\n\n# Testing feat_imp_plot function\nfeat_imp_plot(feature_imp, X_mp4_df)\n\n\n\n\nAn alternative way to plot was via Matplotlib directly (note: Seaborn was built based on Matplotlib, so the plots were pretty similar). The code below were probably a bit more straightforward but without axes named and the values were not sorted (only as an example but more code could be added to do this).\n\n# Matplotlib plot\nfrom matplotlib import pyplot as plt\nplt.barh(X_mp4_df.columns, rfreg.feature_importances_)\n\n<BarContainer object of 22 artists>\n\n\n\n\n\n\n\n\npermutation_importance function from scikit-learn\nThere were known issues with the built-in feature_importances_ attribute in scikit-learn. As quoted from scikit-learn on feature importance evaluation:\n\n… The impurity-based feature importances computed on tree-based models suffer from two flaws that can lead to misleading conclusions. First they are computed on statistics derived from the training dataset and therefore do not necessarily inform us on which features are most important to make good predictions on held-out dataset. Secondly, they favor high cardinality features, that is features with many unique values. Permutation feature importance is an alternative to impurity-based feature importance that does not suffer from these flaws. …\n\nSo I’ve also tried the permutation_importance function (a model-agnostic method).\n\nperm_result = permutation_importance(rfreg, X_mp_test, y_mp_test, n_repeats=10, random_state=1, n_jobs=2)\n\n# Checking data type of perm_result\ntype(perm_result)\n\nsklearn.utils._bunch.Bunch\n\n\nIt normally returns a dictionary-like objects (e.g. Bunch) with the following 3 attributes:\n\nimportances_mean (mean of feature importances)\nimportances_std (standard deviation of feature importances)\nimportances (raw permutation/feature importances scores)\n\nFor details on these attributes, this scikit-learn link will add a bit more explanations.\nI decided to only use importances_mean for now.\n\nperm_imp = perm_result.importances_mean\n\n# Confirm it produces an array\ntype(perm_imp)\n\nnumpy.ndarray\n\n\n\n# Using the function feat_imp_plot() on perm_imp result to show plot\nfeat_imp_plot(perm_imp, X_mp4_df)\n\n\n\n\nIt generated a different feature importances ranking (if looking at top 6 features), although somewhat similar to the previous one.\n\n\n\nSHAP approach\nSHAP values (Lundberg et al. 2020), (Shapley et al. 1953) were used here to provide another way to figure out feature importances. The GitHub repository for this SHAP approach could be accessed here.\nSHAP’s TreeExplainer() was based on Tree SHAP algorithms (Lundberg et al. 2020), and was used to show and explain feature importances within tree models. It could also be extended to boosted tree models such as LightGBM and XGBoost and also other tree models (as explained by the GitHub repository README.md and its documentation link provided). It was also a model-agnostic method, which could be quite handy.\nOther reference\n\nshap_explainer = shap.TreeExplainer(rfreg)\n\n# X_test needs to be a dataframe (not numpy array)\n# otherwise feature names won't show in plot\nshap_values = shap_explainer.shap_values(X_mp_test_df)\n\n# Horizontal bar plot\nshap.summary_plot(shap_values, X_mp_test_df, plot_type = \"bar\")\n\n\n\n\nDot plot version:\n\nshap.summary_plot(shap_values, X_mp_test_df)\n\n\n\n\nViolin plot:\n\nshap.summary_plot(shap_values, X_mp_test_df, plot_type = \"violin\")\n\n# Alternative plot option: \"layered_violin\"\n\n\n\n\n\n\n\n\nHyperparameter tuning\nAn example was shown below on tuning the number of trees (n_estimators) used in the random forest model.\n\n# Function code adapted with thanks from ML Mastery \n# https://machinelearningmastery.com/random-forest-ensemble-in-python/\n\n# ---Evaluate a list of models with different number of trees---\n\n# Define dataset by using the same training dataset as above\nX, y = X_mp4, y_mp4\n\n# Define function to generate a list of models with different no. of trees\ndef models():\n    # Create empty dictionary (key, value pairs) for models\n    models = dict()\n    # Test different number of trees to evaluate\n    no_trees = [50, 100, 250, 500, 1000]\n    for n in no_trees:\n        models[str(n)] = RandomForestRegressor(n_estimators=n)\n    return models\n\n\n# Define function to evaluate a single model using cross-validation\ndef evaluate(model, X, y):\n\n    # RepeatedStratifiedKFold usually for binary or multi-class labels \n    # - ref link: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold\n    # so using ReaptedKFold instead\n    cross_val = RepeatedKFold(n_splits=10, n_repeats=15, random_state=1)\n    # Run evaluation process & collect cv scores\n    # Since estimator/model was based on DecisionTreeRegressor, \n    # using neg_mean_squared_error metric\n    # n_jobs = -1 meaning using all processors to run jobs in parallel\n    scores = cross_val_score(model, X, y, scoring=\"neg_mean_squared_error\", cv=cross_val, n_jobs=-1)\n    return scores\n\n\n# Evaluate results\n# Run models with different RepeatedKFold & different no. of tress\n# with results shown as diff. trees with calculated mean cv scores & std\n\n# Obtain diff. models with diff. trees via models function\nmodels = models()\n\n# Create empty lists for results & names\nresults, names = list(), list()\n\n# Create a for loop to iterate through the list of diff. models\nfor name, model in models.items():\n    # Run the cross validation scores via evaluate function\n    scores = evaluate(model, X, y)\n    # Collect results\n    results.append(scores)\n    # Collect names (different no. of trees)\n    names.append(name)\n    # Show the average mean squared errors and corresponding standard deviations \n    # for each model with diff. no. of trees\n    print((name, mean(scores), std(scores)))\n\n('50', -1.6470594650953017, 1.6444082604560304)\n\n\n('100', -1.6995136024743887, 1.6797340671624852)\n\n\n('250', -1.6716290617106646, 1.6236808789148038)\n\n\n('500', -1.645981936868625, 1.615445700037851)\n\n\n('1000', -1.6532678610618743, 1.604259597928101)\n\n\nThe negated version of the mean squared error (neg_mean_squared_error) was due to how the scoring parameter source code was written in scikit-learn. It was written this way to take into account of both scoring and loss functions (links provided below for further explanations). All scoring metrics could be accessed here for scikit-learn.\nReference links to help with understanding neg_mean_squared_error:\n\nscikit-learn source code\nStackOverflow answer\n\nAlso, the random forest algorithm was stochastic in nature, meaning that every time hyperparameter tuning took place, it would generate different scores due to random bootstrap sampling. The best approach to evaluate model performance during the cross-validation process was to use the average outcome from several runs of cross-validations, then fit the hyperparameters on a final model, or getting several final models ready and then obtaining the average from these models instead.\nBelow was a version of boxplot plotted using Matplotlib showing the differences in the distributions of the cross validation scores and mean squared errors between different number of trees.\n\nplt.boxplot(results, labels=names, showmeans=True)\nplt.show()\n\n\n\n\nTo plot this in Seaborn, I had to prepare the data slightly differently to achieve a different version of the boxplot. Matplotlib was a bit more straightforward to use without these steps.\nI also used natural sort to sort numerical values (GitHub repository). Otherwise, if using sort_values() only, it would only sort the numbers in lexicographical order (i.e. by first digit only), which was not able to show the tree numbers in ascending order.\n\n# Combine results & names lists into dataframe\ncv_results = pd.DataFrame(results, index = [names])\n\n\n# Reset index and rename the number of trees column\ncv_results = cv_results.reset_index().rename(columns={\"level_0\": \"Number_of_trees\"})\n\n\n# Melt the dataframe by number of trees column\ncv_results = cv_results.melt(id_vars=\"Number_of_trees\")\n\n\n# Sort by the number of trees column\ncv_results = cv_results.sort_values(\n    by=\"Number_of_trees\",\n    key=lambda x: np.argsort(index_natsorted(cv_results[\"Number_of_trees\"]))\n)\n\n\n# Seaborn boxplot\nsns.boxplot(cv_results, x=\"Number_of_trees\", y=\"value\", showmeans=True)\n\n<Axes: xlabel='Number_of_trees', ylabel='value'>\n\n\n\n\n\nThe Seaborn boxplot shown should be very similar to the Matplotlib one.\nOther hyperparameters that could be tuned included:\n\ntree depths (max_depth)\nnumber of samples (max_samples)\nnumber of features (max_features) - I didn’t use RDKit to generate molecular features for this post (Datamol version was used instead) which would provide around 209 at least (trying to keep the post at a readable length), but I think this might be a better option when doing cross-validations in model evaluations\nnumber of nodes (max_leaf_nodes)\n\nI’ve decided not to code for these other hyperparameters in the cross-validation step due to length of post (the function code used in cross-validation above could be further adapted to cater for other hyperparameters mentioned here), but they should be looked into if doing full-scale and comprehensive ML using the ensemble random forest algorithm.\n\n\n\nFinal words\nRandom forest was known to be a black-box ML algorithm (Bruce, Bruce, and Gedeck 2020), which was completely different from the white-box ML style revealed in decision tree graphs. Feature importances was therefore crucial to shed some lights and remove some layers of the black-box nature in random forest by showing which features were contributing towards model accuracy by ranking features used to train the model. Cross-validation was also vital to avoid over-fitting (which was more applicable to depth of trees), although in some other cases (e.g. number of trees), it was mentioned that it was unlikely the model would be overfitted. Other options available in scikit-learn ensemble methods that I didn’t get time to try were using voting classifier/regressor and stacking models to reduce biases in models, which might be very useful in other cases.\nFew things I’ve thought of that I could try to improve what I did here was that I should really look for a different set of testing data, rather than using the max phase splits, which was not that ideal. However, as a lot of us are aware, good drug discovery data are hard to come by (a long-standing and complicated problem), I probably need some luck while looking for a different set of drug discovery data later. Another approach that I could try was that I could use RandomForestClassifier() instead on max phase prediction of these small molecules, rather than making pKi value predictions. This might involve re-labelling the max phases for these compounds into a binary or class labels, then I could use the imbalance-learn package to try and alleviate the problem with imbalanced datasets. Nevertheless, I had some fun working on this post and learnt a lot while doing it, and I hope some of the readers might find this post helpful or informative at least.\n\n\n\nAcknowledgement\nI’d like to thank all the authors, developers and contributors who worked towards all of the open-source packages or libraries used in this post. I’d also like to thank all of the other senior cheminformatics and ML practitioners who were sharing their work and knowledge online.\n\n\n\n\n\nReferences\n\nBreiman, Leo. 1998. “Arcing Classifier (with Discussion and a Rejoinder by the Author).” The Annals of Statistics 26 (3). https://doi.org/10.1214/aos/1024691079.\n\n\n———. 2001. “Random Forests.” Machine Learning 45 (1): 5–32. https://doi.org/10.1023/a:1010933404324.\n\n\nBruce, Peter, Andrew Bruce, and Peter Gedeck. 2020. Practical Statistics for Data Scientists. https://www.oreilly.com/library/view/practical-statistics-for/9781492072935/.\n\n\nChawla, N. V., K. W. Bowyer, L. O. Hall, and W. P. Kegelmeyer. 2002. “SMOTE: Synthetic Minority over-Sampling Technique.” Journal of Artificial Intelligence Research 16 (June): 321–57. https://doi.org/10.1613/jair.953.\n\n\nKunz, Nicholas. 2020. SMOGN: Synthetic Minority over-Sampling Technique for Regression with Gaussian Noise (version v0.1.2). PyPI. https://pypi.org/project/smogn/.\n\n\nLundberg, Scott M., Gabriel Erion, Hugh Chen, Alex DeGrave, Jordan M. Prutkin, Bala Nair, Ronit Katz, Jonathan Himmelfarb, Nisha Bansal, and Su-In Lee. 2020. “From Local Explanations to Global Understanding with Explainable AI for Trees.” Nature Machine Intelligence 2 (1): 2522–5839.\n\n\nShapley, Lloyd S et al. 1953. “A Value for n-Person Games.”\n\n\nTorgo, Luís, Rita P. Ribeiro, Bernhard Pfahringer, and Paula Branco. 2013. “SMOTE for Regression.” In, 378–89. Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-642-40669-0_33.\n\n\nWu, Wenglei, Nicholas Kunz, and Paula Branco. 2022. “ImbalancedLearningRegression-a Python Package to Tackle the Imbalanced Regression Problem.” In Joint European Conference on Machine Learning and Knowledge Discovery in Databases, 645–48. Springer."
  },
  {
    "objectID": "posts/12_Shiny_app_chembl/ShinyAppChembl.html",
    "href": "posts/12_Shiny_app_chembl/ShinyAppChembl.html",
    "title": "Shiny app in R",
    "section": "",
    "text": "Back story\nIt has been a long while since I’ve used R in my projects. Last year during the time when I bravely embraced the role of rotating curator for @WeAreRLadies on Twitter around end of October, I did mention that I wanted to learn Shiny. I haven’t forgotten about this actually. So as promised, here it is, my first Shiny app in R, which is really a very simple interactive web app about small molecules from ChEMBL database. The URL to reach this app, ShinyAppChembl, is at: https://jhylin.shinyapps.io/ShinyAppChembl/. It shows a selected set of physicochemical properties for the curated small molecules in different max phases in boxplot formats. Note: it may take a few minutes to load the plot when first opening the app.\n\n\n\nThe process\nSince I haven’t been using a lot of R lately, I just wanted to document how I approached this Shiny app framework, as part of my self-directed learning for R that started around mid-2022. The first place I went to was not Google’s Bard or OpenAI’s ChatGPT, as I was trying to preempt a scenario where if both of these options were temporarily down, what would I do to learn a new tool. So I visited the Shiny website first, and literally started from the “Get Started” section there, then tried to read through the lessons provided. I gathered a quick overview about the core components within a Shiny app, which were the user interface, server logic and the call to run or create app in the end, and thought to get started from there.\nOne of the most helpful online books called, “Mastering Shiny” had clarified a few coding issues for me. The reactivity section in the book was very useful as well to help with understanding the interactivity concept in the app. The best and also the hardest thing at this stage after reading some of the information was to actually start coding for the app in RStudio IDE, which I did soon after.\n\n\n\nTrials-and-errors\nInitially, I’ve noticed in the gallery section from the Shiny website that some of the basic Shiny apps had plots produced with R code using S3 method - the type with class ‘formula’, such as boxplot(formula e.g. y ~ group, data, and so on). So I started with this first and ended up with a draft version shown below:\n\n\n\nFirst draft app using S3 method in R code to plot boxplots - screenshot taken by author\n\n\n\nI then tried the ggplot2 version, which I preferred to use. However, I kept on hitting a roadblock repeatedly (as shown in the image below):\n\n\n\nSecond draft app using ggplot2 boxplot format - screenshot taken by author\n\n\nI ended up working through this issue of not being able to display the boxplots properly over at least two days, where I tried to figure out how to change the code so that the boxplots would appear as the output in the app. I actually wrote a plot function code (as shown below) before working on the app.R file, in order to trial plotting the boxplots, making sure that the code worked before using it in the app.R file.\n```{r}\ndfBoxplot <- function(var) {\n  label <- rlang::englue(\"{{var}} vs. Max Phases of small molecules\")\n  \n  chembl %>% \n    select(`Max Phase`, {{ var }}) %>% \n    ggplot(aes(x = `Max Phase`, y = {{ var }})) +\n    geom_boxplot(aes(group = cut_width(`Max Phase`, 0.25), \n                     colour = `Max Phase`), \n                 outlier.alpha = 0.2) +\n    labs(title = label)\n}\n```\nOnce I made sure this code worked, I transplanted the code into the server section of the app.R file, however it wasn’t that simple obviously. Through the process of more trials-and-errors, I managed to figure out the code for the plot output in the final version, which was not the same as the function code above, but more like this.\n```{r}\n  output$BPlot <- renderPlot({ \n    \n    ggplot(chembl, aes(`Max Phase`, .data[[input$variable]])) +\n      geom_boxplot(aes(group = cut_width(`Max Phase`, 0.25), \n                       colour = `Max Phase`), outlier.alpha = 0.2) +\n      labs(title = \"Distributions of physicochemical properties against max phases\",\n           caption = \"(based on ChEMBL database version 31)\") +\n      theme_minimal()\n    \n    }, res = 96) %>% bindCache(chembl$`Max Phase`, input$variable)\n```\nI then read about the section on “Tidy evaluation” in the “Mastering Shiny” book, which had thoroughly described the problems I’ve encountered (and which I wished I had actually read this section before and not after hitting the roadblock…). So I’d highly recommend new users to read this section and also the rest of the book if Shiny’s also new to you.\n\n\n\nFinal app\nThe final app now looks like this:\n\n\n\nScreenshot taken by author\n\n\n\n\n\nApp deployment\nAfter I got the app working, I looked into where I could deploy the app, since my main goal was to learn and share my work. At first, I went to the Shiny section on the Quarto website to see if it was possible to deploy the app in Quarto. However, after reading through several questions and answers in relation to Shiny apps and Quarto website, it was obvious that it was still not possible yet to deploy the app in an interactive way on Quarto websites (but it was mentioned in Posit community that this was being looked into, so I’m looking forward to the day when we can do exactly that in the future). This means that currently, there will only be an app image showing up in a Quarto document at most. I ended up choosing shinyapp.io to deploy my first Shiny app for now.\n\n\n\nAbout the boxplots\nSince the main goal of this post is more on the process of producing a simple Shiny app for a new comer, I won’t go into the fine details to describe how these boxplots differ between different max phases. Also as a side note, I’m aware that some experts in data visualisations might not really like boxplots in general, but for my case, I’ve got molecules in different max phases where a boxplot is presented for each max phase lining up next to each other. Therefore, in a way, some relative comparisons or differences could be drawn visually in the first glance, although other graph types such as density plots or heat maps might be better options.\nI’ll focus on the “QED Weighted” variable here, as it’s a physicochemical property that has combined several molecular features together as a score (please refer to this post - section: “Some exploratory data analysis” for details about this QED weighted score). For all the boxplots shown when “QED Weighted” is selected from the drop-down box, max phase 4 molecules obviously have higher QED weighted scores in general than all of the other max phases. This is especially clear when comparing the medians between them, with max phase 4 small molecules having a median QED weighted score of more than 0.5, and the rest of the other max phases had 0.5 or below. The higher the QED weighted scores, the more druglike the molecules will be, and for max phase 4 molecules, they are mostly prescription medicines that have already reached approval and are already being widely prescribed. So this makes sense as this is being reflected in the boxplots for these ChEMBL small molecules.\n\n\n\nFinal words\nFinally, I’m quite pleasantly surprised that there is also a Shiny in Python version, which has a Shinylive option to deploy Shiny app interactively in GitHub Gist and so on… I’ll most likely need to read further into this and make this as my next project. This is also a nice break from my recent machine learning projects, which I’ll try to return to once I’ve had enough fun with Shiny!\nThanks for reading."
  },
  {
    "objectID": "ShinyAppChembl/Chembl_intro.html",
    "href": "ShinyAppChembl/Chembl_intro.html",
    "title": "Home",
    "section": "",
    "text": "By choosing a specific physicochemical property from the drop-down box below, a boxplot should appear on the right showing the distribution of the selected physicochemical property for small molecules in different max phases. Note: it may take a few minutes to load the plot when first opening the app."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data in life",
    "section": "",
    "text": "🌟Blog status🌟\nWelcome to my blog on selected cheminformatics, machine learning and data science projects in drug discovery.\n\nLatest project - A short note about preventing model overfitting in PyTorch\nNext project in the pipeline - Curation of adverse drug reactions data on cytochrome P450 substrates\n\n\n🌟Past projects🌟\nDeep learning\n\nA simple deep learning model about adverse drug reactions - this is like an introductory piece to the world of deep learning and is also an early prototype of a QSAR/QSPR workflow as well\n\nMachine learning\n\nTree series - Decision tree 1 - data collection and preprocessing, 2 - data preprocessing and transformation, 3 - model building and estimating experimental errors, Random forest - model building, imbalanced dataset, feature importances & hyperparameter tuning, Random forest classifier - more on imbalanced dataset, Boosted trees - AdaBoost, XGBoost and Scikit-mol\nLogistic regression 1 - Parquet file in Polars dataframe library, 2 - Preprocessing data in Polars dataframe library, 3 - Building logistic regression model using scikit-learn, 4 - Evaluating logistic regression model in scikit-learn, older long version\n\nData explorations\n\nCytochrome P450 and small drug molecules with a focus on CYP3A4 and CYP2D6 inhibitors\nWorking with scaffolds in small molecules - Manipulating SMILES strings\nMolecular similarities in selected COVID-19 antivirals - Using RDKit’s similarity map and fingerprint generator\n\nWeb applications\n\nMolecular visualisation web application - Interactive data table, Using Shiny for Python web application framework\nShinylive app in Python - Data preparation, Embedding app in Quarto document & using pyodide.http\n\n\n\n\n\n\n\n\n\n\n\n\n\nLooking at minimising adverse drug reactions (ADRs)\n\n\n\n\n\n\n\n\n\nApr 21, 2025\n\n\n9 min\n\n\n\n\n\n\n\n\nPrevent model overfitting in deep neural networks\n\n\n\n\n\n\n\n\n\nFeb 11, 2025\n\n\n7 min\n\n\n\n\n\n\n\n\nBuilding a simple deep learning model about adverse drug reactions\n\n\n\n\n\n\n\n\n\nJan 8, 2025\n\n\n21 min\n\n\n\n\n\n\n\n\nNotes on adverse drug reactions (ADRs) data\n\n\nFor strong and moderate strength cytochrome P450 (CYP) enzyme substrates\n\n\n\n\n\n\nJan 8, 2025\n\n\n16 min\n\n\n\n\n\n\n\n\nCytochrome P450 and small drug molecules\n\n\nCYP3A4 and 2D6 inhibitors\n\n\n\n\n\n\nAug 22, 2024\n\n\n27 min\n\n\n\n\n\n\n\n\nBoosted trees\n\n\nSeries 2.3.1 - AdaBoost, XGBoost and Scikit-mol\n\n\n\n\n\n\nJun 6, 2024\n\n\n17 min\n\n\n\n\n\n\n\n\nUsing Molstar in Quarto\n\n\n\n\n\n\n\n\n\nApr 6, 2024\n\n\n1 min\n\n\n\n\n\n\n\n\nRandom forest classifier\n\n\nSeries 2.2.1 - more on imbalanced dataset\n\n\n\n\n\n\nJan 17, 2024\n\n\n13 min\n\n\n\n\n\n\n\n\nRandom forest\n\n\nSeries 2.2 - model building, imbalanced dataset, feature importances & hyperparameter tuning\n\n\n\n\n\n\nNov 22, 2023\n\n\n24 min\n\n\n\n\n\n\n\n\nDecision tree\n\n\nSeries 2.1.1 - data collection and preprocessing\n\n\n\n\n\n\nSep 19, 2023\n\n\n12 min\n\n\n\n\n\n\n\n\nDecision tree\n\n\nSeries 2.1.2 - data preprocessing and transformation\n\n\n\n\n\n\nSep 19, 2023\n\n\n12 min\n\n\n\n\n\n\n\n\nDecision tree\n\n\nSeries 2.1.3 - model building and estimating experimental errors\n\n\n\n\n\n\nSep 19, 2023\n\n\n14 min\n\n\n\n\n\n\n\n\nMolecular visualisation (Molviz) web application\n\n\nUsing Shiny for Python web application framework - part 2\n\n\n\n\n\n\nAug 10, 2023\n\n\n12 min\n\n\n\n\n\n\n\n\nMolecular visualisation (Molviz) web application\n\n\nInteractive data table - part 1\n\n\n\n\n\n\nAug 10, 2023\n\n\n5 min\n\n\n\n\n\n\n\n\nWorking with scaffolds in small molecules\n\n\nManipulating SMILES strings\n\n\n\n\n\n\nJul 6, 2023\n\n\n19 min\n\n\n\n\n\n\n\n\nShinylive app in Python\n\n\nEmbedding app in Quarto document & using pyodide.http to import csv files\n\n\n\n\n\n\nMay 24, 2023\n\n\n8 min\n\n\n\n\n\n\n\n\nShinylive app in Python\n\n\nEmbedding app in Quarto document for compounds in COVID-19 clinical trials\n\n\n\n\n\n\nMay 8, 2023\n\n\n23 min\n\n\n\n\n\n\n\n\nShinylive app in Python\n\n\nData preparation for compounds in COVID-19 clinical trials\n\n\n\n\n\n\nMay 8, 2023\n\n\n11 min\n\n\n\n\n\n\n\n\nShiny app in R\n\n\nSmall molecules in ChEMBL database\n\n\n\n\n\n\nApr 7, 2023\n\n\n6 min\n\n\n\n\n\n\n\n\nPills dataset - Part 3\n\n\nUsing Rust for data visualisation\n\n\n\n\n\n\nFeb 14, 2023\n\n\n10 min\n\n\n\n\n\n\n\n\nPills dataset - Part 2\n\n\nText cleaning using Polars & visualising pills with Plotly\n\n\n\n\n\n\nJan 31, 2023\n\n\n13 min\n\n\n\n\n\n\n\n\nPills dataset - Part 1\n\n\nWeb scraping, Polars & Pandas dataframe libraries\n\n\n\n\n\n\nJan 21, 2023\n\n\n11 min\n\n\n\n\n\n\n\n\nSmall molecules in ChEMBL database\n\n\nSeries 1.1.1 - Parquet file in Polars dataframe library\n\n\n\n\n\n\nJan 4, 2023\n\n\n10 min\n\n\n\n\n\n\n\n\nSmall molecules in ChEMBL database\n\n\nSeries 1.1.3 - Building logistic regression model using scikit-learn\n\n\n\n\n\n\nJan 4, 2023\n\n\n6 min\n\n\n\n\n\n\n\n\nSmall molecules in ChEMBL database\n\n\nSeries 1.1.2 - Preprocessing data in Polars dataframe library\n\n\n\n\n\n\nJan 4, 2023\n\n\n10 min\n\n\n\n\n\n\n\n\nSmall molecules in ChEMBL database\n\n\nSeries 1.1.4 - Evaluating logistic regression model in scikit-learn\n\n\n\n\n\n\nJan 4, 2023\n\n\n10 min\n\n\n\n\n\n\n\n\nSmall molecules in ChEMBL database (old)\n\n\nSeries 1.1 - Polars dataframe library and machine learning in scikit-learn\n\n\n\n\n\n\nJan 4, 2023\n\n\n29 min\n\n\n\n\n\n\n\n\nMolecular similarities in selected COVID-19 antivirals\n\n\nUsing RDKit’s similarity map and fingerprint generator\n\n\n\n\n\n\nNov 19, 2022\n\n\n28 min\n\n\n\n\n\n\n\n\nPhD project\n\n\nA research saga that went through COVID\n\n\n\n\n\n\nOct 23, 2022\n\n\n6 min\n\n\n\n\n\n\n\n\nPublications\n\n\n\n\n\n\n\n\n\nOct 23, 2022\n\n\n1 min\n\n\n\n\n\n\n\n\nLong COVID - an update\n\n\nPDF table scraping, bar graph, interactive map & wordcloud\n\n\n\n\n\n\nSep 19, 2022\n\n\n9 min\n\n\n\n\n\n\n\n\nTable scraping from PDF\n\n\nUsing tabula-py in Python\n\n\n\n\n\n\nSep 15, 2022\n\n\n3 min\n\n\n\n\n\n\n\n\nBlog move\n\n\n\n\n\n\n\n\n\nAug 6, 2022\n\n\n1 min\n\n\n\n\n\n\n\n\nPhenotypes associated with rare diseases\n\n\n\n\n\n\n\n\n\nAug 2, 2022\n\n\n7 min\n\n\n\n\n\n\n\n\nEmbracing social network\n\n\n\n\n\n\n\n\n\nJul 15, 2022\n\n\n1 min\n\n\n\n\n\n\n\n\nNatural history of rare diseases - malformation syndrome\n\n\n\n\n\n\n\n\n\nJun 27, 2022\n\n\n1 min\n\n\n\n\n\n\n\n\nUpdate on portfolio\n\n\n\n\n\n\n\n\n\nJun 13, 2022\n\n\n1 min\n\n\n\n\n\n\n\n\nLong COVID data in SQL\n\n\n\n\n\n\n\n\n\nJun 5, 2022\n\n\n1 min\n\n\n\n\n\n\n\n\nPortfolio projects\n\n\n\n\n\n\n\n\n\nMay 31, 2022\n\n\n0 min\n\n\n\n\n\n\n\n\nLong COVID dashboard\n\n\n\n\n\n\n\n\n\nMay 31, 2022\n\n\n1 min\n\n\n\n\n\n\n\n\nDrugs in rare diseases\n\n\n\n\n\n\n\n\n\nMay 28, 2022\n\n\n3 min\n\n\n\n\n\n\n\n\nFocussing on data analytics\n\n\n\n\n\n\n\n\n\nApr 15, 2022\n\n\n0 min\n\n\n\n\n\n\n\n\nThe beginning of the data science journey\n\n\n\n\n\n\n\n\n\nJan 28, 2022\n\n\n3 min\n\n\n\n\n\n\n\n\nSERCA project\n\n\n\n\n\n\n\n\n\nJan 24, 2022\n\n\n2 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About me",
    "section": "",
    "text": "Aside from being a Taiwanese New Zealander, I stumbled upon the world involving computers a long time ago, and always had an interest in them but didn’t quite go down that career path and ended up having my training to become a pharmacist instead. I worked as a community and hospital pharmacist for many years in New Zealand and Australia (this also happened while doing my master and PhD studies). My interest in the computer and data world was re-ignited from the end of 2021, after completing my PhD on using computer-aided drug design in small molecule discovery in 2020.\nI currently work as a freelance data scientist, and I’m also an enthusiast in using Python mainly (plus R to a smaller extent, and I did play with Rust a little) to work with drug discovery and development data. I’m still very much humbled by everything that is happening in the computational or digital chemistry, cheminformatics and computer-aided drug design fields, as there are a vast amount of information, theories, techniques and experiments to be learnt and absorbed. I also particularly would like to thank several well-known and experienced figures in these areas, which I’ve often mentioned in my blog posts, for their generous sharing of experiences and knowledge through various means.\nWhile sharing my work, I also hope that these work will help people, who are interested in these areas, to get started in coding and learning about the computational side of pharmaceutical chemistry and drug discovery. I’m currently still working on new projects, always trying to brainstorm for the next idea, and also open to any work opportunaties or project collaborations.\nThanks for visiting."
  },
  {
    "objectID": "posts/22_Simple_dnn_adrs/0_Ideas.html",
    "href": "posts/22_Simple_dnn_adrs/0_Ideas.html",
    "title": "Looking at minimising adverse drug reactions (ADRs)",
    "section": "",
    "text": "How it all begins\nI have always wondered if there’s a more succinct, straightforward or better way to look at ADRs. I’m also aware that ADRs as a subject matter is complicated enough in research, but I also can’t help to think that it is also how a newly initiated drug commonly fails in clinical trials (with tons of resources going down the drain after that), and also seeing people experiencing ADRs in real-life previously, it will be unwise to avoid it in the drug discovery and development landscape. So here’s my very tiny attempt at this tremendous task of sorting out how to minimise ADRs by starting at the very beginning, at the preclinical and computational stage.\nMy very early idea is to integrate ADRs with cytochrome P450 (CYP) as they’re closely linked by the effects of CYP inhibitors and inducers. During my previous role, there are a lot of well-known drug reference sources being used frequently on a daily basis, e.g. Martindale, Micromedex, American society of health-system pharmacists’ (ASHP) drug information monographs and so on, and I thought they may be another great sources of drug data, which are known to be absolutely critical in machine learning (ML) tasks (with models being the other crucial component).\nI then started by having a look at SIDER database, which is also another great resource for ADRs and seems very detailed and useful at the first glance. However upon more closer looks, I’ve noted a few things that may need to be improved in order for it to be even more useful. I’ve noted that it is only last updated in 2015 (checked on 16th October 2024), so it’s a bit outdated and appears to be no longer maintained by anyone by the look of a few unanswered issues in its repository (well, I’ve checked back at the SIDER database web link again on 17th April 2025, it seems there’s no further fundings to maintain the project so that’s why…). There are only 1430 drugs available but I guess that’s a good starting point. One of its drug examples, imatinib, has had malignant neoplasm listed as the ADR with highest incidence. I would personally categorise it more under carcinogenicity of the drug instead, and it’s dose-related so can be circumvented. Also imatinib is for leukaemia and other bone marrow cancers so it may be a bit misleading to list it as a “side effect” when its therapeutic indication is also for malignancy. At this point, my idea has evolved to see if it’s possible to actually curate a small, detailed and thorough dataset about ADRs, aiming for better data quality than quantity.\n\n\n\nOther reasons for this work\nIt’s been known that combining results from in vitro biological assays is a major issue in ML predictions due to the wide variations in in vitro experiments running in different labs leading to noises in the ML-predicted outcomes. These variations can be from different equipments used (calibration differences), variations in measurements, transcription errors (possible human errors) and likely many others I haven’t mentioned here. So to mitigate this, my thought is to possibly treat clinical trials as live, in vivo biological assays and assemble data from clinical trials (which are what the pharmaceutical manufacturers’ data sheets usually contain). However, the possible underlying problem here is that there are genetics variations in human populations, age group and gender differences, and likely others as well. Another downside is that clinical trials are usually done in very restricted, highly selective and controlled environments so they won’t be very representative of the real patient populations. This is also the reason why I’m including postmarketing reports in the dataset I’ve been curating. The only thing that may possibly help with these issues is then to document data in details so that these specific factors can be taken into account when training ML models (e.g. when tuning hyperparameters or by using other strategies).\nTL;DR: It may be good to add another layer of data complexity, e.g. the Flockhart cytochrome P450 drug-drug interaction table (Flockhart et al. 2021), to better reflect real-life drug effects in human uses. One more reason for this work which springs to my mind after viewing several different ADMET prediction applications are that most of them seem to be using in vitro-based data (a few other ones use PubChem, which can vary too from different sources e.g. journal papers or from drugbank etc.). I think if the Flockhart table can be added at the same time (to include in-vivo evidence in humans, although as I look through some of the citations for drugs in the table, it is also true that not all of them have in-vivo human-use evidence, however it should have a decent number of them in it). Overall, this may make ADMET research more well-covered and may improve data quality even more. Another thing is Flockhart table differentiates drugs with strong clinical evidence from the moderate ones, and also other ones pending reviews - this is probably something in-vitro data won’t be able to provide.\n\n\n\nWhat have been done so far\n\nData sources\nDetails of data sources used and related information for the current ADRs dataset (file name: cyp_substrates_adrs.csv) will be documented in the ADRs data note. The same data note also applies to the earlier smaller dataset on ADRs for CYP3A4 substrates (file name: cyp3a4_substrates.csv) as well, which is used in the notebook mentioned below.\n\n\n\nData curation\nBefore immersing in the process of curating ADRs data, I’ve made a visit to PubMed briefly to search for papers regarding ADRs, trying to find out which drugs or therapeutic areas are commonly involved in ADRs in real-life. I’ve found 3 papers (Onakpoya, Heneghan, and Aronson 2016), (Insani et al. 2021), (Lisha et al. 2017) that have investigated within critical care settings in hospitals, primary care settings in the communities and worldwide drug withdrawals regarding ADRs. The key problematic therapeutic areas involved in ADRs are:\n\nantimicrobials (for critical medical setting)\ncardiovascular system/anticoagulants (for critical & primary settings)\nanalgesics and sedatives (for critical surgical setting)\nhepatic issues (applies in general)\ncentral nervous system issues (applies in general)\n\nWhile curating the ADRs dataset, I also have a feeling that this type of data may have already existed in proprietary settings, but probably not the open-source versions or if they do, it may have a low chance of being curated by a pharmacist/researcher (me here) who may have a slightly different angle or perspective on therapeutic drugs in general.\nCurrently, an introductory ADRs regressor notebook has been done and stored in this repository showing how ADRs can be represented as PyTorch tensors (with the idea originated from natural language processing (NLP)) in a simple two-layer deep neural network model after I’ve initially curated ADRs for CYP3A4 substrates only. From there, I’ve then attempted to predict therapeutic drug classes for a testing set of molecules within this dataset using shuffled Butina split. The dataset of course is way too small for a deep learning model, and is likely flawed, biased and prone to data leakage etc., but the main idea here is to show that we may be able to observe some patterns or links between drugs (or molecular fingerprints) and ADRs first.\nAfter that, I’ve gone on to curate more CYP substrates-ADRs data based on the Flockhart table, which currently contains ADRs for CYP3A4, 2D6, 2C19, 2C9, 1A2, 2B6, 2E1 and 2C8 substrates. The ADRs documented in the dataset have focussed on ones that are more likely going to affect the qualities of lives of people administering the drugs (CYP substrates) and ones that are potentially going to be life-threatening.\n\n\n\n\nADRs flow chart\nBelow is a flow chart showing possible interactions between drugs and ADRs, with dotted lines representing possible or indirect relationships. This is also not meant to be comprehensive as I’m sure there are many other aspects I haven’t mentioned here, the purpose here is to really stimulate further research ideas about ADRs.\n\n\n\n\nflowchart LR\n  A(drugs) -.-> B(activities)\n  A -- ? via other targets --> C(adverse effects)\n  D(clinical trials) --> C(ADRs)\n  E(postmarketing reports) --> C(ADRs)\n  F(biological target) <--> B(biological activities)\n  A <--> F(biological target)\n  F -.-> C(ADRs)\n  G(CYP3A4/5 substrates) --> C(ADRs)\n  A --> G(CYP450 substrates)\n  H(CYP450-drug metabolism) --> G(CYP450 substrates)\n  A --> H(CYP450 metabolism)\n  H --> I(CYP450 inhibitors)\n  I --> C(ADRs)\n  A --> D(clinical trials)\n  A --> E(postmarketing reports)\n  A --> I(CYP450 inhibitors)\n  I --> G(CYP450 substrates)\n\n\n\n\n\n\n\n\n\n\n\nPossible future work\nHere are my very early thoughts on how this ADRs dataset may be further used and extended in the future:\n\nExploring the possibility of structure-ADRs relationships where we may be able to link ADRs via treating them as dense vectors of real numbers (early demonstration in the introductory ADRs regressor notebook) with two-dimensional (2D) drug molecular structures. This is coming from the commonly known structure-activity or property relationships used for small molecules in drug discovery or materials science, where we’re actively seeking the connections between drug or molecular activities with their 2D molecular structures. I’m just having a very naive thought here about why not looking at this from the ADRs perspective, rather than the usual activity/property part of the molecules. This may shed some lights about how ADRs relate to chemical structures of drugs, potentially may be useful when desgining drugs (a bit like a risk aversion way).\n\n\nPossible ways to do this via machine learning or deep learning:\n\nusing graph neural networks (GNN) so we may treat molecules as undirected 2D graphs where the connections between nodes (atoms) and edges (bonds) don’t matter (i.e. don’t need to be in particular orders or sequences), and build model based on this\nusing recurrent neural networks (RNN) that focusses on using SMILES (similar to the NLP technique), where we may tokenise SMILES strings, convert them into dictionary mapping tokens to indices in the vocabulary and then convert the vocabulary (SMILES strings) into one-hot encodings and build another model based on this concept\nthe molecular representations for drugs such as SMILES, SMARTS, or chemical fingerprints (as vector representations) can be obtained from PubChem, ChEMBL or others, and will require more thoughts into them e.g. whether to use canonical SMILES or not and also types of fingerprints to use etc.\nmay be restricted by computational resources available depending on the sizes of datasets, if images are going to be used or if other larger datasets are going to be integrated with the current smaller ADRs dataset (perhaps active learning can be used; if this is only working off the current small ADRs dataset, then it shouldn’t be a huge problem)\n\n\n\nBy focussing on specific therapeutic targets (within the same therapeutic drug classes), and trying to learn the patterns of ADRs for the same target. It may be possible to look at what common CYP enzymes are involved in their metabolisms and what common ADRs they all share - trying to link them back to drug structures and we may be able to set up ADRs profiles for each CYP enzyme that can be drug class-specific or CYP enzyme type-specific. From here, we may be able to draw out drug-ADRs lineages e.g. a parent compound is metabolised to a child compound where both may be biologically active and related in therapeutic uses with similar or different ADRs.\nThis work is opened to other ideas as well as I’m sure there are very likely other things I haven’t thought of yet!\n\n\n\n\n\n\nReferences\n\nFlockhart, DA., D. Thacker, C. McDonald, and Z. Desta. 2021. “The Flockhart Cytochrome P450 Drug-Drug Interaction Table.” https://drug-interactions.medicine.iu.edu/.\n\n\nInsani, WN., C. Whittlesea, H. Alwafi, KKC. Man, S. Chapman, and L. Wei. 2021. “Prevalence of Adverse Drug Reactions in the Primary Care Setting: A Systematic Review and Meta-Analysis.” PLoS ONE 16 (5). https://doi.org/10.1371/journal.pone.0252161.\n\n\nLisha, J., V. Annalakshmi, J. Maria, and D. Padmini. 2017. “Adverse Drug Reactions in Critical Care Settings: A Systematic Review.” Current Drug Safety 12 (3): 147–61. https://doi.org/10.2174/1574886312666170710192409.\n\n\nOnakpoya, IJ., CJ. Heneghan, and JK. Aronson. 2016. “Worldwide Withdrawal of Medicinal Products Because of Adverse Drug Reactions: A Systematic Review and Analysis.” Critical Reviews in Toxicology 46 (6): 477–89. https://doi.org/10.3109/10408444.2016.1149452."
  }
]